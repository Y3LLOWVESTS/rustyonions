<!-- Generated by scripts/make_crate_codex.sh on 2025-10-22T15:56:42Z -->
# Code Bundle — `ron-kernel`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-kernel/.cargo/config.toml](#crates-ron-kernel--cargo-config-toml)
- [crates/ron-kernel/.github/workflows/kernel-ci.yml](#crates-ron-kernel--github-workflows-kernel-ci-yml)
- [crates/ron-kernel/.github/workflows/rust.yml](#crates-ron-kernel--github-workflows-rust-yml)
- [crates/ron-kernel/Cargo.toml](#crates-ron-kernel-Cargo-toml)
- [crates/ron-kernel/benches/a2_publish_many.rs](#crates-ron-kernel-benches-a2publishmany-rs)
- [crates/ron-kernel/benches/a3_autotune_cap.rs](#crates-ron-kernel-benches-a3autotunecap-rs)
- [crates/ron-kernel/benches/bus_batch.rs](#crates-ron-kernel-benches-busbatch-rs)
- [crates/ron-kernel/benches/bus_lag_vs_publish.rs](#crates-ron-kernel-benches-buslagvspublish-rs)
- [crates/ron-kernel/benches/bus_multi_subscribers.rs](#crates-ron-kernel-benches-busmultisubscribers-rs)
- [crates/ron-kernel/benches/bus_overflow_drop.rs](#crates-ron-kernel-benches-busoverflowdrop-rs)
- [crates/ron-kernel/benches/bus_publish.rs](#crates-ron-kernel-benches-buspublish-rs)
- [crates/ron-kernel/benches/bus_publish_matrix.rs](#crates-ron-kernel-benches-buspublishmatrix-rs)
- [crates/ron-kernel/benches/bus_soa.rs](#crates-ron-kernel-benches-bussoa-rs)
- [crates/ron-kernel/benches/metrics_encode.rs](#crates-ron-kernel-benches-metricsencode-rs)
- [crates/ron-kernel/benches/publish_edge_matrix.rs](#crates-ron-kernel-benches-publishedgematrix-rs)
- [crates/ron-kernel/benches/readiness_handler.rs](#crates-ron-kernel-benches-readinesshandler-rs)
- [crates/ron-kernel/deny.toml](#crates-ron-kernel-deny-toml)
- [crates/ron-kernel/examples/kernel_demo.rs](#crates-ron-kernel-examples-kerneldemo-rs)
- [crates/ron-kernel/examples/minimal_supervision.rs](#crates-ron-kernel-examples-minimalsupervision-rs)
- [crates/ron-kernel/examples/publish_smoke.rs](#crates-ron-kernel-examples-publishsmoke-rs)
- [crates/ron-kernel/fuzz/cfg_parser.rs](#crates-ron-kernel-fuzz-cfgparser-rs)
- [crates/ron-kernel/rust-toolchain.toml](#crates-ron-kernel-rust-toolchain-toml)
- [crates/ron-kernel/scripts/ci_public_api.sh](#crates-ron-kernel-scripts-cipublicapi-sh)
- [crates/ron-kernel/scripts/enforce_ro_headers.sh](#crates-ron-kernel-scripts-enforceroheaders-sh)
- [crates/ron-kernel/scripts/render_mermaid.sh](#crates-ron-kernel-scripts-rendermermaid-sh)
- [crates/ron-kernel/scripts/run_kernel_benches.sh](#crates-ron-kernel-scripts-runkernelbenches-sh)
- [crates/ron-kernel/scripts/run_mog_b1.sh](#crates-ron-kernel-scripts-runmogb1-sh)
- [crates/ron-kernel/src/amnesia.rs](#crates-ron-kernel-src-amnesia-rs)
- [crates/ron-kernel/src/bus/backoff.rs](#crates-ron-kernel-src-bus-backoff-rs)
- [crates/ron-kernel/src/bus/bounded.rs](#crates-ron-kernel-src-bus-bounded-rs)
- [crates/ron-kernel/src/bus/capacity.rs](#crates-ron-kernel-src-bus-capacity-rs)
- [crates/ron-kernel/src/bus/mod.rs](#crates-ron-kernel-src-bus-mod-rs)
- [crates/ron-kernel/src/bus/mog_edge_notify.rs](#crates-ron-kernel-src-bus-mogedgenotify-rs)
- [crates/ron-kernel/src/bus/soa.rs](#crates-ron-kernel-src-bus-soa-rs)
- [crates/ron-kernel/src/bus/test.rs](#crates-ron-kernel-src-bus-test-rs)
- [crates/ron-kernel/src/bus/topic.rs](#crates-ron-kernel-src-bus-topic-rs)
- [crates/ron-kernel/src/config/mod.rs](#crates-ron-kernel-src-config-mod-rs)
- [crates/ron-kernel/src/config/validation.rs](#crates-ron-kernel-src-config-validation-rs)
- [crates/ron-kernel/src/config/watcher.rs](#crates-ron-kernel-src-config-watcher-rs)
- [crates/ron-kernel/src/events.rs](#crates-ron-kernel-src-events-rs)
- [crates/ron-kernel/src/health/mod.rs](#crates-ron-kernel-src-health-mod-rs)
- [crates/ron-kernel/src/internal/constants.rs](#crates-ron-kernel-src-internal-constants-rs)
- [crates/ron-kernel/src/internal/mod.rs](#crates-ron-kernel-src-internal-mod-rs)
- [crates/ron-kernel/src/internal/types.rs](#crates-ron-kernel-src-internal-types-rs)
- [crates/ron-kernel/src/lib.rs](#crates-ron-kernel-src-lib-rs)
- [crates/ron-kernel/src/metrics/buffer.rs](#crates-ron-kernel-src-metrics-buffer-rs)
- [crates/ron-kernel/src/metrics/exporter.rs](#crates-ron-kernel-src-metrics-exporter-rs)
- [crates/ron-kernel/src/metrics/health.rs](#crates-ron-kernel-src-metrics-health-rs)
- [crates/ron-kernel/src/metrics/mod.rs](#crates-ron-kernel-src-metrics-mod-rs)
- [crates/ron-kernel/src/metrics/readiness.rs](#crates-ron-kernel-src-metrics-readiness-rs)
- [crates/ron-kernel/src/mog_autotune.rs](#crates-ron-kernel-src-mogautotune-rs)
- [crates/ron-kernel/src/shutdown.rs](#crates-ron-kernel-src-shutdown-rs)
- [crates/ron-kernel/src/supervisor/backoff.rs](#crates-ron-kernel-src-supervisor-backoff-rs)
- [crates/ron-kernel/src/supervisor/child.rs](#crates-ron-kernel-src-supervisor-child-rs)
- [crates/ron-kernel/src/supervisor/lifecycle.rs](#crates-ron-kernel-src-supervisor-lifecycle-rs)
- [crates/ron-kernel/src/supervisor/mod.rs](#crates-ron-kernel-src-supervisor-mod-rs)
- [crates/ron-kernel/testing/performance/publish_matrix.toml](#crates-ron-kernel-testing-performance-publishmatrix-toml)
- [crates/ron-kernel/tests/amnesia_label.rs](#crates-ron-kernel-tests-amnesialabel-rs)
- [crates/ron-kernel/tests/autotune_capacity.rs](#crates-ron-kernel-tests-autotunecapacity-rs)
- [crates/ron-kernel/tests/autotune_sanity.rs](#crates-ron-kernel-tests-autotunesanity-rs)
- [crates/ron-kernel/tests/bus_basics.rs](#crates-ron-kernel-tests-busbasics-rs)
- [crates/ron-kernel/tests/bus_bounded.rs](#crates-ron-kernel-tests-busbounded-rs)
- [crates/ron-kernel/tests/bus_close_semantics.rs](#crates-ron-kernel-tests-busclosesemantics-rs)
- [crates/ron-kernel/tests/bus_contract.rs](#crates-ron-kernel-tests-buscontract-rs)
- [crates/ron-kernel/tests/edge_notify_loom.rs](#crates-ron-kernel-tests-edgenotifyloom-rs)
- [crates/ron-kernel/tests/health_ready.rs](#crates-ron-kernel-tests-healthready-rs)
- [crates/ron-kernel/tests/loom_bus.rs](#crates-ron-kernel-tests-loombus-rs)
- [crates/ron-kernel/tests/metrics_amnesia.rs](#crates-ron-kernel-tests-metricsamnesia-rs)
- [crates/ron-kernel/tests/metrics_smoke.rs](#crates-ron-kernel-tests-metricssmoke-rs)
- [crates/ron-kernel/tests/property_config.rs](#crates-ron-kernel-tests-propertyconfig-rs)
- [crates/ron-kernel/tests/public_api.rs](#crates-ron-kernel-tests-publicapi-rs)
- [crates/ron-kernel/tests/readiness_degrades.rs](#crates-ron-kernel-tests-readinessdegrades-rs)
- [crates/ron-kernel/tests/soa_smoke.rs](#crates-ron-kernel-tests-soasmoke-rs)
- [crates/ron-kernel/tests/supervisor_backoff.rs](#crates-ron-kernel-tests-supervisorbackoff-rs)
- [crates/ron-kernel/tests/supervisor_backoff_integ.rs](#crates-ron-kernel-tests-supervisorbackoffinteg-rs)
- [crates/ron-kernel/tests/tls_type_invariance.rs](#crates-ron-kernel-tests-tlstypeinvariance-rs)
- [crates/ron-kernel/tests/watcher_integ.rs](#crates-ron-kernel-tests-watcherinteg-rs)

### crates/ron-kernel/.cargo/config.toml
<a id="crates-ron-kernel--cargo-config-toml"></a>

```toml
[build]
rustflags = []

[term]
verbose = false

```

### crates/ron-kernel/.github/workflows/kernel-ci.yml
<a id="crates-ron-kernel--github-workflows-kernel-ci-yml"></a>

```yaml
name: kernel-ci
on: [push, pull_request]
jobs:
  public-api:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - run: cargo install cargo-public-api || true
      - run: cargo public-api -p ron-kernel2 || true
  mermaid:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm i -g @mermaid-js/mermaid-cli
      - run: |
          for f in $(git ls-files 'crates/ron-kernel2/docs/*.mmd' 2>/dev/null); do
            mmdc -i "$f" -o "${f%.mmd}.svg"
          done

```

### crates/ron-kernel/.github/workflows/rust.yml
<a id="crates-ron-kernel--github-workflows-rust-yml"></a>

```yaml
name: rust
on: [push, pull_request]
jobs:
  test:
    strategy:
      matrix:
        amnesia: [off, on]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - name: Build
        run: cargo build -p ron-kernel2
      - name: Test
        run: AMNESIA=${{ matrix.amnesia }} cargo test -p ron-kernel2 --all-features
  loom:
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - name: Run loom tests (ignored)
        run: RUSTFLAGS="--cfg loom" cargo test -p ron-kernel2 -- --ignored

```

### crates/ron-kernel/Cargo.toml
<a id="crates-ron-kernel-Cargo-toml"></a>

```toml
[package]
name = "ron-kernel"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
publish = false

[lib]
name = "ron_kernel"
path = "src/lib.rs"

[features]
# Optional features can be added here (e.g., "kameo")
default = []
# Enable Loom model-checking tests with: cargo test -p ron-kernel --features loom
loom = ["dep:loom"]
#MOG - Phase A:
bus_edge_notify = []   # edge-triggered, coalesced wakeups per subscriber
bus_batch = []         # publish_many(&[T]) single-fence/notify
bus_autotune_cap = []  # cap defaults chosen by N subscribers, warn on oversized caps
metrics_buf = []       # per-thread metrics buffering with periodic flush
#MOG - Phase B: 
bus_soa = []           # SoA ring + per-slot ready bitmask (Arc<T> payload to keep 100% safe)
bus_interest = []      # variant/topic bitmask filtering per subscriber
bus_coalesce = []      # coalesce wakeups by K/Δt thresholds (optional latency trade)
local_dispatch = []    # example helpers/patterns; not a kernel core change


[dependencies]
# Core async
tokio = { version = "1", features = ["macros", "rt-multi-thread", "signal", "time", "io-util", "sync", "net", "fs"] }

# Loom must be optional because the 'loom' feature references it via dep:loom
loom = { version = "0.7", optional = true, default-features = false }

# HTTP stack (workspace standard pins implied)
axum = { version = "0.7", features = ["tokio", "http1", "http2", "json"], default-features = false }
tower = "0.5"
tower-http = { version = "0.6.6", features = ["trace"] }

# Metrics/obs
prometheus = "0.14"
once_cell = "1.19"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["fmt", "env-filter"] }

# Concurrency/locking
parking_lot = "0.12"

# Config & serde
serde = { version = "1.0", features = ["derive"] }
serde_json = "1"
toml = "0.8"

# Misc
anyhow = "1.0"
thiserror = "1.0"

# TLS is intentionally not enforced here (transport services handle it)
tokio-rustls = "0.26.2"
notify = "6"
rand = "0.9"
futures = "0.3"
humantime-serde = "1"

cfg-if = "1"


[dev-dependencies]
reqwest = { version = "0.12", features = ["rustls-tls-native-roots", "json"] }
# Enable "async" so benches can use b.to_async(&rt)
criterion = { version = "0.5", features = ["html_reports", "async"] }
tempfile = "3"
parking_lot = "0.12"

[[bench]]
name = "bus_publish"
harness = false

[[bench]]
name = "bus_lag_vs_publish"
harness = false

[[bench]]
name = "metrics_encode"
harness = false

[[bench]]
name = "bus_overflow_drop"
harness = false

[[bench]]
name = "readiness_handler"
harness = false

[[bench]]
name = "bus_multi_subscribers"
harness = false

[[bench]]
name = "bus_publish_matrix"
harness = false


[[bench]]
name = "bus_batch"
harness = false

[[bench]]
name = "a3_autotune_cap"
harness = false
required-features = ["bus_autotune_cap"]

[[bench]]
name = "a2_publish_many"
harness = false

[[bench]]
name = "bus_soa"
harness = false

```

### crates/ron-kernel/benches/a2_publish_many.rs
<a id="crates-ron-kernel-benches-a2publishmany-rs"></a>

```rust
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion, Throughput};
use std::time::Duration;
use ron_kernel::bus::bounded::Bus;
use tokio::sync::broadcast;

// Drain helper (same shape as other benches).
fn drain_now<T: Clone + Send + 'static>(rx: &mut broadcast::Receiver<T>) -> usize {
    use tokio::sync::broadcast::error::TryRecvError::*;
    let mut n = 0usize;
    loop {
        match rx.try_recv() {
            Ok(_) => n += 1,
            Err(Empty) => break,
            Err(Lagged(_)) => continue,
            Err(Closed) => break,
        }
    }
    n
}

fn bench_a2_batch_vs_single(c: &mut Criterion) {
    // single-threaded RT for stability
    let rt = tokio::runtime::Builder::new_current_thread()
        .enable_time()
        .build()
        .unwrap();

    let mut group = c.benchmark_group("a2_publish_many");
    let subs_set = [1usize, 4];        // focus where notify matters
    let cap = 64usize;                 // tuned sweet spot from MOG
    let bursts = [1usize, 1_000, 5_000, 10_000];

    for &subs in &subs_set {
        for &batch_len in &bursts {
            group.throughput(Throughput::Elements(batch_len as u64));

            // Baseline: single publishes in a loop (no bus_batch feature needed)
            group.bench_with_input(
                BenchmarkId::new("single_loop", format!("subs={subs},cap={cap},n={batch_len}")),
                &(),
                |b, _| {
                    rt.block_on(async {
                        let bus: Bus<u64> = Bus::with_capacity(cap);
                        let mut rxs: Vec<_> = (0..subs).map(|_| bus.subscribe()).collect();

                        b.iter(|| {
                            for i in 0..batch_len as u64 {
                                let _ = bus.publish(i);
                            }
                            for rx in &mut rxs {
                                let _ = drain_now(rx);
                            }
                        });
                    });
                },
            );

            // A2: publish_many (feature-gated); when feature off, this target won’t exist
            #[cfg(feature = "bus_batch")]
            group.bench_with_input(
                BenchmarkId::new("publish_many", format!("subs={subs},cap={cap},n={batch_len}")),
                &(),
                |b, _| {
                    rt.block_on(async {
                        let bus: Bus<u64> = Bus::with_capacity(cap);
                        let mut rxs: Vec<_> = (0..subs).map(|_| bus.subscribe()).collect();

                        // preallocate batch to avoid alloc noise in iter
                        let batch: Vec<u64> = (0..batch_len as u64).collect();

                        b.iter(|| {
                            let _ = bus.publish_many(&batch);
                            for rx in &mut rxs {
                                let _ = drain_now(rx);
                            }
                        });
                    });
                },
            );
        }
    }
    group.finish();
}

criterion_group! {
    name = benches;
    config = {
        Criterion::default()
            .measurement_time(Duration::from_secs(8))
            .warm_up_time(Duration::from_secs(3))
            .sample_size(20)
    };
    targets = bench_a2_batch_vs_single
}
criterion_main!(benches);

```

### crates/ron-kernel/benches/a3_autotune_cap.rs
<a id="crates-ron-kernel-benches-a3autotunecap-rs"></a>

```rust
#![cfg(feature = "bus_autotune_cap")]
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion, black_box};
use ron_kernel::autotune_capacity;



fn bench_autotune_mapping(c: &mut Criterion) {
    let mut g = c.benchmark_group("a3_autotune_mapping");

    for &n in &[1usize, 4, 16, 64, 128] {
        g.bench_with_input(BenchmarkId::from_parameter(n), &n, |b, &n| {
            b.iter(|| {
                let mut s = 0usize;
                for _ in 0..1024 {
                    s ^= autotune_capacity(n, None);
                }
                black_box(s)
            })
        });
    }

    g.bench_function("override_192", |b| {
        b.iter(|| black_box(autotune_capacity(16, Some(192))))
    });

    g.finish();
}

criterion_group!(benches, bench_autotune_mapping);
criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_batch.rs
<a id="crates-ron-kernel-benches-busbatch-rs"></a>

```rust
//! RO:WHAT
//! Bench the bounded Bus<T> publish paths with and without batching.
//!
//! RO:WHY
//! A2 (bus_batch) should reduce notify/wake amplification and fence costs by
//! batching multiple publishes into one sweep with <=1 notify. This bench *must*
//! be env-configurable so we can sweep fanout/cap/burst from the shell.
//!
//! RO:INTERACTS
//! - Uses `ron_kernel::bus::bounded::Bus` directly.
//! - Feature flag `bus_batch` enables the batch path.
//! - Criterion for timing.
//!
//! RO:INVARIANTS
//! - Public API untouched (bench only).
//! - No panics under capacity pressure; drops are handled inside Bus.
//! - Single-threaded Tokio runtime for stability.

use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion, Throughput};
use std::env;
use std::time::Duration;

// We bench the kernel Bus<T> directly.
use ron_kernel::bus::bounded::Bus;

// A small POD event for hot-path measurement.
#[derive(Clone)]
#[allow(dead_code)]
struct Ev(u64);

fn getenv<T: std::str::FromStr>(key: &str, default: T) -> T {
    env::var(key)
        .ok()
        .and_then(|s| s.parse::<T>().ok())
        .unwrap_or(default)
}

// Drain helper: non-blocking, like our EdgeReceiver::try_recv_now_or_never().
fn drain_now<T: Clone + Send + 'static>(rx: &mut tokio::sync::broadcast::Receiver<T>) -> usize {
    use tokio::sync::broadcast::error::TryRecvError::*;
    let mut n = 0usize;
    loop {
        match rx.try_recv() {
            Ok(_) => {
                n += 1;
            }
            Err(Empty) => break,
            Err(Lagged(_)) => continue,
            Err(Closed) => break,
        }
    }
    n
}

fn bench_bus_batch(c: &mut Criterion) {
    // Env-driven configuration (defaults match previous behavior).
    let subs = getenv::<usize>("RON_BENCH_FANOUT", 4);
    let cap = getenv::<usize>("RON_BENCH_CAP", 64);
    let burst = getenv::<usize>("RON_BENCH_BURST", 128);

    eprintln!(
        "[bench cfg] subs={}, cap={}, burst={}  (set RON_BENCH_FANOUT/CAP/BURST to override)",
        subs, cap, burst
    );

    // Single-threaded runtime for stable numbers.
    let rt = tokio::runtime::Builder::new_current_thread()
        .enable_time()
        .build()
        .unwrap();

    let mut g = c.benchmark_group("bus_batch");

    // --- Single publish baseline ---------------------------------------------------------
    g.throughput(Throughput::Elements(10_000));
    g.measurement_time(Duration::from_secs(10));
    g.warm_up_time(Duration::from_secs(3));

    g.bench_with_input(
        BenchmarkId::new(
            "publish_single",
            format!("subs={subs},cap={cap},burst={burst}"),
        ),
        &(),
        |b, _| {
            rt.block_on(async {
                let bus: Bus<Ev> = Bus::with_capacity(cap);
                // spawn subscribers
                let mut rxs: Vec<_> = (0..subs).map(|_| bus.subscribe()).collect();
                b.iter(|| {
                    for i in 0..10_000u64 {
                        let _ = bus.publish(Ev(i));
                    }
                    // drain
                    for rx in &mut rxs {
                        let _ = drain_now(rx);
                    }
                    black_box(());
                });
            });
        },
    );

    // --- Batch publish (A2) --------------------------------------------------------------
    #[cfg(feature = "bus_batch")]
    {
        g.throughput(Throughput::Elements(10_000));
        g.bench_with_input(
            BenchmarkId::new(
                "publish_many",
                format!("subs={subs},cap={cap},burst={burst}"),
            ),
            &(),
            |b, _| {
                rt.block_on(async {
                    let bus: Bus<Ev> = Bus::with_capacity(cap);
                    let mut rxs: Vec<_> = (0..subs).map(|_| bus.subscribe()).collect();

                    let mut batch = Vec::with_capacity(burst.max(1));
                    b.iter(|| {
                        batch.clear();
                        // total elements = 10_000 per iter (≈ 10_000 / burst batches)
                        for i in 0..10_000u64 {
                            batch.push(Ev(i));
                            if batch.len() == burst {
                                let _ = bus.publish_many(&batch);
                                batch.clear();
                            }
                        }
                        if !batch.is_empty() {
                            let _ = bus.publish_many(&batch);
                            batch.clear();
                        }
                        // drain
                        for rx in &mut rxs {
                            let _ = drain_now(rx);
                        }
                        black_box(());
                    });
                });
            },
        );
    }

    g.finish();
}

criterion_group! {
    name = benches;
    config = Criterion::default()
        .measurement_time(Duration::from_secs(6))
        .warm_up_time(Duration::from_secs(2))
        .sample_size(40);
    targets = bench_bus_batch
}
criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_lag_vs_publish.rs
<a id="crates-ron-kernel-benches-buslagvspublish-rs"></a>

```rust
/*!
RO: benches/bus_lag_vs_publish.rs
WHAT: Compare publish throughput under no-subscriber vs single slow subscriber.
WHY : Validate non-blocking publish w/ slow receiver (bounded cost, drops on recv side).
NOTE: Group config tuned to avoid "unable to complete samples" warnings on many machines.
*/

use std::time::Duration;
use criterion::{black_box, criterion_group, criterion_main, Criterion, SamplingMode, BenchmarkId};
use ron_kernel::{Bus, KernelEvent, Metrics};
use tokio::runtime::Builder;

const INNER_PUBLISHES: usize = 25_000;

fn bench_bus_lag_vs_publish(c: &mut Criterion) {
    let rt = Builder::new_multi_thread().enable_all().build().unwrap();

    let mut group = c.benchmark_group("bus_lag_vs_publish");
    group.sampling_mode(SamplingMode::Flat);
    group.sample_size(60);
    group.warm_up_time(Duration::from_secs(2));
    group.measurement_time(Duration::from_secs(8));

    // no_subscribers (upper-bound publish cost)
    group.bench_with_input(BenchmarkId::new("no_subscribers", INNER_PUBLISHES), &(), |b, _| {
        b.iter(|| {
            rt.block_on(async {
                let metrics = Metrics::new(false);
                let bus: Bus<KernelEvent> = metrics.make_bus(1024);
                for i in 0..black_box(INNER_PUBLISHES) {
                    let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                }
            });
        });
    });

    // one_slow_subscriber (non-blocking publish should remain bounded)
    group.bench_with_input(BenchmarkId::new("one_slow_subscriber", INNER_PUBLISHES), &(), |b, _| {
        b.iter(|| {
            rt.block_on(async {
                let metrics = Metrics::new(false);
                let bus: Bus<KernelEvent> = metrics.make_bus(64);

                let mut rx = bus.subscribe();
                let slow = tokio::spawn(async move {
                    loop {
                        match rx.recv().await {
                            Ok(_e) => tokio::time::sleep(Duration::from_micros(black_box(20))).await,
                            Err(_) => break,
                        }
                    }
                });

                for i in 0..black_box(INNER_PUBLISHES) {
                    let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                }

                drop(bus);
                let _ = slow.await;
            });
        });
    });

    group.finish();
}

criterion_group!(benches, bench_bus_lag_vs_publish);
criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_multi_subscribers.rs
<a id="crates-ron-kernel-benches-busmultisubscribers-rs"></a>

```rust
/*!
RO: benches/bus_multi_subscribers.rs
WHAT: Publish throughput with 0, 1, and 16 draining subscribers.
WHY : Show fan-out cost growth as subscriber count rises.
*/

use std::time::Duration;
use criterion::{black_box, criterion_group, criterion_main, Criterion, SamplingMode, BenchmarkId};
use ron_kernel::{Bus, KernelEvent, Metrics};
use tokio::runtime::Builder;

const INNER_PUBLISHES: usize = 10_000;

fn bench_bus_publish(c: &mut Criterion) {
    let rt = Builder::new_multi_thread().enable_all().build().unwrap();

    let mut group = c.benchmark_group("bus_publish");
    group.sampling_mode(SamplingMode::Flat);
    group.sample_size(60);
    group.warm_up_time(Duration::from_secs(2));
    group.measurement_time(Duration::from_secs(8));

    // 0 subscribers
    group.bench_with_input(BenchmarkId::new("0_subscribers", INNER_PUBLISHES), &(), |b, _| {
        b.iter(|| {
            rt.block_on(async {
                let metrics = Metrics::new(false);
                let bus: Bus<KernelEvent> = metrics.make_bus(1024);
                for i in 0..black_box(INNER_PUBLISHES) {
                    let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                }
            });
        });
    });

    // 1 subscriber (draining)
    group.bench_with_input(BenchmarkId::new("1_subscriber", INNER_PUBLISHES), &(), |b, _| {
        b.iter(|| {
            rt.block_on(async {
                let metrics = Metrics::new(false);
                let bus: Bus<KernelEvent> = metrics.make_bus(1024);

                let mut rx = bus.subscribe();
                let drain = tokio::spawn(async move {
                    while let Ok(_ev) = rx.recv().await {}
                });

                for i in 0..black_box(INNER_PUBLISHES) {
                    let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                }

                drop(bus);
                let _ = drain.await;
            });
        });
    });

    // 16 subscribers (draining)
    group.bench_with_input(BenchmarkId::new("16_subscribers", INNER_PUBLISHES), &(), |b, _| {
        b.iter(|| {
            rt.block_on(async {
                let metrics = Metrics::new(false);
                let bus: Bus<KernelEvent> = metrics.make_bus(2048);

                let mut joins = Vec::new();
                for _ in 0..16 {
                    let mut rx = bus.subscribe();
                    joins.push(tokio::spawn(async move {
                        while let Ok(_ev) = rx.recv().await {}
                    }));
                }

                for i in 0..black_box(INNER_PUBLISHES) {
                    let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                }

                drop(bus);
                for j in joins {
                    let _ = j.await;
                }
            });
        });
    });

    group.finish();
}

criterion_group!(benches, bench_bus_publish);
criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_overflow_drop.rs
<a id="crates-ron-kernel-benches-busoverflowdrop-rs"></a>

```rust
/*!
RO: benches/bus_overflow_drop.rs
WHAT: Stress bounded bus with a slow subscriber; ensure publish cost is bounded.
WHY : Validate overflow path keeps publisher fast (drops accounted on recv side).
*/

use std::time::Duration;
use criterion::{black_box, criterion_group, criterion_main, Criterion, SamplingMode, BenchmarkId};
use ron_kernel::{Bus, KernelEvent, Metrics};
use tokio::runtime::Builder;

const INNER_PUBLISHES: usize = 50_000;

fn bench_overflow(c: &mut Criterion) {
    let rt = Builder::new_multi_thread().enable_all().build().unwrap();

    let mut group = c.benchmark_group("bus_overflow");
    group.sampling_mode(SamplingMode::Flat);
    group.sample_size(60);
    group.warm_up_time(Duration::from_secs(2));
    group.measurement_time(Duration::from_secs(8));

    group.bench_with_input(BenchmarkId::new("slow_single_subscriber", INNER_PUBLISHES), &(), |b, _| {
        b.iter(|| {
            rt.block_on(async {
                let metrics = Metrics::new(false);
                // Small capacity to induce overflow quickly
                let bus: Bus<KernelEvent> = metrics.make_bus(32);

                let mut rx = bus.subscribe();
                let slow = tokio::spawn(async move {
                    loop {
                        match rx.recv().await {
                            Ok(_e) => tokio::time::sleep(Duration::from_micros(black_box(50))).await,
                            Err(_) => break,
                        }
                    }
                });

                for i in 0..black_box(INNER_PUBLISHES) {
                    let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                }

                drop(bus);
                let _ = slow.await;
            });
        });
    });

    group.finish();
}

criterion_group!(benches, bench_overflow);
criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_publish.rs
<a id="crates-ron-kernel-benches-buspublish-rs"></a>

```rust
//! RO:WHAT — Bus publish perf: steady-state + bursty (classic vs edge, fanout, tunable caps).
//! RO:WHY  — Show real-world wins by:
//!           • steady-state apples-to-apples,
//!           • burst benches with draining + configurable fanout,
//!           • optional publisher epoch (yield between bursts),
//!           • configurable bus cap to avoid queue backpressure (critical).
//! RO:NOTE — Only `publish()`/`publish_many()` are timed; setup/drain outside hot loops.

use std::{env, time::Duration};

use criterion::{
    black_box, criterion_group, criterion_main, BenchmarkId, Criterion, SamplingMode, Throughput,
};
#[cfg(feature = "bus_batch")]
use criterion::BatchSize;

use ron_kernel::{KernelEvent, Metrics};
use tokio::sync::broadcast::error::RecvError;

// ----------------------------- Env toggles -----------------------------

fn env_usize(key: &str, default_: usize) -> usize {
    env::var(key)
        .ok()
        .and_then(|s| s.parse::<usize>().ok())
        .filter(|&n| n > 0)
        .unwrap_or(default_)
}
fn env_bool(key: &str) -> bool {
    matches!(env::var(key).as_deref(), Ok("1") | Ok("true") | Ok("yes") | Ok("on"))
}

fn burst_size() -> usize { env_usize("RON_BENCH_BURST", 256) }
fn fanout() -> usize { env_usize("RON_BENCH_FANOUT", 4) }
fn pub_epoch_yield() -> bool { env_bool("RON_BENCH_PUB_YIELD") }
fn burst_cap() -> usize { env_usize("RON_BENCH_CAP", 2048) } // default high cap for burst groups
fn tls_flush_threshold() -> usize { env_usize("RON_TLS_FLUSH_THRESHOLD", 64) }

// ------------------------------ Utilities -----------------------------

#[inline(always)]
fn publish_burst<B: Publisher<KernelEvent>>(bus: &B, n: usize) {
    for _ in 0..n {
        let _ = black_box(bus.publish(KernelEvent::Shutdown));
    }
}

trait Publisher<T> {
    fn publish(&self, t: T) -> usize;
}
impl Publisher<KernelEvent> for ron_kernel::bus::bounded::Bus<KernelEvent> {
    #[inline(always)]
    fn publish(&self, t: KernelEvent) -> usize { self.publish(t) }
}

fn spawn_classic_drains(
    rt: &tokio::runtime::Runtime,
    bus: &ron_kernel::bus::bounded::Bus<KernelEvent>,
    n: usize,
) {
    for _ in 0..n {
        let mut rx = bus.subscribe();
        rt.spawn(async move {
            loop {
                match rx.recv().await {
                    Ok(_msg) => {}
                    Err(RecvError::Lagged(_)) => continue,
                    Err(RecvError::Closed) => break,
                }
            }
        });
    }
}

#[cfg(feature = "bus_edge_notify")]
fn spawn_edge_drains(
    rt: &tokio::runtime::Runtime,
    bus: &ron_kernel::bus::bounded::Bus<KernelEvent>,
    n: usize,
) {
    use ron_kernel::bus::bounded::EdgeReceiver;
    for idx in 0..n {
        let mut sub: EdgeReceiver<KernelEvent> = bus.subscribe_edge();
        rt.spawn(async move { sub.run_drain_loop(idx).await; });
    }
}

// -------------------------------- Benches -----------------------------

fn bench_publish(c: &mut Criterion) {
    // Log config once per run so threshold sweeps are easy to map in output.
    let tls_thresh = tls_flush_threshold();
    eprintln!(
        "[bench cfg] RON_TLS_FLUSH_THRESHOLD={}, burst={}, fanout={}, cap={}",
        tls_thresh,
        burst_size(),
        fanout(),
        burst_cap()
    );

    // ============ Group 1: steady-state (classic, idle subscriber) ============
    let mut steady = c.benchmark_group(format!("bus_publish_steady (tls_thresh={})", tls_thresh));
    steady.sampling_mode(SamplingMode::Flat);
    steady.sample_size(80);
    steady.warm_up_time(Duration::from_secs(1));
    steady.measurement_time(Duration::from_secs(6));

    // (A) no subscribers — cap=64 (small, stable)
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(64);
        steady.bench_with_input(BenchmarkId::new("no_subscribers", "publish()"), &(), |b, _| {
            b.iter(|| { let _ = black_box(bus.publish(KernelEvent::Shutdown)); });
        });
    }

    // (B) one subscriber (idle; no recv) — cap=64
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(64);
        let _rx = bus.subscribe(); // keep alive; no recv()
        steady.bench_with_input(BenchmarkId::new("one_subscriber", "publish()"), &(), |b, _| {
            b.iter(|| { let _ = black_box(bus.publish(KernelEvent::Shutdown)); });
        });
    }

    // (C) lagged subscriber (cap=1; no recv)
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(1);
        let _rx = bus.subscribe(); // keep alive; no recv()
        steady.bench_with_input(BenchmarkId::new("lagged_subscriber_cap1", "publish()"), &(), |b, _| {
            b.iter(|| { let _ = black_box(bus.publish(KernelEvent::Shutdown)); });
        });
    }
    steady.finish();

    // Runtime for burst groups
    let rt = tokio::runtime::Builder::new_multi_thread()
        .enable_all()
        .build()
        .expect("tokio rt");

    // ============ Group 2: Bursty — CLASSIC recv drain (fanout) ============
    let mut bursty_classic = c.benchmark_group(format!(
        "bus_publish_bursty_classic (tls_thresh={})",
        tls_thresh
    ));
    bursty_classic.sampling_mode(SamplingMode::Flat);
    bursty_classic.sample_size(60);
    bursty_classic.warm_up_time(Duration::from_secs(1));
    bursty_classic.measurement_time(Duration::from_secs(6));

    let burst = burst_size();
    let fanout_n = fanout();
    let cap = burst_cap(); // USE BIG CAP FOR BURSTS
    let label = format!("burst{}_fanout{}_cap{}", burst, fanout_n, cap);

    // (C1) classic fanout; cap=CAP (avoid backpressure)
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(cap);
        spawn_classic_drains(&rt, &bus, fanout_n);

        bursty_classic.throughput(Throughput::Elements(burst as u64));
        bursty_classic.bench_with_input(BenchmarkId::new("classic_fanout", &label), &(), |b, _| {
            b.iter(|| {
                publish_burst(&bus, burst);
                if pub_epoch_yield() {
                    rt.block_on(async { tokio::task::yield_now().await });
                }
            });
        });

        rt.block_on(async { tokio::task::yield_now().await });
    }

    // (C2) classic lagged fanout; cap=1 (pressure path)
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(1);
        spawn_classic_drains(&rt, &bus, fanout_n);

        let label_lag = format!("burst{}_fanout{}_cap{}", burst, fanout_n, 1);
        bursty_classic.throughput(Throughput::Elements(burst as u64));
        bursty_classic.bench_with_input(BenchmarkId::new("classic_lagged_fanout", &label_lag), &(), |b, _| {
            b.iter(|| {
                publish_burst(&bus, burst);
                if pub_epoch_yield() {
                    rt.block_on(async { tokio::task::yield_now().await });
                }
            });
        });

        rt.block_on(async { tokio::task::yield_now().await });
    }

    bursty_classic.finish();

    // ============ Group 3: Bursty — EDGE recv drain (fanout, gated) ============
    #[cfg(feature = "bus_edge_notify")]
    {
        let mut bursty_edge =
            c.benchmark_group(format!("bus_publish_bursty_edge (tls_thresh={})", tls_thresh));
        bursty_edge.sampling_mode(SamplingMode::Flat);
        bursty_edge.sample_size(60);
        bursty_edge.warm_up_time(Duration::from_secs(1));
        bursty_edge.measurement_time(Duration::from_secs(6));

        let burst = burst_size();
        let fanout_n = fanout();
        let cap = burst_cap();
        let label = format!("burst{}_fanout{}_cap{}", burst, fanout_n, cap);

        // (E1) edge fanout; cap=CAP
        {
            let metrics = Metrics::new(true);
            let bus = metrics.make_bus::<KernelEvent>(cap);
            spawn_edge_drains(&rt, &bus, fanout_n);

            bursty_edge.throughput(Throughput::Elements(burst as u64));
            bursty_edge.bench_with_input(BenchmarkId::new("edge_fanout", &label), &(), |b, _| {
                b.iter(|| {
                    publish_burst(&bus, burst);
                    if pub_epoch_yield() {
                        rt.block_on(async { tokio::task::yield_now().await });
                    }
                });
            });

            rt.block_on(async { tokio::task::yield_now().await });
        }

        // (E2) edge lagged fanout; cap=1
        {
            let metrics = Metrics::new(true);
            let bus = metrics.make_bus::<KernelEvent>(1);
            spawn_edge_drains(&rt, &bus, fanout_n);

            let label_lag = format!("burst{}_fanout{}_cap{}", burst, fanout_n, 1);
            bursty_edge.throughput(Throughput::Elements(burst as u64));
            bursty_edge.bench_with_input(BenchmarkId::new("edge_lagged_fanout", &label_lag), &(), |b, _| {
                b.iter(|| {
                    publish_burst(&bus, burst);
                    if pub_epoch_yield() {
                        rt.block_on(async { tokio::task::yield_now().await });
                    }
                });
            });

            rt.block_on(async { tokio::task::yield_now().await });
        }

        bursty_edge.finish();
    }
}

#[cfg(feature = "bus_batch")]
fn bench_publish_batched(c: &mut Criterion) {
    // ========= Group 4: Bursty — **BATCHED** publish_many (fanout), real A2 path =========
    let tls_thresh = tls_flush_threshold();
    let mut bursty_batched =
        c.benchmark_group(format!("bus_publish_bursty_batched (tls_thresh={})", tls_thresh));
    bursty_batched.sampling_mode(SamplingMode::Flat);
    bursty_batched.sample_size(60);
    bursty_batched.warm_up_time(Duration::from_secs(1));
    bursty_batched.measurement_time(Duration::from_secs(6));

    let rt = tokio::runtime::Builder::new_multi_thread().enable_all().build().expect("tokio rt");

    let burst = burst_size();
    let fanout_n = fanout();
    let cap = burst_cap();
    let label = format!("burst{}_fanout{}_cap{}", burst, fanout_n, cap);

    // (B1) batched fanout; cap=CAP (no backpressure)
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(cap);
        spawn_classic_drains(&rt, &bus, fanout_n);

        bursty_batched.throughput(Throughput::Elements(burst as u64));
        bursty_batched.bench_with_input(BenchmarkId::new("batched_fanout", &label), &(), |b, _| {
            // Prepare per-iter batch without timing the setup (A2 hot path only):
            b.iter_batched_ref(
                || {
                    let mut v = Vec::with_capacity(burst);
                    v.resize(burst, KernelEvent::Shutdown);
                    v
                },
                |batch| {
                    #[allow(unused_must_use)]
                    {
                        bus.publish_many(black_box(&mut batch[..]));
                    }
                    if pub_epoch_yield() {
                        rt.block_on(async { tokio::task::yield_now().await });
                    }
                },
                BatchSize::SmallInput,
            );
        });

        rt.block_on(async { tokio::task::yield_now().await });
    }

    // (B2) batched **lagged** fanout; cap=1 (pressure path) — optional but useful for tail behavior
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(1);
        spawn_classic_drains(&rt, &bus, fanout_n);

        let label_lag = format!("burst{}_fanout{}_cap{}", burst, fanout_n, 1);
        bursty_batched.throughput(Throughput::Elements(burst as u64));
        bursty_batched.bench_with_input(BenchmarkId::new("batched_lagged_fanout", &label_lag), &(), |b, _| {
            b.iter_batched_ref(
                || {
                    let mut v = Vec::with_capacity(burst);
                    v.resize(burst, KernelEvent::Shutdown);
                    v
                },
                |batch| {
                    #[allow(unused_must_use)]
                    {
                        bus.publish_many(black_box(&mut batch[..]));
                    }
                    if pub_epoch_yield() {
                        rt.block_on(async { tokio::task::yield_now().await });
                    }
                },
                BatchSize::SmallInput,
            );
        });

        rt.block_on(async { tokio::task::yield_now().await });
    }

    bursty_batched.finish();
}

// ---- Criterion mains (feature-gated so you can `--features bus_batch`) ----

#[cfg(feature = "bus_batch")]
criterion_group!(benches, bench_publish, bench_publish_batched);

#[cfg(not(feature = "bus_batch"))]
criterion_group!(benches, bench_publish);

criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_publish_matrix.rs
<a id="crates-ron-kernel-benches-buspublishmatrix-rs"></a>

```rust
/*!
RO: benches/bus_publish_matrix.rs
WHAT: Parameterized publish() cost across subscriber counts and capacities.
WHY : Locate sweet spots for default capacity vs fan-out cost.
NOTE: Subscribers actively drain to avoid unbounded lag skewing results.
*/

use std::time::Duration;
use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion, SamplingMode};
use ron_kernel::{Bus, KernelEvent, Metrics};
use tokio::runtime::Builder;

const CAPS: &[usize] = &[32, 64, 128, 256, 4096];
const SUBS: &[usize] = &[0, 1, 4, 16];
const INNER_PUBLISHES: usize = 10_000;

fn bench_bus_publish_matrix(c: &mut Criterion) {
    let rt = Builder::new_multi_thread().enable_all().build().unwrap();

    let mut group = c.benchmark_group("bus_publish_matrix");
    group.sampling_mode(SamplingMode::Flat);
    group.sample_size(60);
    group.warm_up_time(Duration::from_secs(2));
    group.measurement_time(Duration::from_secs(8));

    for &subs in SUBS {
        for &cap in CAPS {
            let id = BenchmarkId::new("publish", format!("subs{}_cap{}", subs, cap));
            group.bench_with_input(id, &(), |b, _| {
                b.iter(|| {
                    rt.block_on(async {
                        let metrics = Metrics::new(false);
                        let bus: Bus<KernelEvent> = metrics.make_bus(cap);

                        // spawn drains
                        let mut joins = Vec::new();
                        for _ in 0..subs {
                            let mut rx = bus.subscribe();
                            joins.push(tokio::spawn(async move {
                                while let Ok(_ev) = rx.recv().await {}
                            }));
                        }

                        for i in 0..black_box(INNER_PUBLISHES) {
                            let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                        }

                        drop(bus);
                        for j in joins {
                            let _ = j.await;
                        }
                    });
                });
            });
        }
    }

    group.finish();
}

criterion_group!(benches, bench_bus_publish_matrix);
criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_soa.rs
<a id="crates-ron-kernel-benches-bussoa-rs"></a>

```rust
// benches/bus_soa.rs
//
// RO:WHAT
// - Criterion bench entrypoint for the SoA backend.
// - Compiles cleanly whether or not the "bus_soa" feature is enabled.
//
// RO:WHY
// - Cargo builds all benches during `cargo bench`. Without guarding, this file
//   would emit E0601 (no main) when the feature is off.
//
// RO:INTERACTS
// - Uses Criterion only when "bus_soa" is enabled.
// - When the feature is disabled, provides a tiny stub `main()` so the bench
//   target still builds and the rest of the suite can run.
//
// RO:INVARIANTS
// - Never pull SoA symbols unless the feature is on.
// - Keep a deterministic group name for CI diffing even if the body is trivial.

#[cfg(not(feature = "bus_soa"))]
fn main() {
    // Feature not enabled; benign stub so `cargo bench` can proceed.
    // Tip: run with `--features bus_soa` to enable this bench's real body.
    eprintln!("bench 'bus_soa' compiled without --features bus_soa; skipping.");
}

#[cfg(feature = "bus_soa")]
mod soa_bench {
    use criterion::{criterion_group, criterion_main, Criterion};

    // If you already have shared bench helpers, import them here, e.g.:
    // use ron_kernel::bench_support::{run_publish_matrix_soa, BenchCfg};

    // Minimal placeholder so the bench runs even before the SoA runner lands.
    // Replace with your real SoA matrix once implemented.
    fn bench_bus_soa(c: &mut Criterion) {
        let mut group = c.benchmark_group("bus_soa");
        // TODO: swap this placeholder with the real SoA publish/deliver matrix.
        group.bench_function("noop_build_only", |b| b.iter(|| 0u64));
        group.finish();
    }

    criterion_group!(name = soa; config = Criterion::default(); targets = bench_bus_soa);
    criterion_main!(soa);
}

```

### crates/ron-kernel/benches/metrics_encode.rs
<a id="crates-ron-kernel-benches-metricsencode-rs"></a>

```rust
/*!
RO: benches/metrics_encode.rs
WHAT: Measure Prometheus registry gather+encode cost (drift guard).
WHY : Catch accidental cardinality/registry growth; not a throughput contest.
*/

use std::time::Duration;
use criterion::{black_box, criterion_group, criterion_main, Criterion, SamplingMode, BenchmarkId};
use prometheus::Encoder;
use ron_kernel::Metrics;

fn bench_metrics(c: &mut Criterion) {
    let mut group = c.benchmark_group("metrics");
    group.sampling_mode(SamplingMode::Flat);
    group.sample_size(60);
    group.warm_up_time(Duration::from_secs(1));
    group.measurement_time(Duration::from_secs(6));

    group.bench_with_input(BenchmarkId::new("gather+encode_text", "registry"), &(), |b, _| {
        b.iter(|| {
            let metrics = Metrics::new(false);
            metrics.set_amnesia(true); // ensure non-empty registry
            let families = (*metrics).registry.gather();
            let mut buf = Vec::new();
            prometheus::TextEncoder::new().encode(&families, &mut buf).unwrap();
            black_box(buf.len());
        });
    });

    group.finish();
}

criterion_group!(benches, bench_metrics);
criterion_main!(benches);

```

### crates/ron-kernel/benches/publish_edge_matrix.rs
<a id="crates-ron-kernel-benches-publishedgematrix-rs"></a>

```rust
use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion, Throughput};
use std::time::Duration;
use tokio::sync::broadcast;

// Measure publish throughput across (subs × capacity) matrix using only public API.
// This bench compiles with/without features (bus_edge_notify, bus_batch).

use ron_kernel::bus::bounded::Bus;

// Drain helper: non-blocking drain, like a simple “now_or_never” for broadcast.
fn drain_now<T: Clone + Send + 'static>(rx: &mut broadcast::Receiver<T>) -> usize {
    use tokio::sync::broadcast::error::TryRecvError::*;
    let mut n = 0usize;
    loop {
        match rx.try_recv() {
            Ok(_) => n += 1,
            Err(Empty) => break,
            Err(Lagged(_)) => continue, // skip lagged; keep draining to head
            Err(Closed) => break,
        }
    }
    n
}

#[cfg(feature = "bus_edge_notify")]
mod edge_metrics {
    use prometheus::proto::MetricType;
    use prometheus::Registry;

    pub fn snapshot(reg: &Registry, name: &str) -> u64 {
        let mut sum = 0f64;
        for mf in reg.gather() {
            if mf.name() == name && mf.get_field_type() == MetricType::COUNTER {
                for m in mf.get_metric() {
                    if let Some(c) = m.get_counter().as_ref() {
                        // rust-protobuf 3.x style: scalar getter is `value()`
                        sum += c.value();
                    }
                }
            }
        }
        sum as u64
    }

    pub fn default_registry() -> Registry {
        prometheus::default_registry().clone()
    }
}

fn bench_publish_edge_matrix(c: &mut Criterion) {
    // Single-threaded runtime for more stable results
    let rt = tokio::runtime::Builder::new_current_thread()
        .enable_time()
        .build()
        .unwrap();

    let mut group = c.benchmark_group("publish_edge_matrix");
    // Tunable matrix; keep small for CI time but representative for perf
    let subs_set = [0usize, 1, 4, 16];
    let caps_set = [32usize, 64, 128, 256];

    // Amount of work per iteration (elements pushed)
    const ELEMS: u64 = 50_000;

    #[cfg(feature = "bus_edge_notify")]
    let reg = edge_metrics::default_registry();

    for &subs in &subs_set {
        for &cap in &caps_set {
            group.throughput(Throughput::Elements(ELEMS));
            group.bench_with_input(
                BenchmarkId::new("publish_single", format!("subs={subs},cap={cap}")),
                &(),
                |b, _| {
                    rt.block_on(async {
                        let bus: Bus<u64> = Bus::with_capacity(cap);

                        // Spawn subscribers
                        let mut rxs: Vec<_> = (0..subs).map(|_| bus.subscribe()).collect();

                        #[cfg(feature = "bus_edge_notify")]
                        let sends_before = edge_metrics::snapshot(&reg, "bus_notify_sends_total");
                        #[cfg(feature = "bus_edge_notify")]
                        let suppressed_before =
                            edge_metrics::snapshot(&reg, "bus_notify_suppressed_total");

                        b.iter(|| {
                            // Producer: push ELEMS events
                            for i in 0..ELEMS {
                                let _ = bus.publish(i);
                            }
                            // Drain for fairness (so next iter starts empty)
                            for rx in &mut rxs {
                                let _ = drain_now(rx);
                            }
                            black_box(())
                        });

                        #[cfg(feature = "bus_edge_notify")]
                        {
                            let sends_after =
                                edge_metrics::snapshot(&reg, "bus_notify_sends_total");
                            let suppressed_after =
                                edge_metrics::snapshot(&reg, "bus_notify_suppressed_total");
                            let sends = sends_after.saturating_sub(sends_before);
                            let suppressed =
                                suppressed_after.saturating_sub(suppressed_before);
                            let total = sends + suppressed;
                            if total > 0 {
                                let pct = (suppressed as f64) * 100.0 / (total as f64);
                                eprintln!(
                                    "[edge] subs={subs}, cap={cap}: sends={sends}, suppressed={suppressed} ({pct:.1}% suppressed)"
                                );
                            }
                        }
                    });
                },
            );
        }
    }
    group.finish();
}

criterion_group! {
    name = benches;
    config = {
        Criterion::default()
            .measurement_time(Duration::from_secs(8))
            .warm_up_time(Duration::from_secs(3))
            .sample_size(20)
    };
    targets = bench_publish_edge_matrix
}
criterion_main!(benches);

```

### crates/ron-kernel/benches/readiness_handler.rs
<a id="crates-ron-kernel-benches-readinesshandler-rs"></a>

```rust
/*!
RO: benches/readiness_handler.rs
WHAT: Measure axum handler overhead for the readiness gate.
WHY : Ensure /readyz is microseconds-fast in both states.
*/

use std::time::Duration;
use criterion::{criterion_group, criterion_main, Criterion, SamplingMode, BenchmarkId};
use axum::http::StatusCode;
use ron_kernel::metrics::health::HealthState;
use ron_kernel::metrics::readiness::{Readiness, readyz_handler};
use tokio::runtime::Builder;

fn bench_readyz(c: &mut Criterion) {
    let rt = Builder::new_multi_thread().enable_all().build().unwrap();

    let mut group = c.benchmark_group("readyz");
    group.sampling_mode(SamplingMode::Flat);
    group.sample_size(60);
    group.warm_up_time(Duration::from_secs(1));
    group.measurement_time(Duration::from_secs(6));

    // not_ready
    group.bench_with_input(BenchmarkId::new("not_ready", "handler()"), &(), |b, _| {
        b.iter(|| {
            rt.block_on(async {
                let health = HealthState::new();
                let ready = Readiness::new(health.clone());
                let resp = readyz_handler(ready).await;
                assert_eq!(resp.status(), StatusCode::SERVICE_UNAVAILABLE);
            });
        });
    });

    // ready
    group.bench_with_input(BenchmarkId::new("ready", "handler()"), &(), |b, _| {
        b.iter(|| {
            rt.block_on(async {
                let health = HealthState::new();
                let ready = Readiness::new(health.clone());
                ready.set_config_loaded(true);
                health.set("kernel", true);
                let resp = readyz_handler(ready).await;
                assert_eq!(resp.status(), StatusCode::OK);
            });
        });
    });

    group.finish();
}

criterion_group!(benches, bench_readyz);
criterion_main!(benches);

```

### crates/ron-kernel/deny.toml
<a id="crates-ron-kernel-deny-toml"></a>

```toml
[advisories]
yanked = "deny"
unmaintained = "deny"
vulnerability = "deny"
[licenses]
allow = ["MIT", "Apache-2.0"]

```

### crates/ron-kernel/examples/kernel_demo.rs
<a id="crates-ron-kernel-examples-kerneldemo-rs"></a>

```rust
// crates/ron-kernel/examples/kernel_demo.rs
//
// Minimal runnable demo for ron-kernel surfaces.
// - Exposes /metrics, /healthz, /readyz
// - Reads RON_CONFIG (default: /tmp/ron-kernel.toml) and toggles amnesia on real content change
// - Publishes KernelEvent::ConfigUpdated { version } on each change
//
// ENV:
//   RON_CONFIG=/tmp/ron-kernel.toml   # optional; default shown
//   RON_AMNESIA=1                     # optional; force amnesia=1 at startup

use ron_kernel::{Bus, KernelEvent, Metrics, HealthState, wait_for_ctrl_c};
use ron_kernel::metrics::readiness::Readiness;
use std::{env, fs, net::SocketAddr, time::{Duration, SystemTime}};
use tokio::task::JoinHandle;

#[tokio::main]
async fn main() {
    // Core kernel surfaces
    let metrics = Metrics::new(false);
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());

    // HTTP exporter (metrics / health / ready)
    let bind: SocketAddr = "127.0.0.1:9600".parse().unwrap();
    let (_handle, local) = metrics
        .clone()
        .serve(bind, health.clone(), ready.clone())
        .await
        .expect("metrics/health/ready server to bind");
    println!("metrics:  http://{}/metrics", local);
    println!("healthz:  http://{}/healthz", local);
    println!("readyz :  http://{}/readyz", local);

    // Config source
    let cfg_path = env::var("RON_CONFIG").unwrap_or_else(|_| "/tmp/ron-kernel.toml".to_string());
    println!("edit {} or set RON_AMNESIA=1 to see updates", cfg_path);

    // Seed readiness + amnesia
    // Mark kernel service healthy for demo visibility; /readyz still waits for config_loaded=true.
    health.set("kernel", true);

    // Apply env override immediately for a quick sanity check; else seed from file.
    let mut config_loaded = false;
    if let Ok(v) = env::var("RON_AMNESIA") {
        if v == "1" || v.eq_ignore_ascii_case("true") {
            metrics.set_amnesia(true);
            config_loaded = true;
        }
    } else if let Some(a) = read_amnesia_flag(&cfg_path) {
        metrics.set_amnesia(a);
        config_loaded = true;
    }
    if config_loaded {
        ready.set_config_loaded(true);
    }

    // Bus for demo events
    let bus: Bus<KernelEvent> = Bus::new().with_metrics(metrics.clone());

    // --- A3: Capacity Autotune (feature-gated) --------------------------------
    // For demo purposes we assume ~4 global subscribers. This computes a cache-friendly
    // capacity and exports it via the `bus_cap_selected` gauge. When the feature is OFF,
    // this block is not compiled and no behavior changes.
    #[cfg(feature = "bus_autotune_cap")]
    {
        // If you later expose a Bus::with_capacity(cap) builder path, you can pass `cap` there.
        // For now, we record and print the selection for observability.
        let expected_subs = 4usize;
        let cap = ron_kernel::bus::capacity::autotune_capacity(expected_subs, None);
        println!("autotune: expected_subs={} → selected bus cap = {}", expected_subs, cap);
    }
    // ---------------------------------------------------------------------------

    // Poller: detect real content changes, apply amnesia, publish ConfigUpdated
    let poller: JoinHandle<()> = tokio::spawn({
        let metrics = metrics.clone();
        let ready = ready.clone();
        let bus = bus.clone();
        let cfg_path = cfg_path.clone();
        async move {
            let mut last_hash: Option<u64> = None;
            let mut version: u64 = 1;

            loop {
                let (hash, amnesia) = match read_file_and_hash(&cfg_path) {
                    Some((h, a)) => (Some(h), Some(a)),
                    None => (None, None),
                };

                if hash.is_some() && hash != last_hash {
                    // We have a real change; mark config loaded and flip amnesia.
                    ready.set_config_loaded(true);
                    if let Some(a) = amnesia {
                        metrics.set_amnesia(a);
                    }
                    bus.publish(KernelEvent::ConfigUpdated { version });
                    println!(
                        "kernel event: ConfigUpdated {{ version: {} }} → amnesia={:?}",
                        version, amnesia
                    );
                    version = version.saturating_add(1);
                    last_hash = hash;
                }

                tokio::time::sleep(Duration::from_millis(500)).await;
            }
        }
    });

    println!("press Ctrl-C to stop …");
    wait_for_ctrl_c().await;
    poller.abort(); // best-effort cleanup
}

// --- helpers ---------------------------------------------------------------

// Parse `amnesia = true|false` from a TOML-ish line.
fn read_amnesia_flag(path: &str) -> Option<bool> {
    let s = fs::read_to_string(path).ok()?;
    for line in s.lines() {
        let t = line.trim();
        if t.starts_with("amnesia") && t.contains('=') {
            let val = t.splitn(2, '=').nth(1)?.trim();
            let val = val.trim_matches(|c: char| c == '"' || c.is_ascii_whitespace());
            return Some(val.eq_ignore_ascii_case("true"));
        }
    }
    None
}

// Read file and return (content_hash, amnesia_flag) using a tiny FNV-1a 64-bit hash.
fn read_file_and_hash(path: &str) -> Option<(u64, bool)> {
    let s = fs::read_to_string(path).ok()?;
    let mut hasher = Fnv1a64::new();
    hasher.update(s.as_bytes());
    // Fold in mtime to ensure delta on edits even if content normalizes
    if let Ok(meta) = fs::metadata(path) {
        if let Ok(mtime) = meta.modified() {
            if let Ok(dur) = mtime.duration_since(SystemTime::UNIX_EPOCH) {
                hasher.update(&dur.as_nanos().to_le_bytes());
            }
        }
    }
    let amnesia = s.lines().any(|line| {
        let t = line.trim();
        t.starts_with("amnesia")
            && t.contains('=')
            && t.splitn(2, '=')
                .nth(1)
                .map(|v| {
                    v.trim()
                        .trim_matches(|c: char| c == '"' || c.is_ascii_whitespace())
                        .eq_ignore_ascii_case("true")
                })
                .unwrap_or(false)
    });
    Some((hasher.finish(), amnesia))
}

// Tiny FNV-1a (64-bit) hasher (self-contained).
struct Fnv1a64(u64);
impl Fnv1a64 {
    fn new() -> Self { Self(0xcbf29ce484222325) } // offset basis
    fn update(&mut self, bytes: &[u8]) {
        const PRIME: u64 = 0x100000001b3;
        let mut h = self.0;
        for b in bytes {
            h ^= *b as u8 as u64;
            h = h.wrapping_mul(PRIME);
        }
        self.0 = h;
    }
    fn finish(&self) -> u64 { self.0 }
}

```

### crates/ron-kernel/examples/minimal_supervision.rs
<a id="crates-ron-kernel-examples-minimalsupervision-rs"></a>

```rust
use std::net::SocketAddr;
use std::time::Duration;

use ron_kernel::metrics::readiness::Readiness;
use ron_kernel::{HealthState, KernelEvent, Metrics};

#[tokio::main]
async fn main() {
    // Metrics + readiness demo server
    let metrics = Metrics::new(false);
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());
    ready.set_config_loaded(true);

    let (handle, local) = metrics
        .clone()
        .serve(
            "127.0.0.1:0".parse::<SocketAddr>().unwrap(),
            health.clone(),
            ready.clone(),
        )
        .await
        .unwrap();
    println!("metrics at http://{}/metrics", local);

    // Build a generic bus and attach metrics
    let bus = metrics.make_bus::<KernelEvent>(1024);

    // === Subscriber task =====================================================
    #[cfg(feature = "bus_edge_notify")]
    {
        // Edge-aware subscriber: disciplined drain loop (A5)
        let mut sub = bus.subscribe_edge();
        tokio::spawn(async move {
            // sub_index is for labeling; not used by the inlined helper today
            sub.run_drain_loop(0).await;
        });
    }

    #[cfg(not(feature = "bus_edge_notify"))]
    {
        // Classic subscriber: just recv in a loop
        let mut rx = bus.subscribe();
        tokio::spawn(async move {
            while rx.recv().await.is_ok() {}
        });
    }
    // ========================================================================

    // === Publisher demo workload ============================================
    // If `bus_batch` is enabled, publish in bursts via publish_many (A2).
    // Otherwise fall back to single-message publishes.
    #[cfg(feature = "bus_batch")]
    {
        // Replace the publisher loop (demo) to exercise batches
        let bus2 = bus.clone();
        tokio::spawn(async move {
            let mut v = 0u64;
            let mut scratch = Vec::with_capacity(256);
            loop {
                scratch.clear();
                for _ in 0..128 {
                    scratch.push(KernelEvent::ConfigUpdated { version: v });
                    v = v.wrapping_add(1);
                }
                // A2: single-sweep publish
                let _ = bus2.publish_many(&scratch);
                tokio::time::sleep(Duration::from_millis(25)).await;
            }
        });
    }

    #[cfg(not(feature = "bus_batch"))]
    {
        // One-at-a-time publisher (original behavior)
        let bus2 = bus.clone();
        tokio::spawn(async move {
            let mut v = 0u64;
            loop {
                let _ = bus2.publish(KernelEvent::ConfigUpdated { version: v });
                v = v.wrapping_add(1);
                tokio::time::sleep(Duration::from_millis(50)).await;
            }
        });
    }
    // ========================================================================

    tokio::signal::ctrl_c().await.unwrap();
    handle.abort();
}

```

### crates/ron-kernel/examples/publish_smoke.rs
<a id="crates-ron-kernel-examples-publishsmoke-rs"></a>

```rust
//! RO:WHAT
//! Minimal smoke to exercise the bus and expose counters over /metrics.
//!
//! RO:WHY
//! Validate A2 (bus_batch) in a live process and make it trivial to curl the
//! exporter and confirm notify/batch/publish counters move.
//!
//! RO:INTERACTS
//! - ron_kernel::Metrics (serves /metrics on ephemeral port)
//! - ron_kernel::bus::bounded::{Bus, EdgeReceiver} (feature-gated)
//!
//! RO:INVARIANTS
//! - Runs indefinitely until Ctrl-C.
//! - Env-driven config for subs/cap/burst/tick to avoid code edits.

use std::{env, time::Duration};
use tokio::time::{interval, sleep};

use ron_kernel::Metrics;

fn getenv<T: std::str::FromStr>(key: &str, default: T) -> T {
    env::var(key)
        .ok()
        .and_then(|s| s.parse::<T>().ok())
        .unwrap_or(default)
}

#[tokio::main(flavor = "multi_thread")]
async fn main() -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    // --- Metrics + HTTP on an ephemeral port (":0") ---
    let metrics = Metrics::new(false);
    let (_server, addr) = {
        use ron_kernel::metrics::{health::HealthState, readiness::Readiness};
        let health = HealthState::new();
        let ready = Readiness::new(health.clone());
        // bind to :0 so OS picks a free port
        metrics
            .clone()
            .serve(([127, 0, 0, 1], 0).into(), health, ready)
            .await?
    };
    println!("metrics at http://{}/metrics", addr);
    println!("curl it in another terminal; press Ctrl-C here to stop …");

    // --- Config via env (defaults are sane for laptops) ---
    let cap = getenv::<usize>("RON_BENCH_CAP", 4096);
    let subs = getenv::<usize>("RON_BENCH_FANOUT", 4);
    let burst = getenv::<usize>("RON_BENCH_BURST", 256);
    let tick_ms = getenv::<u64>("RON_TICK_MS", 1000);
    println!(
        "[example cfg] subs={}, cap={}, burst={}, tick_ms={}",
        subs, cap, burst, tick_ms
    );

    // --- Bus + subscribers (edge receivers if feature enabled) ---
    let bus = metrics.make_bus::<u64>(cap);

    #[cfg(feature = "bus_edge_notify")]
    {
        use ron_kernel::bus::bounded::EdgeReceiver;
        for i in 0..subs {
            let mut edge: EdgeReceiver<u64> = bus.subscribe_edge();
            tokio::spawn(async move {
                edge.run_drain_loop(i).await;
            });
        }
    }
    #[cfg(not(feature = "bus_edge_notify"))]
    {
        let mut rxs: Vec<_> = (0..subs).map(|_| bus.subscribe()).collect();
        for mut rx in rxs {
            let m = metrics.clone();
            tokio::spawn(async move {
                loop {
                    // Drain as events arrive; account lag/drops via handle_recv if provided.
                    let _ = ron_kernel::bus::bounded::Bus::<u64>::handle_recv(rx.recv().await, Some(&m));
                }
            });
        }
    }

    // --- Periodic publisher ---
    // Aim for "burst" elements per tick. With bus_batch ON, this is one publish_many per burst.
    let mut tick = interval(Duration::from_millis(tick_ms));
    let mut next = 0u64;

    loop {
        tick.tick().await;

        #[cfg(feature = "bus_batch")]
        {
            // One batch per tick; adjust tick_ms to control overall rate
            let mut buf = Vec::with_capacity(burst);
            buf.clear();
            for _ in 0..burst {
                buf.push(next);
                next = next.wrapping_add(1);
            }
            let _ = bus.publish_many(&buf);
        }

        #[cfg(not(feature = "bus_batch"))]
        {
            for _ in 0..burst {
                let _ = bus.publish(next);
                next = next.wrapping_add(1);
            }
        }

        // Give TLS flusher a beat between bursts (if metrics_buf is on).
        sleep(Duration::from_millis(50)).await;
    }

    #[allow(unreachable_code)]
    {
        Ok(())
    }
}

```

### crates/ron-kernel/fuzz/cfg_parser.rs
<a id="crates-ron-kernel-fuzz-cfgparser-rs"></a>

```rust
// fuzz target placeholder for config validation/precedence
fn main() {}

```

### crates/ron-kernel/rust-toolchain.toml
<a id="crates-ron-kernel-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["rustfmt","clippy"]

```

### crates/ron-kernel/scripts/ci_public_api.sh
<a id="crates-ron-kernel-scripts-cipublicapi-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
cargo install cargo-public-api >/dev/null 2>&1 || true
cargo public-api -p ron-kernel --simplified

```

### crates/ron-kernel/scripts/enforce_ro_headers.sh
<a id="crates-ron-kernel-scripts-enforceroheaders-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Enforce presence of "RO:" header lines near the top of every Rust source file.
# Skips files under target/ and any generated code paths.

fail() { echo "RO header missing in: $1" >&2; exit 1; }

git ls-files 'crates/ron-kernel/**/*.rs' \
  | grep -vE '^target/' \
  | while read -r file; do
      head -n 25 "$file" | grep -q 'RO:' || fail "$file"
    done

echo "RO header check passed."

```

### crates/ron-kernel/scripts/render_mermaid.sh
<a id="crates-ron-kernel-scripts-rendermermaid-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
which mmdc >/dev/null || npm i -g @mermaid-js/mermaid-cli
for f in $(git ls-files 'crates/ron-kernel2/docs/*.mmd' 2>/dev/null); do
  mmdc -i "$f" -o "${f%.mmd}.svg"
done

```

### crates/ron-kernel/scripts/run_kernel_benches.sh
<a id="crates-ron-kernel-scripts-runkernelbenches-sh"></a>

```bash
#!/usr/bin/env bash
# RO: scripts/run_kernel_benches.sh
set -euo pipefail

echo "=== System ==="
uname -a || true
rustc -Vv
cargo -V

echo
echo "=== Running benches (stable) ==="
cargo bench -p ron-kernel

echo
echo "=== Criterion reports ==="
echo "Open: target/criterion/report/index.html"

```

### crates/ron-kernel/scripts/run_mog_b1.sh
<a id="crates-ron-kernel-scripts-runmogb1-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT — Run SoA micro benches and tests (B1).
# RO:WHY  — Repeatable ritual for quick signal before Bus wiring.
# RO:INTERACTS — benches/bus_soa.rs; tests/soa_smoke.rs; Cargo features.
# RO:INVARIANTS — non-destructive; no feature bleed into other benches.

set -euo pipefail

echo "[MOG B1] build+test (feature=bus_soa)"
cargo test -p ron-kernel --features bus_soa -- tests:: # narrow run
cargo test -p ron-kernel --features bus_soa

echo "[MOG B1] benches (feature=bus_soa)"
cargo bench -p ron-kernel --features bus_soa --bench bus_soa

```

### crates/ron-kernel/src/amnesia.rs
<a id="crates-ron-kernel-src-amnesia-rs"></a>

```rust
//! RO:WHAT — Amnesia mode: single source of truth + metrics hook.
//! RO:WHY  — Pillar 1 (Kernel): central flag for RAM-first ops; SEC/RES concern.
//! RO:INTERACTS — metrics::exporter::Metrics (amnesia gauge), config::watcher/apply, readiness (orthogonal).
//! RO:INVARIANTS — lock-free reads; coherent under races; never gates readiness; updates metrics atomically.
//! RO:METRICS/LOGS — metrics.amnesia_mode (0/1 or label on="true|false") kept in sync on set().
//! RO:CONFIG — toggled by ConfigUpdated (from watcher); env RON_AMNESIA may also flip it.
//! RO:SECURITY — no secrets; boolean only.
//! RO:TEST HOOKS — unit: toggle coherency; integ: watcher flip updates gauge.

use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc,
};

use crate::metrics::exporter::Metrics;

/// Amnesia flag with atomic semantics and metrics synchronization.
#[derive(Clone, Debug)]
pub struct Amnesia(Arc<AtomicBool>);

impl Amnesia {
    /// Create with initial state.
    pub fn new(initial: bool) -> Self {
        Self(Arc::new(AtomicBool::new(initial)))
    }

    /// Read current state (lock-free).
    #[inline]
    pub fn get(&self) -> bool {
        self.0.load(Ordering::Relaxed)
    }

    /// Set state and synchronize the exported gauge.
    ///
    /// Never blocks; safe to call from config apply or env poller.
    pub fn set(&self, on: bool, metrics: &Metrics) {
        self.0.store(on, Ordering::Relaxed);
        metrics.set_amnesia(on);
    }
}

```

### crates/ron-kernel/src/bus/backoff.rs
<a id="crates-ron-kernel-src-bus-backoff-rs"></a>

```rust
//! Two-phase backoff helper for publisher slow paths (bench/SoA use).
//! Default is ultra-light: short spin (16) then yield. Tunable via env:
//!   RON_PUB_SPIN   => u32 spins (max 256; default 16)
//!   RON_PUB_YIELD  => "0" disables yield, anything else enables (default ON)

use std::cell::Cell;
use std::sync::OnceLock;
use std::thread;

#[derive(Copy, Clone)]
pub struct TwoPhaseBackoff {
    spins_left: Cell<u32>,
    yield_enabled: bool,
}

impl TwoPhaseBackoff {
    #[inline]
    pub fn new() -> Self {
        static SPINS: OnceLock<u32> = OnceLock::new();
        static YIELD: OnceLock<bool> = OnceLock::new();

        let spins = *SPINS.get_or_init(|| {
            std::env::var("RON_PUB_SPIN")
                .ok()
                .and_then(|v| v.parse::<u32>().ok())
                .filter(|&n| n <= 256)
                .unwrap_or(16)
        });
        let yield_enabled = *YIELD.get_or_init(|| {
            std::env::var("RON_PUB_YIELD").map(|v| v != "0").unwrap_or(true)
        });

        Self { spins_left: Cell::new(spins), yield_enabled }
    }

    /// Call when publish cannot immediately progress (slot full/lagged).
    #[inline]
    pub fn tick(&self) {
        let left = self.spins_left.get();
        if left > 0 {
            std::hint::spin_loop();
            self.spins_left.set(left - 1);
        } else if self.yield_enabled {
            thread::yield_now();
        } else {
            std::hint::spin_loop();
        }
    }

    #[inline]
    pub fn reset(&self) {
        self.spins_left.set(16);
    }
}

```

### crates/ron-kernel/src/bus/bounded.rs
<a id="crates-ron-kernel-src-bus-bounded-rs"></a>

```rust
//! Bounded, non-blocking in-process broadcast bus.
//!
//! MOG (features):
//! - `bus_edge_notify`: coalesced per-subscriber wake via `pending` bit + disciplined drain.
//! - `bus_batch`: batch publishing API with single notify sweep (A2).
//! - `metrics_buf`: thread-local buffering for hot-path counters (publish/notify).

use std::sync::Arc;

use tokio::sync::broadcast;
use tokio::sync::broadcast::error::RecvError;

#[cfg(feature = "bus_edge_notify")]
use {
    std::sync::{Mutex, Weak},
    tokio::sync::Notify,
};

use crate::Metrics;

#[cfg(feature = "bus_edge_notify")]
use crate::bus::mog_edge_notify::{prom_metrics::PromMetrics, EdgeNotify};

/// Kernel bus wrapper around `tokio::broadcast`.
#[derive(Clone)]
pub struct Bus<T: Clone + Send + 'static> {
    tx: broadcast::Sender<T>,
    metrics: Option<Arc<Metrics>>,

    #[cfg(feature = "bus_edge_notify")]
    edge: Arc<EdgeRegistry>,
}

impl<T: Clone + Send + 'static> Bus<T> {
    pub fn new() -> Self {
        let (tx, _rx) = broadcast::channel::<T>(1024);
        Self {
            tx,
            metrics: None,
            #[cfg(feature = "bus_edge_notify")]
            edge: Arc::new(EdgeRegistry::default()),
        }
    }

    pub fn with_capacity(capacity: usize) -> Self {
        let (tx, _rx) = broadcast::channel::<T>(capacity);
        Self {
            tx,
            metrics: None,
            #[cfg(feature = "bus_edge_notify")]
            edge: Arc::new(EdgeRegistry::default()),
        }
    }

    pub fn with_metrics(mut self, metrics: Arc<Metrics>) -> Self {
        self.metrics = Some(metrics);
        self
    }

    #[inline]
    pub fn receiver_count(&self) -> usize {
        self.tx.receiver_count()
    }

    /// Single publish (existing path), with optional TLS metrics buffering.
    pub fn publish(&self, msg: T) -> usize {
        let receivers = self.tx.receiver_count();

        if receivers == 0 {
            if let Some(m) = &self.metrics {
                // Count as "published attempt" + explicit "no receivers".
                #[cfg(feature = "metrics_buf")]
                {
                    if let Some(hot) = m.hot() {
                        hot.inc_published();
                    }
                }
                #[cfg(not(feature = "metrics_buf"))]
                {
                    m.bus_published_total.inc();
                }
                m.bus_no_receivers_total.inc();
            }
            return 0;
        }

        match self.tx.send(msg) {
            Ok(_) => {
                // Account publish on the hot path.
                if let Some(m) = &self.metrics {
                    #[cfg(feature = "metrics_buf")]
                    {
                        if let Some(hot) = m.hot() {
                            hot.inc_published();
                        }
                    }
                    #[cfg(not(feature = "metrics_buf"))]
                    {
                        m.bus_published_total.inc();
                    }
                }

                // Coalesced edge-notify sweep if enabled.
                #[cfg(feature = "bus_edge_notify")]
                self.edge_sweep();

                receivers
            }
            Err(_e) => {
                if let Some(m) = &self.metrics {
                    m.bus_dropped_total.inc();
                }
                0
            }
        }
    }

    /// A2: Batch publish with one notify sweep at the end (feature-gated).
    #[cfg(feature = "bus_batch")]
    pub fn publish_many(&self, batch: &[T]) -> usize {
        if batch.is_empty() {
            return 0;
        }

        let receivers = self.tx.receiver_count();
        if receivers == 0 {
            if let Some(m) = &self.metrics {
                // Visibility: attempted to publish N items with no listeners.
                #[cfg(feature = "metrics_buf")]
                {
                    if let Some(hot) = m.hot() {
                        hot.add_published(batch.len() as u64);
                    }
                }
                #[cfg(not(feature = "metrics_buf"))]
                {
                    m.bus_published_total.inc_by(batch.len() as u64);
                }
                m.bus_no_receivers_total.inc_by(batch.len() as u64);
                m.bus_batch_publish_total.inc();
                m.bus_batch_len_histogram.observe(batch.len() as f64);
            }
            return 0;
        }

        // Send all elements; if any send fails (closed), account drop and stop.
        let mut sent = 0usize;
        for item in batch {
            match self.tx.send(item.clone()) {
                Ok(_) => sent += 1,
                Err(_e) => {
                    if let Some(m) = &self.metrics {
                        m.bus_dropped_total.inc();
                    }
                    break;
                }
            }
        }

        // One coalesced edge-notify sweep (A2).
        #[cfg(feature = "bus_edge_notify")]
        self.edge_sweep();

        if let Some(m) = &self.metrics {
            if sent > 0 {
                #[cfg(feature = "metrics_buf")]
                {
                    if let Some(hot) = m.hot() {
                        hot.add_published(sent as u64);
                    }
                }
                #[cfg(not(feature = "metrics_buf"))]
                {
                    m.bus_published_total.inc_by(sent as u64);
                }
            }
            m.bus_batch_publish_total.inc();
            m.bus_batch_len_histogram.observe(batch.len() as f64);
        }

        receivers
    }

    /// Subscribe and get a classical broadcast `Receiver<T>` (feature-agnostic).
    pub fn subscribe(&self) -> broadcast::Receiver<T> {
        self.tx.subscribe()
    }

    pub fn handle_recv(
        res: Result<T, broadcast::error::RecvError>,
        metrics: Option<&Metrics>,
    ) -> Option<T> {
        match res {
            Ok(v) => Some(v),
            Err(broadcast::error::RecvError::Lagged(n)) => {
                if let Some(m) = metrics {
                    m.bus_receiver_lag_total.inc_by(n as u64);
                }
                None
            }
            Err(broadcast::error::RecvError::Closed) => None,
        }
    }

    // === Internal: one sweep across live subscribers to deliver a single notify per sub ======

    #[cfg(feature = "bus_edge_notify")]
    fn edge_sweep(&self) {
        // Prometheus metrics for A1/A5 (counters + per-sub pending gauge internally updated
        // by the receiver drain loops). Small, stateless helper.
        let prom = PromMetrics::default();

        let mut sent = 0u64;
        let mut suppressed = 0u64;

        self.edge.with_signals(|signals| {
            signals.retain(|w| w.upgrade().is_some());
            for w in signals.iter() {
                if let Some(sig) = w.upgrade() {
                    // RELAXED is sufficient: visibility is handled by ring fences.
                    if EdgeNotify::maybe_mark_pending_and_should_wake_metrics(&sig.pending, &prom) {
                        sig.notify.notify_one();
                        sent += 1;
                    } else {
                        suppressed += 1;
                    }
                }
            }
        });

        if let Some(m) = &self.metrics {
            // Route 'sends' through TLS buffer when enabled; 'suppressed' stays direct.
            #[cfg(feature = "metrics_buf")]
            {
                if sent > 0 {
                    if let Some(hot) = m.hot() {
                        // Count one notify per sweep (keep it simple on hot path).
                        hot.inc_notify();
                    }
                }
            }
            #[cfg(not(feature = "metrics_buf"))]
            {
                if sent > 0 {
                    m.bus_notify_sends_total.inc_by(sent);
                }
            }

            if suppressed > 0 {
                m.bus_notify_suppressed_total.inc_by(suppressed);
            }
        }
    }

    // === MOG subscriber helpers (feature-gated) ============================================

    /// Subscribe with an internal edge signal (pending bit + Notify) used to coalesce wakes.
    #[cfg(feature = "bus_edge_notify")]
    pub fn subscribe_edge(&self) -> EdgeReceiver<T> {
        let rx = self.tx.subscribe();
        let signal = Arc::new(EdgeSignal::default());
        self.edge.register_signal(&signal);
        EdgeReceiver {
            signal,
            rx,
            metrics: self.metrics.clone(),
        }
    }
}

/// Receiver wrapper (unchanged shape).
pub struct Receiver<T: Clone + Send + 'static> {
    inner: broadcast::Receiver<T>,
    metrics: Option<Arc<Metrics>>,
}

impl<T: Clone + Send + 'static> Receiver<T> {
    pub fn new(inner: broadcast::Receiver<T>, metrics: Option<Arc<Metrics>>) -> Self {
        Self { inner, metrics }
    }

    pub async fn recv(&mut self) -> Option<T> {
        loop {
            match self.inner.recv().await {
                Ok(v) => return Some(v),
                Err(RecvError::Lagged(n)) => {
                    if let Some(m) = &self.metrics {
                        m.bus_receiver_lag_total.inc_by(n as u64);
                    }
                    continue;
                }
                Err(RecvError::Closed) => return None,
            }
        }
    }
}

/* ======== MOG helpers and types (feature-gated; minimal, generic-safe) ==================== */

#[cfg(feature = "bus_edge_notify")]
#[derive(Default)]
struct EdgeRegistry {
    signals: Mutex<Vec<Weak<EdgeSignal>>>,
}

#[cfg(feature = "bus_edge_notify")]
impl EdgeRegistry {
    fn register_signal(&self, sig: &Arc<EdgeSignal>) {
        self.signals.lock().unwrap().push(Arc::downgrade(sig));
    }
    fn with_signals<F: FnOnce(&mut Vec<Weak<EdgeSignal>>) -> ()>(&self, f: F) {
        let mut guard = self.signals.lock().unwrap();
        f(&mut guard);
    }
}

#[cfg(feature = "bus_edge_notify")]
#[derive(Default)]
struct EdgeSignal {
    pending: std::sync::atomic::AtomicBool,
    notify: Notify,
}

#[cfg(feature = "bus_edge_notify")]
pub struct EdgeReceiver<T: Clone + Send + 'static> {
    signal: Arc<EdgeSignal>,
    rx: broadcast::Receiver<T>,
    metrics: Option<Arc<Metrics>>,
}

#[cfg(feature = "bus_edge_notify")]
impl<T: Clone + Send + 'static> EdgeReceiver<T> {
    #[inline]
    pub fn try_recv_now_or_never(&mut self) -> usize {
        use tokio::sync::broadcast::error::TryRecvError::*;
        let mut drained = 0usize;
        loop {
            match self.rx.try_recv() {
                Ok(_msg) => drained += 1,
                Err(Empty) => break,
                Err(Lagged(n)) => {
                    if let Some(m) = &self.metrics {
                        m.bus_receiver_lag_total.inc_by(n as u64);
                    }
                }
                Err(Closed) => break,
            }
        }
        drained
    }

    #[inline]
    pub async fn await_notify(&self) {
        self.signal.notify.notified().await;
    }

    #[inline]
    pub fn pending(&self) -> &std::sync::atomic::AtomicBool {
        &self.signal.pending
    }
    #[inline]
    pub fn notify(&self) -> &Notify {
        &self.signal.notify
    }

    /// Disciplined drain loop (A5) with race check and per-sub pending gauge.
    pub async fn run_drain_loop(&mut self, sub_index: usize) {
        // Prom metrics handle `bus_sub_pending{sub}` updates.
        let prom = PromMetrics::default();

        loop {
            // Drain in bounded bursts to amortize wakes while keeping latency tight.
            let mut drained = 0usize;
            loop {
                let n = self.try_recv_now_or_never();
                if n == 0 {
                    break;
                }
                drained += n;
                if drained >= 1024 {
                    break;
                }
            }

            // Race check — if a publish raced our clear, keep draining (skip await).
            if EdgeNotify::after_drain_race_check(self.pending(), &prom, sub_index) {
                continue;
            }

            // Await next wake to avoid ping-pong.
            self.await_notify().await;
        }
    }
}

```

### crates/ron-kernel/src/bus/capacity.rs
<a id="crates-ron-kernel-src-bus-capacity-rs"></a>

```rust
//! RO:WHAT
//!   Capacity autotune helper for the bounded bus ring.
//!
//! RO:WHY
//!   Picking a too-large cap is cache-hostile; too-small can increase churn/drops.
//!   This feature-gated helper chooses a sweet-spot cap from expected subscriber
//!   count with guardrails and observability (Prometheus counters/gauges).
//!
//! RO:INTERACTS
//!   - Used by examples (kernel_demo) and callers that want reasonable defaults.
//!   - Exposes Prometheus metrics via the *default* registry.
//!
//! RO:INVARIANTS
//!   - Public kernel API remains frozen; this is an internal helper.
//!   - When feature `bus_autotune_cap` is OFF, callers should not reference it.
//!   - Caps returned are restricted to {64, 128, 256} unless explicitly overridden.
//!
//! RO:TESTS
//!   - Unit: mapping for key N (0,1,4,5,16,17,64,128)
//!   - Property: monotone in N; override respected; warnings on >256
//!
//! RO:SAFETY
//!   - No `unsafe`. Pure computation + metrics.
//!
//! RO:METRICS
//!   - `bus_autotune_warn_total{reason="cap_gt_256"}`
//!   - `bus_cap_selected` (gauge)

#![cfg(feature = "bus_autotune_cap")]

use once_cell::sync::Lazy;
use prometheus::{opts, register_gauge, register_int_counter_vec, Gauge, IntCounterVec};

/// Warn counter for guardrails.
static AUTOTUNE_WARN_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        opts!("bus_autotune_warn_total", "Autotune guardrail warnings"),
        &["reason"]
    )
    .expect("register bus_autotune_warn_total")
});

/// Last selected cap (observability).
static BUS_CAP_SELECTED: Lazy<Gauge> = Lazy::new(|| {
    register_gauge!("bus_cap_selected", "Current bus capacity selected by autotune")
        .expect("register bus_cap_selected")
});

/// Choose a cache-friendly capacity from an expected subscriber count `expected_subs`.
/// If `override_cap` is provided, it always wins (and may be any power-of-two the caller desires).
/// Guardrail: when the *effective* cap exceeds 256, we emit a warning counter.
///
/// Mapping (when `override_cap` is `None`):
///   - N ≤ 4   → 64
///   - N ≤ 16  → 128
///   - else    → 256 (warn if caller later uses >256)
pub fn autotune_capacity(expected_subs: usize, override_cap: Option<usize>) -> usize {
    let cap = match override_cap {
        Some(c) => c,
        None => {
            if expected_subs <= 4 {
                64
            } else if expected_subs <= 16 {
                128
            } else {
                256
            }
        }
    };

    if cap > 256 {
        AUTOTUNE_WARN_TOTAL
            .with_label_values(&["cap_gt_256"])
            .inc();
    }

    BUS_CAP_SELECTED.set(cap as f64);
    cap
}

/// Helper for tests/benches to reset gauge (kept for internal use).
#[cfg(test)]
pub fn __test_reset_metrics() {
    BUS_CAP_SELECTED.set(0.0);
}

```

### crates/ron-kernel/src/bus/mod.rs
<a id="crates-ron-kernel-src-bus-mod-rs"></a>

```rust
//! Bus module index.
//!
//! Layout:
//! - `bounded.rs`          : tokio::broadcast/AoS backend (default)
//! - `soa.rs`              : SoA ring backend (feature: bus_soa)
//! - `mog_edge_notify.rs`  : A1/A5 helpers (edge-triggered notify + disciplined drain)
//! - `capacity.rs`         : A3 autotune helper (feature: bus_autotune_cap)
//!
//! RO:WHAT
//!   Central selector + feature-gated helpers for the kernel bus.
//!
//! RO:WHY
//!   Keep call-sites stable while we experiment with a SoA backend.
//!   When `bus_soa` is enabled, we re-export SoA *under* a `bounded`-shaped
//!   module so existing paths (`crate::bus::bounded::Bus`) remain valid.
//!
//! RO:INVARIANTS
//!   - Public API stays stable; features are OFF-by-default.
//!   - No `unsafe` here.
//!   - `crate::bus::bounded::Bus` always exists and compiles.
//!
//! RO:INTERACTS
//!   - `bounded.rs` (default AoS) or `soa.rs` (feature=bus_soa) as the active backend.
//!   - `mog_edge_notify.rs` when feature `bus_edge_notify` is on.
//!   - `capacity.rs` when feature `bus_autotune_cap` is on.

#![allow(clippy::module_inception)] // for the bounded re-export wrapper when bus_soa is on

/// A3: Capacity autotune helper (feature-gated).
#[cfg(feature = "bus_autotune_cap")]
pub mod capacity;

#[cfg(feature = "bus_autotune_cap")]
pub use capacity::autotune_capacity;

/// Default backend (`bounded`) when SoA is NOT enabled.
#[cfg(not(feature = "bus_soa"))]
pub mod bounded;

/// Optional SoA backend (feature: bus_soa).
#[cfg(feature = "bus_soa")]
pub mod soa;

/// When `bus_soa` is ON, re-export SoA items under a `bounded`-shaped module
/// so `crate::bus::bounded::Bus` remains valid at existing call-sites.
/// We keep `pub mod soa;` above so advanced users can still import `soa::*`
/// explicitly if they want to.
#[cfg(feature = "bus_soa")]
pub mod bounded {
    pub use super::soa::*;
}

/// A1/A5 helpers (edge-triggered notify + disciplined drain).
#[cfg(feature = "bus_edge_notify")]
pub mod mog_edge_notify;

// ---------------------------------------------------------------------------
// Convenience re-exports (non-breaking):
//   - These make `use crate::bus::Bus;` work regardless of backend.
//   - Purely additive; they do not remove or rename any existing items.
// ---------------------------------------------------------------------------

pub use bounded::{Bus, Receiver};

#[cfg(feature = "bus_edge_notify")]
pub use bounded::EdgeReceiver;

```

### crates/ron-kernel/src/bus/mog_edge_notify.rs
<a id="crates-ron-kernel-src-bus-mogedgenotify-rs"></a>

```rust
// crates/ron-kernel/src/bus/mog_edge_notify.rs

/*!
MOG A1 + A5 — Edge-Triggered Notify + Disciplined Drain
Feature: `bus_edge_notify`

Internal helpers:
- Coalesce wakeups per subscriber using a `pending` bit (A1).
- Disciplined drain loop that clears `pending` safely and avoids ping-pong wakes (A5).

Public API: **None** (internal only). Wire these helpers into the bus internals.
Zero behavior change unless the bus calls into this module under the `bus_edge_notify` feature.
*/

#![cfg(feature = "bus_edge_notify")]
#![deny(unsafe_code)]

use core::sync::atomic::{AtomicBool, Ordering};

/// Minimal metrics hook used by this module.
/// Keep it decoupled; provide a Prometheus impl below (optional).
pub trait EdgeMetrics: Send + Sync + 'static {
    fn inc_notify_sent(&self) {}
    fn inc_notify_suppressed(&self) {}
    fn set_sub_pending(&self, _sub_idx: usize, _val: bool) {}
}
impl EdgeMetrics for () {}

/// Per-subscriber edge notifier (stateless; state lives in passed-in atomics).
#[derive(Default, Debug)]
pub struct EdgeNotify;

impl EdgeNotify {
    /// Publisher-side: set `pending` to true. If we transitioned 0→1, caller should send a wake.
    /// (Legacy signature — no metrics.)
    #[inline(always)]
    pub fn maybe_mark_pending_and_should_wake(pending: &AtomicBool) -> bool {
        // Relaxed is sufficient: message visibility comes from the ring’s Release/Acquire.
        let prev = pending.swap(true, Ordering::Relaxed);
        !prev
    }

    /// Publisher-side (metrics-aware): increments sends/suppressed counters.
    #[inline(always)]
    pub fn maybe_mark_pending_and_should_wake_metrics<M: EdgeMetrics>(
        pending: &AtomicBool,
        metrics: &M,
    ) -> bool {
        let prev = pending.swap(true, Ordering::Relaxed);
        if !prev {
            metrics.inc_notify_sent();
            true
        } else {
            metrics.inc_notify_suppressed();
            false
        }
    }

    /// Subscriber-side (legacy): clear `pending=false` after draining and perform a race check.
    /// Returns `true` if new work arrived during/after the clear.
    ///
    /// NOTE: Kept for compatibility, but prefer `after_drain_race_check()` below,
    /// which uses a stronger detection pattern.
    #[inline(always)]
    pub fn clear_pending_and_race_check(pending: &AtomicBool) -> bool {
        let _was_set = pending.swap(false, Ordering::Relaxed);
        pending.load(Ordering::Relaxed)
    }

    /// Subscriber-side: disciplined race-check after draining.
    ///
    /// Pattern:
    ///   drain_all();
    ///   if EdgeNotify::after_drain_race_check(pending, metrics, sub_idx) { continue; }
    ///   await_notify();
    ///
    /// Returns `true` if a publish raced after we cleared pending — the caller should
    /// skip awaiting and re-enter the drain loop immediately.
    #[inline(always)]
    pub fn after_drain_race_check<M: EdgeMetrics>(
        pending: &AtomicBool,
        metrics: &M,
        sub_idx: usize,
    ) -> bool {
        // 1) Clear pending (we are about to await).
        pending.store(false, Ordering::Relaxed);
        metrics.set_sub_pending(sub_idx, false);

        // 2) Race detect: if a publisher set it after our clear, swap(false) returns true.
        let raced = pending.swap(false, Ordering::Relaxed);
        if raced {
            // Re-arm to true so subsequent publishers get suppression (coalescing continues).
            pending.store(true, Ordering::Relaxed);
            metrics.set_sub_pending(sub_idx, true);
        }
        raced
    }

    /// Subscriber-side: disciplined drain loop.
    ///
    /// - `try_recv_now` must drain ALL available items and return the number drained.
    /// - `await_notify` waits for a single notification (e.g., `notify.notified().await`).
    pub async fn drain_loop<TryNow, AwaitFut, M>(
        &self,
        sub_idx: usize,
        pending: &AtomicBool,
        mut try_recv_now: TryNow,
        mut await_notify: impl FnMut() -> AwaitFut,
        metrics: &M,
    ) where
        TryNow: FnMut() -> usize,
        AwaitFut: core::future::Future<Output = ()>,
        M: EdgeMetrics,
    {
        metrics.set_sub_pending(sub_idx, true);
        loop {
            // 1) Drain everything currently available.
            loop {
                let n = try_recv_now();
                if n == 0 {
                    break;
                }
            }

            // 2) Clear pending + race check. If raced, keep draining (skip await).
            if Self::after_drain_race_check(pending, metrics, sub_idx) {
                continue;
            }

            // 3) Await next wake to avoid ping-pong.
            await_notify().await;
            metrics.set_sub_pending(sub_idx, true);
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use core::sync::atomic::AtomicBool;

    #[test]
    fn publisher_edges_are_coalesced() {
        let pending = AtomicBool::new(false);

        // First mark triggers a wake
        assert!(EdgeNotify::maybe_mark_pending_and_should_wake(&pending));
        // Further marks coalesce (no additional wakes)
        assert!(!EdgeNotify::maybe_mark_pending_and_should_wake(&pending));
        assert!(!EdgeNotify::maybe_mark_pending_and_should_wake(&pending));

        // After a normal after-drain race check with no race, we should be clear
        let raced = EdgeNotify::after_drain_race_check(&pending, &(), 0);
        assert!(!raced);

        // Next publish becomes a new edge again
        assert!(EdgeNotify::maybe_mark_pending_and_should_wake(&pending));
    }

    #[test]
    fn after_drain_no_race_returns_false() {
        let pending = AtomicBool::new(true);
        // Simulate: we drained; now we do the after-drain check; no concurrent publisher
        let raced = EdgeNotify::after_drain_race_check(&pending, &(), 0);
        assert!(!raced, "no publisher raced; should return false");
        assert!(!pending.load(Ordering::Relaxed), "pending remains false");
    }
}

/// Optional: Prometheus-backed metrics for A1/A5 (counters + per-sub gauge).
/// Enable by constructing `PromMetrics` and passing &PromMetrics to drain/publish paths.
#[cfg(feature = "bus_edge_notify")]
pub mod prom_metrics {
    use super::EdgeMetrics;
    use once_cell::sync::Lazy;
    use prometheus::{
        opts, register_int_counter, register_int_gauge_vec, IntCounter, IntGaugeVec,
    };

    static NOTIFY_SENDS_TOTAL: Lazy<IntCounter> = Lazy::new(|| {
        register_int_counter!(
            opts!("bus_notify_sends_total", "Notify calls performed on 0→1 edges")
        )
        .expect("register bus_notify_sends_total")
    });

    static NOTIFY_SUPPRESSED_TOTAL: Lazy<IntCounter> = Lazy::new(|| {
        register_int_counter!(
            opts!(
                "bus_notify_suppressed_total",
                "Notify attempts suppressed because subscriber was already pending"
            )
        )
        .expect("register bus_notify_suppressed_total")
    });

    static SUB_PENDING: Lazy<IntGaugeVec> = Lazy::new(|| {
        register_int_gauge_vec!(
            "bus_sub_pending",
            "Pending bit per subscriber (0|1)",
            &["sub"]
        )
        .expect("register bus_sub_pending")
    });

    /// Prometheus-backed EdgeMetrics. Label is `sub` with the numeric index.
    #[derive(Clone, Default)]
    pub struct PromMetrics;

    impl EdgeMetrics for PromMetrics {
        #[inline(always)]
        fn inc_notify_sent(&self) {
            NOTIFY_SENDS_TOTAL.inc();
        }
        #[inline(always)]
        fn inc_notify_suppressed(&self) {
            NOTIFY_SUPPRESSED_TOTAL.inc();
        }
        #[inline(always)]
        fn set_sub_pending(&self, sub_idx: usize, val: bool) {
            SUB_PENDING
                .with_label_values(&[&format!("{sub_idx}")])
                .set(if val { 1 } else { 0 });
        }
    }
}

```

### crates/ron-kernel/src/bus/soa.rs
<a id="crates-ron-kernel-src-bus-soa-rs"></a>

```rust
#![cfg(feature = "bus_soa")]

//! SoA (Structure-of-Arrays) ring backend for the in-process bus.

use core::sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering};
use std::sync::Arc;
use tokio::sync::Notify;

use crate::Metrics;
use tokio::sync::broadcast::error::RecvError;

#[cfg(feature = "bus_edge_notify")]
mod edge_helper {
    use core::sync::atomic::{AtomicBool, AtomicUsize, Ordering};
    use std::sync::{Arc, Weak};
    use tokio::sync::Notify;

    #[derive(Default)]
    pub struct EdgeSignal {
        pub notify: Notify,
        pub pending: AtomicBool,
    }

    pub struct EdgeNotify;

    impl EdgeNotify {
        #[inline]
        pub fn set_pending_and_notify(sig: &Arc<EdgeSignal>) -> bool {
            let prev = sig.pending.swap(true, Ordering::AcqRel);
            if !prev {
                sig.notify.notify_one();
            }
            !prev
        }
        #[inline]
        pub fn clear_pending_and_race_check(pending: &AtomicBool) -> bool {
            let _was_set = pending.swap(false, Ordering::AcqRel);
            pending.load(Ordering::Relaxed)
        }
    }

    /// Reader-friendly registry with occasional GC and O(1) "is there anyone?" fast-path.
    #[derive(Default)]
    pub struct EdgeRegistry {
        pub signals: parking_lot::RwLock<Vec<Weak<EdgeSignal>>>,
        pub gc_tick: AtomicUsize,
        pub active: AtomicUsize, // count of live edge subscribers
    }

    impl EdgeRegistry {
        pub fn register(&self, sig: &Arc<EdgeSignal>) {
            let mut w = self.signals.write();
            w.push(Arc::downgrade(sig));
            self.active.fetch_add(1, Ordering::Relaxed);
        }

        pub fn deregister(&self) {
            self.active.fetch_sub(1, Ordering::Relaxed);
        }

        /// Iterate with a read-lock. Return `true` if any dead Weak were seen.
        pub fn for_each_with_read<F: FnMut(&Arc<EdgeSignal>)>(&self, mut f: F) -> bool {
            let r = self.signals.read();
            let mut saw_dead = false;
            for w in r.iter() {
                if let Some(sig) = w.upgrade() {
                    f(&sig);
                } else {
                    saw_dead = true;
                }
            }
            saw_dead
        }

        /// Occasionally compact dead entries. Called rarely to avoid write-lock churn.
        pub fn maybe_gc(&self, saw_dead: bool) {
            if !saw_dead {
                return;
            }
            let tick = self.gc_tick.fetch_add(1, Ordering::Relaxed);
            if (tick & 63) != 0 {
                return;
            }
            let mut w = self.signals.write();
            w.retain(|weak| weak.strong_count() > 0);
        }
    }
}
#[cfg(feature = "bus_edge_notify")]
use edge_helper::{EdgeNotify, EdgeRegistry, EdgeSignal};

// ===== Slot ==================================================================

// Keep it lean: no per-message Arc; clone T under a Mutex like the bounded backend.
pub(crate) struct Slot<T> {
    seq: AtomicU64,
    msg: parking_lot::Mutex<Option<T>>,
    ready_mask: AtomicU64,
}
impl<T> Slot<T> {
    fn new() -> Self {
        Self {
            seq: AtomicU64::new(0),
            msg: parking_lot::Mutex::new(None),
            ready_mask: AtomicU64::new(0),
        }
    }
}

// ===== Bus ===================================================================

pub struct Bus<T: Clone + Send + 'static> {
    cap: usize,
    seq: Arc<AtomicU64>,
    slots: Arc<Vec<Slot<T>>>,

    subs_in_use: Arc<parking_lot::Mutex<[bool; 64]>>,
    sub_count: Arc<parking_lot::Mutex<usize>>,

    global_notify: Arc<Notify>,

    publishers: Arc<AtomicUsize>,
    closed: Arc<AtomicBool>,

    metrics: Option<Arc<Metrics>>,

    #[cfg(feature = "bus_edge_notify")]
    edge: Arc<EdgeRegistry>,
}

impl<T: Clone + Send + 'static> Bus<T> {
    pub fn new() -> Self { Self::with_capacity(1024) }

    pub fn with_capacity(cap: usize) -> Self {
        let mut v = Vec::with_capacity(cap);
        for _ in 0..cap { v.push(Slot::new()); }
        Self {
            cap,
            seq: Arc::new(AtomicU64::new(0)),
            slots: Arc::new(v),
            subs_in_use: Arc::new(parking_lot::Mutex::new([false; 64])),
            sub_count: Arc::new(parking_lot::Mutex::new(0)),
            global_notify: Arc::new(Notify::new()),
            publishers: Arc::new(AtomicUsize::new(1)),
            closed: Arc::new(AtomicBool::new(false)),
            metrics: None,
            #[cfg(feature = "bus_edge_notify")]
            edge: Arc::new(EdgeRegistry::default()),
        }
    }

    pub fn with_metrics(mut self, metrics: Arc<Metrics>) -> Self { self.metrics = Some(metrics); self }

    #[inline] pub fn receiver_count(&self) -> usize { *self.sub_count.lock() }

    #[inline]
    fn current_mask(&self) -> u64 {
        let subs = self.subs_in_use.lock();
        let mut mask: u64 = 0;
        for bit in 0..64 { if subs[bit] { mask |= 1u64 << bit; } }
        mask
    }

    /// Writer order:
    /// 1) payload -> msg (under lock)
    /// 2) ready_mask.store(mask, Release)
    /// 3) seq.store(next, Release)
    #[inline]
    fn publish_inner(&self, val: T, mask: u64, do_wake: bool) -> usize {
        let rc = self.receiver_count();
        if rc == 0 {
            if let Some(m) = &self.metrics { m.bus_no_receivers_total.inc(); }
            return 0;
        }

        let next = self.seq.fetch_add(1, Ordering::AcqRel) + 1;
        let idx = (next as usize) % self.cap;

        {
            let mut guard = self.slots[idx].msg.lock();
            *guard = Some(val);
        }
        self.slots[idx].ready_mask.store(mask, Ordering::Release);
        self.slots[idx].seq.store(next, Ordering::Release);

        if let Some(m) = &self.metrics { m.bus_published_total.inc(); }

        if do_wake {
            #[cfg(feature = "bus_edge_notify")]
            {
                // O(1) fast-path: if no edge subscribers, skip the whole sweep.
                if self.edge.active.load(Ordering::Relaxed) != 0 {
                    self.edge_sweep();
                }
            }
            #[cfg(not(feature = "bus_edge_notify"))]
            self.global_notify.notify_waiters();
        }

        rc
    }

    pub fn publish(&self, msg: T) -> usize {
        let mask = self.current_mask();
        self.publish_inner(msg, mask, true)
    }

    #[cfg(feature = "bus_batch")]
    pub fn publish_many(&self, batch: &[T]) -> usize {
        if batch.is_empty() { return 0; }
        let rc = self.receiver_count();
        if rc == 0 {
            if let Some(m) = &self.metrics {
                m.bus_no_receivers_total.inc_by(batch.len() as u64);
                m.bus_batch_publish_total.inc();
                m.bus_batch_len_histogram.observe(batch.len() as f64);
            }
            return 0;
        }
        let mask = self.current_mask();
        for item in batch { let _ = self.publish_inner(item.clone(), mask, false); }

        #[cfg(feature = "bus_edge_notify")]
        {
            if self.edge.active.load(Ordering::Relaxed) != 0 {
                self.edge_sweep();
            }
        }
        #[cfg(not(feature = "bus_edge_notify"))]
        self.global_notify.notify_waiters();

        if let Some(m) = &self.metrics {
            m.bus_batch_publish_total.inc();
            m.bus_batch_len_histogram.observe(batch.len() as f64);
        }
        rc
    }

    pub fn subscribe(&self) -> Receiver<T> {
        let (id, _count) = {
            let mut used = self.subs_in_use.lock();
            let mut idx: Option<usize> = None;
            for i in 0..64 {
                if !used[i] { used[i] = true; idx = Some(i); break; }
            }
            let mut sc = self.sub_count.lock();
            if idx.is_some() { *sc += 1; }
            (idx.expect("up to 64 subscribers"), *sc)
        };

        let tail = self.seq.load(Ordering::Acquire);
        Receiver {
            bus_cap: self.cap,
            ring: self.slots.clone(),
            tail,
            id: id as u8,
            global_notify: self.global_notify.clone(),
            _metrics: self.metrics.clone(),
            subs_in_use: Arc::clone(&self.subs_in_use),
            sub_count: Arc::clone(&self.sub_count),
            closed: Arc::clone(&self.closed),
            seq: Arc::clone(&self.seq),
        }
    }

    #[cfg(feature = "bus_edge_notify")]
    pub fn subscribe_edge(&self) -> EdgeReceiver<T> {
        let inner = self.subscribe();
        let signal = Arc::new(EdgeSignal::default());
        self.edge.register(&signal);
        EdgeReceiver { inner, signal, registry: Arc::clone(&self.edge) }
    }

    #[inline]
    pub fn handle_recv(res: Result<T, RecvError>, metrics: Option<&Metrics>) -> Option<T> {
        match res {
            Ok(v) => Some(v),
            Err(RecvError::Lagged(_)) => { if let Some(m) = metrics { m.bus_receiver_lag_total.inc_by(1); } None }
            Err(RecvError::Closed) => None,
        }
    }

    #[cfg(feature = "bus_edge_notify")]
    fn edge_sweep(&self) {
        let mut sent = 0u64;
        let mut suppressed = 0u64;

        let saw_dead = self.edge.for_each_with_read(|sig| {
            if EdgeNotify::set_pending_and_notify(sig) { sent += 1; } else { suppressed += 1; }
        });
        self.edge.maybe_gc(saw_dead);

        if let Some(m) = &self.metrics {
            if sent > 0 { m.bus_notify_sends_total.inc_by(sent); }
            if suppressed > 0 { m.bus_notify_suppressed_total.inc_by(suppressed); }
        }
    }
}

impl<T: Clone + Send + 'static> Clone for Bus<T> {
    fn clone(&self) -> Self {
        self.publishers.fetch_add(1, Ordering::AcqRel);
        Self {
            cap: self.cap,
            seq: Arc::clone(&self.seq),
            slots: Arc::clone(&self.slots),
            subs_in_use: Arc::clone(&self.subs_in_use),
            sub_count: Arc::clone(&self.sub_count),
            global_notify: Arc::clone(&self.global_notify),
            publishers: Arc::clone(&self.publishers),
            closed: Arc::clone(&self.closed),
            metrics: self.metrics.clone(),
            #[cfg(feature = "bus_edge_notify")]
            edge: Arc::clone(&self.edge),
        }
    }
}

impl<T: Clone + Send + 'static> Drop for Bus<T> {
    fn drop(&mut self) {
        if self.publishers.fetch_sub(1, Ordering::AcqRel) == 1 {
            self.closed.store(true, Ordering::Release);
            self.global_notify.notify_waiters();
        }
    }
}

// ===== Receiver ==============================================================

pub struct Receiver<T: Clone + Send + 'static> {
    pub(crate) bus_cap: usize,
    pub(crate) ring: Arc<Vec<Slot<T>>>,
    pub(crate) tail: u64,
    pub(crate) id: u8,
    pub(crate) global_notify: Arc<Notify>,
    pub(crate) _metrics: Option<Arc<Metrics>>,
    pub(crate) subs_in_use: Arc<parking_lot::Mutex<[bool; 64]>>,
    pub(crate) sub_count: Arc<parking_lot::Mutex<usize>>,
    pub(crate) closed: Arc<AtomicBool>,
    pub(crate) seq: Arc<AtomicU64>,
}

impl<T: Clone + Send + 'static> Receiver<T> {
    pub async fn recv(&mut self) -> Result<T, RecvError> {
        loop {
            let next = self.tail + 1;
            let idx = (next as usize) % self.bus_cap;
            let slot = &self.ring[idx];

            let slot_seq = slot.seq.load(Ordering::Acquire);

            if slot_seq > next {
                let delta = slot_seq - next;
                self.tail = slot_seq - 1;
                return Err(RecvError::Lagged(delta));
            }

            if slot_seq == 0 || slot_seq < next {
                if self.closed.load(Ordering::Acquire) {
                    let cur = self.seq.load(Ordering::Acquire);
                    if cur < next { return Err(RecvError::Closed); }
                }
                self.global_notify.notified().await;
                continue;
            }

            let bit = 1u64 << (self.id as u64);
            let prev_mask = slot.ready_mask.fetch_and(!bit, Ordering::AcqRel);
            if (prev_mask & bit) == 0 {
                self.tail = slot_seq;
                return Err(RecvError::Lagged(1));
            }

            let cloned = {
                let guard = slot.msg.lock();
                let v = guard.as_ref().expect("payload must exist if bit was set");
                v.clone()
            };

            self.tail = slot_seq;
            return Ok(cloned);
        }
    }
}

impl<T: Clone + Send + 'static> Drop for Receiver<T> {
    fn drop(&mut self) {
        let mut used = self.subs_in_use.lock();
        used[self.id as usize] = false;
        let mut c = self.sub_count.lock();
        *c = c.saturating_sub(1);
    }
}

// ===== Edge Receiver =========================================================

#[cfg(feature = "bus_edge_notify")]
pub struct EdgeReceiver<T: Clone + Send + 'static> {
    pub(crate) inner: Receiver<T>,
    pub(crate) signal: Arc<EdgeSignal>,
    pub(crate) registry: Arc<EdgeRegistry>,
}

#[cfg(feature = "bus_edge_notify")]
impl<T: Clone + Send + 'static> EdgeReceiver<T> {
    #[inline]
    pub fn try_recv_now_or_never(&mut self) -> usize {
        let mut drained = 0usize;
        loop {
            let next = self.inner.tail + 1;
            let idx = (next as usize) % self.inner.bus_cap;
            let slot = &self.inner.ring[idx];

            let slot_seq = slot.seq.load(Ordering::Acquire);
            if slot_seq == 0 || slot_seq < next { break; }
            if slot_seq > next { self.inner.tail = slot_seq - 1; continue; }

            let bit = 1u64 << (self.inner.id as u64);
            let prev_mask = slot.ready_mask.fetch_and(!bit, Ordering::AcqRel);
            if (prev_mask & bit) == 0 { self.inner.tail = slot_seq; continue; }

            {
                let guard = slot.msg.lock();
                let _ = guard.as_ref().expect("payload must exist if bit was set");
            }

            self.inner.tail = slot_seq;
            drained += 1;
        }
        drained
    }

    pub async fn run_drain_loop(&mut self, _sub_index: usize) {
        loop {
            let mut total = 0usize;
            loop {
                let n = self.try_recv_now_or_never();
                if n == 0 { break; }
                total += n;
                if total >= 1024 { break; }
            }
            let raced = edge_helper::EdgeNotify::clear_pending_and_race_check(&self.signal.pending);
            if raced { continue; }
            if total == 0 {
                self.signal.notify.notified().await;
                continue;
            }
            self.signal.notify.notified().await;
        }
    }

    pub async fn drain(&mut self, max: usize) -> usize {
        if max == 0 { return 0; }
        let mut drained = 0usize;
        while drained < max {
            match self.inner.recv().await {
                Ok(_v) => drained += 1,
                Err(RecvError::Lagged(_)) => {},
                Err(RecvError::Closed) => break,
            }
        }
        drained
    }

    #[inline] pub async fn await_notify(&self) { self.signal.notify.notified().await; }
    pub fn pending(&self) -> &core::sync::atomic::AtomicBool { &self.signal.pending }
}

#[cfg(feature = "bus_edge_notify")]
impl<T: Clone + Send + 'static> Drop for EdgeReceiver<T> {
    fn drop(&mut self) {
        // Mark one fewer active edge subscriber; Weak will GC later.
        self.registry.deregister();
    }
}

```

### crates/ron-kernel/src/bus/test.rs
<a id="crates-ron-kernel-src-bus-test-rs"></a>

```rust
/*!
Unit tests for the Bus contract (lives next to the implementation so it runs with unit tests too).

Contract under test:
- Zero subscribers: publish returns Ok(0) and increments bus_no_receivers_total.
- One subscriber: publish returns Ok(1) and does NOT increment bus_no_receivers_total again.

These are intentionally minimal: they do not receive messages; they only validate publish semantics + metrics.
*/

#![cfg(test)]

use crate::events::KernelEvent;
use crate::Metrics;

#[test]
fn publish_with_zero_subscribers_returns_ok_zero_and_counts_metric() {
    let metrics = Metrics::new(false);
    let bus = metrics.make_bus(8);

    let before = metrics.bus_no_receivers_total.get();
    let delivered = bus.publish(KernelEvent::ConfigUpdated { version: 1 });
    assert_eq!(delivered, Ok(0), "zero subscribers must yield Ok(0)");
    let after = metrics.bus_no_receivers_total.get();
    assert_eq!(
        after,
        before + 1,
        "bus_no_receivers_total must increment on publish with zero subscribers"
    );
}

#[test]
fn publish_with_one_subscriber_returns_ok_one_and_metric_stays_flat() {
    let metrics = Metrics::new(false);
    let bus = metrics.make_bus(8);

    // establish baseline and add one subscriber
    let base = metrics.bus_no_receivers_total.get();
    let _rx = bus.subscribe();

    // publish and assert Ok(1)
    let delivered = bus.publish(KernelEvent::ConfigUpdated { version: 2 });
    assert_eq!(delivered, Ok(1), "one subscriber must yield Ok(1)");

    // metric must not increment in this case
    let now = metrics.bus_no_receivers_total.get();
    assert_eq!(
        now, base,
        "bus_no_receivers_total must NOT increment when at least one subscriber exists"
    );
}

```

### crates/ron-kernel/src/bus/topic.rs
<a id="crates-ron-kernel-src-bus-topic-rs"></a>

```rust
//! RO:WHAT — Topic-scoped buses (internal utility).
//! RO:WHY  — Allows internal modules/tests to use name-scoped buses without changing public API.
//! RO:INTERACTS — bus::bounded::Bus, metrics (optional).
//! RO:INVARIANTS — No cross-topic delivery; lazy create; no external re-export.
//! RO:METRICS/LOGS — bus_topics_total (gauge).
//! RO:CONFIG — N/A.
//! RO:SECURITY — N/A.

#![allow(dead_code)]

use std::{collections::HashMap, sync::Arc};
use parking_lot::RwLock;

use super::bounded::Bus;
use crate::metrics::exporter::Metrics;

pub type Topic = &'static str;

#[derive(Default)]
pub struct TopicBus<T: Clone + Send + 'static> {
    inner: RwLock<HashMap<Topic, Bus<T>>>,
    metrics: Option<Arc<Metrics>>,
}

impl<T: Clone + Send + 'static> TopicBus<T> {
    pub fn new() -> Self {
        Self {
            inner: RwLock::new(HashMap::new()),
            metrics: None,
        }
    }

    pub fn with_metrics(mut self, metrics: Arc<Metrics>) -> Self {
        self.metrics = Some(metrics);
        self
    }

    pub fn topic(&self, name: Topic) -> Bus<T> {
        let mut guard = self.inner.write();
        if let Some(bus) = guard.get(name) {
            return bus.clone();
        }
        let bus = match &self.metrics {
            Some(m) => Bus::new().with_metrics(m.clone()),
            None => Bus::new(),
        };
        guard.insert(name, bus.clone());
        if let Some(m) = &self.metrics {
            // FIX: use the correct gauge field name from Metrics
            m.bus_topics_total.set(guard.len() as i64);
        }
        bus
    }
}

```

### crates/ron-kernel/src/config/mod.rs
<a id="crates-ron-kernel-src-config-mod-rs"></a>

```rust
/*!
Config — load + hot-reload + event emission.

Rules:
- Precedence: ENV > FILE > DEFAULTS.
- Autobump version if a semantic toggle (e.g., amnesia) changes without explicit version.
- No-op writes do not emit `ConfigUpdated`.
*/

use anyhow::Context;
use serde::{Deserialize, Serialize};
use std::{env, fs, path::Path};

/// Kernel configuration loaded from file/env with sane defaults.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct Config {
    /// Monotonically increasing config version used to order updates.
    pub version: u64,
    /// When `true`, run in amnesia mode (RAM-only posture surfaced to metrics).
    pub amnesia: bool,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            version: 1,
            amnesia: true,
        }
    }
}

/// DTO published on the bus when a new configuration becomes active.
#[derive(Debug, Clone)]
pub struct ConfigUpdated {
    /// Version that became active after reload/autobump.
    pub version: u64,
}

/// Load configuration from `path` (if it exists), then apply ENV overrides.
///
/// ENV precedence:
/// - `RON_AMNESIA` — truthy strings: `1|true|on|yes`
/// - `RON_VERSION` — `u64` parse
pub fn load_from(path: impl AsRef<Path>) -> anyhow::Result<Config> {
    // Defaults
    let mut cfg = Config::default();

    // File
    if path.as_ref().exists() {
        let raw = fs::read_to_string(path.as_ref()).with_context(|| "read config file")?;
        let from_file: Config = toml::from_str(&raw).with_context(|| "parse toml")?;
        cfg = from_file;
    }

    // ENV overrides
    if let Ok(s) = env::var("RON_AMNESIA") {
        let s = s.to_ascii_lowercase();
        cfg.amnesia = matches!(s.as_str(), "1" | "true" | "on" | "yes");
    }

    if let Ok(v) = env::var("RON_VERSION") {
        cfg.version = v.parse::<u64>().with_context(|| "RON_VERSION parse")?;
    }

    Ok(cfg)
}

/// Compare `old` vs `new` and decide if we should emit `ConfigUpdated`.
///
/// Logic:
/// - No-op (identical) → `None`
/// - Only `amnesia` flipped and version unchanged → **autobump** and emit
/// - Any change with version increase → emit
pub fn apply_reload(old: &Config, mut new: Config) -> Option<ConfigUpdated> {
    if new == *old {
        return None;
    }

    let amnesia_changed = new.amnesia != old.amnesia;
    let version_increased = new.version > old.version;

    if amnesia_changed && !version_increased {
        // Autobump
        new.version = old.version.saturating_add(1);
        return Some(ConfigUpdated {
            version: new.version,
        });
    }

    if version_increased || amnesia_changed {
        return Some(ConfigUpdated {
            version: new.version,
        });
    }

    None
}

```

### crates/ron-kernel/src/config/validation.rs
<a id="crates-ron-kernel-src-config-validation-rs"></a>

```rust
//! RO:WHAT — Pure validation/sanitization for `Config`.
//! RO:WHY  — Keeps I/O out of validation; enables property/fuzz tests; SEC/RES concern.
//! RO:INTERACTS — config::watcher (apply), metrics/readiness (config_loaded), events.
//! RO:INVARIANTS — Deterministic; no side effects; clamps to safe ranges; deny unknown fields is enforced on the struct.
//! RO:METRICS/LOGS — N/A.
//! RO:CONFIG — Validates ports/timeouts/amnesia; extend as struct grows.
//! RO:SECURITY — Rejects malformed values early.
//! RO:TEST HOOKS — table tests; property: idempotent sanitize.

use std::time::Duration;

use crate::internal::types::BoxError;
use crate::Config; // expected in crate root per project notes

#[derive(thiserror::Error, Debug)]
pub enum ConfigError {
    #[error("invalid port: {0}")]
    InvalidPort(u16),
    #[error("timeout out of range: {0:?}")]
    InvalidTimeout(Duration),
}

const PORT_MIN: u16 = 1;
const PORT_MAX: u16 = 65535;
const TIMEOUT_MIN: Duration = Duration::from_millis(10);
const TIMEOUT_MAX: Duration = Duration::from_secs(300);

pub fn validate(cfg: &Config) -> Result<(), ConfigError> {
    if !(PORT_MIN..=PORT_MAX).contains(&cfg.http_port) {
        return Err(ConfigError::InvalidPort(cfg.http_port));
    }
    if cfg.request_timeout < TIMEOUT_MIN || cfg.request_timeout > TIMEOUT_MAX {
        return Err(ConfigError::InvalidTimeout(cfg.request_timeout));
    }
    // amnesia is boolean; always valid
    Ok(())
}

pub fn sanitize(mut cfg: Config) -> Result<Config, BoxError> {
    if cfg.http_port == 0 {
        cfg.http_port = 9600;
    }
    if cfg.request_timeout < TIMEOUT_MIN {
        cfg.request_timeout = TIMEOUT_MIN;
    } else if cfg.request_timeout > TIMEOUT_MAX {
        cfg.request_timeout = TIMEOUT_MAX;
    }
    Ok(cfg)
}

```

### crates/ron-kernel/src/config/watcher.rs
<a id="crates-ron-kernel-src-config-watcher-rs"></a>

```rust
//! RO:WHAT — Config watchers: filesystem (TOML) + env poller.
//! RO:WHY  — Hot-reload posture without blocking; keep amnesia gauge in sync.
//! RO:INVARIANTS — Non-blocking; no locks across .await; errors are logged and ignored; only emit on real change.

use super::{Config, ConfigCell};
use crate::{Bus, Metrics, events::KernelEvent};
use anyhow::Context;
use notify::{Config as NotifyConfig, Event, EventKind, RecommendedWatcher, RecursiveMode, Watcher};
use std::{env, path::PathBuf, sync::Arc};
use tokio::{fs, sync::mpsc, task};

/// Spawn a file watcher on a TOML file. On write/create, parse and apply if changed.
pub fn spawn_file_watcher(
    path: PathBuf,
    cell: Arc<ConfigCell>,
    bus: Bus,
    metrics: Metrics,
    autobump: bool,
) {
    let (tx, mut rx) = mpsc::unbounded_channel::<()>();

    // Blocking thread for notify (keeps OS handle alive).
    let path_clone = path.clone();
    let _handle = task::spawn_blocking(move || {
        let tx_inner = tx.clone();
        let mut watcher: RecommendedWatcher = RecommendedWatcher::new(
            move |res: Result<Event, notify::Error>| {
                if let Ok(event) = res {
                    match event.kind {
                        EventKind::Create(_) | EventKind::Modify(_) => {
                            let _ = tx_inner.send(());
                        }
                        _ => {}
                    }
                }
            },
            NotifyConfig::default(),
        )
        .expect("create watcher");

        watcher
            .watch(&path_clone, RecursiveMode::NonRecursive)
            .expect("watch path");

        loop {
            std::thread::park();
        }
    });

    // Async side: on signal, reload and apply.
    tokio::spawn(async move {
        while let Some(()) = rx.recv().await {
            if let Err(e) = reload_from_file(&path, &cell, &bus, &metrics, autobump).await {
                eprintln!("[kernel.config] failed to reload {:?}: {e:#}", path);
            }
        }
    });
}

/// Reload the config from TOML and apply it (only if changed). May autobump version.
async fn reload_from_file(
    path: &PathBuf,
    cell: &Arc<ConfigCell>,
    bus: &Bus,
    metrics: &Metrics,
    autobump: bool,
) -> anyhow::Result<()> {
    let bytes = fs::read(path).await.with_context(|| format!("read {:?}", path))?;
    let text = String::from_utf8_lossy(&bytes);
    let mut file_cfg: Config =
        toml::from_str(&text).with_context(|| format!("parse TOML {:?}", path))?;

    let old = cell.get();

    // CONTENT-based change: in our minimal config, content == {amnesia}
    let content_changed = old.amnesia != file_cfg.amnesia;

    if !autobump {
        // Strict mode: apply only when the whole struct differs.
        if *old == file_cfg {
            return Ok(());
        }
        // Apply as-is (file controls version).
        cell.set(file_cfg.clone());
        metrics.set_amnesia(file_cfg.amnesia);
        let _ = bus.publish(KernelEvent::ConfigUpdated { version: file_cfg.version });
        return Ok(());
    }

    // Autobump mode: apply only when content changes; set version = max(file.version, old.version + 1).
    if content_changed {
        if file_cfg.version <= old.version {
            file_cfg.version = old.version.saturating_add(1);
        }
        cell.set(file_cfg.clone());
        metrics.set_amnesia(file_cfg.amnesia);
        let _ = bus.publish(KernelEvent::ConfigUpdated { version: file_cfg.version });
        return Ok(());
    }

    // No content change. Optionally adopt a higher version from file (no event).
    if file_cfg.version > old.version {
        let mut next = (*old).clone();
        next.version = file_cfg.version;
        cell.set(next);
        // No event — content unchanged; version-only bump is local bookkeeping.
    }

    Ok(())
}

/// Spawn an env poller that checks a single key and toggles amnesia on change.
/// Values: on|off|true|false|1|0 (case-insensitive). Emits only on real change; may autobump.
pub fn spawn_env_poller(
    key: &'static str,
    poll_secs: u64,
    cell: Arc<ConfigCell>,
    bus: Bus,
    metrics: Metrics,
    autobump: bool,
) {
    tokio::spawn(async move {
        // Seed from env on boot, if present.
        if let Some(v) = read_bool_env(key) {
            let old = cell.get();
            if old.amnesia != v {
                let mut next = (*old).clone();
                next.amnesia = v;
                if autobump {
                    next.version = next.version.saturating_add(1);
                }
                cell.set(next.clone());
                metrics.set_amnesia(next.amnesia);
                let _ = bus.publish(KernelEvent::ConfigUpdated { version: next.version });
            }
        }

        let mut last = read_bool_env(key);
        let mut interval = tokio::time::interval(std::time::Duration::from_secs(poll_secs));
        loop {
            interval.tick().await;
            let curr = read_bool_env(key);
            if curr != last {
                last = curr;
                if let Some(v) = curr {
                    let old = cell.get();
                    if old.amnesia != v {
                        let mut next = (*old).clone();
                        next.amnesia = v;
                        if autobump {
                            next.version = next.version.saturating_add(1);
                        }
                        cell.set(next.clone());
                        metrics.set_amnesia(next.amnesia);
                        let _ = bus.publish(KernelEvent::ConfigUpdated { version: next.version });
                    }
                }
            }
        }
    });
}

/// Parse boolean-ish env values.
fn read_bool_env(key: &str) -> Option<bool> {
    env::var(key).ok().and_then(|s| match s.to_ascii_lowercase().as_str() {
        "1" | "true" | "on" | "yes" => Some(true),
        "0" | "false" | "off" | "no" => Some(false),
        _ => None,
    })
}

```

### crates/ron-kernel/src/events.rs
<a id="crates-ron-kernel-src-events-rs"></a>

```rust
//! RO:WHAT — KernelEvent enum shared across the kernel bus.
//! RO:WHY  — Central, stable event vocabulary for kernel interactions.
//! RO:INVARIANTS — Backward-compatible additions only; no breaking renames.

/// Events published on the kernel bus.
#[derive(Debug, Clone)]
pub enum KernelEvent {
    /// Health probe from a service (declarative signal).
    Health {
        /// Service name emitting the health status.
        service: String,
        /// Whether the service currently reports healthy.
        ok: bool,
    },
    /// Configuration updated to a monotonic version.
    ConfigUpdated {
        /// Version that became active.
        version: u64,
    },
    /// A supervised service crashed (supervisor should record+restart).
    ServiceCrashed {
        /// Service name that crashed.
        service: String,
    },
    /// Request orderly shutdown of the kernel.
    Shutdown,
}

```

### crates/ron-kernel/src/health/mod.rs
<a id="crates-ron-kernel-src-health-mod-rs"></a>

```rust
/*!
Health state — liveness vs readiness (degrade-first).

- Uses `parking_lot::RwLock` (faster, no poisoning).
- `all_ready()` governs `/readyz` (true → 200, false → 503 + `Retry-After: 1`).
- `missing()` returns a stable list for `/readyz` body.
*/

use parking_lot::RwLock;
use serde::{Deserialize, Serialize};
use std::sync::Arc;

/// Snapshot of coarse-grained health used by kernel/demo routes.
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct HealthSnapshot {
    /// True when essential services are running (supervisors satisfied).
    pub services_ok: bool,
    /// True when configuration load completed and is valid.
    pub config_loaded: bool,
    /// Current amnesia posture (observable; not part of readiness truth).
    pub amnesia: bool,
}

/// Mutable health state with cheap readers and exclusive writers.
#[derive(Debug, Default)]
pub struct HealthState {
    inner: RwLock<HealthSnapshot>,
}

impl HealthState {
    /// Construct a new health state wrapped in `Arc`.
    pub fn new() -> Arc<Self> {
        Arc::new(Self {
            inner: RwLock::new(HealthSnapshot::default()),
        })
    }

    /// Mutate the snapshot in place.
    pub fn set(&self, f: impl FnOnce(&mut HealthSnapshot)) {
        let mut guard = self.inner.write();
        f(&mut guard);
    }

    /// Obtain a cheap cloned snapshot.
    pub fn snapshot(&self) -> HealthSnapshot {
        self.inner.read().clone()
    }

    /// Readiness policy: *both* services and config must be OK.
    pub fn all_ready(&self) -> bool {
        let s = self.inner.read();
        s.services_ok && s.config_loaded
    }

    /// Names of components that currently prevent readiness.
    pub fn missing(&self) -> Vec<String> {
        let s = self.inner.read();
        let mut out = Vec::new();
        if !s.services_ok {
            out.push("services".to_string());
        }
        if !s.config_loaded {
            out.push("config".to_string());
        }
        out
    }
}

```

### crates/ron-kernel/src/internal/constants.rs
<a id="crates-ron-kernel-src-internal-constants-rs"></a>

```rust
//! RO:WHAT — Centralized constants for kernel tuning and invariants.
//! RO:WHY  — Keep perf/backpressure and retry limits consistent with blueprints (avoid drift).
//! RO:INTERACTS — bus capacity (bus::Bus), supervisor backoff (supervisor), readiness (metrics).
//! RO:INVARIANTS — bounded queues; backoff caps; no unbounded growth anywhere.

/// Default broadcast capacity per sender (bounded).
#[allow(dead_code)]
pub const DEFAULT_BUS_CAPACITY: usize = 4096;

/// Supervisor backoff: initial delay in milliseconds.
pub const SUP_BACKOFF_MS_START: u64 = 100;

/// Supervisor backoff cap in milliseconds (jittered up to this).
pub const SUP_BACKOFF_MS_CAP: u64 = 30_000;

```

### crates/ron-kernel/src/internal/mod.rs
<a id="crates-ron-kernel-src-internal-mod-rs"></a>

```rust
//! RO:WHAT — Internal glue (non-public) for kernel constants and helpers.
//! RO:WHY  — Keep public surface frozen; avoid leaking new types.
//! RO:INTERACTS — constants used by bus/supervisor; not re-exported.
pub mod constants;

```

### crates/ron-kernel/src/internal/types.rs
<a id="crates-ron-kernel-src-internal-types-rs"></a>

```rust
//! RO:WHAT — Internal shared type aliases and small enums.
//! RO:WHY  — Reduces duplication and drift across modules; GOV/RES concern.
//! RO:INTERACTS — supervisor, metrics, bus, readiness, config.
//! RO:INVARIANTS — No heavy deps; stable aliases only; no cross-await locks introduced.
//! RO:METRICS/LOGS — N/A.
//! RO:CONFIG — N/A.
//! RO:SECURITY — N/A.
//! RO:TEST HOOKS — Type-only; covered transitively by module tests.

use std::time::Duration;

pub type ServiceName = &'static str;
pub type Version = u64;
pub type Millis = u64;
pub type BoxError = Box<dyn std::error::Error + Send + Sync + 'static>;

/// Default bounded channel capacity for the in-process bus.
pub const DEFAULT_BUS_CAPACITY: usize = 1024;

/// Reason a supervised child stopped.
#[derive(Debug, Clone)]
pub enum CrashReason {
    Panic(String),
    Exit(i32),
    Oom,
    Error(String),
    Unknown,
}

/// Jitter bounds helper.
#[inline]
pub fn clamp_duration(v: Duration, min: Duration, max: Duration) -> Duration {
    if v < min {
        min
    } else if v > max {
        max
    } else {
        v
    }
}

```

### crates/ron-kernel/src/lib.rs
<a id="crates-ron-kernel-src-lib-rs"></a>

```rust
//! # ron-kernel — microkernel core
//!
//! RO:WHAT
//!   Crate root for the RustyOnions microkernel. Exposes the frozen public API:
//!   `Bus`, `KernelEvent`, `Metrics`, `HealthState`, `Config`, and `wait_for_ctrl_c()`.
//!
//! RO:WHY
//!   Provide lifecycle/supervision, readiness gates, config hot-reload, bounded event bus,
//!   and canonical observability surfaces (/metrics, /healthz, /readyz) for nodes.
//!
//! RO:INVARIANTS
//!   - Public API is semver-guarded; perf toggles live behind features and default OFF.
//!   - Readiness contract: `/readyz` returns 503 until BOTH (config_loaded && services_healthy).
//!   - Concurrency: no locks across `.await`; bounded channels; one receiver per task.
//!   - Amnesia mode surfaced via metrics (`amnesia_mode` gauge) and events.
//!
//! See: `examples/kernel_demo` for an integration sanity run.
#![forbid(unsafe_code)]
#![deny(clippy::all, clippy::pedantic)]
#![allow(clippy::module_name_repetitions)]

/// A3 helper — capacity autotune — re-exported at crate root for stable imports in tests/benches.
#[cfg(feature = "bus_autotune_cap")]
pub use crate::bus::autotune_capacity;

// -----------------------------------------------------------------------------
// Internal structure
// -----------------------------------------------------------------------------

pub mod internal {
    pub mod types;
}

pub mod amnesia;

pub mod events;     // KernelEvent enum
pub mod shutdown;   // wait_for_ctrl_c()

// IMPORTANT: use the directory module so we pick up `bus/mod.rs` and its feature wiring.
// (Previously this was an inline `pub mod bus { ... }`, which prevented `bus/mod.rs` from loading.)
pub mod bus;

pub mod metrics;

// Use your existing config module (which itself may declare submodules like watcher/validation)
pub mod config;

// Supervision
pub mod supervisor {
    pub mod backoff;
    pub mod child;
    pub mod lifecycle;
}

// -----------------------------------------------------------------------------
// Frozen public API re-exports (SemVer-guarded)
// -----------------------------------------------------------------------------
pub use crate::bus::bounded::Bus;
pub use crate::events::KernelEvent;
pub use crate::metrics::exporter::Metrics;
pub use crate::metrics::health::HealthState;
pub use crate::shutdown::wait_for_ctrl_c;
pub use crate::config::Config;

// If you maintain an experimental MOG helper module at crate root, keep this.
// If it doesn't exist in your tree, comment/remove the next line to avoid compile errors.
pub mod mog_autotune;

```

### crates/ron-kernel/src/metrics/buffer.rs
<a id="crates-ron-kernel-src-metrics-buffer-rs"></a>

```rust
//! RO:WHAT — Thread-local metric buffers for hot-path counters (feature: metrics_buf).
//! RO:WHY  — PERF: remove atomics from publish path; flush deltas on a timer or threshold.
//! RO:INTERACTS — metrics::exporter::Metrics (Prometheus registry)
//! RO:INVARIANTS — no locks across .await on hot path; best-effort flush on drop
//! RO:METRICS — bus_metrics_tls_flush_total (+ existing counters)
//! RO:CONFIG — flush interval (ms), flush threshold (events)
//! RO:TEST — unit: tls_no_loss_on_drop(); fuzz: interleaved_flush_ordering()

#![cfg(feature = "metrics_buf")]

use prometheus::IntCounter;
use std::{cell::Cell, sync::Arc};
use tokio::sync::Mutex;

thread_local! {
    static PUBLISHED_BUF: Cell<u64> = const { Cell::new(0) };
    static NOTIFY_BUF:    Cell<u64> = const { Cell::new(0) };
}

// Shared sinks owned by the exporter; hot path writes to TLS cells and we flush into these.
#[derive(Clone)]
pub struct BufferedSinks {
    pub published: IntCounter,
    pub notify:    IntCounter,
    pub tls_flush_total: IntCounter,
    // threshold for flushing TLS buffers
    flush_threshold: Arc<usize>,
}

impl BufferedSinks {
    pub fn new(
        published: IntCounter,
        notify: IntCounter,
        tls_flush_total: IntCounter,
        flush_threshold: usize,
    ) -> Self {
        // Guardrail: enforce a minimum of 64 to avoid per-message flush in prod.
        Self {
            published,
            notify,
            tls_flush_total,
            flush_threshold: Arc::new(flush_threshold.max(64)),
        }
    }

    #[inline]
    pub fn add_published(&self, n: u64) {
        if n == 0 {
            return;
        }
        PUBLISHED_BUF.with(|c| c.set(c.get().saturating_add(n)));
        self.maybe_flush();
    }

    #[inline]
    pub fn add_notify(&self, n: u64) {
        if n == 0 {
            return;
        }
        NOTIFY_BUF.with(|c| c.set(c.get().saturating_add(n)));
        self.maybe_flush();
    }

    #[inline]
    fn maybe_flush(&self) {
        let thr = *self.flush_threshold as u64;
        let mut do_flush = false;
        PUBLISHED_BUF.with(|c| if c.get() >= thr { do_flush = true; });
        NOTIFY_BUF.with(|c| if c.get() >= thr { do_flush = true; });
        if do_flush {
            self.flush();
        }
    }

    pub fn flush(&self) {
        let mut p = 0u64;
        let mut n = 0u64;
        PUBLISHED_BUF.with(|c| {
            p = c.get();
            c.set(0);
        });
        NOTIFY_BUF.with(|c| {
            n = c.get();
            c.set(0);
        });
        if p != 0 {
            self.published.inc_by(p);
        }
        if n != 0 {
            self.notify.inc_by(n);
        }
        if p != 0 || n != 0 {
            self.tls_flush_total.inc();
        }
    }
}

// Background pump handle (periodically flush TLS buffers into shared counters).
#[derive(Clone)]
pub struct FlushPump {
    sinks: BufferedSinks,
    // keep a stop latch if you want (not strictly required in the kernel's long-lived proc)
    stop: Arc<Mutex<bool>>,
}

impl FlushPump {
    pub fn new(sinks: BufferedSinks) -> Self {
        Self {
            sinks,
            stop: Arc::new(Mutex::new(false)),
        }
    }

    /// Convenience for exporter: build a pump from the hot counters facade.
    pub fn new_from_hot(hot: Arc<HotCounters>) -> Self {
        // Same module, can access the inner to clone sinks.
        Self::new(hot.0.clone())
    }

    pub async fn run(self, interval_ms: u64) {
        let mut ticker =
            tokio::time::interval(std::time::Duration::from_millis(interval_ms.max(1)));
        loop {
            ticker.tick().await;
            if *self.stop.lock().await {
                break;
            }
            self.sinks.flush();
        }
    }
}

// Public facade used by the bus (hot path).
#[derive(Clone)]
pub struct HotCounters(pub(super) BufferedSinks);

impl HotCounters {
    pub fn new(sinks: BufferedSinks) -> Self {
        Self(sinks)
    }
    #[inline]
    pub fn inc_published(&self) {
        self.0.add_published(1);
    }
    #[inline]
    pub fn add_published(&self, n: u64) {
        self.0.add_published(n);
    }
    #[inline]
    pub fn inc_notify(&self) {
        self.0.add_notify(1);
    }
}

/// Best-effort drop flush to avoid counter loss on thread teardown.
impl Drop for HotCounters {
    fn drop(&mut self) {
        self.0.flush();
    }
}

```

### crates/ron-kernel/src/metrics/exporter.rs
<a id="crates-ron-kernel-src-metrics-exporter-rs"></a>

```rust
//! RO:WHAT — Prometheus exporter + metrics registry; mounts /metrics, /healthz, /readyz.
//! RO:WHY  — Observability pillar; RED metrics and kernel signals for ops; PERF/RES concerns.
//! RO:PERF — Optional thread-local metrics buffering (feature: `metrics_buf`) removes atomics from the hot path.
//! RO:MOG  — A1/A5 edge notify counters; A2 batch publish counters; TLS buffer flush counter.

use std::{net::SocketAddr, sync::Arc};

use axum::{routing::get, Router};
use prometheus::{
    Encoder, Histogram, HistogramOpts, IntCounter, IntCounterVec, IntGauge, Opts, Registry,
    TextEncoder,
};
use tokio::{net::TcpListener, task::JoinHandle};

use crate::internal::types::{BoxError, ServiceName};
use crate::metrics::{health::HealthState, readiness::Readiness};
use crate::Bus;

#[cfg(feature = "metrics_buf")]
use crate::metrics::buffer::{BufferedSinks, FlushPump, HotCounters};

/// Kernel metrics registry and handles.
#[derive(Clone)]
pub struct Metrics {
    pub registry: Registry,
    pub request_latency_seconds: Histogram,

    pub service_restarts_total: IntCounterVec,

    // Bus counters/gauges
    pub bus_published_total: IntCounter,
    pub bus_no_receivers_total: IntCounter,
    pub bus_receiver_lag_total: IntCounter,
    pub bus_dropped_total: IntCounter,
    pub bus_topics_total: IntGauge,

    // MOG A1/A5 telemetry
    pub bus_notify_sends_total: IntCounter,
    pub bus_notify_suppressed_total: IntCounter,

    // MOG A2 telemetry
    pub bus_batch_publish_total: IntCounter,
    pub bus_batch_len_histogram: Histogram,

    // TLS metrics buffering visibility
    #[cfg(feature = "metrics_buf")]
    pub bus_metrics_tls_flush_total: IntCounter,

    // Expose configured TLS threshold as a gauge for easy verification
    #[cfg(feature = "metrics_buf")]
    pub bus_metrics_tls_threshold: IntGauge,

    pub amnesia_mode: IntGauge,

    // Hot-path counters facade (kept behind Arc to avoid per-call Drop)
    #[cfg(feature = "metrics_buf")]
    hot: Option<Arc<HotCounters>>,
}

impl Metrics {
    pub fn new(initial_amnesia: bool) -> Arc<Self> {
        let registry = Registry::new();

        let request_latency_seconds = Histogram::with_opts(
            HistogramOpts::new("request_latency_seconds", "Kernel request latency (seconds)")
                .buckets(vec![
                    0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0,
                ]),
        )
        .expect("histogram");

        let service_restarts_total = IntCounterVec::new(
            Opts::new("service_restarts_total", "Total restarts of supervised services"),
            &["service"],
        )
        .expect("counter vec");

        let bus_published_total = IntCounter::with_opts(Opts::new(
            "bus_published_total",
            "Total messages published on kernel bus",
        ))
        .unwrap();
        let bus_no_receivers_total = IntCounter::with_opts(Opts::new(
            "bus_no_receivers_total",
            "Publishes with zero receivers",
        ))
        .unwrap();
        let bus_receiver_lag_total = IntCounter::with_opts(Opts::new(
            "bus_receiver_lag_total",
            "Lagged/missed messages observed by receivers",
        ))
        .unwrap();
        let bus_dropped_total = IntCounter::with_opts(Opts::new(
            "bus_dropped_total",
            "Messages dropped due to closed/overrun channel",
        ))
        .unwrap();
        let bus_topics_total =
            IntGauge::with_opts(Opts::new("bus_topics_total", "Number of distinct topic buses"))
                .unwrap();

        // A1/A5
        let bus_notify_sends_total = IntCounter::with_opts(Opts::new(
            "bus_notify_sends_total",
            "Edge-triggered notifies sent to subscribers",
        ))
        .unwrap();
        let bus_notify_suppressed_total = IntCounter::with_opts(Opts::new(
            "bus_notify_suppressed_total",
            "Notifies suppressed by pending=true (coalesced)",
        ))
        .unwrap();

        // A2
        let bus_batch_publish_total = IntCounter::with_opts(Opts::new(
            "bus_batch_publish_total",
            "Calls to publish_many (A2)",
        ))
        .unwrap();
        let bus_batch_len_histogram = Histogram::with_opts(
            HistogramOpts::new("bus_batch_len_histogram", "publish_many batch sizes (A2)")
                .buckets(vec![
                    1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0, 512.0, 1024.0,
                ]),
        )
        .expect("histogram");

        // Amnesia gauge
        let amnesia_mode =
            IntGauge::with_opts(Opts::new("amnesia_mode", "1 when amnesia mode is enabled"))
                .unwrap();

        // Register all
        registry.register(Box::new(request_latency_seconds.clone())).unwrap();
        registry.register(Box::new(service_restarts_total.clone())).unwrap();
        registry.register(Box::new(bus_published_total.clone())).unwrap();
        registry.register(Box::new(bus_no_receivers_total.clone())).unwrap();
        registry.register(Box::new(bus_receiver_lag_total.clone())).unwrap();
        registry.register(Box::new(bus_dropped_total.clone())).unwrap();
        registry.register(Box::new(bus_topics_total.clone())).unwrap();
        registry.register(Box::new(bus_notify_sends_total.clone())).unwrap();
        registry.register(Box::new(bus_notify_suppressed_total.clone())).unwrap();
        registry.register(Box::new(bus_batch_publish_total.clone())).unwrap();
        registry.register(Box::new(bus_batch_len_histogram.clone())).unwrap();
        registry.register(Box::new(amnesia_mode.clone())).unwrap();

        // TLS buffering metrics
        #[cfg(feature = "metrics_buf")]
        let bus_metrics_tls_flush_total = {
            let c = IntCounter::with_opts(Opts::new(
                "bus_metrics_tls_flush_total",
                "TLS metrics buffer flushes (visibility when buffering is enabled)",
            ))
            .unwrap();
            registry.register(Box::new(c.clone())).ok();
            c
        };

        #[cfg(feature = "metrics_buf")]
        let bus_metrics_tls_threshold = {
            let g = IntGauge::with_opts(Opts::new(
                "bus_metrics_tls_threshold",
                "Configured TLS flush threshold",
            ))
            .unwrap();
            registry.register(Box::new(g.clone())).ok();
            g
        };

        // Choose and publish the threshold; construct sinks + hot facade.
        #[cfg(feature = "metrics_buf")]
        let (hot, chosen_threshold) = {
            let threshold: usize = 64; // tune under benches (64..512)
            let sinks = BufferedSinks::new(
                bus_published_total.clone(),
                bus_notify_sends_total.clone(),
                bus_metrics_tls_flush_total.clone(),
                threshold,
            );
            (Some(Arc::new(HotCounters::new(sinks))), threshold)
        };

        #[cfg(feature = "metrics_buf")]
        {
            bus_metrics_tls_threshold.set(chosen_threshold as i64);
            tracing::info!(
                threshold = chosen_threshold,
                "metrics_buf enabled; TLS flush threshold configured"
            );
        }

        let me = Arc::new(Self {
            registry,
            request_latency_seconds,
            service_restarts_total,
            bus_published_total,
            bus_no_receivers_total,
            bus_receiver_lag_total,
            bus_dropped_total,
            bus_topics_total,
            bus_notify_sends_total,
            bus_notify_suppressed_total,
            bus_batch_publish_total,
            bus_batch_len_histogram,
            #[cfg(feature = "metrics_buf")]
            bus_metrics_tls_flush_total,
            #[cfg(feature = "metrics_buf")]
            bus_metrics_tls_threshold,
            amnesia_mode,
            #[cfg(feature = "metrics_buf")]
            hot,
        });

        me.set_amnesia(initial_amnesia);
        me
    }

    pub fn set_amnesia(&self, on: bool) {
        self.amnesia_mode.set(if on { 1 } else { 0 });
    }

    /// Start HTTP server exposing /metrics, /healthz, /readyz.
    pub async fn serve(
        self: Arc<Self>,
        addr: SocketAddr,
        health: HealthState,
        ready: Readiness,
    ) -> Result<(JoinHandle<()>, SocketAddr), BoxError> {
        let listener = TcpListener::bind(addr).await?;
        let local = listener.local_addr()?;

        let registry = self.registry.clone();
        let app = Router::new()
            .route(
                "/metrics",
                get(move || {
                    let registry = registry.clone();
                    async move {
                        let mf = registry.gather();
                        let mut buf = Vec::new();
                        TextEncoder::new().encode(&mf, &mut buf).unwrap();
                        (axum::http::StatusCode::OK, buf)
                    }
                }),
            )
            .route("/healthz", get({
                let health = health.clone();
                move || crate::metrics::health::healthz_handler(health.clone())
            }))
            .route("/readyz", get({
                let ready = ready.clone();
                move || crate::metrics::readiness::readyz_handler(ready.clone())
            }));

        let handle = tokio::spawn(async move {
            axum::serve(listener, app).await.ok();
        });

        #[cfg(feature = "metrics_buf")]
        if let Some(hot) = self.hot.clone() {
            let pump = FlushPump::new_from_hot(hot);
            tokio::spawn(async move { pump.run(200).await }); // ~200ms cadence
        }

        Ok((handle, local))
    }

    pub fn inc_restart(&self, service: ServiceName) {
        self.service_restarts_total
            .with_label_values(&[service])
            .inc();
    }

    pub fn make_bus<T: Clone + Send + 'static>(self: &Arc<Self>, capacity: usize) -> Bus<T> {
        use crate::bus::bounded::Bus;
        Bus::with_capacity(capacity).with_metrics(self.clone())
    }

    #[cfg(feature = "metrics_buf")]
    #[inline]
    pub fn hot(&self) -> Option<&HotCounters> {
        self.hot.as_deref()
    }
}

```

### crates/ron-kernel/src/metrics/health.rs
<a id="crates-ron-kernel-src-metrics-health-rs"></a>

```rust
use std::collections::BTreeMap;
use std::sync::Arc;

use axum::{response::IntoResponse, Json};
use parking_lot::RwLock;

use crate::internal::types::ServiceName;

#[derive(Clone)]
pub struct HealthState {
    inner: Arc<RwLock<BTreeMap<ServiceName, bool>>>,
}

impl HealthState {
    pub fn new() -> Self {
        Self {
            inner: Arc::new(RwLock::new(BTreeMap::new())),
        }
    }

    pub fn set(&self, service: ServiceName, ok: bool) {
        let mut w = self.inner.write();
        w.insert(service, ok);
    }

    pub fn snapshot(&self) -> BTreeMap<ServiceName, bool> {
        self.inner.read().clone()
    }

    pub fn all_ready(&self) -> bool {
        // Not ready until at least one service has reported AND all are healthy.
        let r = self.inner.read();
        !r.is_empty() && r.values().all(|v| *v)
    }
}

pub async fn healthz_handler(state: HealthState) -> impl IntoResponse {
    if state.all_ready() {
        let body = serde_json::to_value(state.snapshot()).unwrap();
        (axum::http::StatusCode::OK, Json(body))
    } else {
        let body = state
            .snapshot()
            .into_iter()
            .filter(|(_, ok)| !*ok)
            .map(|(k, _)| k)
            .collect::<Vec<_>>();
        (
            axum::http::StatusCode::SERVICE_UNAVAILABLE,
            Json(serde_json::json!({ "unhealthy": body })),
        )
    }
}

impl Default for HealthState {
    fn default() -> Self {
        Self::new()
    }
}

```

### crates/ron-kernel/src/metrics/mod.rs
<a id="crates-ron-kernel-src-metrics-mod-rs"></a>

```rust
//! RO:WHAT — Metrics module index and re-exports for RON-CORE.
//! RO:WHY  — Centralize exporter + health + readiness; expose optional TLS buffering at `metrics::buffer`.

pub mod exporter;
pub mod health;
pub mod readiness;

// Declare the submodule *unconditionally* so the name `crate::metrics::buffer` always exists.
// The file itself is feature-gated internally, so this is safe in all builds.
pub mod buffer;

// Re-export the primary metrics type so call-sites can use `crate::metrics::Metrics`.
pub use exporter::Metrics;

// Convenience re-exports (common call-sites).
pub use health::HealthState;
pub use readiness::Readiness;

```

### crates/ron-kernel/src/metrics/readiness.rs
<a id="crates-ron-kernel-src-metrics-readiness-rs"></a>

```rust
use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc,
};

use axum::{response::IntoResponse, Json};

use crate::metrics::health::HealthState;

#[derive(Clone)]
pub struct Readiness {
    health: HealthState,
    config_loaded: Arc<AtomicBool>,
}

impl Readiness {
    pub fn new(health: HealthState) -> Self {
        Self {
            health,
            config_loaded: Arc::new(AtomicBool::new(false)),
        }
    }

    pub fn set_config_loaded(&self, yes: bool) {
        self.config_loaded.store(yes, Ordering::Relaxed);
    }

    pub fn ready(&self) -> bool {
        self.config_loaded.load(Ordering::Relaxed) && self.health.all_ready()
    }
}

pub async fn readyz_handler(state: Readiness) -> axum::response::Response {
    if state.ready() {
        (axum::http::StatusCode::OK, Json(serde_json::json!({ "ready": true }))).into_response()
    } else {
        let mut missing = vec![];
        if !state.config_loaded.load(std::sync::atomic::Ordering::Relaxed) {
            missing.push("config");
        }
        if !state.health.all_ready() {
            missing.push("services");
        }
        let mut resp = axum::response::Response::new(
            serde_json::to_vec(&serde_json::json!({ "missing": missing }))
                .unwrap()
                .into(),
        );
        *resp.status_mut() = axum::http::StatusCode::SERVICE_UNAVAILABLE;
        resp.headers_mut()
            .insert("Retry-After", axum::http::HeaderValue::from_static("3"));
        resp
    }
}

```

### crates/ron-kernel/src/mog_autotune.rs
<a id="crates-ron-kernel-src-mogautotune-rs"></a>

```rust
/*!
MOG A3 — Capacity Autotune + Guardrails (feature: `bus_autotune_cap`)

Purpose:
- Provide a safe, side-effect free helper to pick a ring/channel capacity from the expected load.
- This does NOT mutate global state; callers must opt-in to use it.

Integration:
- Call `autotune_capacity(expected_subs, override_cap)` from your Bus builder.
- If `override_cap` is `Some`, it wins (after normalization).
- Otherwise (feature ON) we choose plateaus: <=4 → 64, <=16 → 128, else → 256.
- Feature OFF: conservative 128 default.

Observability:
- Warn if chosen capacity >256 (cache-hostile territory for typical workloads).

Safety:
- No panics. Always returns >= 2. Overrides are rounded to power-of-two and clamped.
*/

#![allow(dead_code)] // until wired in by a builder

use core::cmp::{max, min};

/// Returns a recommended capacity given the expected subscriber count
/// and an optional explicit override.
///
/// Feature gating:
/// - `bus_autotune_cap` **enabled**: use plateau heuristic when `override_cap` is None.
/// - Feature **disabled**: honor override (normalized) or fall back to 128.
///
/// Invariants:
/// - Never returns < 2.
/// - Overrides are rounded to the next power-of-two and clamped to [2, 65_536].
#[allow(unused_variables)]
pub fn autotune_capacity(expected_subs: usize, override_cap: Option<usize>) -> usize {
    cfg_if::cfg_if! {
        if #[cfg(feature = "bus_autotune_cap")] {
            // If caller provides override, respect it after normalization.
            if let Some(c) = override_cap {
                return normalize_override(c);
            }

            // Plateau heuristic tuned for cache-local rings.
            let chosen = if expected_subs <= 4 {
                64
            } else if expected_subs <= 16 {
                128
            } else {
                256
            };

            if chosen > 256 {
                tracing::warn!(
                    cap = chosen,
                    expected_subs,
                    "bus_autotune_cap: capacity >256 is likely cache-hostile; consider 64/128/256 unless proven otherwise"
                );
            }
            chosen
        } else {
            // Feature disabled: be conservative/predictable.
            match override_cap {
                Some(c) => normalize_override(c),
                None => 128,
            }
        }
    }
}

/// Normalize a caller-provided override:
/// - minimum of 2
/// - clamped to 65_536
/// - rounded up to next power-of-two
#[inline]
fn normalize_override(cap: usize) -> usize {
    let bounded = min(max(cap, 2), 65_536);
    next_pow2(bounded)
}

#[inline]
fn next_pow2(n: usize) -> usize {
    if n <= 2 { return 2; }
    n.next_power_of_two()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn override_is_normalized_pow2_and_clamped() {
        assert_eq!(autotune_capacity(0, Some(1)), 2);
        assert_eq!(autotune_capacity(0, Some(3)), 4);
        assert_eq!(autotune_capacity(0, Some(64)), 64);
        assert_eq!(autotune_capacity(0, Some(65_000)), 65_536);
        assert_eq!(autotune_capacity(0, Some(100_000)), 65_536);
    }

    #[test]
    fn default_when_disabled_is_reasonable() {
        // This holds regardless of feature; with feature ON, values are >=64,
        // with feature OFF default is 128.
        let cap = autotune_capacity(8, None);
        assert!(cap >= 64);
    }

    #[test]
    fn heuristic_plateaus_are_expected_when_enabled() {
        // These assertions hold for feature-enabled builds; for feature-off they
        // still validate general bounds.
        let small = autotune_capacity(1, None);
        let mid   = autotune_capacity(8, None);
        let big   = autotune_capacity(32, None);

        assert!(small >= 64, "small expected ≥64, got {}", small);
        assert!(mid   >= 64 && mid <= 256, "mid in [64,256], got {}", mid);
        assert!(big   >= 128, "big expected ≥128, got {}", big);
    }
}

```

### crates/ron-kernel/src/shutdown.rs
<a id="crates-ron-kernel-src-shutdown-rs"></a>

```rust
//! RO:WHAT — Helper to await Ctrl+C for cooperative shutdown.
//! RO:WHY  — Common pattern for binaries to align with kernel readiness and graceful stop.
//! RO:INTERACTS — May be used to trigger KernelEvent::Shutdown by callers (kernel doesn't emit it automatically).
//! RO:INVARIANTS — async-signal safe; no blocking in Drop.

/// Wait for a Ctrl+C signal.
pub async fn wait_for_ctrl_c() {
    let _ = tokio::signal::ctrl_c().await;
}

```

### crates/ron-kernel/src/supervisor/backoff.rs
<a id="crates-ron-kernel-src-supervisor-backoff-rs"></a>

```rust
//! RO:WHAT — Jittered exponential backoff with cap and reset.
//! RO:WHY  — Prevents thundering herds on crash-loops; RES concern.
//! RO:INTERACTS — lifecycle.rs (sleep scheduling), child.rs (restart cadence).
//! RO:INVARIANTS — Monotone until cap; jitter bounded; no panics on edge cases.
//! RO:METRICS/LOGS — None (observed externally by restart counters).
//! RO:CONFIG — init/max/factor/jitter ranges validated by config layer.
//! RO:SECURITY — N/A.
//! RO:TEST HOOKS — unit: sequence grows; jitter within bounds; reset works.

use rand::{rng, Rng};
use std::time::Duration;

#[derive(Debug, Clone)]
pub struct Backoff {
    current: Duration,
    init: Duration,
    max: Duration,
    factor: f64,
    jitter: f64, // 0.2 => ±20%
}

impl Backoff {
    pub fn new(init: Duration, max: Duration, factor: f64, jitter: f64) -> Self {
        let init = if init.is_zero() { Duration::from_millis(100) } else { init };
        let max = if max < init { init } else { max };
        let factor = if factor < 1.0 { 1.0 } else { factor };
        let jitter = jitter.clamp(0.0, 1.0);
        Self {
            current: init,
            init,
            max,
            factor,
            jitter,
        }
    }

    pub fn next(&mut self) -> Duration {
        let base = self.current;
        // prepare next (monotone up to cap)
        let next = Duration::from_secs_f64((base.as_secs_f64() * self.factor).min(self.max.as_secs_f64()));
        self.current = next;

        // apply jitter to current sleep (the 'base' value)
        if self.jitter == 0.0 {
            return base;
        }
        let j = rng().random_range(-self.jitter..=self.jitter);
        let secs = base.as_secs_f64() * (1.0 + j);
        Duration::from_secs_f64(secs.clamp(self.init.as_secs_f64(), self.max.as_secs_f64()))
    }

    pub fn reset(&mut self) {
        self.current = self.init;
    }
}

```

### crates/ron-kernel/src/supervisor/child.rs
<a id="crates-ron-kernel-src-supervisor-child-rs"></a>

```rust
use std::future::Future;
use tokio::task;

use crate::events::KernelEvent;
use crate::internal::types::{BoxError, ServiceName};
use crate::metrics::exporter::Metrics;
use crate::Bus;

pub async fn run_once<F, Fut>(
    name: ServiceName,
    metrics: &Metrics,
    bus: &Bus<KernelEvent>,
    work: F,
) -> Result<(), BoxError>
where
    F: Fn() -> Fut + Send + Sync + 'static,
    Fut: Future<Output = Result<(), BoxError>> + Send + 'static,
{
    let join = task::spawn(async move { work().await }).await;

    match join {
        Ok(Ok(())) => {
            metrics.inc_restart(name);
            bus.publish(KernelEvent::ServiceCrashed { service: name.to_string() });
            Ok(())
        }
        Ok(Err(e)) => {
            metrics.inc_restart(name);
            bus.publish(KernelEvent::ServiceCrashed { service: name.to_string() });
            Err(e)
        }
        Err(_join_err) => {
            metrics.inc_restart(name);
            bus.publish(KernelEvent::ServiceCrashed { service: name.to_string() });
            Ok(())
        }
    }
}

```

### crates/ron-kernel/src/supervisor/lifecycle.rs
<a id="crates-ron-kernel-src-supervisor-lifecycle-rs"></a>

```rust
use std::collections::VecDeque;
use std::time::{Duration, Instant};

use crate::events::KernelEvent;
use crate::internal::types::{BoxError, ServiceName};
use crate::metrics::{exporter::Metrics, health::HealthState};
use crate::Bus;

use super::backoff::Backoff;
use super::child::run_once;

pub struct Supervisor {
    name: ServiceName,
    metrics: Metrics,
    bus: Bus<KernelEvent>,
    health: HealthState,
    backoff: Backoff,
    max_restarts: u32,
    window: Duration,
    recent: VecDeque<Instant>,
}

impl Supervisor {
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        name: ServiceName,
        metrics: Metrics,
        bus: Bus<KernelEvent>,
        health: HealthState,
        backoff: Backoff,
        max_restarts: u32,
        window: Duration,
    ) -> Self {
        Self {
            name,
            metrics,
            bus,
            health,
            backoff,
            max_restarts,
            window,
            recent: VecDeque::with_capacity(max_restarts as usize + 1),
        }
    }

    pub async fn run<F, Fut>(&mut self, work: F) -> !
    where
        F: Fn() -> Fut + Send + Sync + Clone + 'static,
        Fut: std::future::Future<Output = Result<(), BoxError>> + Send + 'static,
    {
        self.health.set(self.name, true);
        loop {
            let factory = work.clone();
            let _ = run_once(self.name, &self.metrics, &self.bus, factory).await;
            self.health.set(self.name, false);

            let now = Instant::now();
            self.recent.push_back(now);
            while let Some(&front) = self.recent.front() {
                if now.duration_since(front) > self.window {
                    self.recent.pop_front();
                } else {
                    break;
                }
            }
            if self.recent.len() as u32 > self.max_restarts {
                let _ = self.backoff.next();
                let cap = self.backoff.next();
                tokio::time::sleep(cap).await;
                continue;
            }

            let sleep = self.backoff.next();
            tokio::time::sleep(sleep).await;
            self.health.set(self.name, true);
        }
    }
}

```

### crates/ron-kernel/src/supervisor/mod.rs
<a id="crates-ron-kernel-src-supervisor-mod-rs"></a>

```rust
//! RO:WHAT — Crash-only supervision with jittered exponential backoff and labeled restart metrics.
//! RO:WHY  — RESilience: children may crash; we restart with backoff and publish ServiceCrashed.
//! RO:INTERACTS — metrics::Metrics (service_restarts_total{service}); bus::Bus (ServiceCrashed).
//! RO:INVARIANTS — jittered backoff (100ms→30s cap), intensity cap optional; no lock across .await.

use crate::{events::KernelEvent, metrics::Metrics};
use anyhow::Result;
use rand::{rng, Rng};
use std::future::Future;
use tokio::time::{sleep, Duration};

fn jitter_ms(base: u64) -> u64 {
    if base <= 1 {
        return 1;
    }
    let mut r = rng();
    let half = base / 2;
    half + r.random_range(0..half.max(1))
}

/// Supervise an async child factory. On error, increments labeled restart metric and emits ServiceCrashed.
/// The `spawn` closure should create a fresh future each attempt.
pub async fn supervise_with_backoff<Fut, Spawn>(
    service: &str,
    metrics: Metrics,
    bus: crate::bus::Bus,
    mut spawn: Spawn,
) -> !
where
    Fut: Future<Output = Result<()>> + Send + 'static,
    Spawn: FnMut() -> Fut + Send + 'static,
{
    let service_name = service.to_string();
    let mut backoff = crate::internal::constants::SUP_BACKOFF_MS_START;

    loop {
        let res = spawn().await;
        if let Err(err) = res {
            // Publish crash and count a restart.
            let _ = bus.publish(KernelEvent::ServiceCrashed {
                service: service_name.clone(),
                reason: err.to_string(),
            });
            metrics
                .service_restarts_total
                .with_label_values(&[&service_name])
                .inc();
        }
        // Sleep with jitter (cap at 30s).
        backoff = (backoff.saturating_mul(2)).min(crate::internal::constants::SUP_BACKOFF_MS_CAP);
        let sleep_ms = jitter_ms(backoff);
        sleep(Duration::from_millis(sleep_ms)).await;
    }
}

#[cfg(test)]
mod tests {
    use super::jitter_ms;

    #[test]
    fn jitter_is_within_bounds_and_nonzero() {
        // Basic sanity: jitter must be at least 1 and not exceed base.
        for &base in &[2, 4, 8, 16, 32, 64, 128] {
            let j = jitter_ms(base);
            assert!(j >= 1, "jitter must be >=1");
            assert!(j <= base, "jitter must be <= base (got {} for {})", j, base);
        }
        // Base 1 -> clamped to 1.
        assert_eq!(jitter_ms(1), 1);
        assert_eq!(jitter_ms(0), 1);
    }
}

```

### crates/ron-kernel/testing/performance/publish_matrix.toml
<a id="crates-ron-kernel-testing-performance-publishmatrix-toml"></a>

```toml
[runs.default]
publish_rps = [100, 500, 1000]
fanout = [1, 4, 8]
duration_secs = 30

```

### crates/ron-kernel/tests/amnesia_label.rs
<a id="crates-ron-kernel-tests-amnesialabel-rs"></a>

```rust
use ron_kernel::Metrics;

#[test]
fn amnesia_gauge_flips_between_0_and_1() {
    let metrics = Metrics::new(false);

    // starts at 0
    assert_eq!(metrics.amnesia_mode.get(), 0);

    // flip on -> 1
    metrics.set_amnesia(true);
    assert_eq!(metrics.amnesia_mode.get(), 1);

    // flip off -> 0
    metrics.set_amnesia(false);
    assert_eq!(metrics.amnesia_mode.get(), 0);
}

```

### crates/ron-kernel/tests/autotune_capacity.rs
<a id="crates-ron-kernel-tests-autotunecapacity-rs"></a>

```rust
#![cfg(feature = "bus_autotune_cap")]
use ron_kernel::autotune_capacity;



#[test]
fn mapping_basic_thresholds() {
    assert_eq!(autotune_capacity(0, None), 64);
    assert_eq!(autotune_capacity(1, None), 64);
    assert_eq!(autotune_capacity(4, None), 64);
    assert_eq!(autotune_capacity(5, None), 128);
    assert_eq!(autotune_capacity(16, None), 128);
    assert_eq!(autotune_capacity(17, None), 256);
    assert_eq!(autotune_capacity(64, None), 256);
}

#[test]
fn override_is_respected() {
    assert_eq!(autotune_capacity(1, Some(128)), 128);
    assert_eq!(autotune_capacity(32, Some(64)), 64);
}

#[test]
fn monotone_in_n_with_default_map() {
    let mut prev = 0;
    for n in 0..200 {
        let cap = autotune_capacity(n, None);
        assert!(cap >= prev);
        prev = cap;
    }
}

```

### crates/ron-kernel/tests/autotune_sanity.rs
<a id="crates-ron-kernel-tests-autotunesanity-rs"></a>

```rust
use criterion::{criterion_group, criterion_main, Criterion, black_box};

fn bench_autotune(c: &mut Criterion) {
    let mut g = c.benchmark_group("autotune");
    g.bench_function("expected_4_none", |b| {
        b.iter(|| {
            let mut sum = 0usize;
            for n in 0..1000 {
                // Call through a small trampoline to avoid LTO folding in release.
                sum ^= tramp(4 + (n & 1));
            }
            black_box(sum)
        })
    });
    g.finish();
}

#[inline(never)]
fn tramp(expected: usize) -> usize {
    ron_kernel::mog_autotune::autotune_capacity(expected, None)
}

criterion_group!(benches, bench_autotune);
criterion_main!(benches);

```

### crates/ron-kernel/tests/bus_basics.rs
<a id="crates-ron-kernel-tests-busbasics-rs"></a>

```rust
use ron_kernel::{Bus, KernelEvent, Metrics};

#[tokio::test]
async fn zero_and_one_subscriber_paths() {
    let metrics = Metrics::new(false);
    let bus: Bus<KernelEvent> = Bus::new().with_metrics(metrics.clone());

    // 0 subscribers -> publish returns 0
    let delivered = bus.publish(KernelEvent::Shutdown);
    assert_eq!(delivered, 0, "no subscribers -> delivered count should be 0");

    // subscribe one receiver -> publish returns 1
    let mut rx = bus.subscribe();
    let delivered2 = bus.publish(KernelEvent::Shutdown);
    assert_eq!(delivered2, 1, "one subscriber -> delivered should be 1");

    // drain without lag (and exercise helper)
    let _ = Bus::handle_recv(rx.recv().await, Some(&metrics));
}

```

### crates/ron-kernel/tests/bus_bounded.rs
<a id="crates-ron-kernel-tests-busbounded-rs"></a>

```rust
//! Bounded bus: lag accounting and publish semantics.

use ron_kernel::{Bus, KernelEvent, Metrics};

#[tokio::test]
async fn lagged_receiver_increments_lag_counter_and_publish_counts() {
    let metrics = Metrics::new(false);
    // small capacity to force lag quickly
    let bus: Bus<KernelEvent> = Bus::with_capacity(8).with_metrics(metrics.clone());
    let mut rx = bus.subscribe();

    // With one subscriber, publish returns 1
    let n = bus.publish(KernelEvent::ConfigUpdated { version: 1 });
    assert_eq!(n, 1);

    // Overflow receiver by sending many without reading
    for i in 0..2048usize {
        let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
    }

    // Receiver sees either a value or Lagged; account via helper
    let _ = Bus::handle_recv(rx.recv().await, Some(&metrics));

    // We should have observed some lag
    assert!(
        metrics.bus_receiver_lag_total.get() > 0,
        "expected bus_receiver_lag_total to increase"
    );
}

```

### crates/ron-kernel/tests/bus_close_semantics.rs
<a id="crates-ron-kernel-tests-busclosesemantics-rs"></a>

```rust
//! When the sender is dropped, broadcast receivers observe `Closed`.

use ron_kernel::Bus;

#[tokio::test]
async fn receiver_observes_closed_on_sender_drop() {
    let bus: Bus<String> = Bus::with_capacity(8);
    let mut rx = bus.subscribe();

    // Drop all senders (cloned senders would need dropping too; we have only one)
    drop(bus);

    // Receiver should now get Err(Closed)
    let res = rx.recv().await;
    assert!(matches!(
        res,
        Err(tokio::sync::broadcast::error::RecvError::Closed)
    ));
}

```

### crates/ron-kernel/tests/bus_contract.rs
<a id="crates-ron-kernel-tests-buscontract-rs"></a>

```rust
use ron_kernel::{Bus, KernelEvent, Metrics};

#[tokio::test]
async fn publish_zero_subscribers_counts_and_returns_zero() {
    let metrics = Metrics::new(false);
    let bus: Bus<KernelEvent> = Bus::new().with_metrics(metrics.clone());

    let n = bus.publish(KernelEvent::Shutdown);
    assert_eq!(n, 0);

    let m = bus.publish(KernelEvent::Shutdown);
    assert_eq!(m, 0);
}

#[tokio::test]
async fn publish_with_subscriber_returns_one() {
    let metrics = Metrics::new(false);
    let bus: Bus<KernelEvent> = Bus::new().with_metrics(metrics.clone());
    let mut rx = bus.subscribe();

    let n = bus.publish(KernelEvent::Shutdown);
    assert_eq!(n, 1);

    let _ = Bus::handle_recv(rx.recv().await, Some(&metrics));
}

#[tokio::test]
async fn lagged_receiver_increments_lag_counter() {
    let metrics = Metrics::new(false);
    let bus: Bus<String> = Bus::new().with_metrics(metrics.clone());
    let mut rx = bus.subscribe();

    for i in 0..2048 {
        let _ = bus.publish(format!("m{i}"));
    }

    let _ = Bus::handle_recv(rx.recv().await, Some(&metrics));
}

```

### crates/ron-kernel/tests/edge_notify_loom.rs
<a id="crates-ron-kernel-tests-edgenotifyloom-rs"></a>

```rust
#![cfg(all(feature = "bus_edge_notify", feature = "loom"))]

//! RO:WHAT
//!   Loom litmus tests for lost-wake and drain-after-clear races.
//!
//! RO:WHY
//!   Ensure the pending bit pattern guarantees no lost wakeups.
//!
//! NOTE
//!   Uses `loom`'s std shims; keep test tiny to avoid state explosion.

use loom::sync::Arc;
use loom::thread;
use std::sync::atomic::{AtomicBool, Ordering};

#[test]
fn lost_wake_is_prevented() {
    loom::model(|| {
        let pending = Arc::new(AtomicBool::new(false));

        // Publisher: set pending and "notify if 0->1".
        let p = {
            let pending = pending.clone();
            thread::spawn(move || {
                let was = pending.swap(true, Ordering::Relaxed);
                // if !was { notify(); }  // modeled implicitly
                was
            })
        };

        // Subscriber: drain, clear, then race-check.
        let s = {
            let pending = pending.clone();
            thread::spawn(move || {
                // drain_all(); // modeled as already drained
                pending.store(false, Ordering::Relaxed);
                // race check
                let raced = pending.swap(false, Ordering::Relaxed);
                if raced {
                    // re-arm
                    pending.store(true, Ordering::Relaxed);
                }
                raced
            })
        };

        let _pub_was_pending = p.join().unwrap();
        let raced = s.join().unwrap();

        // If publisher observed 0->1 and subscriber cleared, either:
        // - race detected (raced=true), subscriber will continue draining
        // - or subscriber awaits but pending remains true (observed by next poll)
        // We assert that *eventually* pending is true if race happened.
        if raced {
            assert!(pending.load(Ordering::Relaxed));
        }
    });
}

```

### crates/ron-kernel/tests/health_ready.rs
<a id="crates-ron-kernel-tests-healthready-rs"></a>

```rust
//! Readiness and health endpoints: handler semantics (no actual HTTP client).
use std::net::SocketAddr;

use axum::http::StatusCode;
use ron_kernel::{HealthState, Metrics};
use ron_kernel::metrics::readiness::{readyz_handler, Readiness};

#[tokio::test]
async fn readiness_transitions_to_ok_when_config_and_services_ready() {
    let metrics = Metrics::new(false);
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());

    // Start server just to ensure the router builds; we won't fetch it here.
    let (_handle, _addr) = metrics
        .clone()
        .serve("127.0.0.1:0".parse::<SocketAddr>().unwrap(), health.clone(), ready.clone())
        .await
        .unwrap();

    // Initially not ready (config not loaded)
    let resp = readyz_handler(ready.clone()).await;
    assert_eq!(resp.status(), StatusCode::SERVICE_UNAVAILABLE);

    // Make both gates true
    ready.set_config_loaded(true);
    health.set("svc", true);

    // Now the handler should return 200 OK
    let ok_resp = readyz_handler(ready.clone()).await;
    assert_eq!(ok_resp.status(), StatusCode::OK);
}

```

### crates/ron-kernel/tests/loom_bus.rs
<a id="crates-ron-kernel-tests-loombus-rs"></a>

```rust
//! Loom interleavings for Bus subscribe/publish ensure no panics or deadlocks.
//! Run with: cargo test -p ron-kernel --features loom -- --nocapture

#![cfg(feature = "loom")]

use loom::thread;
use ron_kernel::{Bus, KernelEvent, Metrics};

#[test]
fn bus_publish_subscribe_concurrent() {
    loom::model(|| {
        let metrics = Metrics::new(false);
        let bus: Bus<KernelEvent> = metrics.make_bus(8);

        let bus_pub = bus.clone();
        let t_pub = thread::spawn(move || {
            let _ = bus_pub.publish(KernelEvent::Shutdown);
            let _ = bus_pub.publish(KernelEvent::ConfigUpdated { version: 1 });
        });

        let bus_sub = bus.clone();
        let t_sub = thread::spawn(move || {
            let mut rx = bus_sub.subscribe();
            let _ = rx.recv();
            let _ = rx.recv();
        });

        t_pub.join().unwrap();
        t_sub.join().unwrap();
    });
}

```

### crates/ron-kernel/tests/metrics_amnesia.rs
<a id="crates-ron-kernel-tests-metricsamnesia-rs"></a>

```rust
//! Ensures amnesia_mode gauge flips 0 <-> 1 and is exposed by the exporter.

use prometheus::Encoder; // brings TextEncoder::encode into scope
use ron_kernel::Metrics;
use ron_kernel::metrics::health::HealthState;
use ron_kernel::metrics::readiness::Readiness;

#[tokio::test]
async fn amnesia_mode_gauge_flips_and_exports() {
    let metrics = Metrics::new(false);

    // Sanity: initial seed should be 0
    {
        // NOTE: 'registry' is a field on Metrics; metrics is Arc<Metrics>
        let families = (*metrics).registry.gather();
        let mut buf = Vec::new();
        prometheus::TextEncoder::new()
            .encode(&families, &mut buf)
            .unwrap();
        let text = String::from_utf8(buf).unwrap();
        assert!(
            text.contains("amnesia_mode 0"),
            "expected amnesia_mode 0 at start, got:\n{text}"
        );
    }

    metrics.set_amnesia(true);
    {
        let families = (*metrics).registry.gather();
        let mut buf = Vec::new();
        prometheus::TextEncoder::new()
            .encode(&families, &mut buf)
            .unwrap();
        let text = String::from_utf8(buf).unwrap();
        assert!(
            text.contains("amnesia_mode 1"),
            "expected amnesia_mode 1 after flip, got:\n{text}"
        );
    }

    // Boot the HTTP exporter quickly to catch regressions in wiring.
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());
    ready.set_config_loaded(true);
    health.set("kernel", true);

    let (_handle, bound) =
        metrics.clone().serve("127.0.0.1:0".parse().unwrap(), health, ready).await.unwrap();
    assert_ne!(bound.port(), 0);
}

```

### crates/ron-kernel/tests/metrics_smoke.rs
<a id="crates-ron-kernel-tests-metricssmoke-rs"></a>

```rust
//! Smoke test: Metrics::serve mounts routes and binds successfully.

use std::net::SocketAddr;

use ron_kernel::{HealthState, Metrics};
use ron_kernel::metrics::readiness::Readiness;

#[tokio::test]
async fn metrics_server_binds_and_runs() {
    let metrics = Metrics::new(false);
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());

    // Toggle minimal readiness so /readyz can return 200 once needed
    ready.set_config_loaded(true);
    health.set("kernel", true);

    let addr: SocketAddr = "127.0.0.1:0".parse().unwrap();
    let (handle, bound) = metrics.clone().serve(addr, health.clone(), ready.clone()).await.unwrap();

    // bound should be a real ephemeral port
    assert_ne!(bound.port(), 0);

    // shut it down
    handle.abort();
}

```

### crates/ron-kernel/tests/property_config.rs
<a id="crates-ron-kernel-tests-propertyconfig-rs"></a>

```rust
//! Aligns integer values with float checks.

use ron_kernel::Metrics;

#[test]
fn property_config_sanity_numbers_cast() {
    // this test just needs Metrics in scope; we don't actually use it.
    let _metrics = Metrics::new(false);

    // pretend these came from a config (i64s):
    let v0: i64 = 0;
    let v1: i64 = 1;
    let v2: i64 = 0;

    // cast to f64 before float math
    assert!((v0 as f64 - 0.0).abs() < f64::EPSILON);
    assert!((v1 as f64 - 1.0).abs() < f64::EPSILON);
    assert!((v2 as f64 - 0.0).abs() < f64::EPSILON);
}

```

### crates/ron-kernel/tests/public_api.rs
<a id="crates-ron-kernel-tests-publicapi-rs"></a>

```rust
//! Verifies the frozen public API is re-exported at the crate root.
//! Fails to compile if any item disappears or moves.

use ron_kernel::{
    Bus,
    KernelEvent,
    Metrics,
    HealthState,
    Config,
    wait_for_ctrl_c,
};

#[test]
fn api_compiles_and_names_resolve() {
    // Type names resolve? good enough for compile-time surface guard.
    let _ = std::any::type_name::<Bus<KernelEvent>>();
    let _ = std::any::type_name::<Metrics>();
    let _ = std::any::type_name::<HealthState>();
    let _ = std::any::type_name::<Config>();
    let _ = wait_for_ctrl_c as fn() -> _;
}

```

### crates/ron-kernel/tests/readiness_degrades.rs
<a id="crates-ron-kernel-tests-readinessdegrades-rs"></a>

```rust
//! /readyz returns 503 until both gates (config_loaded & services_ok) are true.

use axum::http::StatusCode;
use ron_kernel::Metrics;
use ron_kernel::metrics::health::HealthState;
use ron_kernel::metrics::readiness::{Readiness, readyz_handler};

#[tokio::test]
async fn readiness_degrades_then_ok() {
    let _metrics = Metrics::new(false); // ensures registry initialized, but not required here
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());

    // Initially: both gates false -> 503
    let resp = readyz_handler(ready.clone()).await;
    assert_eq!(resp.status(), StatusCode::SERVICE_UNAVAILABLE);

    // Flip just one gate -> still 503
    ready.set_config_loaded(true);
    let resp = readyz_handler(ready.clone()).await;
    assert_eq!(resp.status(), StatusCode::SERVICE_UNAVAILABLE);

    // Flip services_ok via HealthState -> 200
    health.set("kernel", true);
    let resp = readyz_handler(ready.clone()).await;
    assert_eq!(resp.status(), StatusCode::OK);
}

```

### crates/ron-kernel/tests/soa_smoke.rs
<a id="crates-ron-kernel-tests-soasmoke-rs"></a>

```rust
//! RO:WHAT — Integration smoke for SoA backend under the `bus_soa` feature.
//! RO:WHY  — Ensure crate-level feature compiles & basic flows hold.

#![cfg(feature = "bus_soa")]

use ron_kernel::bus::bounded::Bus; // bounded is re-exported to SoA when feature=bus_soa
use tokio::runtime::Runtime;

#[test]
fn feature_compiles_and_basic_flow_ok() {
    let rt = Runtime::new().unwrap();
    rt.block_on(async {
        let bus: Bus<u64> = Bus::with_capacity(16);
        let mut rx = bus.subscribe();
        let _rc = bus.publish(42);
        // bounded-style: recv returns Result<T, Lagged>, use handle_recv to map to Option
        let got = Bus::handle_recv(rx.recv().await, None);
        assert_eq!(got, Some(42));
    });
}

```

### crates/ron-kernel/tests/supervisor_backoff.rs
<a id="crates-ron-kernel-tests-supervisorbackoff-rs"></a>

```rust
use ron_kernel::Metrics;

/// Minimal invariant: the supervisor restart counter should be usable and
/// monotonically increasing under a service label. This stands in until the
/// real supervisor backoff is wired.
#[test]
fn service_restart_counter_increments_monotonically() {
    let metrics = Metrics::new(false);

    // Simulate a supervisor incrementing a labeled counter.
    let ctr = metrics.service_restarts_total.with_label_values(&["demo"]);

    let before = ctr.get();
    ctr.inc();
    let after1 = ctr.get();
    assert_eq!(after1, before + 1, "inc() should add exactly 1");

    ctr.inc_by(5);
    let after2 = ctr.get();
    assert_eq!(after2, after1 + 5, "inc_by(5) should add exactly 5");
}

```

### crates/ron-kernel/tests/supervisor_backoff_integ.rs
<a id="crates-ron-kernel-tests-supervisorbackoffinteg-rs"></a>

```rust
use std::time::{Duration, Instant};

use ron_kernel::{Bus, KernelEvent, Metrics, HealthState};
use ron_kernel::metrics::readiness::Readiness;
use ron_kernel::supervisor::{backoff::Backoff, lifecycle::Supervisor};

#[tokio::test]
async fn supervisor_restarts_and_backoff_grows() {
    let metrics = Metrics::new(false);
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());
    ready.set_config_loaded(true);

    let bus: Bus<KernelEvent> = Bus::new().with_metrics(metrics.clone());

    let work = || async {
        Err::<(), Box<dyn std::error::Error + Send + Sync + 'static>>("fail".into())
    };

    let mut sup = Supervisor::new(
        "testsvc",
        (*metrics).clone(),
        bus.clone(),
        health.clone(),
        Backoff::new(Duration::from_millis(100), Duration::from_millis(400), 2.0, 0.0),
        100,
        Duration::from_secs(10),
    );

    let start = Instant::now();
    let h = tokio::spawn(async move { sup.run(work).await });

    tokio::time::sleep(Duration::from_millis(850)).await;
    h.abort();

    // read the counter from the *_total vec
    let c = metrics
        .service_restarts_total
        .with_label_values(&["testsvc"])
        .get();
    assert!(c >= 3, "expected >=3 restarts, got {}", c);

    let elapsed = start.elapsed();
    assert!(elapsed >= Duration::from_millis(300));
}

```

### crates/ron-kernel/tests/tls_type_invariance.rs
<a id="crates-ron-kernel-tests-tlstypeinvariance-rs"></a>

```rust
//! Compile-time guard: the crate must use `tokio_rustls::rustls::ServerConfig`.
//! If someone swaps to `rustls::ServerConfig` directly, this test will fail to compile.

#[test]
fn tls_type_is_tokio_rustls_serverconfig() {
    // This function will fail to compile if the type path is wrong.
    fn _requires_tokio_rustls(_: &tokio_rustls::rustls::ServerConfig) {}

    // Name resolution check (uses the type so clippy doesn’t flag it as unused).
    let _typename = std::any::type_name::<tokio_rustls::rustls::ServerConfig>();

    // Keep a phantom value to ensure the path remains valid across refactors.
    let _phantom: Option<&tokio_rustls::rustls::ServerConfig> = None;

    // No runtime assertions needed—the compile-time type checks above are the point.
}

```

### crates/ron-kernel/tests/watcher_integ.rs
<a id="crates-ron-kernel-tests-watcherinteg-rs"></a>

```rust
//! Integration glue: exercise ConfigUpdated emission + amnesia gauge flip.

use std::fs;
use std::time::Duration;

use ron_kernel::{Bus, KernelEvent, Metrics};

#[tokio::test]
async fn amnesia_flip_emits_single_update() {
    let dir = tempfile::tempdir().unwrap();
    let cfg_path = dir.path().join("ron-kernel.toml");
    fs::write(
        &cfg_path,
        "amnesia = false\nhttp_port = 0\nrequest_timeout_ms = 1000\n",
    )
    .unwrap();

    let metrics = Metrics::new(false);
    let bus: Bus<KernelEvent> = Bus::new().with_metrics(metrics.clone());
    let mut rx = bus.subscribe();

    // Simulate watcher apply; replace with real watcher if present.
    tokio::spawn({
        let metrics = metrics.clone();
        let bus = bus.clone();
        async move {
            metrics.set_amnesia(true);
            bus.publish(KernelEvent::ConfigUpdated { version: 1 });
        }
    });

    let mut updates = 0u32;
    let deadline = tokio::time::Instant::now() + Duration::from_millis(500);

    loop {
        let now = tokio::time::Instant::now();
        if now >= deadline {
            break;
        }
        let remaining = deadline - now;

        // Bound this await so the loop can re-check the deadline.
        match tokio::time::timeout(remaining, rx.recv()).await {
            Ok(Ok(ev)) => {
                if let KernelEvent::ConfigUpdated { .. } = ev {
                    updates += 1;
                }
            }
            Ok(Err(_lagged)) => {
                // Ignore lag for this test: we're only counting ConfigUpdated.
            }
            Err(_elapsed) => {
                // No message before deadline — exit loop.
                break;
            }
        }
    }

    assert_eq!(updates, 1, "expected exactly one ConfigUpdated");
    metrics.set_amnesia(false);
}

```

