<!-- Generated by scripts/make_crate_codex.sh on 2025-11-16T15:43:54Z -->
# Code Bundle — `ron-audit`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-audit/.cargo/config.toml](#crates-ron-audit--cargo-config-toml)
- [crates/ron-audit/Cargo.toml](#crates-ron-audit-Cargo-toml)
- [crates/ron-audit/benches/hash_b3.rs](#crates-ron-audit-benches-hashb3-rs)
- [crates/ron-audit/benches/verify_chain.rs](#crates-ron-audit-benches-verifychain-rs)
- [crates/ron-audit/benches/wal_batching.rs](#crates-ron-audit-benches-walbatching-rs)
- [crates/ron-audit/deny.toml](#crates-ron-audit-deny-toml)
- [crates/ron-audit/fuzz/Cargo.toml](#crates-ron-audit-fuzz-Cargo-toml)
- [crates/ron-audit/fuzz/fuzz_targets/fuzz_canon_vectors.rs](#crates-ron-audit-fuzz-fuzztargets-fuzzcanonvectors-rs)
- [crates/ron-audit/fuzz/fuzz_targets/fuzz_record_roundtrip.rs](#crates-ron-audit-fuzz-fuzztargets-fuzzrecordroundtrip-rs)
- [crates/ron-audit/loom/chain_loom.rs](#crates-ron-audit-loom-chainloom-rs)
- [crates/ron-audit/rust-toolchain.toml](#crates-ron-audit-rust-toolchain-toml)
- [crates/ron-audit/scripts/beta_check.sh](#crates-ron-audit-scripts-betacheck-sh)
- [crates/ron-audit/src/bounds/mod.rs](#crates-ron-audit-src-bounds-mod-rs)
- [crates/ron-audit/src/canon/mod.rs](#crates-ron-audit-src-canon-mod-rs)
- [crates/ron-audit/src/canon/rules.rs](#crates-ron-audit-src-canon-rules-rs)
- [crates/ron-audit/src/canon/vectors.rs](#crates-ron-audit-src-canon-vectors-rs)
- [crates/ron-audit/src/dto.rs](#crates-ron-audit-src-dto-rs)
- [crates/ron-audit/src/errors.rs](#crates-ron-audit-src-errors-rs)
- [crates/ron-audit/src/hash/b3.rs](#crates-ron-audit-src-hash-b3-rs)
- [crates/ron-audit/src/hash/mod.rs](#crates-ron-audit-src-hash-mod-rs)
- [crates/ron-audit/src/lib.rs](#crates-ron-audit-src-lib-rs)
- [crates/ron-audit/src/metrics/mod.rs](#crates-ron-audit-src-metrics-mod-rs)
- [crates/ron-audit/src/prelude.rs](#crates-ron-audit-src-prelude-rs)
- [crates/ron-audit/src/privacy/mod.rs](#crates-ron-audit-src-privacy-mod-rs)
- [crates/ron-audit/src/sink/export.rs](#crates-ron-audit-src-sink-export-rs)
- [crates/ron-audit/src/sink/mod.rs](#crates-ron-audit-src-sink-mod-rs)
- [crates/ron-audit/src/sink/ram.rs](#crates-ron-audit-src-sink-ram-rs)
- [crates/ron-audit/src/sink/traits.rs](#crates-ron-audit-src-sink-traits-rs)
- [crates/ron-audit/src/sink/wal.rs](#crates-ron-audit-src-sink-wal-rs)
- [crates/ron-audit/src/stream/mod.rs](#crates-ron-audit-src-stream-mod-rs)
- [crates/ron-audit/src/verify/chain.rs](#crates-ron-audit-src-verify-chain-rs)
- [crates/ron-audit/src/verify/mod.rs](#crates-ron-audit-src-verify-mod-rs)
- [crates/ron-audit/src/verify/record.rs](#crates-ron-audit-src-verify-record-rs)
- [crates/ron-audit/testing/vectors/manifest_example.json](#crates-ron-audit-testing-vectors-manifestexample-json)
- [crates/ron-audit/testing/vectors/record_max.json](#crates-ron-audit-testing-vectors-recordmax-json)
- [crates/ron-audit/testing/vectors/record_small.json](#crates-ron-audit-testing-vectors-recordsmall-json)
- [crates/ron-audit/tests/api_compat.rs](#crates-ron-audit-tests-apicompat-rs)
- [crates/ron-audit/tests/append_only.rs](#crates-ron-audit-tests-appendonly-rs)
- [crates/ron-audit/tests/bounds.rs](#crates-ron-audit-tests-bounds-rs)
- [crates/ron-audit/tests/canonicalization.rs](#crates-ron-audit-tests-canonicalization-rs)
- [crates/ron-audit/tests/export_checkpoints.rs](#crates-ron-audit-tests-exportcheckpoints-rs)
- [crates/ron-audit/tests/idempotency.rs](#crates-ron-audit-tests-idempotency-rs)
- [crates/ron-audit/tests/multi_writer_ordering.rs](#crates-ron-audit-tests-multiwriterordering-rs)
- [crates/ron-audit/tests/privacy_policies.rs](#crates-ron-audit-tests-privacypolicies-rs)
- [crates/ron-audit/tests/verify_soa.rs](#crates-ron-audit-tests-verifysoa-rs)

### crates/ron-audit/.cargo/config.toml
<a id="crates-ron-audit--cargo-config-toml"></a>

```toml
[build]
rustflags = ["-Dwarnings"]

[target.'cfg(all())']
# Keep deterministic builds where possible.
rustflags = ["-C", "debuginfo=1"]

```

### crates/ron-audit/Cargo.toml
<a id="crates-ron-audit-Cargo-toml"></a>

```toml
[package]
name = "ron-audit"
version = "0.1.0"
edition = "2021"
rust-version = "1.80"
description = "RON-CORE audit-chain helpers (canon, hash, verify, sinks) for AuditRecord."
license = "MIT OR Apache-2.0"
repository = "https://github.com/rustyonions/RustyOnions"
homepage = "https://rustyonions.dev"

[lib]
name = "ron_audit"
path = "src/lib.rs"

[features]
# Minimal default: in-RAM sink only, no WAL/export/metrics/SIMD.
default = []

# Future: real write-ahead log sink.
wal = []

# Future: checkpoint / export helpers.
export = []

# Future: prometheus/ron-metrics wiring for audit ops.
with-metrics = []

# Optional: SIMD-accelerated linkage comparisons (std::simd).
# NOTE: Hashing remains delegated to blake3; this only affects how we compare
# prev/self_hash strings in verify_link/verify_chain_soa.
simd = []

[dependencies]
# Placeholder; DTOs currently live locally in `dto.rs`, but we keep the
# dependency wired so we can migrate `AuditRecord` into ron-proto later
# without changing host Cargo manifests.
ron-proto = { path = "../ron-proto" }

serde = { version = "1", features = ["derive"] }
serde_json = "1"

thiserror = "1"
blake3 = "1"
unicode-normalization = "0.1"

[dev-dependencies]
# Sync-only Criterion (no async needed here).
criterion = { version = "0.5", features = ["html_reports"] }

[[bench]]
name = "hash_b3"
harness = false

[[bench]]
name = "verify_chain"
harness = false

[[bench]]
name = "wal_batching"
harness = false

```

### crates/ron-audit/benches/hash_b3.rs
<a id="crates-ron-audit-benches-hashb3-rs"></a>

```rust
//! RO:WHAT — Criterion microbench for canonicalize + BLAKE3 hashing of AuditRecord.
//! RO:WHY  — PERF: baseline BLAKE3 throughput on canonical audit payloads.
//! RO:INTERACTS — ron_audit::hash::b3_no_self; dto::AuditRecord; serde_json.
//! RO:INVARIANTS — pure; no I/O; stable record shape; no global state.
//! RO:METRICS — bench-only; no runtime counters.
//! RO:CONFIG — in-code record sizes; no env knobs yet.
//! RO:SECURITY — synthetic records only; no real keys/PII.
//! RO:TEST — perf: Criterion group `hash_b3_small` / `hash_b3_large`.

use std::time::{SystemTime, UNIX_EPOCH};

use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::b3_no_self;
use ron_audit::AuditRecord;
use serde_json::json;

fn mk_record(attr_bytes: usize) -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    let payload = "x".repeat(attr_bytes.max(1));

    let mut rec = AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "bench@ron-audit".to_string(),
        seq: 0,
        stream: "hash_b3".to_string(),
        kind: AuditKind::IndexWrite,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("bench-hash-b3".to_string()),
        attrs: json!({ "payload": payload }),
        prev: "b3:0".to_string(),
        self_hash: String::new(),
    };

    // Fill self_hash once, even though `b3_no_self` ignores it, to keep the
    // record closer to real-world usage.
    rec.self_hash = b3_no_self(&rec).expect("hash");
    rec
}

fn hash_b3_small(c: &mut Criterion) {
    let rec = mk_record(64);

    c.bench_function("hash_b3_small_64B_attrs", |b| {
        b.iter(|| {
            let h = b3_no_self(black_box(&rec)).expect("hash");
            black_box(h);
        });
    });
}

fn hash_b3_large(c: &mut Criterion) {
    // ~1 KiB attrs to stay within DEFAULT_MAX_ATTRS_BYTES.
    let rec = mk_record(1024);

    c.bench_function("hash_b3_large_1KiB_attrs", |b| {
        b.iter(|| {
            let h = b3_no_self(black_box(&rec)).expect("hash");
            black_box(h);
        });
    });
}

criterion_group!(benches, hash_b3_small, hash_b3_large);
criterion_main!(benches);

```

### crates/ron-audit/benches/verify_chain.rs
<a id="crates-ron-audit-benches-verifychain-rs"></a>

```rust
//! RO:WHAT — Criterion microbench for chain verification (scalar API vs SoA).
//! RO:WHY  — PERF/RES: compare verify_chain (reference) and verify_chain_soa (fast path)
//!           on realistic chain lengths.
//! RO:INTERACTS — ron_audit::hash::b3_no_self;
//!                ron_audit::verify::{verify_record, verify_link, verify_chain, verify_chain_soa}.
//! RO:INVARIANTS — no unsafe; same semantics for scalar and SoA; only performance differs.
//! RO:METRICS — bench-only; no runtime counters.
//! RO:CONFIG — chain length configured in-code; env knobs can be added later.
//! RO:SECURITY — synthetic records only; no real keys/PII.
//! RO:TEST — unit: tests/verify_soa.rs; perf: this bench.

use std::time::{SystemTime, UNIX_EPOCH};

use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::b3_no_self;
use ron_audit::verify::{verify_chain, verify_chain_soa};
use ron_audit::AuditRecord;
use serde_json::json;

fn mk_chain(len: usize) -> Vec<AuditRecord> {
    assert!(len > 0);

    let mut out = Vec::with_capacity(len);

    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    // genesis
    let mut genesis = AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "bench@ron-audit".to_string(),
        seq: 0,
        stream: "verify_chain".to_string(),
        kind: AuditKind::CapIssued,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("bench-verify-chain".to_string()),
        attrs: json!({ "seq": 0u64 }),
        prev: "b3:0".to_string(),
        self_hash: String::new(),
    };
    genesis.self_hash = b3_no_self(&genesis).expect("hash");
    out.push(genesis);

    while out.len() < len {
        let prev = out.last().expect("non-empty");
        let mut rec = AuditRecord {
            v: 1,
            ts_ms,
            writer_id: prev.writer_id.clone(),
            seq: prev.seq + 1,
            stream: prev.stream.clone(),
            kind: AuditKind::IndexWrite,
            actor: ActorRef::default(),
            subject: SubjectRef::default(),
            reason: ReasonCode("bench-verify-chain".to_string()),
            attrs: json!({ "seq": prev.seq + 1 }),
            prev: prev.self_hash.clone(),
            self_hash: String::new(),
        };
        rec.self_hash = b3_no_self(&rec).expect("hash");
        out.push(rec);
    }

    out
}

/// For comparison: scalar reference API over an owned iterator.
///
/// NOTE: This includes the cost of cloning the chain when we call
/// `chain.clone().into_iter()`, which matches how callers would typically
/// use the public API.
fn bench_verify_chain_scalar_api(c: &mut Criterion) {
    let chain = mk_chain(512);

    // Sanity-check: scalar API must succeed once outside the hot loop.
    verify_chain(chain.clone().into_iter()).expect("verify_chain scalar API");

    c.bench_function("verify_chain_scalar_len_512", |b| {
        b.iter(|| {
            // Clone per-iteration to match real-world "owned iterator" usage.
            let owned = black_box(chain.clone());
            verify_chain(owned.into_iter()).expect("scalar verify");
        });
    });
}

/// SoA-style fast path over a contiguous slice.
///
/// This avoids per-iteration cloning and uses the SoA slice-based verifier.
/// It should be at least as fast as the scalar path, often faster for large chains.
fn bench_verify_chain_soa(c: &mut Criterion) {
    let chain = mk_chain(512);

    // Sanity-check: SoA API must succeed once outside the hot loop.
    verify_chain_soa(&chain).expect("verify_chain_soa");

    c.bench_function("verify_chain_soa_len_512", |b| {
        b.iter(|| {
            verify_chain_soa(black_box(&chain)).expect("soa verify");
        });
    });
}

criterion_group!(
    benches,
    bench_verify_chain_scalar_api,
    bench_verify_chain_soa
);
criterion_main!(benches);

```

### crates/ron-audit/benches/wal_batching.rs
<a id="crates-ron-audit-benches-walbatching-rs"></a>

```rust
//! RO:WHAT — Criterion microbench for per-record vs batched append into an AuditSink.
//! RO:WHY  — PERF/ECON: rough guidance for WAL/batch tuning in hosts (fsync cadence, batch size).
//! RO:INTERACTS — ron_audit::sink::{ram::RamSink, AuditSink}; stream::BufferedSink; hash::b3_no_self.
//! RO:INVARIANTS — append-only; prev == last.self_hash; bounded record sizes.
//! RO:METRICS — bench-only; host metrics will live in svc-* crates.
//! RO:CONFIG — batch size configured in code; env toggles can be added later.
//! RO:SECURITY — synthetic records; no real keys/PII; in-RAM only.
//! RO:TEST — perf: Criterion group `wal_single_append` / `wal_buffered_append`.

use std::time::{SystemTime, UNIX_EPOCH};

use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::b3_no_self;
use ron_audit::sink::{ram::RamSink, AuditSink};
use ron_audit::stream::BufferedSink;
use ron_audit::AuditRecord;
use serde_json::json;

fn mk_records(count: usize) -> Vec<AuditRecord> {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    let mut out = Vec::with_capacity(count);

    // genesis
    let mut prev_hash = "b3:0".to_string();
    for seq in 0..count as u64 {
        let mut rec = AuditRecord {
            v: 1,
            ts_ms,
            writer_id: "bench@ron-audit".to_string(),
            seq,
            stream: "wal_batching".to_string(),
            kind: AuditKind::IndexWrite,
            actor: ActorRef::default(),
            subject: SubjectRef::default(),
            reason: ReasonCode("bench-wal-batching".to_string()),
            attrs: json!({ "seq": seq }),
            prev: prev_hash.clone(),
            self_hash: String::new(),
        };
        rec.self_hash = b3_no_self(&rec).expect("hash");
        prev_hash = rec.self_hash.clone();
        out.push(rec);
    }

    out
}

fn wal_single_append(c: &mut Criterion) {
    // A moderately large batch to make per-record append overhead visible.
    let records = mk_records(512);

    c.bench_function("wal_single_append_512", |b| {
        b.iter(|| {
            let sink = RamSink::new();
            for rec in black_box(&records) {
                sink.append(rec).expect("append");
            }
        });
    });
}

fn wal_buffered_append(c: &mut Criterion) {
    let records = mk_records(512);

    c.bench_function("wal_buffered_append_512", |b| {
        b.iter(|| {
            let sink = RamSink::new();
            let buffered = BufferedSink::new(sink);
            buffered
                .append_all(black_box(&records))
                .expect("buffered append_all");
        });
    });
}

criterion_group!(benches, wal_single_append, wal_buffered_append);
criterion_main!(benches);

```

### crates/ron-audit/deny.toml
<a id="crates-ron-audit-deny-toml"></a>

```toml
# Keep aligned with workspace deny policy; local file allows per-crate notes.
[advisories]
yanked = "deny"

[bans]
multiple-versions = "deny"

[licenses]
allow = [
  "MIT",
  "Apache-2.0",
  "Unicode-DFS-2016",
  "Unicode-3.0",
  "CC0-1.0",
  "CDLA-Permissive-2.0",
  "OpenSSL",
]

```

### crates/ron-audit/fuzz/Cargo.toml
<a id="crates-ron-audit-fuzz-Cargo-toml"></a>

```toml
[package]
name = "ron-audit2-fuzz"
version = "0.0.0"
publish = false
edition = "2021"

[workspace]

[dependencies]
libfuzzer-sys = "0.4"

[dependencies.ron-audit2]
path = ".."

[profile.release]
debug = 1

[[bin]]
name = "fuzz_record_roundtrip"
path = "fuzz_targets/fuzz_record_roundtrip.rs"

[[bin]]
name = "fuzz_canon_vectors"
path = "fuzz_targets/fuzz_canon_vectors.rs"

```

### crates/ron-audit/fuzz/fuzz_targets/fuzz_canon_vectors.rs
<a id="crates-ron-audit-fuzz-fuzztargets-fuzzcanonvectors-rs"></a>

```rust

```

### crates/ron-audit/fuzz/fuzz_targets/fuzz_record_roundtrip.rs
<a id="crates-ron-audit-fuzz-fuzztargets-fuzzrecordroundtrip-rs"></a>

```rust

```

### crates/ron-audit/loom/chain_loom.rs
<a id="crates-ron-audit-loom-chainloom-rs"></a>

```rust

```

### crates/ron-audit/rust-toolchain.toml
<a id="crates-ron-audit-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["rustfmt", "clippy"]

```

### crates/ron-audit/scripts/beta_check.sh
<a id="crates-ron-audit-scripts-betacheck-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Simple beta gate for ron-audit.
# Runs:
#   1) fmt + clippy + unit tests
#   2) benches for hash_b3, verify_chain, wal_batching with saved baselines
#
# Usage (from repo root):
#   bash crates/ron-audit/scripts/beta_check.sh
#   BASE=local-dev bash crates/ron-audit/scripts/beta_check.sh
#
# Notes:
#   - Baseline suffix defaults to YYYYMMDD if BASE is not set.
#   - This script does NOT enable any cargo features by default
#     (run simd benches separately if needed).

CRATE="ron-audit"

# Resolve repo root (two levels up from scripts/)
ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
cd "$ROOT_DIR"

BASE_SUFFIX="${BASE:-$(date +%Y%m%d)}"

echo "[beta-check] crate=${CRATE} root=${ROOT_DIR}"
echo "[beta-check] 1) fmt + clippy + unit tests"

cargo fmt -p "${CRATE}"
cargo clippy -p "${CRATE}" --no-deps -- -D warnings
cargo test -p "${CRATE}"

echo "[beta-check] 2) benches (hash_b3, verify_chain, wal_batching)"

cargo bench -p "${CRATE}" --bench hash_b3 \
  -- --save-baseline "audit-hash_b3-${BASE_SUFFIX}"

cargo bench -p "${CRATE}" --bench verify_chain \
  -- --save-baseline "audit-verify_chain-${BASE_SUFFIX}"

cargo bench -p "${CRATE}" --bench wal_batching \
  -- --save-baseline "audit-wal_batching-${BASE_SUFFIX}"

echo "[beta-check] done."

```

### crates/ron-audit/src/bounds/mod.rs
<a id="crates-ron-audit-src-bounds-mod-rs"></a>

```rust
//! Size bounds checks for audit records.

use crate::errors::BoundsError;
use crate::AuditRecord;

/// Default maximum serialized size (in bytes) for `attrs`.
pub const DEFAULT_MAX_ATTRS_BYTES: usize = 1024;

/// Default maximum serialized size (in bytes) for a full record.
pub const DEFAULT_MAX_RECORD_BYTES: usize = 4096;

/// Check size bounds on an `AuditRecord`.
///
/// Hosts can call this prior to hashing/append to enforce their SLOs.
pub fn check(
    rec: &AuditRecord,
    max_attrs_bytes: usize,
    max_record_bytes: usize,
) -> Result<(), BoundsError> {
    let attrs_bytes = serde_json::to_vec(&rec.attrs)
        .map(|v| v.len())
        .unwrap_or_default();

    if attrs_bytes > max_attrs_bytes {
        return Err(BoundsError::AttrsTooLarge {
            actual: attrs_bytes,
            max: max_attrs_bytes,
        });
    }

    let record_bytes = serde_json::to_vec(rec).map(|v| v.len()).unwrap_or_default();

    if record_bytes > max_record_bytes {
        return Err(BoundsError::RecordTooLarge {
            actual: record_bytes,
            max: max_record_bytes,
        });
    }

    Ok(())
}

```

### crates/ron-audit/src/canon/mod.rs
<a id="crates-ron-audit-src-canon-mod-rs"></a>

```rust
//! Canonicalization for `AuditRecord`.
//!
//! The goal is to produce a **stable byte representation** of a record
//! *without* its `self_hash` field, suitable for hashing and dedupe.
//!
//! Rules (as per IDB):
//! - Struct fields appear in a fixed order.
//! - Strings are NFC-normalized.
//! - Floats are rejected (only ints/booleans/strings/objects/arrays allowed).
//! - Unknown top-level fields are rejected.

use serde_json::{Map, Value};
use unicode_normalization::UnicodeNormalization;

use crate::AuditRecord;

/// Errors produced during canonicalization.
#[derive(Debug, thiserror::Error)]
pub enum CanonError {
    /// The record could not be encoded as a JSON object.
    #[error("record was not encodable as a JSON object")]
    NonObject,

    /// The record was missing a required field.
    #[error("record missing required field `{0}`")]
    MissingField(&'static str),

    /// The record contained unexpected extra fields.
    #[error("record contained unexpected fields")]
    UnexpectedFields,

    /// A floating-point number was encountered in the payload.
    #[error("floats are not allowed in audit payloads")]
    FloatDisallowed,

    /// JSON encoding failed.
    #[error("failed to encode canonical JSON")]
    Encode,
}

/// Produce canonical bytes for an `AuditRecord` *without* its `self_hash`.
///
/// This function:
/// - Removes the `self_hash` field entirely.
/// - Re-orders top-level fields into a stable order.
/// - NFC-normalizes all strings recursively.
/// - Rejects floats anywhere in the payload.
pub fn canonicalize_without_self_hash(rec: &AuditRecord) -> Result<Vec<u8>, CanonError> {
    // Serialize the record into a generic JSON value first.
    let mut value = serde_json::to_value(rec).map_err(|_| CanonError::Encode)?;

    let obj = value.as_object_mut().ok_or(CanonError::NonObject)?;

    // Drop self_hash; we'll recompute it from the canonical bytes.
    obj.remove("self_hash");

    // Expected top-level order (must match AuditRecord field layout).
    const ORDER: [&str; 11] = [
        "v",
        "ts_ms",
        "writer_id",
        "seq",
        "stream",
        "kind",
        "actor",
        "subject",
        "reason",
        "attrs",
        "prev",
    ];

    let mut out = Map::new();

    for key in ORDER {
        let value = obj.remove(key).ok_or(CanonError::MissingField(key))?;
        let normalized = normalize_value(value)?;
        out.insert(key.to_string(), normalized);
    }

    // If anything is left, the record had extra fields we don't know about.
    if !obj.is_empty() {
        return Err(CanonError::UnexpectedFields);
    }

    let canonical = Value::Object(out);
    serde_json::to_vec(&canonical).map_err(|_| CanonError::Encode)
}

fn normalize_value(value: Value) -> Result<Value, CanonError> {
    match value {
        Value::Null | Value::Bool(_) => Ok(value),
        Value::Number(n) => {
            // Only integral numbers are allowed; floats are rejected.
            if n.as_i64().is_some() || n.as_u64().is_some() {
                Ok(Value::Number(n))
            } else {
                Err(CanonError::FloatDisallowed)
            }
        }
        Value::String(s) => {
            let normalized: String = s.nfc().collect();
            Ok(Value::String(normalized))
        }
        Value::Array(values) => {
            let mut out = Vec::with_capacity(values.len());
            for v in values {
                out.push(normalize_value(v)?);
            }
            Ok(Value::Array(out))
        }
        Value::Object(map) => {
            // For nested maps we keep insertion order as provided by serde_json,
            // but still normalize all nested values and reject floats.
            let mut out = Map::new();
            for (k, v) in map {
                let normalized = normalize_value(v)?;
                out.insert(k, normalized);
            }
            Ok(Value::Object(out))
        }
    }
}

```

### crates/ron-audit/src/canon/rules.rs
<a id="crates-ron-audit-src-canon-rules-rs"></a>

```rust
//! Canon rules scaffold.

```

### crates/ron-audit/src/canon/vectors.rs
<a id="crates-ron-audit-src-canon-vectors-rs"></a>

```rust
//! Frozen test vectors scaffold.

```

### crates/ron-audit/src/dto.rs
<a id="crates-ron-audit-src-dto-rs"></a>

```rust
//! Small DTO helpers for ron-audit.
//!
//! For now, `AuditRecord` and its helper types live here. The long-term plan
//! (per the blueprints) is to host these DTOs in `ron-proto` and have
//! `ron-audit` re-export them, but that module doesn't exist yet.

use serde::{Deserialize, Serialize};
use serde_json::Value;

/// Canonical audit record shape.
///
/// This matches the IDB specification:
///
/// ```text
/// #[serde(deny_unknown_fields)]
/// pub struct AuditRecord {
///   pub v: u16,             // schema major
///   pub ts_ms: u64,         // advisory wall-clock millis
///   pub writer_id: String,  // "svc-gateway@inst-123" (lex order stable)
///   pub seq: u64,           // strictly monotone per (writer_id, stream)
///   pub stream: String,     // "ingress" | "policy" | ...
///   pub kind: AuditKind,    // CapIssued | PolicyChanged | IndexWrite | ...
///   pub actor: ActorRef,    // {cap_id?, key_fpr?, passport_id?, anon?:bool}
///   pub subject: SubjectRef,// {content_id? "b3:<hex>", ledger_txid?, name?}
///   pub reason: ReasonCode, // normalized taxonomy
///   pub attrs: serde_json::Value, // ≤ 1 KiB canonicalized
///   pub prev: String,       // "b3:<hex>" previous or "b3:0" for genesis
///   pub self_hash: String,  // "b3:<hex>" over canonicalized record excl. self_hash
/// }
/// ```
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct AuditRecord {
    /// Schema major version.
    pub v: u16,
    /// Advisory wall-clock timestamp (milliseconds since Unix epoch).
    pub ts_ms: u64,
    /// Logical writer identifier (e.g. "svc-edge@inst-123").
    pub writer_id: String,
    /// Strictly monotone per `(writer_id, stream)`.
    pub seq: u64,
    /// Logical stream (e.g. "ingress", "policy", "index").
    pub stream: String,
    /// High-level category of the event.
    pub kind: AuditKind,
    /// Actor performing the action.
    pub actor: ActorRef,
    /// Subject of the action.
    pub subject: SubjectRef,
    /// Normalized reason taxonomy.
    pub reason: ReasonCode,
    /// Free-form, canonicalized attributes (bounded in size).
    pub attrs: Value,
    /// Previous record's `self_hash` ("b3:<hex>" or "b3:0" for genesis).
    pub prev: String,
    /// Canonical BLAKE3 hash of the record excluding `self_hash`.
    pub self_hash: String,
}

/// High-level category of an audit event.
///
/// This is intentionally minimal for now; more variants can be added as the
/// taxonomy hardens.
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
#[serde(rename_all = "snake_case")]
pub enum AuditKind {
    /// Fallback for events that haven't been fully classified yet.
    #[default]
    Unknown,
    /// Capability issued (e.g. macaroon/passport/cap token).
    CapIssued,
    /// Capability revoked or invalidated.
    CapRevoked,
    /// Policy document changed.
    PolicyChanged,
    /// Storage/index write operation.
    IndexWrite,
    /// A read / get operation was served.
    GetServed,
    /// Request was rejected due to quotas/limits.
    QuotaReject,
}

/// Reference to the actor performing the audited action.
///
/// Fields are optional; different layers may populate different subsets.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct ActorRef {
    /// Capability identifier (e.g. passport/cap token id).
    #[serde(skip_serializing_if = "Option::is_none")]
    pub cap_id: Option<String>,

    /// Key fingerprint (e.g. Ed25519 public key hash).
    #[serde(skip_serializing_if = "Option::is_none")]
    pub key_fpr: Option<String>,

    /// Passport identifier (from svc-passport).
    #[serde(skip_serializing_if = "Option::is_none")]
    pub passport_id: Option<String>,

    /// Whether the actor is anonymous.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub anon: Option<bool>,
}

/// Reference to the subject of the audited action.
///
/// Again, all fields are optional so hosts can fill as much as they know.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct SubjectRef {
    /// ContentId / object hash ("b3:<hex>").
    #[serde(skip_serializing_if = "Option::is_none")]
    pub content_id: Option<String>,

    /// Ledger transaction id (when present).
    #[serde(skip_serializing_if = "Option::is_none")]
    pub ledger_txid: Option<String>,

    /// Human-readable name or label, if applicable.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// Normalized reason taxonomy.
///
/// For now this is a thin newtype over `String` so we can evolve the
/// vocabulary without breaking the wire schema.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
#[serde(transparent)]
pub struct ReasonCode(pub String);

/// Fixed-size dedupe key derived from the canonical bytes of an `AuditRecord`.
///
/// This is the raw BLAKE3 output used for indexing / dedupe structures.
pub type DedupeKey = [u8; 32];

/// Export-friendly representation of a chain head.
///
/// Host crates can use this when exposing heads over admin/diagnostic APIs.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChainHeadDto {
    /// Stream identifier (e.g. logical stream or partition key).
    pub stream: String,
    /// Last known sequence number within the stream.
    pub seq: u64,
    /// Last known `self_hash` at the head of the stream.
    pub head: String,
}

```

### crates/ron-audit/src/errors.rs
<a id="crates-ron-audit-src-errors-rs"></a>

```rust
//! Error types for ron-audit.
//!
//! These are intentionally small and host-friendly; higher layers can wrap them
//! in richer error stacks if desired.

use std::io;

use thiserror::Error;

use crate::canon::CanonError;

/// Errors produced while appending audit records into a sink.
#[derive(Debug, Error)]
pub enum AppendError {
    /// The sink is full / backpressure threshold hit.
    #[error("audit sink is full or backpressured")]
    Full,

    /// The record exceeded size bounds (attrs or full record).
    #[error("audit record size exceeded bounds")]
    SizeExceeded,

    /// The sink detected tampering or chain breakage (e.g. prev/self mismatch).
    #[error("audit chain tamper detected")]
    Tamper,

    /// Underlying IO error from a WAL or storage layer.
    #[error("io error while appending audit record: {0}")]
    Io(#[from] io::Error),

    /// Canonical form violated schema or invariants.
    #[error("schema / canonicalization error")]
    Schema,
}

/// Errors produced while verifying canonical form or chain linkage.
#[derive(Debug, Error)]
pub enum VerifyError {
    /// The computed hash did not match the record's `self_hash`.
    #[error("self hash mismatch")]
    HashMismatch,

    /// Canonicalization failed (NFC, floats, unknown fields, etc).
    #[error("canonicalization error: {0}")]
    Canon(#[from] CanonError),

    /// Chain linkage between two adjacent records failed.
    #[error("prev/self linkage mismatch")]
    LinkMismatch,
}

/// Errors produced by bounds checks (size limits).
#[derive(Debug, Error)]
pub enum BoundsError {
    /// `attrs` payload exceeded the configured maximum number of bytes.
    #[error("attrs too large: {actual} bytes (max {max})")]
    AttrsTooLarge {
        /// Actual serialized size in bytes.
        actual: usize,
        /// Configured maximum size in bytes.
        max: usize,
    },

    /// Full record exceeded the configured maximum number of bytes.
    #[error("record too large: {actual} bytes (max {max})")]
    RecordTooLarge {
        /// Actual serialized size in bytes.
        actual: usize,
        /// Configured maximum size in bytes.
        max: usize,
    },
}

```

### crates/ron-audit/src/hash/b3.rs
<a id="crates-ron-audit-src-hash-b3-rs"></a>

```rust
//! BLAKE3 hashing for canonical audit records.

use blake3::Hasher;

use crate::canon::{canonicalize_without_self_hash, CanonError};
use crate::dto::DedupeKey;
use crate::AuditRecord;

/// Compute the canonical BLAKE3 hash of a record, excluding `self_hash`,
/// and return it in the `"b3:<hex>"` string form used on-chain.
pub fn b3_no_self(rec: &AuditRecord) -> Result<String, CanonError> {
    let bytes = canonicalize_without_self_hash(rec)?;
    let mut hasher = Hasher::new();
    hasher.update(&bytes);
    let hash = hasher.finalize();
    Ok(format!("b3:{}", hash.to_hex()))
}

/// Compute the canonical BLAKE3 hash of a record, excluding `self_hash`,
/// and return the raw 32-byte output as a dedupe key.
pub fn dedupe_key(rec: &AuditRecord) -> Result<DedupeKey, CanonError> {
    let bytes = canonicalize_without_self_hash(rec)?;
    let mut hasher = Hasher::new();
    hasher.update(&bytes);
    let hash = hasher.finalize();
    let mut out = [0u8; 32];
    out.copy_from_slice(hash.as_bytes());
    Ok(out)
}

```

### crates/ron-audit/src/hash/mod.rs
<a id="crates-ron-audit-src-hash-mod-rs"></a>

```rust
//! Hash helpers for `AuditRecord`.

mod b3;

pub use b3::{b3_no_self, dedupe_key};

```

### crates/ron-audit/src/lib.rs
<a id="crates-ron-audit-src-lib-rs"></a>

```rust
//! ron-audit — audit-chain helpers for `AuditRecord`.
//!
//! RO:WHAT — Library for canonicalization, hashing, verification and sink traits
//!           over `AuditRecord`.
//! RO:WHY  — Give Micronode/Macronode hosts one precise place to agree on how
//!           audit chains are formed, hashed and checked.
//! RO:INTERACTS — Intended to be wired by svc-edge, svc-registry, svc-storage,
//!           micronode, macronode, etc. DTOs currently live locally; they can
//!           be migrated into `ron-proto` later without changing this crate's
//!           outward API.
//!
//! NOTE: The original IDB sketched `pub use ron_proto::audit::AuditRecord;`,
//! but `ron_proto::audit` does not exist yet. For now we define the DTOs
//! locally (in `dto`) and re-export from there.

#![forbid(unsafe_code)]
#![deny(missing_docs)]
#![deny(clippy::unwrap_used, clippy::expect_used, clippy::await_holding_lock)]

mod errors;

pub mod bounds;
pub mod canon;
pub mod dto;
pub mod hash;
pub mod metrics;
pub mod prelude;
pub mod privacy;
pub mod sink;
pub mod stream;
pub mod verify;

/// Primary DTO used by ron-audit — currently defined locally in `dto`.
pub use crate::dto::AuditRecord;

pub use crate::canon::CanonError;
pub use crate::errors::{AppendError, BoundsError, VerifyError};
pub use crate::sink::{AuditSink, AuditStream, ChainState};

```

### crates/ron-audit/src/metrics/mod.rs
<a id="crates-ron-audit-src-metrics-mod-rs"></a>

```rust
// crates/ron-audit/src/metrics/mod.rs
//! RO:WHAT  — Zero-IO metrics hook for ron-audit (library-only).
//! RO:WHY   — Let hosts publish `audit_*` metrics (Prometheus, etc.) without
//!            pulling heavy deps into the core crate.
//! RO:INTERACTS — Host services (svc-edge, svc-gateway, micronode, etc.) can
//!                install a recorder; ron-audit stays ignorant of the backend.
//!
//! Design notes:
//! - Default is a NO-OP recorder: no allocations, no locks on the hot path.
//! - This crate never depends on prometheus/tokio/axum; that’s host territory.
//! - API is intentionally tiny and stable: counter + histogram + gauge.
//! - Install is best-effort: first caller wins; later calls are ignored.
//!
//! Example (host crate):
//! ```ignore
//! use ron_audit::metrics::{install_recorder, MetricsRecorder};
//!
//! struct PromRecorder { /* wraps prometheus registry */ }
//! impl MetricsRecorder for PromRecorder {
//!     fn counter_add(&self, name: &'static str, by: u64) { /* ... */ }
//!     fn hist_ns(&self, name: &'static str, value: u64) { /* ... */ }
//!     fn gauge_set(&self, name: &'static str, value: i64) { /* ... */ }
//! }
//!
//! static PROM: PromRecorder = PromRecorder { /* ... */ };
//!
//! pub fn init_metrics() {
//!     ron_audit::metrics::install_recorder(&PROM);
//! }
//! ```
//!
//! Inside ron-audit we can call the helpers in hot paths (e.g. verify, append)
//! without knowing how they are implemented by the host.

use std::sync::OnceLock;

/// Minimal interface a host-side metrics backend must implement.
///
/// All methods must be cheap and non-blocking — they are called on the audit
/// hot path (verify/append). Any heavy lifting (aggregation, encoding, I/O)
/// should be done in the host, off the hot path.
pub trait MetricsRecorder: Send + Sync + 'static {
    /// Monotonic counter add.
    ///
    /// Example names (host suggestion):
    /// - "ron_audit_emit_total"
    /// - "ron_audit_verify_ok_total"
    /// - "ron_audit_verify_fail_total"
    fn counter_add(&self, name: &'static str, by: u64);

    /// Histogram observation in nanoseconds.
    ///
    /// Hosts may choose to export in seconds/milliseconds; the unit here is
    /// just a convention for the value we pass.
    fn hist_ns(&self, name: &'static str, value: u64);

    /// Gauge set for instantaneous values.
    ///
    /// Example names:
    /// - "ron_audit_heads_tracked"
    /// - "ron_audit_wal_queue_depth"
    fn gauge_set(&self, name: &'static str, value: i64);
}

/// NO-OP recorder used when no host has installed a real backend.
///
/// This is the default; it ensures we never panic or allocate on the hot path
/// even if nothing is wired up yet.
struct NoopRecorder;

impl MetricsRecorder for NoopRecorder {
    #[inline]
    fn counter_add(&self, _name: &'static str, _by: u64) {
        // no-op
    }

    #[inline]
    fn hist_ns(&self, _name: &'static str, _value: u64) {
        // no-op
    }

    #[inline]
    fn gauge_set(&self, _name: &'static str, _value: i64) {
        // no-op
    }
}

static NOOP_RECORDER: NoopRecorder = NoopRecorder;

/// Global recorder pointer; first install wins.
///
/// We store a `&'static dyn MetricsRecorder` so hosts can keep their own
/// statics and avoid extra allocations here.
static RECORDER: OnceLock<&'static dyn MetricsRecorder> = OnceLock::new();

#[inline]
fn recorder() -> &'static dyn MetricsRecorder {
    // If a host has installed a recorder, use it; otherwise fall back to NOOP.
    RECORDER.get().copied().unwrap_or(&NOOP_RECORDER)
}

/// Install a global metrics recorder.
///
/// This should be called once by a host crate at startup. If called multiple
/// times, only the first recorder is kept; subsequent calls are ignored.
///
/// This behavior is intentional: it avoids surprising mid-flight swaps.
pub fn install_recorder(rec: &'static dyn MetricsRecorder) {
    let _ = RECORDER.set(rec);
}

/// Increment a counter by `by`.
///
/// Thin wrapper around `MetricsRecorder::counter_add`.
#[inline]
pub fn counter_add(name: &'static str, by: u64) {
    recorder().counter_add(name, by);
}

/// Observe a latency value (nanoseconds) in a histogram.
///
/// Thin wrapper around `MetricsRecorder::hist_ns`.
#[inline]
pub fn hist_ns(name: &'static str, value: u64) {
    recorder().hist_ns(name, value);
}

/// Set a gauge to `value`.
///
/// Thin wrapper around `MetricsRecorder::gauge_set`.
#[inline]
pub fn gauge_set(name: &'static str, value: i64) {
    recorder().gauge_set(name, value);
}

```

### crates/ron-audit/src/prelude.rs
<a id="crates-ron-audit-src-prelude-rs"></a>

```rust
/*!
RO:WHAT — Convenience prelude for common ron-audit types and helpers.
RO:WHY — DX: allow hosts/tests/benches to import a stable surface with a single use line.
RO:INTERACTS — bounds, canon, hash, verify, sink, dto.
RO:INVARIANTS — stable re-export set; no heavy dependencies pulled in accidentally.
RO:METRICS/LOGS — none.
RO:CONFIG — none.
RO:SECURITY — re-exports only; no logic.
RO:TEST HOOKS — doc test in this file; tests/api_compat.rs.
*/

pub use crate::bounds::{check as check_bounds, DEFAULT_MAX_ATTRS_BYTES, DEFAULT_MAX_RECORD_BYTES};
pub use crate::canon::{canonicalize_without_self_hash, CanonError};
pub use crate::hash::{b3_no_self, dedupe_key};
pub use crate::sink::{AuditSink, AuditStream, ChainState};
pub use crate::verify::{verify_chain, verify_chain_soa, verify_link, verify_record};
pub use crate::AuditRecord;
pub use crate::{AppendError, BoundsError, VerifyError};

```

### crates/ron-audit/src/privacy/mod.rs
<a id="crates-ron-audit-src-privacy-mod-rs"></a>

```rust
//! Privacy policy helpers for audit records.
//!
//! This is intentionally conservative for now: `validate` is a no-op that
//! always succeeds. Future iterations can add heuristics or policy hooks.

use crate::AuditRecord;

/// Errors raised by privacy policy checks.
#[derive(Debug, thiserror::Error)]
pub enum PrivacyError {
    /// Placeholder error for when PII or disallowed data is detected.
    #[error("privacy policy violation detected")]
    Violation,
}

/// Validate an `AuditRecord` against privacy policies.
///
/// At the moment this performs no checks and always returns `Ok(())`.
/// Hosts can add richer inspection logic later without breaking the
/// public function signature.
pub fn validate(_rec: &AuditRecord) -> Result<(), PrivacyError> {
    Ok(())
}

```

### crates/ron-audit/src/sink/export.rs
<a id="crates-ron-audit-src-sink-export-rs"></a>

```rust
//! Checkpoint / export helpers for audit chains.
//!
//! This is intentionally minimal for now; it can be extended later to
//! implement Merkle-style roots or chunked exports.

#[cfg(feature = "export")]
use crate::AuditRecord;

/// Simple checkpoint description for a contiguous span of records.
#[cfg(feature = "export")]
#[derive(Debug, Clone)]
pub struct Checkpoint {
    /// Inclusive start sequence number.
    pub from_seq: u64,
    /// Inclusive end sequence number.
    pub to_seq: u64,
    /// Hash of the last record in the span.
    pub head: String,
}

/// Compute a trivial checkpoint from a slice of records.
///
/// For now we just capture `[seq_min, seq_max]` and the `self_hash` of
/// the last record; this is enough to get tests going and can be
/// swapped for a more sophisticated construction later.
#[cfg(feature = "export")]
pub fn checkpoint_from_slice(records: &[AuditRecord]) -> Option<Checkpoint> {
    let last = records.last()?;
    let first_seq = records.first().map(|r| r.seq).unwrap_or(last.seq);
    Some(Checkpoint {
        from_seq: first_seq,
        to_seq: last.seq,
        head: last.self_hash.clone(),
    })
}

```

### crates/ron-audit/src/sink/mod.rs
<a id="crates-ron-audit-src-sink-mod-rs"></a>

```rust
//! Sink traits and basic implementations for audit chains.

mod traits;
pub use traits::{AuditSink, AuditStream, ChainState};

pub mod ram;

#[cfg(feature = "wal")]
pub mod wal;

#[cfg(feature = "export")]
pub mod export;

```

### crates/ron-audit/src/sink/ram.rs
<a id="crates-ron-audit-src-sink-ram-rs"></a>

```rust
//! Simple in-memory `AuditSink` implementation.
//!
//! This is primarily for testing and small deployments; it does not provide
//! durability beyond process lifetime.

use std::collections::HashMap;
use std::sync::RwLock;

use crate::errors::AppendError;
use crate::sink::{AuditSink, AuditStream, ChainState};
use crate::{dto::ChainHeadDto, AuditRecord};

/// In-memory append-only sink, keyed by stream.
#[derive(Debug, Default)]
pub struct RamSink {
    inner: RwLock<HashMap<String, Vec<AuditRecord>>>,
}

impl RamSink {
    /// Create an empty in-memory sink.
    pub fn new() -> Self {
        Self::default()
    }

    /// Get a copy of all records for a stream.
    pub fn records_for(&self, stream: &str) -> Vec<AuditRecord> {
        let guard = self
            .inner
            .read()
            .unwrap_or_else(|poisoned| poisoned.into_inner());

        guard.get(stream).cloned().unwrap_or_default()
    }

    /// Export a snapshot of all known chain heads.
    ///
    /// This is an in-memory convenience helper intended for:
    /// - admin/diagnostic APIs, and
    /// - tests that need to assert on checkpoint semantics.
    ///
    /// Each entry corresponds to a single logical stream.
    pub fn heads(&self) -> Vec<ChainHeadDto> {
        let guard = self
            .inner
            .read()
            .unwrap_or_else(|poisoned| poisoned.into_inner());

        guard
            .iter()
            .filter_map(|(stream, records)| {
                records.last().map(|last| ChainHeadDto {
                    stream: stream.clone(),
                    seq: last.seq,
                    head: last.self_hash.clone(),
                })
            })
            .collect()
    }
}

impl AuditStream for RamSink {
    fn state(&self, stream: &str) -> ChainState {
        let guard = self
            .inner
            .read()
            .unwrap_or_else(|poisoned| poisoned.into_inner());

        if let Some(records) = guard.get(stream) {
            if let Some(last) = records.last() {
                return ChainState {
                    head: last.self_hash.clone(),
                    seq: last.seq,
                };
            }
        }

        ChainState::default()
    }
}

impl AuditSink for RamSink {
    fn append(&self, rec: &AuditRecord) -> Result<String, AppendError> {
        let mut guard = self
            .inner
            .write()
            .unwrap_or_else(|poisoned| poisoned.into_inner());

        let stream = rec.stream.clone();
        let records = guard.entry(stream.clone()).or_default();

        // Enforce simple append-only linkage rule: prev == last.self_hash.
        if let Some(last) = records.last() {
            if rec.prev != last.self_hash {
                return Err(AppendError::Tamper);
            }
        }

        records.push(rec.clone());
        Ok(rec.self_hash.clone())
    }
}

```

### crates/ron-audit/src/sink/traits.rs
<a id="crates-ron-audit-src-sink-traits-rs"></a>

```rust
//! Core sink traits for append-only audit chains.

use crate::errors::AppendError;
use crate::AuditRecord;

/// Snapshot of a chain head for a given stream.
#[derive(Debug, Clone, Default)]
pub struct ChainState {
    /// Last known `self_hash` at the head of the stream.
    pub head: String,
    /// Last known sequence number for the stream.
    pub seq: u64,
}

/// Read-only view of audit stream state.
pub trait AuditStream: Send + Sync {
    /// Return the current chain state for a given stream.
    fn state(&self, stream: &str) -> ChainState;

    /// Convenience helper: `state(stream).seq + 1`.
    fn next_seq(&self, stream: &str) -> u64 {
        self.state(stream).seq.saturating_add(1)
    }
}

/// Append-only sink for audit records.
///
/// Implementations are expected to:
/// - Enforce `prev/self_hash` consistency.
/// - Enforce monotonic `seq` within a stream.
/// - Provide persistence guarantees appropriate for the deployment.
pub trait AuditSink: Send + Sync {
    /// Append a single record to the sink.
    ///
    /// Implementations typically:
    /// - Validate bounds.
    /// - Validate hash and linkage.
    /// - Commit to WAL / storage.
    fn append(&self, rec: &AuditRecord) -> Result<String, AppendError>;

    /// Flush any buffered data to durable storage.
    fn flush(&self) -> Result<(), AppendError> {
        Ok(())
    }
}

```

### crates/ron-audit/src/sink/wal.rs
<a id="crates-ron-audit-src-sink-wal-rs"></a>

```rust
//! Placeholder WAL-backed sink implementation.
//!
//! This module is feature-gated behind `wal` and currently provides a
//! minimal, non-durable implementation that behaves like `RamSink`.
//!
//! A real WAL-backed sink can replace this without breaking the public
//! trait surface.

#[cfg(feature = "wal")]
use std::sync::Arc;

#[cfg(feature = "wal")]
use crate::sink::{AuditSink, AuditStream, ChainState};
#[cfg(feature = "wal")]
use crate::{errors::AppendError, AuditRecord};

/// Minimal WAL sink placeholder.
///
/// Internally this just forwards to an in-memory `RamSink`. The type is
/// present so that higher layers can experiment with the `wal` feature
/// flag without breaking compilation.
#[cfg(feature = "wal")]
#[derive(Debug, Default)]
pub struct WalSink {
    inner: Arc<crate::sink::ram::RamSink>,
}

#[cfg(feature = "wal")]
impl WalSink {
    /// Construct a new placeholder WAL sink.
    pub fn new() -> Self {
        Self {
            inner: Arc::new(crate::sink::ram::RamSink::new()),
        }
    }
}

#[cfg(feature = "wal")]
impl AuditStream for WalSink {
    fn state(&self, stream: &str) -> ChainState {
        self.inner.state(stream)
    }
}

#[cfg(feature = "wal")]
impl AuditSink for WalSink {
    fn append(&self, rec: &AuditRecord) -> Result<String, AppendError> {
        self.inner.append(rec)
    }

    fn flush(&self) -> Result<(), AppendError> {
        self.inner.flush()
    }
}

```

### crates/ron-audit/src/stream/mod.rs
<a id="crates-ron-audit-src-stream-mod-rs"></a>

```rust
//! Streaming helpers for audit sinks.
//!
//! For the initial seed we keep this extremely small; hosts can build
//! richer batching / mpsc-based streaming layers on top.

use crate::errors::AppendError;
use crate::sink::AuditSink;
use crate::AuditRecord;

/// A simple buffered sink wrapper that collects records and flushes them
/// in a single batch call.
///
/// The current implementation just forwards records one-by-one; it
/// exists mainly to give tests somewhere to hang future stream logic.
#[derive(Debug)]
pub struct BufferedSink<S> {
    inner: S,
}

impl<S> BufferedSink<S> {
    /// Wrap an existing sink.
    pub fn new(inner: S) -> Self {
        Self { inner }
    }

    /// Access the inner sink.
    pub fn into_inner(self) -> S {
        self.inner
    }
}

impl<S> BufferedSink<S>
where
    S: AuditSink,
{
    /// Append all given records, stopping on the first error.
    pub fn append_all(&self, records: &[AuditRecord]) -> Result<(), AppendError> {
        for rec in records {
            self.inner.append(rec)?;
        }
        self.inner.flush()
    }
}

```

### crates/ron-audit/src/verify/chain.rs
<a id="crates-ron-audit-src-verify-chain-rs"></a>

```rust
/*!
RO:WHAT — Scalar and SoA-style helpers for verifying audit chains.
RO:WHY — Integrity/RES: cheaply validate self_hash and prev/self linkage over large batches.
RO:INTERACTS — super::record::verify_record; crate::errors::VerifyError; crate::AuditRecord.
RO:INVARIANTS — no unsafe; verify_chain is the scalar reference; verify_chain_soa must be
                 semantics-identical. The `simd` feature is currently a no-op hook reserved for
                 future optimizations; scalar equality remains the oracle.
RO:METRICS/LOGS — none here; callers may instrument latency externally.
RO:CONFIG — none; batch size is provided by callers.
RO:SECURITY — tamper-evident: any mismatch is surfaced as VerifyError::HashMismatch or LinkMismatch.
RO:TEST HOOKS — tests/idempotency.rs, tests/multi_writer_ordering.rs, tests/verify_soa.rs;
                 benches/verify_chain.rs.
*/

use crate::errors::VerifyError;
use crate::verify::verify_record;
use crate::AuditRecord;

/// Internal helper for comparing prev/self_hash.
///
/// For now this is a thin wrapper around `==` in all configurations. The `simd`
/// feature flag is reserved for future, stable SIMD-based implementations once
/// the ecosystem and MSRV make that a good trade-off.
///
/// Keeping this helper as a single choke point allows us to:
/// - keep scalar equality as the correctness oracle today;
/// - later drop in a feature-gated optimized implementation without touching
///   the rest of the verification code.
#[inline]
fn eq_hashes(a: &str, b: &str) -> bool {
    // NOTE: `simd` feature currently does not change behavior. When we add a
    // stable SIMD implementation (via an external crate or std support),
    // it will live behind this helper.
    #[cfg(feature = "simd")]
    {
        a == b
    }

    #[cfg(not(feature = "simd"))]
    {
        a == b
    }
}

/// Verify that `next` correctly links to `prev`.
///
/// At minimum we check:
/// - `next.prev == prev.self_hash`
pub fn verify_link(prev: &AuditRecord, next: &AuditRecord) -> Result<(), VerifyError> {
    if eq_hashes(&next.prev, &prev.self_hash) {
        Ok(())
    } else {
        Err(VerifyError::LinkMismatch)
    }
}

/// Scalar reference implementation: verify a full chain of audit records
/// provided as an iterator.
///
/// The iterator is consumed; each record is verified individually and
/// adjacency is checked via [`verify_link`].
pub fn verify_chain<I>(iter: I) -> Result<(), VerifyError>
where
    I: IntoIterator<Item = AuditRecord>,
{
    let mut last: Option<AuditRecord> = None;

    for rec in iter {
        verify_record(&rec)?;
        if let Some(prev) = &last {
            verify_link(prev, &rec)?;
        }
        last = Some(rec);
    }

    Ok(())
}

/// SoA-style batch verifier over a contiguous slice of records.
///
/// This is intended as a "fast path" for hosts that already have a `&[AuditRecord]`
/// in memory. It is kept separate from [`verify_chain`] so the scalar reference
/// implementation can remain small and obviously correct.
///
/// Semantics:
/// - If the slice is empty, returns `Ok(())`.
/// - For each record, recomputes and checks its `self_hash`.
/// - For each adjacent pair `(prev, next)` checks `next.prev == prev.self_hash`
///   via the `eq_hashes` helper (which is currently scalar in all modes).
pub fn verify_chain_soa(chain: &[AuditRecord]) -> Result<(), VerifyError> {
    if chain.is_empty() {
        return Ok(());
    }

    // First pass: verify each record's self_hash.
    for rec in chain {
        verify_record(rec)?;
    }

    // Second pass: SoA-style linkage check.
    for i in 1..chain.len() {
        let prev = &chain[i - 1];
        let next = &chain[i];

        if !eq_hashes(&next.prev, &prev.self_hash) {
            return Err(VerifyError::LinkMismatch);
        }
    }

    Ok(())
}

```

### crates/ron-audit/src/verify/mod.rs
<a id="crates-ron-audit-src-verify-mod-rs"></a>

```rust
/*!
RO:WHAT — Verification helpers for individual audit records and chains.
RO:WHY — Integrity: enforce self_hash correctness and prev/self linkage invariants.
RO:INTERACTS — crate::hash, crate::errors, crate::dto::AuditRecord.
RO:INVARIANTS — no unsafe; verify_chain is scalar reference; verify_chain_soa is batch fast path with matching semantics.
RO:METRICS/LOGS — none here; callers may instrument latency/histograms externally.
RO:CONFIG — none.
RO:SECURITY — any tamper in the audit chain is surfaced as VerifyError.
RO:TEST HOOKS — unit tests (idempotency, multi_writer_ordering, verify_soa); benches/verify_chain.rs.
*/

mod chain;
mod record;

pub use chain::{verify_chain, verify_chain_soa, verify_link};
pub use record::verify_record;

```

### crates/ron-audit/src/verify/record.rs
<a id="crates-ron-audit-src-verify-record-rs"></a>

```rust
//! Per-record verification helpers.

use crate::errors::VerifyError;
use crate::hash::b3_no_self;
use crate::AuditRecord;

/// Verify a single `AuditRecord` by recomputing its canonical hash and
/// comparing it to `self_hash`.
pub fn verify_record(rec: &AuditRecord) -> Result<(), VerifyError> {
    let expected = b3_no_self(rec)?;
    if rec.self_hash == expected {
        Ok(())
    } else {
        Err(VerifyError::HashMismatch)
    }
}

```

### crates/ron-audit/testing/vectors/manifest_example.json
<a id="crates-ron-audit-testing-vectors-manifestexample-json"></a>

```json

```

### crates/ron-audit/testing/vectors/record_max.json
<a id="crates-ron-audit-testing-vectors-recordmax-json"></a>

```json

```

### crates/ron-audit/testing/vectors/record_small.json
<a id="crates-ron-audit-testing-vectors-recordsmall-json"></a>

```json

```

### crates/ron-audit/tests/api_compat.rs
<a id="crates-ron-audit-tests-apicompat-rs"></a>

```rust
/*!
RO:WHAT — API surface smoke test for prelude and core modules.
RO:WHY — GOV/DX: catch obvious API breakage before semver checks.
RO:INTERACTS — ron_audit::prelude; dto::AuditRecord.
RO:INVARIANTS — prelude compiles; basic hash/verify/bounds round-trip works.
RO:TEST HOOKS — Unit tests here; CI later wires cargo-public-api.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::prelude::*;
use serde_json::json;

fn mk_record() -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "writer@test".to_string(),
        seq: 0,
        stream: "stream@test".to_string(),
        kind: AuditKind::CapIssued,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("api-compat-test".to_string()),
        attrs: json!({ "ok": true }),
        prev: "b3:0".to_string(),
        self_hash: String::new(),
    }
}

#[test]
fn prelude_smoke_round_trip() {
    let mut rec = mk_record();

    // hash without self, then set self_hash and verify
    rec.self_hash = b3_no_self(&rec).expect("hash");
    verify_record(&rec).expect("verify");

    // bounds check via prelude re-exports
    check_bounds(&rec, DEFAULT_MAX_ATTRS_BYTES, DEFAULT_MAX_RECORD_BYTES).expect("bounds");
}

```

### crates/ron-audit/tests/append_only.rs
<a id="crates-ron-audit-tests-appendonly-rs"></a>

```rust
/*!
RO:WHAT — Append-only behavior and basic chain head semantics for RamSink.
RO:WHY — Integrity: enforce append-only and detect tamper on prev/self linkage.
RO:INTERACTS — ron_audit::sink::ram::RamSink; hash::b3_no_self; AppendError.
RO:INVARIANTS — append is append-only; prev must equal last.self_hash; per-stream heads tracked.
RO:TEST HOOKS — Unit tests in this file; fuzz/loom reserved for host q.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::b3_no_self;
use ron_audit::sink::{ram::RamSink, AuditSink, AuditStream};
use ron_audit::{AppendError, AuditRecord};
use serde_json::json;

fn mk_record(stream: &str, seq: u64, prev: &str) -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    let mut rec = AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "writer@test".to_string(),
        seq,
        stream: stream.to_string(),
        kind: AuditKind::Unknown,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("test-append-only".to_string()),
        attrs: json!({ "case": "append_only" }),
        prev: prev.to_string(),
        self_hash: String::new(),
    };

    rec.self_hash = b3_no_self(&rec).expect("hash");
    rec
}

#[test]
fn append_updates_head_and_seq_per_stream() {
    let sink = RamSink::new();

    let genesis = mk_record("s1", 0, "b3:0");
    let head1 = sink.append(&genesis).expect("append genesis");
    let state1 = sink.state("s1");
    assert_eq!(state1.seq, 0);
    assert_eq!(state1.head, head1);

    let rec2 = mk_record("s1", 1, &head1);
    let head2 = sink.append(&rec2).expect("append second");
    let state2 = sink.state("s1");
    assert_eq!(state2.seq, 1);
    assert_eq!(state2.head, head2);
    assert_ne!(state2.head, head1);
}

#[test]
fn append_rejects_prev_mismatch_tamper() {
    let sink = RamSink::new();

    let genesis = mk_record("s1", 0, "b3:0");
    let head1 = sink.append(&genesis).expect("append genesis");

    // Tampered record: prev does NOT match last.self_hash.
    let mut bad = mk_record("s1", 1, "b3:not-the-head");
    // keep self_hash consistent for the bad record itself
    bad.self_hash = b3_no_self(&bad).expect("hash bad");

    assert_ne!(bad.prev, head1);

    let err = sink.append(&bad).expect_err("tamper should be rejected");
    match err {
        AppendError::Tamper => {}
        other => panic!("expected AppendError::Tamper, got {other:?}"),
    }
}

```

### crates/ron-audit/tests/bounds.rs
<a id="crates-ron-audit-tests-bounds-rs"></a>

```rust
/*!
RO:WHAT — Bounds checking for attrs and full record sizes.
RO:WHY — PERF/RES: protect sinks from unbounded payloads.
RO:INTERACTS — ron_audit::bounds; dto::AuditRecord; serde_json.
RO:INVARIANTS — attrs ≤ configured max; record ≤ configured max.
RO:TEST HOOKS — Unit tests here; fuzz will hit more attr shapes later.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::bounds;
use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::{AuditRecord, BoundsError};
use serde_json::json;

fn base_record() -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "writer@test".to_string(),
        seq: 0,
        stream: "stream@test".to_string(),
        kind: AuditKind::Unknown,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("bounds-test".to_string()),
        attrs: json!({ "ok": true }),
        prev: "b3:0".to_string(),
        self_hash: "b3:placeholder".to_string(),
    }
}

#[test]
fn small_record_respects_default_bounds() {
    let rec = base_record();
    bounds::check(
        &rec,
        bounds::DEFAULT_MAX_ATTRS_BYTES,
        bounds::DEFAULT_MAX_RECORD_BYTES,
    )
    .expect("small record should pass bounds");
}

#[test]
fn oversized_attrs_are_rejected() {
    let mut rec = base_record();
    let big = "x".repeat(bounds::DEFAULT_MAX_ATTRS_BYTES + 1);
    rec.attrs = json!(big);

    let err = bounds::check(
        &rec,
        bounds::DEFAULT_MAX_ATTRS_BYTES,
        bounds::DEFAULT_MAX_RECORD_BYTES,
    )
    .expect_err("attrs beyond limit must be rejected");

    match err {
        BoundsError::AttrsTooLarge { .. } => {}
        other => panic!("expected AttrsTooLarge, got {other:?}"),
    }
}

#[test]
fn oversized_record_is_rejected() {
    let mut rec = base_record();
    // Make the record body large via a long reason string.
    rec.reason = ReasonCode("x".repeat(5_000));

    let err = bounds::check(&rec, bounds::DEFAULT_MAX_ATTRS_BYTES, 512)
        .expect_err("record beyond limit must be rejected");

    match err {
        BoundsError::RecordTooLarge { .. } => {}
        other => panic!("expected RecordTooLarge, got {other:?}"),
    }
}

```

### crates/ron-audit/tests/canonicalization.rs
<a id="crates-ron-audit-tests-canonicalization-rs"></a>

```rust
/*!
RO:WHAT — Canonicalization invariants (drop self_hash, NFC, no floats).
RO:WHY — Integrity: stable hash surface and replay idempotency.
RO:INTERACTS — ron_audit::canon; dto::AuditRecord; serde_json.
RO:INVARIANTS — self_hash ignored; strings NFC-normalized; floats rejected.
RO:TEST HOOKS — Unit tests here; fuzz covers attr edge cases later.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::canon::{canonicalize_without_self_hash, CanonError};
use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::AuditRecord;
use serde_json::json;

fn base_record() -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "writer@test".to_string(),
        seq: 0,
        stream: "stream@test".to_string(),
        kind: AuditKind::CapIssued,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("canon-test".to_string()),
        attrs: json!({ "label": "ok" }),
        prev: "b3:0".to_string(),
        self_hash: "b3:placeholder".to_string(),
    }
}

#[test]
fn canonicalization_drops_self_hash() {
    let mut r1 = base_record();
    r1.self_hash = "b3:aaaa".to_string();

    let mut r2 = r1.clone();
    r2.self_hash = "b3:bbbb".to_string();

    let c1 = canonicalize_without_self_hash(&r1).expect("canon r1");
    let c2 = canonicalize_without_self_hash(&r2).expect("canon r2");

    assert_eq!(c1, c2, "self_hash must not affect canonical bytes");
}

#[test]
fn canonicalization_rejects_floats_in_attrs() {
    let mut r = base_record();
    r.attrs = json!({ "price": 1.5 });

    let res = canonicalize_without_self_hash(&r);
    match res {
        Err(CanonError::FloatDisallowed) => {}
        other => panic!("expected FloatDisallowed, got {other:?}"),
    }
}

#[test]
fn canonicalization_nfc_normalizes_strings() {
    // "Café" with decomposed é
    let decomposed = "Cafe\u{0301}";

    let mut r = base_record();
    r.attrs = json!({ "label": decomposed });

    let bytes = canonicalize_without_self_hash(&r).expect("canon");
    let value: serde_json::Value = serde_json::from_slice(&bytes).expect("valid json from canon");

    let label = value["attrs"]["label"]
        .as_str()
        .expect("attrs.label must be string");

    assert_eq!(label, "Café", "label must be NFC-normalized");
}

```

### crates/ron-audit/tests/export_checkpoints.rs
<a id="crates-ron-audit-tests-exportcheckpoints-rs"></a>

```rust
use std::collections::HashMap;

use ron_audit::dto::{ActorRef, AuditKind, AuditRecord, ReasonCode, SubjectRef};
use ron_audit::sink::ram::RamSink;
use ron_audit::AuditSink;
use serde_json::json;

/// Helper to build a minimal, self-consistent `AuditRecord` for tests.
///
/// NOTE: This does *not* compute a real BLAKE3 self_hash; tests here only care
/// about append-only semantics and head export, not cryptographic integrity.
fn make_record(stream: &str, seq: u64, prev: &str, self_hash: &str) -> AuditRecord {
    AuditRecord {
        v: 1,
        ts_ms: 0,
        writer_id: "svc-test@inst-1".to_string(),
        seq,
        stream: stream.to_string(),
        kind: AuditKind::Unknown,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("test".to_string()),
        attrs: json!({}),
        prev: prev.to_string(),
        self_hash: self_hash.to_string(),
    }
}

#[test]
fn export_heads_returns_latest_head_per_stream() {
    let sink = RamSink::new();

    // Build a small chain on two logical streams: "ingress" and "policy".
    // We use simple fake hashes here; we only care about linkage and export.
    let r1_ing = make_record("ingress", 1, "b3:0", "b3:ing-1");
    let r2_ing = make_record("ingress", 2, "b3:ing-1", "b3:ing-2");

    let r1_pol = make_record("policy", 1, "b3:0", "b3:pol-1");
    let r2_pol = make_record("policy", 2, "b3:pol-1", "b3:pol-2");
    let r3_pol = make_record("policy", 3, "b3:pol-2", "b3:pol-3");

    // Append in interleaved order to ensure ordering logic is per-stream.
    sink.append(&r1_ing).expect("append r1_ing");
    sink.append(&r1_pol).expect("append r1_pol");
    sink.append(&r2_ing).expect("append r2_ing");
    sink.append(&r2_pol).expect("append r2_pol");
    sink.append(&r3_pol).expect("append r3_pol");

    let heads = sink.heads();
    assert_eq!(heads.len(), 2, "expected one head per stream");

    let mut by_stream: HashMap<String, (u64, String)> = HashMap::new();
    for head in heads {
        by_stream.insert(head.stream.clone(), (head.seq, head.head.clone()));
    }

    // ingress: last ing record was seq=2, self_hash="b3:ing-2"
    let ingress = by_stream.get("ingress").expect("ingress head missing");
    assert_eq!(ingress.0, 2, "Ingress seq should be 2");
    assert_eq!(ingress.1, "b3:ing-2", "Ingress head hash mismatch");

    // policy: last pol record was seq=3, self_hash="b3:pol-3"
    let policy = by_stream.get("policy").expect("policy head missing");
    assert_eq!(policy.0, 3, "Policy seq should be 3");
    assert_eq!(policy.1, "b3:pol-3", "Policy head hash mismatch");
}

#[test]
fn export_heads_skips_empty_streams() {
    let sink = RamSink::new();

    // Only write to "ingress", leave "policy" empty.
    let r1_ing = make_record("ingress", 1, "b3:0", "b3:ing-1");
    sink.append(&r1_ing).expect("append r1_ing");

    let heads = sink.heads();
    assert_eq!(heads.len(), 1, "only one non-empty stream expected");

    let head = &heads[0];
    assert_eq!(head.stream, "ingress");
    assert_eq!(head.seq, 1);
    assert_eq!(head.head, "b3:ing-1");
}

```

### crates/ron-audit/tests/idempotency.rs
<a id="crates-ron-audit-tests-idempotency-rs"></a>

```rust
/*!
RO:WHAT — Idempotency of dedupe_key and hash/verify pipeline.
RO:WHY — ECON/RES: safe replay via stable canonicalization.
RO:INTERACTS — ron_audit::hash; verify; dto::AuditRecord.
RO:INVARIANTS — Same canonical record → same dedupe key; tamper breaks verify.
RO:TEST HOOKS — Unit tests here; fuzz targets canonicalization later.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::{b3_no_self, dedupe_key};
use ron_audit::verify::verify_record;
use ron_audit::{AuditRecord, VerifyError};
use serde_json::json;

fn base_record() -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "writer@test".to_string(),
        seq: 0,
        stream: "stream@test".to_string(),
        kind: AuditKind::CapIssued,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("idempotency-test".to_string()),
        attrs: json!({ "k": "v" }),
        prev: "b3:0".to_string(),
        self_hash: "b3:placeholder".to_string(),
    }
}

#[test]
fn dedupe_key_is_stable_across_self_hash_changes() {
    let mut r1 = base_record();
    let mut r2 = base_record();

    r1.self_hash = "b3:aaaa".to_string();
    r2.self_hash = "b3:bbbb".to_string();

    let k1 = dedupe_key(&r1).expect("dedupe r1");
    let k2 = dedupe_key(&r2).expect("dedupe r2");

    assert_eq!(k1, k2, "dedupe key must ignore self_hash differences");
}

#[test]
fn verify_record_succeeds_for_matching_hash() {
    let mut r = base_record();
    r.self_hash = b3_no_self(&r).expect("hash");
    verify_record(&r).expect("verify must succeed");
}

#[test]
fn verify_record_fails_on_tamper() {
    let mut r = base_record();
    r.self_hash = b3_no_self(&r).expect("hash");
    verify_record(&r).expect("baseline verify");

    // Tamper: change attrs but keep old self_hash.
    r.attrs = json!({ "k": "tampered" });

    let err = verify_record(&r).expect_err("tamper must fail verify");
    match err {
        VerifyError::HashMismatch => {}
        other => panic!("expected HashMismatch, got {other:?}"),
    }
}

```

### crates/ron-audit/tests/multi_writer_ordering.rs
<a id="crates-ron-audit-tests-multiwriterordering-rs"></a>

```rust
/*!
RO:WHAT — Multi-stream / multi-writer state semantics for RamSink.
RO:WHY — GOV/RES: clarify that only per-stream heads are exposed; no global order.
RO:INTERACTS — ron_audit::sink::ram::RamSink; hash::b3_no_self.
RO:INVARIANTS — Single writer per stream head; streams are independent.
RO:TEST HOOKS — Unit tests here; loom model covers host queueing later.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::b3_no_self;
use ron_audit::sink::{ram::RamSink, AuditSink, AuditStream};
use ron_audit::AuditRecord;
use serde_json::json;

fn mk_record(writer_id: &str, stream: &str, seq: u64, prev: &str) -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    let mut rec = AuditRecord {
        v: 1,
        ts_ms,
        writer_id: writer_id.to_string(),
        seq,
        stream: stream.to_string(),
        kind: AuditKind::IndexWrite,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("multi-writer-test".to_string()),
        attrs: json!({ "stream": stream, "seq": seq }),
        prev: prev.to_string(),
        self_hash: String::new(),
    };
    rec.self_hash = b3_no_self(&rec).expect("hash");
    rec
}

#[test]
fn per_stream_heads_are_independent() {
    let sink = RamSink::new();

    let a1 = mk_record("writer-a", "stream-a", 0, "b3:0");
    let b1 = mk_record("writer-b", "stream-b", 0, "b3:0");

    let head_a = sink.append(&a1).expect("append a1");
    let head_b = sink.append(&b1).expect("append b1");

    let state_a = sink.state("stream-a");
    let state_b = sink.state("stream-b");

    assert_eq!(state_a.seq, 0);
    assert_eq!(state_b.seq, 0);
    assert_eq!(state_a.head, head_a);
    assert_eq!(state_b.head, head_b);
    assert_ne!(
        state_a.head, state_b.head,
        "heads for distinct streams must be independent"
    );
}

#[test]
fn stream_state_is_snapshot_only() {
    let sink = RamSink::new();

    let a1 = mk_record("writer-a", "stream-a", 0, "b3:0");
    let head1 = sink.append(&a1).expect("append a1");
    let snapshot_before = sink.state("stream-a");
    assert_eq!(snapshot_before.seq, 0);
    assert_eq!(snapshot_before.head, head1);

    let a2 = mk_record("writer-a", "stream-a", 1, &head1);
    let head2 = sink.append(&a2).expect("append a2");
    let snapshot_after = sink.state("stream-a");

    assert_eq!(snapshot_after.seq, 1);
    assert_eq!(snapshot_after.head, head2);
    assert_ne!(snapshot_after.head, snapshot_before.head);
}

```

### crates/ron-audit/tests/privacy_policies.rs
<a id="crates-ron-audit-tests-privacypolicies-rs"></a>

```rust
/*!
RO:WHAT — Privacy policy hook smoke tests.
RO:WHY — SEC/GOV: ensure the hook is callable and side-effect free for now.
RO:INTERACTS — ron_audit::privacy; dto::AuditRecord.
RO:INVARIANTS — validate() must not mutate; default is allow-all.
RO:TEST HOOKS — Unit tests here; future policy logic can extend coverage.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::privacy;
use ron_audit::AuditRecord;
use serde_json::json;

fn base_record() -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "writer@test".to_string(),
        seq: 0,
        stream: "stream@test".to_string(),
        kind: AuditKind::Unknown,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("privacy-test".to_string()),
        attrs: json!({ "field": "value" }),
        prev: "b3:0".to_string(),
        self_hash: "b3:placeholder".to_string(),
    }
}

#[test]
fn privacy_validate_is_noop_for_now() {
    let rec = base_record();
    privacy::validate(&rec).expect("default privacy hook should pass");
}

```

### crates/ron-audit/tests/verify_soa.rs
<a id="crates-ron-audit-tests-verifysoa-rs"></a>

```rust
/*!
RO:WHAT — Cross-check between scalar verify_chain and verify_chain_soa.
RO:WHY — GOV/RES: ensure SoA fast path preserves scalar semantics on good and bad chains.
RO:INTERACTS — ron_audit::verify::{verify_chain, verify_chain_soa}; hash::b3_no_self; dto::AuditRecord.
RO:INVARIANTS — both paths must agree on success/failure for the same input chain.
RO:METRICS/LOGS — none; this is test-only.
RO:CONFIG — chain lengths fixed in test.
RO:SECURITY — synthetic records; no real PII or keys.
RO:TEST HOOKS — part of ron-audit unit test suite.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::b3_no_self;
use ron_audit::verify::{verify_chain, verify_chain_soa};
use ron_audit::AuditRecord;
use serde_json::json;

fn mk_chain(len: usize) -> Vec<AuditRecord> {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    let mut out = Vec::with_capacity(len);

    // genesis
    let mut genesis = AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "verify-soa@test".to_string(),
        seq: 0,
        stream: "verify_soa".to_string(),
        kind: AuditKind::CapIssued,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("verify-soa-test".to_string()),
        attrs: json!({ "seq": 0u64 }),
        prev: "b3:0".to_string(),
        self_hash: String::new(),
    };
    genesis.self_hash = b3_no_self(&genesis).expect("hash");
    out.push(genesis);

    while out.len() < len {
        let prev = out.last().expect("non-empty");
        let mut rec = AuditRecord {
            v: 1,
            ts_ms,
            writer_id: prev.writer_id.clone(),
            seq: prev.seq + 1,
            stream: prev.stream.clone(),
            kind: AuditKind::IndexWrite,
            actor: ActorRef::default(),
            subject: SubjectRef::default(),
            reason: ReasonCode("verify-soa-test".to_string()),
            attrs: json!({ "seq": prev.seq + 1 }),
            prev: prev.self_hash.clone(),
            self_hash: String::new(),
        };
        rec.self_hash = b3_no_self(&rec).expect("hash");
        out.push(rec);
    }

    out
}

#[test]
fn soa_and_scalar_agree_on_valid_chain() {
    let chain = mk_chain(128);

    // Scalar reference over owned iterator.
    verify_chain(chain.clone().into_iter()).expect("scalar verify");

    // SoA fast path over slice.
    verify_chain_soa(&chain).expect("soa verify");
}

#[test]
fn soa_and_scalar_agree_on_tampered_chain() {
    let mut chain = mk_chain(16);

    // Tamper: break linkage between two records.
    if chain.len() > 2 {
        chain[2].prev = "b3:not-a-real-prev".to_string();
    }

    let scalar = verify_chain(chain.clone().into_iter());
    let soa = verify_chain_soa(&chain);

    assert!(
        scalar.is_err() && soa.is_err(),
        "both scalar and soa verify must fail on tampered chain"
    );
}

```

