<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:54:58Z -->
# Code Bundle — `svc-dht`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/svc-dht/.cargo/config.toml](#crates-svc-dht--cargo-config-toml)
- [crates/svc-dht/.github/workflows/ci.yml](#crates-svc-dht--github-workflows-ci-yml)
- [crates/svc-dht/.github/workflows/fuzz.yml](#crates-svc-dht--github-workflows-fuzz-yml)
- [crates/svc-dht/.github/workflows/mermaid.yml](#crates-svc-dht--github-workflows-mermaid-yml)
- [crates/svc-dht/.github/workflows/perf.yml](#crates-svc-dht--github-workflows-perf-yml)
- [crates/svc-dht/.rustfmt.toml](#crates-svc-dht--rustfmt-toml)
- [crates/svc-dht/Cargo.toml](#crates-svc-dht-Cargo-toml)
- [crates/svc-dht/benches/lookup_bench.rs](#crates-svc-dht-benches-lookupbench-rs)
- [crates/svc-dht/build.rs](#crates-svc-dht-build-rs)
- [crates/svc-dht/clippy.toml](#crates-svc-dht-clippy-toml)
- [crates/svc-dht/examples/find_providers.rs](#crates-svc-dht-examples-findproviders-rs)
- [crates/svc-dht/examples/provide.rs](#crates-svc-dht-examples-provide-rs)
- [crates/svc-dht/fuzz/fuzz_targets/kad_packet_decode.rs](#crates-svc-dht-fuzz-fuzztargets-kadpacketdecode-rs)
- [crates/svc-dht/fuzz/fuzz_targets/msg_frame_decode.rs](#crates-svc-dht-fuzz-fuzztargets-msgframedecode-rs)
- [crates/svc-dht/loom/loom_hedge.rs](#crates-svc-dht-loom-loomhedge-rs)
- [crates/svc-dht/loom/loom_kbucket.rs](#crates-svc-dht-loom-loomkbucket-rs)
- [crates/svc-dht/rust-toolchain.toml](#crates-svc-dht-rust-toolchain-toml)
- [crates/svc-dht/scripts/chaos/netem.sh](#crates-svc-dht-scripts-chaos-netem-sh)
- [crates/svc-dht/scripts/chaos/partition.sh](#crates-svc-dht-scripts-chaos-partition-sh)
- [crates/svc-dht/scripts/provide-and-check.sh](#crates-svc-dht-scripts-provide-and-check-sh)
- [crates/svc-dht/scripts/render-mermaid.sh](#crates-svc-dht-scripts-render-mermaid-sh)
- [crates/svc-dht/scripts/run-local.sh](#crates-svc-dht-scripts-run-local-sh)
- [crates/svc-dht/scripts/smoke_svc_dht.sh](#crates-svc-dht-scripts-smokesvcdht-sh)
- [crates/svc-dht/scripts/ttl-demo.sh](#crates-svc-dht-scripts-ttl-demo-sh)
- [crates/svc-dht/scripts/two-node-local.sh](#crates-svc-dht-scripts-two-node-local-sh)
- [crates/svc-dht/src/bootstrap.rs](#crates-svc-dht-src-bootstrap-rs)
- [crates/svc-dht/src/cache/memory.rs](#crates-svc-dht-src-cache-memory-rs)
- [crates/svc-dht/src/cache/mod.rs](#crates-svc-dht-src-cache-mod-rs)
- [crates/svc-dht/src/cache/sled_cache.rs](#crates-svc-dht-src-cache-sledcache-rs)
- [crates/svc-dht/src/codec/decode.rs](#crates-svc-dht-src-codec-decode-rs)
- [crates/svc-dht/src/codec/encode.rs](#crates-svc-dht-src-codec-encode-rs)
- [crates/svc-dht/src/codec/frame.rs](#crates-svc-dht-src-codec-frame-rs)
- [crates/svc-dht/src/codec/limits.rs](#crates-svc-dht-src-codec-limits-rs)
- [crates/svc-dht/src/codec/mod.rs](#crates-svc-dht-src-codec-mod-rs)
- [crates/svc-dht/src/config.rs](#crates-svc-dht-src-config-rs)
- [crates/svc-dht/src/errors.rs](#crates-svc-dht-src-errors-rs)
- [crates/svc-dht/src/health.rs](#crates-svc-dht-src-health-rs)
- [crates/svc-dht/src/invariants.rs](#crates-svc-dht-src-invariants-rs)
- [crates/svc-dht/src/lib.rs](#crates-svc-dht-src-lib-rs)
- [crates/svc-dht/src/main.rs](#crates-svc-dht-src-main-rs)
- [crates/svc-dht/src/metrics.rs](#crates-svc-dht-src-metrics-rs)
- [crates/svc-dht/src/peer/bucket.rs](#crates-svc-dht-src-peer-bucket-rs)
- [crates/svc-dht/src/peer/id.rs](#crates-svc-dht-src-peer-id-rs)
- [crates/svc-dht/src/peer/mod.rs](#crates-svc-dht-src-peer-mod-rs)
- [crates/svc-dht/src/peer/selector.rs](#crates-svc-dht-src-peer-selector-rs)
- [crates/svc-dht/src/peer/table.rs](#crates-svc-dht-src-peer-table-rs)
- [crates/svc-dht/src/pipeline/asn_guard.rs](#crates-svc-dht-src-pipeline-asnguard-rs)
- [crates/svc-dht/src/pipeline/deadlines.rs](#crates-svc-dht-src-pipeline-deadlines-rs)
- [crates/svc-dht/src/pipeline/hedging.rs](#crates-svc-dht-src-pipeline-hedging-rs)
- [crates/svc-dht/src/pipeline/lookup.rs](#crates-svc-dht-src-pipeline-lookup-rs)
- [crates/svc-dht/src/pipeline/mod.rs](#crates-svc-dht-src-pipeline-mod-rs)
- [crates/svc-dht/src/pipeline/provide.rs](#crates-svc-dht-src-pipeline-provide-rs)
- [crates/svc-dht/src/pipeline/rate_limit.rs](#crates-svc-dht-src-pipeline-ratelimit-rs)
- [crates/svc-dht/src/pq/algo.rs](#crates-svc-dht-src-pq-algo-rs)
- [crates/svc-dht/src/pq/gating.rs](#crates-svc-dht-src-pq-gating-rs)
- [crates/svc-dht/src/pq/mod.rs](#crates-svc-dht-src-pq-mod-rs)
- [crates/svc-dht/src/pq/verify.rs](#crates-svc-dht-src-pq-verify-rs)
- [crates/svc-dht/src/provider/mod.rs](#crates-svc-dht-src-provider-mod-rs)
- [crates/svc-dht/src/provider/record.rs](#crates-svc-dht-src-provider-record-rs)
- [crates/svc-dht/src/provider/republish.rs](#crates-svc-dht-src-provider-republish-rs)
- [crates/svc-dht/src/provider/store.rs](#crates-svc-dht-src-provider-store-rs)
- [crates/svc-dht/src/provider/ttl.rs](#crates-svc-dht-src-provider-ttl-rs)
- [crates/svc-dht/src/readiness.rs](#crates-svc-dht-src-readiness-rs)
- [crates/svc-dht/src/rpc/bus.rs](#crates-svc-dht-src-rpc-bus-rs)
- [crates/svc-dht/src/rpc/discv5.rs](#crates-svc-dht-src-rpc-discv5-rs)
- [crates/svc-dht/src/rpc/http.rs](#crates-svc-dht-src-rpc-http-rs)
- [crates/svc-dht/src/rpc/kad.rs](#crates-svc-dht-src-rpc-kad-rs)
- [crates/svc-dht/src/rpc/mod.rs](#crates-svc-dht-src-rpc-mod-rs)
- [crates/svc-dht/src/supervision/backoff.rs](#crates-svc-dht-src-supervision-backoff-rs)
- [crates/svc-dht/src/supervision/mod.rs](#crates-svc-dht-src-supervision-mod-rs)
- [crates/svc-dht/src/supervision/signals.rs](#crates-svc-dht-src-supervision-signals-rs)
- [crates/svc-dht/src/supervision/supervisor.rs](#crates-svc-dht-src-supervision-supervisor-rs)
- [crates/svc-dht/src/tracing.rs](#crates-svc-dht-src-tracing-rs)
- [crates/svc-dht/src/transport/clients.rs](#crates-svc-dht-src-transport-clients-rs)
- [crates/svc-dht/src/transport/mod.rs](#crates-svc-dht-src-transport-mod-rs)
- [crates/svc-dht/src/transport/tor.rs](#crates-svc-dht-src-transport-tor-rs)
- [crates/svc-dht/src/types.rs](#crates-svc-dht-src-types-rs)
- [crates/svc-dht/tests/api_smoke.rs](#crates-svc-dht-tests-apismoke-rs)
- [crates/svc-dht/tests/asn_diversity.rs](#crates-svc-dht-tests-asndiversity-rs)
- [crates/svc-dht/tests/chaos/netem.rs](#crates-svc-dht-tests-chaos-netem-rs)
- [crates/svc-dht/tests/chaos/partition.rs](#crates-svc-dht-tests-chaos-partition-rs)
- [crates/svc-dht/tests/chaos/soak_churn.rs](#crates-svc-dht-tests-chaos-soakchurn-rs)
- [crates/svc-dht/tests/deadline_hedge.rs](#crates-svc-dht-tests-deadlinehedge-rs)
- [crates/svc-dht/tests/kbucket_props.rs](#crates-svc-dht-tests-kbucketprops-rs)
- [crates/svc-dht/tests/nodeid_and_store.rs](#crates-svc-dht-tests-nodeidandstore-rs)
- [crates/svc-dht/tests/provider_roundtrip.rs](#crates-svc-dht-tests-providerroundtrip-rs)
- [crates/svc-dht/tests/readiness_bootstrap.rs](#crates-svc-dht-tests-readinessbootstrap-rs)

### crates/svc-dht/.cargo/config.toml
<a id="crates-svc-dht--cargo-config-toml"></a>

```toml
[alias]
fmt = "fmt --all"
clippy = "clippy --all-targets -- -D warnings"
test-all = "test --all-features"

```

### crates/svc-dht/.github/workflows/ci.yml
<a id="crates-svc-dht--github-workflows-ci-yml"></a>

```yaml
name: ci
on: [push, pull_request]
jobs:
  ci:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo 'placeholder CI (fmt/clippy/tests/deny/coverage/mutation)'

```

### crates/svc-dht/.github/workflows/fuzz.yml
<a id="crates-svc-dht--github-workflows-fuzz-yml"></a>

```yaml
name: fuzz
on:
  schedule: [{cron: "0 3 * * *"}]
jobs:
  fuzz:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo 'placeholder fuzz workflow'

```

### crates/svc-dht/.github/workflows/mermaid.yml
<a id="crates-svc-dht--github-workflows-mermaid-yml"></a>

```yaml
name: mermaid
on: [push, pull_request]
jobs:
  render:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo 'placeholder mermaid render'

```

### crates/svc-dht/.github/workflows/perf.yml
<a id="crates-svc-dht--github-workflows-perf-yml"></a>

```yaml
name: perf
on:
  workflow_dispatch:
  schedule: [{cron: "0 6 * * *"}]
jobs:
  perf:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo 'placeholder perf SLO regression check'

```

### crates/svc-dht/.rustfmt.toml
<a id="crates-svc-dht--rustfmt-toml"></a>

```toml
max_width = 100
use_small_heuristics = "Max"


```

### crates/svc-dht/Cargo.toml
<a id="crates-svc-dht-Cargo-toml"></a>

```toml
[package]
name = "svc-dht"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
authors = ["RustyOnions"]
description = "RustyOnions DHT service (Kademlia/Discv5)—discovery & providers"
repository = "https://github.com/RustyOnions/RustyOnions"
rust-version = "1.80.0"
build = "build.rs"

[features]
default = ["tls"]
tls = []
arti = []            # Tor/Arti via ron-transport
sled-cache = []      # optional sled-backed cache layer

[dependencies]
tokio = { version = "1.47.0", features = ["rt-multi-thread","macros","signal","time","sync","io-util","net"] }
axum = { version = "0.7.9", features = ["tokio","http1","http2","json"] }
hyper = "1.4"
http = "1.1"
tower = "0.5"
tower-http = { version = "0.6.6", features = ["trace","cors","timeout"] }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter","fmt","json"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
thiserror = "2.0"
anyhow = "1.0"
bytes = "1.6"
prometheus = "0.14"
once_cell = "1.19"
rand = "0.9"
blake3 = "1.5"
base64 = "0.22"
hex = "0.4"
arc-swap = "1.7"
parking_lot = "0.12"

# RON crates via relative paths (works whether or not workspace.dependencies exists)
ron-kernel    = { path = "../ron-kernel" }
ron-metrics   = { path = "../ron-metrics" }
ron-transport = { path = "../ron-transport" }
ron-proto     = { path = "../ron-proto" }
oap           = { path = "../oap" }

# Optional sled cache
sled = { version = "0.34", optional = true }

[dev-dependencies]
tokio = { version = "1.47.0", features = ["rt-multi-thread","macros","time","sync"] }
reqwest = { version = "0.12", default-features = false, features = ["rustls-tls-native-roots","json"] }
criterion = { version = "0.5", features = ["async_tokio"] }

[[bench]]
name = "lookup_bench"
harness = false

[build-dependencies]
chrono = { version = "0.4", default-features = false, features = ["clock"] }

```

### crates/svc-dht/benches/lookup_bench.rs
<a id="crates-svc-dht-benches-lookupbench-rs"></a>

```rust
//! Criterion + custom stats: lookup baseline and optional hedge tail-rescue sim.
//! RO:WHAT — (1) Baseline lookup path with β sweep and zero stagger (fast).
//!           (2) Optional tail-rescue sim showing P50/P95/P99 (env-gated).
//! RO:RUN  — Fast baseline only (default):
//!            cargo bench -p svc-dht --bench lookup_bench
//!           Include tail-rescue sim (tunable):
//!            DHT_SIM=1 DHT_TRIALS=600 DHT_PSLOW=0.05 DHT_STAGGER_MS=2 cargo bench -p svc-dht --bench lookup_bench

use std::sync::{
    atomic::{AtomicU64, Ordering},
    Arc,
};
use std::time::{Duration, Instant};

use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};
use svc_dht::pipeline::hedging::race_hedged;
use svc_dht::pipeline::lookup::{LookupCtx, LookupRequest};
use svc_dht::provider::Store;

// ---------- tiny helpers ----------
fn percentiles(mut xs: Vec<f64>) -> (f64, f64, f64) {
    if xs.is_empty() {
        return (0.0, 0.0, 0.0);
    }
    xs.sort_by(|a, b| a.partial_cmp(b).unwrap());
    let idx = |p: f64| -> usize {
        let n = xs.len() as f64;
        let k = (p * (n - 1.0)).round() as usize;
        k.min(xs.len() - 1)
    };
    (xs[idx(0.50)], xs[idx(0.95)], xs[idx(0.99)])
}

// SplitMix-like deterministic mixer (no non-Send RNG).
#[inline]
fn mix64(mut x: u64) -> u64 {
    x = x.wrapping_add(0x9E3779B97F4A7C15);
    let mut z = x;
    z = (z ^ (z >> 30)).wrapping_mul(0xBF58476D1CE4E5B9);
    z = (z ^ (z >> 27)).wrapping_mul(0x94D049BB133111EB);
    z ^ (z >> 31)
}
#[inline]
fn mix_range_inc(x: u64, min: u64, max: u64) -> u64 {
    let span = max.saturating_sub(min) + 1;
    min + (mix64(x) % span)
}

// ---------- optional tail-rescue sim (env-gated) ----------
fn maybe_print_hedge_tail_rescue(rt: &tokio::runtime::Runtime) {
    let sim = std::env::var("DHT_SIM").ok().and_then(|s| s.parse::<u8>().ok()).unwrap_or(0);
    if sim == 0 {
        // Keep benches fast unless explicitly enabled.
        return;
    }

    let trials: usize =
        std::env::var("DHT_TRIALS").ok().and_then(|s| s.parse().ok()).unwrap_or(400);
    let p_slow: f64 = std::env::var("DHT_PSLOW").ok().and_then(|s| s.parse().ok()).unwrap_or(0.05);
    let hedge_stagger_ms: u64 =
        std::env::var("DHT_STAGGER_MS").ok().and_then(|s| s.parse().ok()).unwrap_or(2);
    let slow_min: u64 =
        std::env::var("DHT_SLOW_MIN_MS").ok().and_then(|s| s.parse().ok()).unwrap_or(80);
    let slow_max: u64 =
        std::env::var("DHT_SLOW_MAX_MS").ok().and_then(|s| s.parse().ok()).unwrap_or(120);
    let fast_min: u64 =
        std::env::var("DHT_FAST_MIN_MS").ok().and_then(|s| s.parse().ok()).unwrap_or(1);
    let fast_max: u64 =
        std::env::var("DHT_FAST_MAX_MS").ok().and_then(|s| s.parse().ok()).unwrap_or(2);
    let leg_budget_ms: u64 =
        std::env::var("DHT_LEG_BUDGET_MS").ok().and_then(|s| s.parse().ok()).unwrap_or(150);

    let leg_budget = Duration::from_millis(leg_budget_ms);
    let ctr = Arc::new(AtomicU64::new(1));

    let run_beta = |beta: usize| -> Vec<f64> {
        let mut out = Vec::with_capacity(trials);
        rt.block_on(async {
            for _ in 0..trials {
                let t0 = Instant::now();
                let _ = race_hedged::<_, _, (), ()>(
                    beta,
                    Duration::from_millis(hedge_stagger_ms),
                    leg_budget,
                    {
                        let ctr = ctr.clone();
                        move |leg_idx| {
                            let seed =
                                ctr.fetch_add(1, Ordering::Relaxed).wrapping_add(leg_idx as u64);
                            async move {
                                // primary slow with prob p_slow; hedges fast
                                let slow_roll = (mix64(seed) as f64) / (u64::MAX as f64);
                                let is_slow_primary = leg_idx == 0 && slow_roll < p_slow;
                                let delay_ms = if is_slow_primary {
                                    mix_range_inc(seed ^ 0xA5A5, slow_min, slow_max)
                                } else {
                                    mix_range_inc(seed ^ 0x5A5A, fast_min, fast_max)
                                };
                                tokio::time::sleep(Duration::from_millis(delay_ms)).await;
                                Ok(())
                            }
                        }
                    },
                )
                .await;
                out.push(t0.elapsed().as_secs_f64() * 1_000.0);
            }
        });
        out
    };

    let b0 = run_beta(0);
    let b1 = run_beta(1);
    let b2 = run_beta(2);
    let b3 = run_beta(3);
    let (b0_p50, b0_p95, b0_p99) = percentiles(b0);
    let (b1_p50, b1_p95, b1_p99) = percentiles(b1);
    let (b2_p50, b2_p95, b2_p99) = percentiles(b2);
    let (b3_p50, b3_p95, b3_p99) = percentiles(b3);

    println!(
        "\n=== Hedge Tail Rescue (trials={} p_slow={:.1}% stagger={}ms budget={}ms) ===",
        trials,
        p_slow * 100.0,
        hedge_stagger_ms,
        leg_budget_ms
    );
    println!("β=0  P50={:.2}ms  P95={:.2}ms  P99={:.2}ms", b0_p50, b0_p95, b0_p99);
    println!("β=1  P50={:.2}ms  P95={:.2}ms  P99={:.2}ms", b1_p50, b1_p95, b1_p99);
    println!("β=2  P50={:.2}ms  P95={:.2}ms  P99={:.2}ms", b2_p50, b2_p95, b2_p99);
    println!("β=3  P50={:.2}ms  P95={:.2}ms  P99={:.2}ms", b3_p50, b3_p95, b3_p99);
    println!("(sim is env-gated; default bench does not run it)");
}

// ---------- (1) Baseline: lookup over in-memory store (no stagger) ----------
fn bench_lookup_baseline(c: &mut Criterion) {
    let store = Arc::new(Store::new(Duration::from_secs(60)));
    let cid = "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef".to_string();

    // Warm providers so the lookup path returns immediately.
    for i in 0..8 {
        store.add(cid.clone(), format!("local://node{i}"), Some(Duration::from_secs(60)));
    }
    let ctx = LookupCtx::new(store, 64);

    // Current-thread RT for stable measurements.
    let rt = tokio::runtime::Builder::new_current_thread().enable_time().build().expect("rt");

    // Print the optional tail simulation (fast baseline remains unaffected if DHT_SIM=0).
    maybe_print_hedge_tail_rescue(&rt);

    let mut group = c.benchmark_group("lookup_baseline");
    for beta in [0usize, 1, 2, 3] {
        group.bench_with_input(BenchmarkId::new("beta", beta), &beta, |b, &bval| {
            b.iter(|| {
                rt.block_on(async {
                    let req = LookupRequest {
                        cid: cid.clone(),
                        alpha: 1,
                        beta: bval,
                        hop_budget: 6,
                        deadline: Duration::from_millis(200),
                        hedge_stagger: Duration::from_millis(0), // ← zero to measure orchestration
                        min_leg_budget: Duration::from_millis(5),
                    };
                    // Don’t panic in benches; rare timing hiccups shouldn’t fail the run.
                    let _ = ctx.run(req).await;
                });
            });
        });
    }
    group.finish();
}

criterion_group!(benches, bench_lookup_baseline);
criterion_main!(benches);

```

### crates/svc-dht/build.rs
<a id="crates-svc-dht-build-rs"></a>

```rust
use std::process::Command;

fn main() {
    // Best-effort short git SHA
    let sha = Command::new("git")
        .args(["rev-parse", "--short", "HEAD"])
        .output()
        .ok()
        .and_then(|o| {
            if o.status.success() {
                Some(String::from_utf8_lossy(&o.stdout).trim().to_string())
            } else {
                None
            }
        })
        .unwrap_or_else(|| "unknown".to_string());

    // Build timestamp (UTC, RFC3339)
    let ts = chrono::Utc::now().to_rfc3339();

    println!("cargo:rustc-env=BUILD_GIT_SHA={}", sha);
    println!("cargo:rustc-env=BUILD_TS={}", ts);
}

```

### crates/svc-dht/clippy.toml
<a id="crates-svc-dht-clippy-toml"></a>

```toml
warn-on-all-wildcard-imports = true

```

### crates/svc-dht/examples/find_providers.rs
<a id="crates-svc-dht-examples-findproviders-rs"></a>

```rust
//! Example: GET /dht/find_providers/:cid from a running svc-dht.
//! Run the service in another terminal: `cargo run -p svc-dht`
//! Then: `cargo run -p svc-dht --example find_providers -- b3:deadbeef`

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let cid = std::env::args().nth(1).unwrap_or_else(|| "b3:deadbeef".into());
    let addr = std::env::var("DHT_ADDR").unwrap_or_else(|_| "127.0.0.1:5301".into());
    let url = format!("http://{addr}/dht/find_providers/{cid}");
    let txt = reqwest::get(url).await?.text().await?;
    println!("{txt}");
    Ok(())
}

```

### crates/svc-dht/examples/provide.rs
<a id="crates-svc-dht-examples-provide-rs"></a>

```rust
//! Example: POST /dht/provide to a running svc-dht.
//! Run the service in another terminal: `cargo run -p svc-dht`
//! Then: `cargo run -p svc-dht --example provide -- b3:deadbeef local://nodeA 60`

use std::time::Duration;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let mut args = std::env::args().skip(1);
    let cid = args.next().unwrap_or_else(|| "b3:deadbeef".to_string());
    let node = args.next().unwrap_or_else(|| "local://nodeA".to_string());
    let ttl = args.next().and_then(|s| s.parse::<u64>().ok()).unwrap_or(60);
    let addr = std::env::var("DHT_ADDR").unwrap_or_else(|_| "127.0.0.1:5301".into());

    let url = format!("http://{addr}/dht/provide");
    let body = serde_json::json!({ "cid": cid, "node": node, "ttl_secs": ttl });
    let cli = reqwest::Client::builder().timeout(Duration::from_secs(5)).build()?;
    let res = cli.post(url).json(&body).send().await?.text().await?;
    println!("{res}");
    Ok(())
}

```

### crates/svc-dht/fuzz/fuzz_targets/kad_packet_decode.rs
<a id="crates-svc-dht-fuzz-fuzztargets-kadpacketdecode-rs"></a>

```rust
// fuzz: kad_packet_decode (placeholder).

```

### crates/svc-dht/fuzz/fuzz_targets/msg_frame_decode.rs
<a id="crates-svc-dht-fuzz-fuzztargets-msgframedecode-rs"></a>

```rust
// fuzz: msg_frame_decode (placeholder).

```

### crates/svc-dht/loom/loom_hedge.rs
<a id="crates-svc-dht-loom-loomhedge-rs"></a>

```rust
// loom: hedged fan-out invariants (placeholder).

```

### crates/svc-dht/loom/loom_kbucket.rs
<a id="crates-svc-dht-loom-loomkbucket-rs"></a>

```rust
// loom: k-bucket invariants (placeholder).

```

### crates/svc-dht/rust-toolchain.toml
<a id="crates-svc-dht-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["clippy", "rustfmt"]

```

### crates/svc-dht/scripts/chaos/netem.sh
<a id="crates-svc-dht-scripts-chaos-netem-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# Apply/remove tc netem profiles (placeholder).

```

### crates/svc-dht/scripts/chaos/partition.sh
<a id="crates-svc-dht-scripts-chaos-partition-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# Simulate network partition topology locally (placeholder).

```

### crates/svc-dht/scripts/provide-and-check.sh
<a id="crates-svc-dht-scripts-provide-and-check-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
CID="${1:-b3:deadbeef}"
NODE="${2:-local://nodeA}"
TTL="${3:-60}"
ADDR="${4:-127.0.0.1:5301}"

curl -s -X POST "http://${ADDR}/dht/provide" \
  -H "content-type: application/json" \
  -d "{\"cid\":\"${CID}\",\"node\":\"${NODE}\",\"ttl_secs\":${TTL}}" | jq

curl -s "http://${ADDR}/dht/find_providers/${CID}" | jq
curl -s "http://${ADDR}/metrics" | grep -E "dht_lookup_latency_seconds_count|dht_lookup_hops|dht_lookups_total" || true

```

### crates/svc-dht/scripts/render-mermaid.sh
<a id="crates-svc-dht-scripts-render-mermaid-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# Render docs/*.mmd to SVG (placeholder).

```

### crates/svc-dht/scripts/run-local.sh
<a id="crates-svc-dht-scripts-run-local-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# run-local.sh — local smoke: readyz → provide → find → metrics

ADDR="${1:-127.0.0.1:5301}"
CID="${2:-b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef}"
NODE="${3:-local://nodeA}"
TTL="${4:-60}"

echo ">>> Waiting for readyz at http://${ADDR}/readyz ..."
for i in $(seq 1 100); do
  code=$(curl -s -o /dev/null -w "%{http_code}" "http://${ADDR}/readyz" || true)
  [ "$code" = "200" ] && echo "ready" && break
  sleep 0.1
done

echo ">>> Version:"
curl -s "http://${ADDR}/version" | jq -r '.'

echo ">>> Provide:"
curl -s -X POST "http://${ADDR}/dht/provide" \
  -H "content-type: application/json" \
  -d "{\"cid\":\"${CID}\",\"node\":\"${NODE}\",\"ttl_secs\":${TTL}}" | jq -r '.'

echo ">>> Find:"
curl -s "http://${ADDR}/dht/find_providers/${CID}" | jq -r '.'

echo ">>> Metrics (grep dht_*):"
curl -s "http://${ADDR}/metrics" | grep -E "dht_lookup_|dht_lookups_total|dht_provides_total" || true

echo "done"

```

### crates/svc-dht/scripts/smoke_svc_dht.sh
<a id="crates-svc-dht-scripts-smokesvcdht-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

echo "== svc-dht smoke start =="
echo "== format + clippy =="
cargo fmt -p svc-dht
cargo clippy -p svc-dht --no-deps -- -D warnings

echo "== unit/integration tests =="
cargo test -p svc-dht -- --nocapture

echo "== bench (short) =="
cargo bench -p svc-dht --bench lookup_bench -- --measurement-time 2 --warm-up-time 1 || true

echo "== local E2E (provide/find/metrics) =="
# runs against a locally started svc-dht (in another terminal)
crates/svc-dht/scripts/run-local.sh || true

echo "== done =="

```

### crates/svc-dht/scripts/ttl-demo.sh
<a id="crates-svc-dht-scripts-ttl-demo-sh"></a>

```bash
#!/usr/bin/env bash
# ttl-demo.sh — local provide → find_providers → TTL expiry demo for svc-dht
# Supports auto-spawn of the service.
#
# Usage:
#   ./ttl-demo.sh [--spawn] [--cid b3:short] [--node local://tmp] [--ttl 2] [--addr 127.0.0.1:5301] [--timeout 30]
#
# Notes:
# - If --spawn is provided, this script will run `cargo run -p svc-dht` in the background,
#   wait for /readyz, perform the demo, and then terminate the service.
# - Requires: curl; jq (optional for pretty JSON)
#
#
# EXAMPLE RUN: 
# TERMINAL A: cargo run -p svc-dht
# TERMINAL B: crates/svc-dht/scripts/ttl-demo.sh --spawn --ttl 2
#

set -euo pipefail

CID="b3:short"
NODE="local://tmp"
TTL=2
ADDR="127.0.0.1:5301"
TIMEOUT=30
SPAWN=0
CARGO_CMD="cargo run -p svc-dht"
LOGFILE="/tmp/svc-dht.demo.log"

while [[ $# -gt 0 ]]; do
  case "$1" in
    --cid)      CID="$2"; shift 2 ;;
    --node)     NODE="$2"; shift 2 ;;
    --ttl)      TTL="$2"; shift 2 ;;
    --addr)     ADDR="$2"; shift 2 ;;
    --timeout)  TIMEOUT="$2"; shift 2 ;;
    --spawn)    SPAWN=1; shift ;;
    -h|--help)
      echo "Usage: $0 [--spawn] [--cid b3:short] [--node local://tmp] [--ttl 2] [--addr 127.0.0.1:5301] [--timeout 30]"
      exit 0
      ;;
    *)
      echo "Unknown arg: $1"
      exit 1
      ;;
  esac
done

has_jq() { command -v jq >/dev/null 2>&1; }
json_pretty() { if has_jq; then jq; else python3 -m json.tool 2>/dev/null || cat; fi; }
get() { curl -sS "http://$ADDR$1"; }
post_json() { curl -sS -H "content-type: application/json" -d "$2" "http://$ADDR$1"; }

PROC_PGID=""
cleanup() {
  if [[ "$SPAWN" -eq 1 && -n "${PROC_PGID:-}" ]]; then
    echo
    echo ">>> Stopping spawned svc-dht (pgid=$PROC_PGID)"
    kill -TERM "-$PROC_PGID" >/dev/null 2>&1 || true
    sleep 1
    kill -KILL "-$PROC_PGID" >/dev/null 2>&1 || true
  fi
}
trap cleanup EXIT

if [[ "$SPAWN" -eq 1 ]]; then
  echo ">>> Spawning svc-dht and logging to $LOGFILE"
  # Start in its own process group so we can kill the whole tree cleanly later.
  bash -c "set -m; $CARGO_CMD &> '$LOGFILE' & echo \$! > '$LOGFILE.pid'; disown" &
  # Wait for pid file
  for _ in $(seq 1 50); do
    [[ -f "$LOGFILE.pid" ]] && break
    sleep 0.1
  done
  if [[ ! -f "$LOGFILE.pid" ]]; then
    echo "Failed to obtain svc-dht PID (check $LOGFILE)."
    exit 1
  fi
  PID="$(cat "$LOGFILE.pid")"
  # Get the process group id (pgid == pid for group leader)
  PROC_PGID="$(ps -o pgid= -p "$PID" 2>/dev/null | tr -d ' ')"
  if [[ -z "$PROC_PGID" ]]; then
    echo "Could not determine process group; PID=$PID. Proceeding without kill group."
  fi
fi

echo ">>> Waiting for readiness at http://$ADDR/readyz (timeout ${TIMEOUT}s)..."
deadline=$(( $(date +%s) + TIMEOUT ))
while :; do
  # Capture both curl status and http code
  HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "http://$ADDR/readyz" || echo 000)
  if [[ "$HTTP_CODE" == "200" ]]; then
    echo "Ready."
    break
  fi
  if (( $(date +%s) >= deadline )); then
    echo "Service not ready (HTTP $HTTP_CODE) before timeout."
    if [[ "$SPAWN" -eq 1 ]]; then
      echo "Last 50 lines from $LOGFILE:"
      tail -n 50 "$LOGFILE" || true
    fi
    exit 1
  fi
  sleep 0.2
done

echo
echo ">>> Version:"
get "/version" | json_pretty

echo
echo ">>> Posting provide (cid=$CID, node=$NODE, ttl=$TTL s)"
RESP=$(post_json "/dht/provide" "$(printf '{"cid":"%s","node":"%s","ttl_secs":%s}' "$CID" "$NODE" "$TTL")")
echo "$RESP" | json_pretty

echo
echo ">>> Immediate find_providers:"
get "/dht/find_providers/$CID" | json_pretty

echo
echo ">>> Debug snapshot (with seconds remaining):"
get "/dht/_debug/list" | json_pretty

echo
echo ">>> Metrics (before sleep):"
get "/metrics" | grep -E "dht_provides_total|dht_lookups_total" || true

echo
echo ">>> Sleeping ${TTL}s + 1 to allow TTL to expire..."
sleep $((TTL + 1))

echo
echo ">>> find_providers after expiry (should be empty):"
get "/dht/find_providers/$CID" | json_pretty

echo
echo ">>> Metrics (after):"
get "/metrics" | grep -E "dht_provides_total|dht_lookups_total" || true

if [[ "$SPAWN" -eq 1 ]]; then
  echo
  echo ">>> svc-dht logs (tail):"
  tail -n 50 "$LOGFILE" || true
fi

echo
echo "Done."

```

### crates/svc-dht/scripts/two-node-local.sh
<a id="crates-svc-dht-scripts-two-node-local-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# RO:WHAT — Launch two svc-dht nodes on different admin ports, seed them, prove cross-node lookup.
# RO:RUN
#   chmod +x crates/svc-dht/scripts/two-node-local.sh
#   crates/svc-dht/scripts/two-node-local.sh

ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
BIN="target/debug/svc-dht"

if ! command -v jq >/dev/null 2>&1; then
  echo "jq required"; exit 1
fi

echo "== build =="
cargo build -p svc-dht >/dev/null

CID="b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"

killall -q svc-dht || true
sleep 0.2

echo "== start node A (5301) =="
RON_DHT_ADMIN_ADDR=127.0.0.1:5301 \
RON_DHT_SEEDS="" \
RON_DHT_NODE_URI="local://nodeA" \
"${BIN}" >/tmp/svc-dht-A.log 2>&1 &

echo "== start node B (5302) =="
RON_DHT_ADMIN_ADDR=127.0.0.1:5302 \
RON_DHT_SEEDS="http://127.0.0.1:5301" \
RON_DHT_NODE_URI="local://nodeB" \
"${BIN}" >/tmp/svc-dht-B.log 2>&1 &

ready() { curl -fsS "$1/readyz" >/dev/null 2>&1; }

echo "== wait ready =="
for i in {1..50}; do
  ready http://127.0.0.1:5301 && ready http://127.0.0.1:5302 && break
  sleep 0.1
done

echo "== provide on node A =="
curl -fsS -X POST http://127.0.0.1:5301/provide \
  -H 'content-type: application/json' \
  -d "{\"cid\":\"${CID}\",\"node\":\"local://nodeA\",\"ttl_secs\":60}" | jq .

echo "== find from node B (should discover A) =="
curl -fsS "http://127.0.0.1:5302/find/${CID}" | jq .

echo "== metrics B (grep dht_) =="
curl -fsS http://127.0.0.1:5302/metrics | grep -E '^dht_' || true

echo "== tail logs (A/B hints) =="
echo "-- A --"; tail -n 3 /tmp/svc-dht-A.log || true
echo "-- B --"; tail -n 3 /tmp/svc-dht-B.log || true

echo "== done =="

```

### crates/svc-dht/src/bootstrap.rs
<a id="crates-svc-dht-src-bootstrap-rs"></a>

```rust
//! RO:WHAT — Seed dialing + min-fill readiness gate
//! RO:WHY — Bring table to life before accepting work; Concerns: RES/PERF
//! RO:INTERACTS — peer::table, metrics, readiness, transport
//! RO:INVARIANTS — backoff with jitter; no locks across .await
//! RO:TEST — readiness_bootstrap.rs

use crate::{config::Config, metrics::DhtMetrics, readiness::ReadyGate};
use rand::{rng, Rng};
use ron_kernel::HealthState;
use std::sync::Arc;
use tokio::time::{sleep, Duration};
use tracing::{info, warn};

pub struct Supervisor {
    shutdown_tx: Option<tokio::sync::oneshot::Sender<()>>,
    handle: tokio::task::JoinHandle<()>,
}

impl Supervisor {
    pub async fn shutdown(mut self) {
        if let Some(tx) = self.shutdown_tx.take() {
            let _ = tx.send(());
        }
        let _ = self.handle.await;
    }
}

pub async fn spawn_bootstrap_supervisor(
    cfg: Config,
    _health: Arc<HealthState>,
    ready: Arc<ReadyGate>,
    _metrics: Arc<DhtMetrics>,
) -> anyhow::Result<Supervisor> {
    let (tx, mut rx) = tokio::sync::oneshot::channel::<()>();

    let handle = tokio::spawn(async move {
        // Single pass for MVP; in Phase 2 we'll loop with backoff until quorum/min-fill.
        tokio::select! {
            _ = &mut rx => {
                info!("bootstrap supervisor: shutdown");
            }
            _ = do_once(&cfg) => {
                ready.set_ready();
                info!("bootstrap: min-fill reached; ready gate opened");
            }
        }
    });

    Ok(Supervisor { shutdown_tx: Some(tx), handle })
}

async fn do_once(cfg: &Config) {
    // TODO Phase 2: dial seeds via ron-transport; refresh k-buckets by distance
    if cfg.seeds.is_empty() {
        warn!("no seeds configured; table will rely on inbound discovery");
        sleep(Duration::from_millis(300)).await;
    } else {
        for s in &cfg.seeds {
            let _ = s; // simulate dial
            let jitter = rng().random_range(10..60);
            sleep(Duration::from_millis(jitter)).await;
        }
    }
}

```

### crates/svc-dht/src/cache/memory.rs
<a id="crates-svc-dht-src-cache-memory-rs"></a>

```rust
// cache::memory - RAM cache (placeholder).

```

### crates/svc-dht/src/cache/mod.rs
<a id="crates-svc-dht-src-cache-mod-rs"></a>

```rust
//! RO:WHAT — Cache facade (RAM default; sled optional)
//! RO:WHY — Micronode amnesia by default; Concerns: PERF/SEC
pub mod memory; // TODO phase 2
#[cfg(feature = "sled-cache")]
pub mod sled_cache; // TODO phase 2

```

### crates/svc-dht/src/cache/sled_cache.rs
<a id="crates-svc-dht-src-cache-sledcache-rs"></a>

```rust
// cache::sled_cache - sled-backed cache (placeholder).

```

### crates/svc-dht/src/codec/decode.rs
<a id="crates-svc-dht-src-codec-decode-rs"></a>

```rust
// codec::decode - parsers (placeholder).

```

### crates/svc-dht/src/codec/encode.rs
<a id="crates-svc-dht-src-codec-encode-rs"></a>

```rust
// codec::encode - serializers (placeholder).

```

### crates/svc-dht/src/codec/frame.rs
<a id="crates-svc-dht-src-codec-frame-rs"></a>

```rust
// codec::frame - OAP/1 frame constants (placeholder).

```

### crates/svc-dht/src/codec/limits.rs
<a id="crates-svc-dht-src-codec-limits-rs"></a>

```rust
//! RO:WHAT — Central protocol size/time limits (OAP guidance mirrored)
//! RO:WHY — Hardening; Concerns: SEC
pub const MAX_FRAME_BYTES: usize = 1_048_576; // 1 MiB
pub const CHUNK_BYTES: usize = 64 * 1024; // 64 KiB (storage stream knob)

```

### crates/svc-dht/src/codec/mod.rs
<a id="crates-svc-dht-src-codec-mod-rs"></a>

```rust
//! RO:WHAT — Codec module (frame/encode/decode/limits)
//! RO:WHY — Isolate parser logic for fuzzing; Concerns: SEC/RES
pub mod decode; // TODO phase 2
pub mod encode;
pub mod frame; // TODO phase 2
pub mod limits; // TODO phase 2

```

### crates/svc-dht/src/config.rs
<a id="crates-svc-dht-src-config-rs"></a>

```rust
//! RO:WHAT — svc-dht configuration (binds, α/β, k, seeds, timeouts, amnesia)
//! RO:WHY — Centralized knobs; Concerns: GOV/RES/PERF; hot-reload-friendly shape
//! RO:INTERACTS — bootstrap, peer::table, rpc/http handlers, transport
//! RO:INVARIANTS — values bounded; α ≤ k; β ≤ α; timeouts sane; amnesia honored
//! RO:TEST — config parse unit tests; trybuild for compile-fail when invalid

use serde::{Deserialize, Serialize};
use std::{
    env,
    net::{IpAddr, Ipv4Addr, SocketAddr},
    time::Duration,
};

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Config {
    pub admin_bind: SocketAddr,
    pub alpha: usize,
    pub beta: usize,
    pub k: usize,
    pub hop_budget: usize,
    pub dial_timeout_ms: u64,
    pub idle_timeout_ms: u64,
    pub seeds: Vec<String>,
    pub amnesia: bool,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            admin_bind: SocketAddr::from((IpAddr::V4(Ipv4Addr::LOCALHOST), 5301)),
            alpha: 3,
            beta: 1,
            k: 20,
            hop_budget: 6,
            dial_timeout_ms: 1_500,
            idle_timeout_ms: 5_000,
            seeds: vec![],
            amnesia: true,
        }
    }
}

impl Config {
    pub fn from_env() -> anyhow::Result<Self> {
        let mut cfg = Self::default();
        if let Ok(s) = env::var("DHT_ADMIN_BIND") {
            cfg.admin_bind = s.parse()?;
        }
        if let Ok(v) = env::var("DHT_ALPHA") {
            cfg.alpha = v.parse()?;
        }
        if let Ok(v) = env::var("DHT_BETA") {
            cfg.beta = v.parse()?;
        }
        if let Ok(v) = env::var("DHT_K") {
            cfg.k = v.parse()?;
        }
        if let Ok(v) = env::var("DHT_HOP_BUDGET") {
            cfg.hop_budget = v.parse()?;
        }
        if let Ok(v) = env::var("DHT_DIAL_TIMEOUT_MS") {
            cfg.dial_timeout_ms = v.parse()?;
        }
        if let Ok(v) = env::var("DHT_IDLE_TIMEOUT_MS") {
            cfg.idle_timeout_ms = v.parse()?;
        }
        if let Ok(v) = env::var("DHT_SEEDS") {
            cfg.seeds =
                v.split(',').map(|s| s.trim().to_string()).filter(|s| !s.is_empty()).collect();
        }
        if let Ok(v) = env::var("RON_AMNESIA") {
            cfg.amnesia = matches!(v.as_str(), "1") || v.eq_ignore_ascii_case("true");
        }
        cfg.validate()?;
        Ok(cfg)
    }

    pub fn validate(&self) -> anyhow::Result<()> {
        use anyhow::bail;
        if self.alpha == 0 || self.k == 0 {
            bail!("alpha and k must be > 0");
        }
        if self.beta > self.alpha {
            bail!("beta must be <= alpha");
        }
        if self.k < self.alpha {
            bail!("k (bucket size) should be >= alpha");
        }
        if self.hop_budget == 0 {
            bail!("hop budget must be > 0");
        }
        if self.dial_timeout_ms < 100 || self.idle_timeout_ms < 500 {
            bail!("timeouts too small");
        }
        if self.seeds.iter().any(|s| s.len() > 255) {
            bail!("seed too long");
        }
        Ok(())
    }

    pub fn dial_timeout(&self) -> Duration {
        Duration::from_millis(self.dial_timeout_ms)
    }
    pub fn idle_timeout(&self) -> Duration {
        Duration::from_millis(self.idle_timeout_ms)
    }
}

```

### crates/svc-dht/src/errors.rs
<a id="crates-svc-dht-src-errors-rs"></a>

```rust
//! RO:WHAT — Error taxonomy for svc-dht with user hints
//! RO:WHY — Deterministic, typed errors; Concerns: DX/GOV/SEC
//! RO:INTERACTS — rpc/http, pipeline, provider store
//! RO:INVARIANTS — stable Display; avoid leaking internals
//! RO:TEST — unit tests for Display and status mapping

use thiserror::Error;

#[derive(Debug, Error)]
pub enum DhtError {
    #[error("bootstrap quorum not reached")]
    NoBootstrap,
    #[error("asn diversity floor not met")]
    AsnCap,
    #[error("payload oversize")]
    OverSize,
    #[error("hop budget exceeded")]
    HopBudget,
    #[error("timeout")]
    Timeout,
    #[error("internal: {0}")]
    Internal(String),
}

```

### crates/svc-dht/src/health.rs
<a id="crates-svc-dht-src-health-rs"></a>

```rust
//! RO:WHAT — Health/liveness helpers
//! RO:WHY — Truthful health; Concerns: RES/GOV
//! RO:INTERACTS — /healthz
//! RO:INVARIANTS — cheap checks; truth over green
//! RO:TEST — healthz returns 200

use ron_kernel::HealthState;
use std::sync::Arc;

pub type HealthHandles = Arc<HealthState>;

```

### crates/svc-dht/src/invariants.rs
<a id="crates-svc-dht-src-invariants-rs"></a>

```rust
//! svc-dht invariants — compile-time and doc-level assertions that define the contract
//! RO:WHAT — Kademlia- and pipeline-related constants/invariants that other modules rely on.
//! RO:WHY  — Guard against accidental drift during refactors. Fail fast at build time.
//! RO:GATES — F (Functional), RES (Resilience), PERF (no per-call heap).
//!
//! Invariants:
//! - NodeId is 32 bytes (BLAKE3 digest); XOR distance is exactly 32 bytes.
//! - α (alpha: fanout) in [1, 16] (small, bounded concurrency per round).
//! - β (beta: hedges) in [0, 4] (limit tail-rescue parallelism).
//! - hop_budget in [1, 64] (guard against runaway traversal).
//! - Hedge stagger and leg budget are sane (stagger << budget).
//!
//! ```text
//! Kademlia rounds proceed with α parallel queries; hedging may add up to β extra legs
//! per logical lookup, spaced by a small stagger delay to rescue tail latency.
//! ```

#![allow(clippy::doc_markdown)]

pub const NODEID_LEN: usize = 32;
pub const ALPHA_MIN: usize = 1;
pub const ALPHA_MAX: usize = 16;
pub const BETA_MIN: usize = 0;
pub const BETA_MAX: usize = 4;
pub const HOPS_MIN: usize = 1;
pub const HOPS_MAX: usize = 64;

/// Sanity check helper usable in const context
const fn within(v: usize, lo: usize, hi: usize) -> bool {
    v >= lo && v <= hi
}

/// Compile-time assertions — these run when this module is referenced.
#[allow(dead_code)]
pub const fn _compile_time_guards() {
    // NodeId length must remain 32 (BLAKE3).
    // If this ever changes, XOR distance math must be updated.
    assert!(NODEID_LEN == 32);

    // Parameter envelopes (keep lookup bounded).
    assert!(within(ALPHA_MIN, 1, 32));
    assert!(within(ALPHA_MAX, 1, 32));
    assert!(ALPHA_MIN <= ALPHA_MAX);

    assert!(within(BETA_MIN, 0, 8));
    assert!(within(BETA_MAX, 0, 8));
    assert!(BETA_MIN <= BETA_MAX);

    assert!(within(HOPS_MIN, 1, 256));
    assert!(within(HOPS_MAX, 1, 256));
    assert!(HOPS_MIN <= HOPS_MAX);
}

/// Tiny doc test to lock the NodeId XOR shape without importing the full type.
/// (Keeps this module independent.)
#[cfg(test)]
mod tests {
    #[test]
    fn xor_distance_is_32_bytes() {
        let a = [0xAAu8; 32];
        let b = [0x55u8; 32];
        let mut out = [0u8; 32];
        for (i, o) in out.iter_mut().enumerate() {
            *o = a[i] ^ b[i];
        }
        assert_eq!(out.len(), 32);
        assert_eq!(out[0], 0xFF);
        assert_eq!(out[31], 0xFF);
    }
}

```

### crates/svc-dht/src/lib.rs
<a id="crates-svc-dht-src-lib-rs"></a>

```rust
//! RO:WHAT — Public crate surface & re-exports for svc-dht (Kademlia service)
//! RO:WHY — P10 Overlay/Transport/Discovery; Concerns: SEC/RES/PERF/GOV
//! RO:INTERACTS — ron-kernel (Bus/Health), ron-transport (I/O), axum (admin), ron-proto (DTOs)
//! RO:INVARIANTS — no lock across .await; single-writer per k-bucket; OAP max_frame=1MiB; chunk≈64KiB
//! RO:METRICS — exposes dht_* histograms/counters; /metrics, /healthz, /readyz
//! RO:CONFIG — svc-dht Config; amnesia honored
//! RO:SECURITY — capability checks occur at ingress/gateway; DHT path rejects oversize/abuse
//! RO:TEST — tests/* integration; loom later for kbucket single-writer

pub mod config;
pub mod errors;
pub mod health;
pub mod metrics;
pub mod readiness;
pub mod tracing;
pub use tracing as ro_tracing;

pub mod bootstrap;
pub mod cache;
pub mod codec;
pub mod peer;
pub mod pipeline;
pub mod provider;
pub mod rpc;
pub mod supervision;
pub mod transport;
pub mod types;

pub use config::Config;
pub use health::HealthHandles;
pub use metrics::DhtMetrics;
pub use provider::Store as ProviderStore;
pub use readiness::ReadyGate;

```

### crates/svc-dht/src/main.rs
<a id="crates-svc-dht-src-main-rs"></a>

```rust
//! RO:WHAT — Binary entrypoint: init tracing/metrics, load config, spawn supervisor, serve admin HTTP
//! RO:WHY — Service bootstrap; Concerns SEC/RES/PERF/GOV with observable readiness

use axum::{
    routing::{get, post},
    Router,
};
use std::{net::SocketAddr, sync::Arc, time::Duration};
use tokio::task::JoinHandle;
use tracing::{info, warn};

use ron_kernel::{wait_for_ctrl_c, HealthState};
use svc_dht::provider::ttl::spawn_pruner;
use svc_dht::rpc::http;
use svc_dht::{
    bootstrap, config::Config, metrics::DhtMetrics, pipeline::lookup::LookupCtx,
    readiness::ReadyGate, ro_tracing, ProviderStore,
};

#[tokio::main(flavor = "multi_thread")]
async fn main() -> anyhow::Result<()> {
    ro_tracing::init();
    let cfg = Config::from_env()?;
    let health = Arc::new(HealthState::default());
    let ready = Arc::new(ReadyGate::new());
    let metrics = Arc::new(DhtMetrics::new()?);
    let providers = Arc::new(ProviderStore::new(Duration::from_secs(600)));
    let _pruner = spawn_pruner(providers.clone());

    // Pipeline context — set a sane global leg concurrency
    let lookup_ctx = Arc::new(LookupCtx::new(providers.clone(), /*max_legs*/ 64));

    // Admin HTTP
    let (admin_task, admin_addr) = serve_admin(
        cfg.admin_bind,
        health.clone(),
        ready.clone(),
        metrics.clone(),
        providers.clone(),
        // pipeline knobs from Config
        cfg.alpha,
        cfg.beta,
        cfg.hop_budget,
        /* default_deadline */ Duration::from_millis(300),
        /* hedge_stagger   */ Duration::from_millis(25),
        /* min_leg_budget  */ Duration::from_millis(50),
        lookup_ctx.clone(),
    )
    .await?;
    info!(%admin_addr, "svc-dht admin up");

    // Bootstrap routing state & supervision
    let sup = bootstrap::spawn_bootstrap_supervisor(
        cfg.clone(),
        health.clone(),
        ready.clone(),
        metrics.clone(),
    )
    .await?;

    // Wait for Ctrl-C and shutdown
    wait_for_ctrl_c().await;
    warn!("shutdown requested");
    sup.shutdown().await;
    admin_task.abort();
    Ok(())
}

#[allow(clippy::too_many_arguments)]
async fn serve_admin(
    bind: SocketAddr,
    health: Arc<HealthState>,
    ready: Arc<ReadyGate>,
    metrics: Arc<DhtMetrics>,
    providers: Arc<ProviderStore>,
    alpha: usize,
    beta: usize,
    hop_budget: usize,
    default_deadline: Duration,
    hedge_stagger: Duration,
    min_leg_budget: Duration,
    lookup_ctx: Arc<LookupCtx>,
) -> anyhow::Result<(JoinHandle<()>, SocketAddr)> {
    let app = Router::new()
        .route("/healthz", get(http::healthz))
        .route("/readyz", get(http::readyz))
        .route("/version", get(http::version))
        .route("/metrics", get(http::metrics))
        .route("/dht/find_providers/:cid", get(http::find_providers))
        .route("/dht/provide", post(http::provide))
        .route("/dht/_debug/list", get(http::debug_list))
        .with_state(http::State::new(
            health,
            ready,
            metrics,
            providers,
            alpha,
            beta,
            hop_budget,
            default_deadline,
            hedge_stagger,
            min_leg_budget,
            lookup_ctx,
        ));

    let listener = tokio::net::TcpListener::bind(bind).await?;
    let addr = listener.local_addr()?;
    let task = tokio::spawn(async move {
        axum::serve(listener, app).await.unwrap();
    });
    Ok((task, addr))
}

```

### crates/svc-dht/src/metrics.rs
<a id="crates-svc-dht-src-metrics-rs"></a>

```rust
//! RO:WHAT — Prometheus metrics for svc-dht
//! RO:WHY — Observability; Concerns: PERF/GOV
//! RO:INTERACTS — rpc/http /metrics; bootstrap/pipeline update counters
//! RO:INVARIANTS — register once; cheap hot path

use once_cell::sync::Lazy;
use prometheus::{
    register_histogram, register_int_counter, Encoder, Histogram, IntCounter, TextEncoder,
};

pub struct DhtMetrics {
    pub lookups_total: IntCounter,
    pub provides_total: IntCounter,
    pub lookup_latency_seconds: Histogram,
    pub lookup_hops: Histogram,
}

impl DhtMetrics {
    pub fn new() -> anyhow::Result<Self> {
        Ok(Self {
            lookups_total: register_int_counter!("dht_lookups_total", "Total DHT lookups")?,
            provides_total: register_int_counter!("dht_provides_total", "Total DHT provides")?,
            lookup_latency_seconds: register_histogram!(
                "dht_lookup_latency_seconds",
                "Lookup latency seconds",
                vec![0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0]
            )?,
            lookup_hops: register_histogram!(
                "dht_lookup_hops",
                "Lookup hop count",
                vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0]
            )?,
        })
    }

    /// RO:WHAT — Record one lookup completion with latency + hop count.
    pub fn observe_lookup(&self, dur: std::time::Duration, hops: u32) {
        self.lookups_total.inc();
        self.lookup_latency_seconds.observe(dur.as_secs_f64());
        self.lookup_hops.observe(hops as f64);
    }

    pub fn encode() -> anyhow::Result<String> {
        static ENC: Lazy<TextEncoder> = Lazy::new(TextEncoder::new);
        let mf = prometheus::gather();
        let mut buf = Vec::with_capacity(8 * 1024);
        ENC.encode(&mf, &mut buf)?;
        Ok(String::from_utf8_lossy(&buf).to_string())
    }
}

```

### crates/svc-dht/src/peer/bucket.rs
<a id="crates-svc-dht-src-peer-bucket-rs"></a>

```rust
//! RO:WHAT — Single-writer Kademlia bucket (MVP)
//! RO:WHY — Enforce single-writer discipline; Concerns: RES
use super::id::NodeId;
use parking_lot::Mutex;

pub struct KBucket {
    k: usize,
    // single-writer: interior mut guarded, not held across await in higher layers
    inner: Mutex<Vec<NodeId>>,
}

impl KBucket {
    pub fn new(k: usize) -> Self {
        Self { k, inner: Mutex::new(Vec::with_capacity(k)) }
    }

    pub fn touch(&self, id: NodeId) {
        let mut g = self.inner.lock();
        if let Some(pos) = g.iter().position(|x| *x == id) {
            let n = g.remove(pos);
            g.insert(0, n);
            return;
        }
        if g.len() < self.k {
            g.insert(0, id);
        } else {
            // naive eviction: drop tail (older)
            g.pop();
            g.insert(0, id);
        }
    }

    pub fn snapshot(&self) -> Vec<NodeId> {
        self.inner.lock().clone()
    }
}

```

### crates/svc-dht/src/peer/id.rs
<a id="crates-svc-dht-src-peer-id-rs"></a>

```rust
//! RO:WHAT — Compact `NodeId` and XOR distance
//! RO:WHY  — Kademlia math; Concerns: PERF/RES

use blake3::hash;

#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]
pub struct NodeId([u8; 32]);

impl NodeId {
    #[inline]
    pub fn from_pubkey(pk: &[u8]) -> Self {
        let h = hash(pk);
        Self(*h.as_bytes())
    }

    /// XOR distance between two node IDs.
    #[inline]
    pub fn distance(&self, other: &Self) -> [u8; 32] {
        let mut out = [0u8; 32];
        // Avoid index-based loop to satisfy clippy::needless_range_loop.
        for (dst, (&a, &b)) in out.iter_mut().zip(self.0.iter().zip(other.0.iter())) {
            *dst = a ^ b;
        }
        out
    }

    /// Optional helpers (handy in tests/callers).
    #[inline]
    pub fn to_bytes(self) -> [u8; 32] {
        self.0
    }

    #[inline]
    pub fn from_bytes(b: [u8; 32]) -> Self {
        Self(b)
    }
}

```

### crates/svc-dht/src/peer/mod.rs
<a id="crates-svc-dht-src-peer-mod-rs"></a>

```rust
//! RO:WHAT — Peer ID, Kademlia k-buckets, routing table, selectors
//! RO:WHY — Core routing structures; Concerns: RES/PERF
pub mod bucket;
pub mod id;
pub mod selector;
pub mod table;

pub use id::NodeId;
pub use table::RoutingTable;

```

### crates/svc-dht/src/peer/selector.rs
<a id="crates-svc-dht-src-peer-selector-rs"></a>

```rust
//! RO:WHAT — α-parallel, β-hedged selection placeholder
//! RO:WHY — Tail control; Concerns: PERF/RES
pub struct Selector {
    pub alpha: usize,
    pub beta: usize,
}
impl Selector {
    pub fn new(alpha: usize, beta: usize) -> Self {
        Self { alpha, beta }
    }
}

```

### crates/svc-dht/src/peer/table.rs
<a id="crates-svc-dht-src-peer-table-rs"></a>

```rust
//! RO:WHAT — Routing table over buckets
//! RO:WHY — Find closest peers; Concerns: PERF
use super::{bucket::KBucket, id::NodeId};

pub struct RoutingTable {
    buckets: Vec<KBucket>,
    _k: usize, // kept for shape; prefixed to avoid dead_code warning until used
}

impl RoutingTable {
    pub fn new(k: usize) -> Self {
        // 256-bit space → 256 buckets (MVP)
        let buckets = (0..256).map(|_| KBucket::new(k)).collect();
        Self { buckets, _k: k }
    }

    pub fn observe(&self, me: NodeId, peer: NodeId) {
        let dist = me.distance(&peer);
        let idx = leading_zeros(&dist) as usize;
        let idx = idx.min(self.buckets.len() - 1);
        self.buckets[idx].touch(peer);
    }

    pub fn closest(&self, _me: NodeId, _target: NodeId, n: usize) -> Vec<NodeId> {
        // MVP: concat from all buckets; refine in phase 2
        let mut out = Vec::with_capacity(n);
        for b in &self.buckets {
            for id in b.snapshot() {
                out.push(id);
                if out.len() == n {
                    return out;
                }
            }
        }
        out
    }
}

fn leading_zeros(bytes: &[u8; 32]) -> u32 {
    for (i, b) in bytes.iter().enumerate() {
        if *b != 0 {
            return (i as u32) * 8 + b.leading_zeros();
        }
    }
    256
}

```

### crates/svc-dht/src/pipeline/asn_guard.rs
<a id="crates-svc-dht-src-pipeline-asnguard-rs"></a>

```rust
// pipeline::asn_guard - ASN diversity (placeholder).

```

### crates/svc-dht/src/pipeline/deadlines.rs
<a id="crates-svc-dht-src-pipeline-deadlines-rs"></a>

```rust
//! RO:WHAT — Deadline budgeting for composite operations
//! RO:WHY — Ensure hedging/fanout stays within the caller budget; Concerns: PERF/RES

use std::time::{Duration, Instant};

#[derive(Clone, Copy, Debug)]
pub struct DeadlineBudget {
    start: Instant,
    total: Duration,
}

impl DeadlineBudget {
    pub fn new(total: Duration) -> Self {
        Self { start: Instant::now(), total }
    }
    pub fn remaining(&self) -> Duration {
        let spent = self.start.elapsed();
        if spent >= self.total {
            Duration::from_millis(0)
        } else {
            self.total - spent
        }
    }
    pub fn total(&self) -> Duration {
        self.total
    }
    pub fn spent(&self) -> Duration {
        self.start.elapsed()
    }
}

```

### crates/svc-dht/src/pipeline/hedging.rs
<a id="crates-svc-dht-src-pipeline-hedging-rs"></a>

```rust
//! RO:WHAT — β-hedged race between lookup legs with stagger
//! RO:WHY — Reduce tail latency while respecting deadline; Concerns: PERF/RES

use std::future::Future;
use std::time::Duration;
use tokio::time::{sleep, timeout};

/// Race a primary future with up to `beta` hedges, each staggered by `stagger`.
/// Each leg is wrapped with `timeout(leg_budget)`. The first Ok wins; errors are
/// collected and last error is returned if all fail/timeout.
pub async fn race_hedged<F, Fut, T, E>(
    beta: usize,
    stagger: Duration,
    leg_budget: Duration,
    mut mk_leg: F,
) -> Result<T, E>
where
    F: FnMut(usize) -> Fut + Send + Sync + 'static,
    Fut: Future<Output = Result<T, E>> + Send + 'static,
    T: Send + 'static,
    E: Send + Clone + Default + 'static,
{
    // beta == 0 means: just one primary
    let hedges = beta.saturating_add(1);
    let mut handles = Vec::with_capacity(hedges);

    for i in 0..hedges {
        let fut = mk_leg(i);
        let h = tokio::spawn(async move {
            let t = timeout(leg_budget, fut).await;
            match t {
                Ok(r) => r,
                Err(_) => Err(timeout_err()),
            }
        });
        handles.push(h);
        if i + 1 < hedges && !stagger.is_zero() {
            sleep(stagger).await;
        }
    }

    let mut last_err = None;
    for h in handles {
        match h.await {
            Ok(Ok(v)) => return Ok(v),
            Ok(Err(e)) => last_err = Some(e),
            Err(_) => {}
        }
    }
    Err(last_err.expect("no legs executed"))
}

// Local error helper for timeouts in the hedge layer.
fn timeout_err<E>() -> E
where
    E: Default,
{
    E::default()
}

```

### crates/svc-dht/src/pipeline/lookup.rs
<a id="crates-svc-dht-src-pipeline-lookup-rs"></a>

```rust
//! RO:WHAT — Lookup FSM: fanout (α) → hedge (β) → converge, under a deadline & hop budget
//! RO:WHY — Tail control & budget adherence; Concerns: PERF/RES
//! RO:INTERACTS — provider::Store (local for MVP); later: transport/kad over ron-transport
//! RO:INVARIANTS — no lock held across .await; limiter bounds total leg concurrency

use super::{deadlines::DeadlineBudget, hedging::race_hedged, rate_limit::Limiter};
use crate::provider::Store;
use anyhow::{anyhow, Result};
use std::{sync::Arc, time::Duration};
use tokio::time::Instant;

#[derive(Clone, Debug)]
pub struct LookupRequest {
    pub cid: String,
    pub alpha: usize,
    pub beta: usize,
    pub hop_budget: usize,
    pub deadline: Duration,
    /// Stagger between hedge legs (β) — small to control tail.
    pub hedge_stagger: Duration,
    /// Per-leg minimum budget (clamped by remaining deadline).
    pub min_leg_budget: Duration,
}

#[derive(Clone, Debug)]
pub struct LookupResult {
    pub providers: Vec<String>,
    pub hops: u32,
    pub elapsed: Duration,
}

pub struct LookupCtx {
    store: Arc<Store>,
    limiter: Limiter,
}

impl LookupCtx {
    pub fn new(store: Arc<Store>, max_concurrent_legs: usize) -> Self {
        Self { store, limiter: Limiter::new(max_concurrent_legs) }
    }

    /// Run a lookup under α/β/hedge/deadline/hop_budget. In this MVP, legs query the local
    /// provider store (network-free), but we still exercise hedging and budgets.
    pub async fn run(&self, req: LookupRequest) -> Result<LookupResult> {
        if req.alpha == 0 {
            return Err(anyhow!("alpha must be > 0"));
        }
        if req.hop_budget == 0 {
            return Err(anyhow!("hop budget must be > 0"));
        }

        let budget = DeadlineBudget::new(req.deadline);
        let started = Instant::now();

        // Compose leg runner. Each leg simulates a "hop" by counting attempt number.
        let cid = req.cid.clone();
        let store = self.store.clone();
        let limiter = self.limiter.clone();

        // Effective leg budget: honor remaining global deadline, but not below min_leg_budget.
        let leg_budget = budget.remaining().max(req.min_leg_budget);

        // In the local MVP there is **no artificial jitter** inside legs.
        // Hedging still races futures; whichever returns first wins.
        let beta = req.beta;
        let stagger = req.hedge_stagger;

        let result = race_hedged::<_, _, _, HedgeErr>(beta, stagger, leg_budget, move |leg_idx| {
            let cid = cid.clone();
            let store = store.clone();
            let limiter = limiter.clone();
            async move {
                let _permit = limiter.acquire().await;
                let providers = store.get_live(&cid);
                if providers.is_empty() {
                    Err(HedgeErr) // in a networked version we'd query peers here
                } else {
                    Ok((providers, leg_idx as u32 + 1)) // hops ~ legs tried until success
                }
            }
        })
        .await;

        match result {
            Ok((providers, hops)) => {
                Ok(LookupResult { providers, hops, elapsed: started.elapsed() })
            }
            Err(_) => Err(anyhow!("lookup failed or timed out")),
        }
    }
}

#[derive(Clone, Copy, Debug, Default)]
struct HedgeErr;

```

### crates/svc-dht/src/pipeline/mod.rs
<a id="crates-svc-dht-src-pipeline-mod-rs"></a>

```rust
//! RO:WHAT — Request orchestration (lookup/provide/hedging/limits)
//! RO:WHY — Keep policies out of handlers; Concerns: PERF/RES
pub mod deadlines;
pub mod hedging;
pub mod lookup;
pub mod rate_limit;
// (left for later slices)
pub mod provide { /* TODO: networked replication in next slice */
}
pub mod asn_guard { /* TODO: ASN diversity guard in next slice */
}

```

### crates/svc-dht/src/pipeline/provide.rs
<a id="crates-svc-dht-src-pipeline-provide-rs"></a>

```rust
// pipeline::provide - provide flow (placeholder).

```

### crates/svc-dht/src/pipeline/rate_limit.rs
<a id="crates-svc-dht-src-pipeline-ratelimit-rs"></a>

```rust
//! RO:WHAT — Simple global rate limiter for in-flight lookup legs
//! RO:WHY — Backpressure to avoid overload; Concerns: RES/PERF

use tokio::sync::{OwnedSemaphorePermit, Semaphore};

#[derive(Clone)]
pub struct Limiter {
    sem: std::sync::Arc<Semaphore>,
}

impl Limiter {
    /// new: max concurrent legs (global)
    pub fn new(max_legs: usize) -> Self {
        Self { sem: std::sync::Arc::new(Semaphore::new(max_legs)) }
    }
    pub async fn acquire(&self) -> OwnedSemaphorePermit {
        self.sem.clone().acquire_owned().await.expect("semaphore closed")
    }
}

```

### crates/svc-dht/src/pq/algo.rs
<a id="crates-svc-dht-src-pq-algo-rs"></a>

```rust
// pq::algo - ML-DSA/SPHINCS+ selection (placeholder).

```

### crates/svc-dht/src/pq/gating.rs
<a id="crates-svc-dht-src-pq-gating-rs"></a>

```rust
// pq::gating - REQUIRE/REQUIRE_ON policy (placeholder).

```

### crates/svc-dht/src/pq/mod.rs
<a id="crates-svc-dht-src-pq-mod-rs"></a>

```rust
// pq::mod - PQ posture surface (placeholder).

```

### crates/svc-dht/src/pq/verify.rs
<a id="crates-svc-dht-src-pq-verify-rs"></a>

```rust
// pq::verify - dual-sign verify (placeholder).

```

### crates/svc-dht/src/provider/mod.rs
<a id="crates-svc-dht-src-provider-mod-rs"></a>

```rust
//! RO:WHAT — Provider record facade (RAM default; TTL pruning worker)
//! RO:WHY — Enables local provide/find_providers without network
//! RO:INVARIANTS — TTL respected; amnesia-friendly (no disk by default)

pub mod record;
pub mod republish;
pub mod store;
pub mod ttl;

pub use store::Store;

```

### crates/svc-dht/src/provider/record.rs
<a id="crates-svc-dht-src-provider-record-rs"></a>

```rust
//! RO:WHAT — ProviderRecord v1 (MVP: node string + expiry)
//! RO:WHY — Minimal schema to exercise provide/find locally

use std::time::{Duration, Instant};

#[derive(Clone, Debug)]
pub struct ProviderRecord {
    pub cid: String,
    pub node: String,
    pub expires_at: Instant,
}

impl ProviderRecord {
    pub fn new(cid: String, node: String, ttl: Duration) -> Self {
        Self { cid, node, expires_at: Instant::now() + ttl }
    }
    pub fn expired(&self, now: Instant) -> bool {
        now >= self.expires_at
    }
}

```

### crates/svc-dht/src/provider/republish.rs
<a id="crates-svc-dht-src-provider-republish-rs"></a>

```rust
//! RO:WHAT — Placeholder for republish/refresh logic
//! RO:WHY — Left for Phase 2 (networked replication)
pub struct Republisher;

```

### crates/svc-dht/src/provider/store.rs
<a id="crates-svc-dht-src-provider-store-rs"></a>

```rust
//! RO:WHAT — In-memory provider store with TTL
//! RO:WHY — Micronode default; keeps MVP simple
use super::record::ProviderRecord;
use parking_lot::RwLock;
use std::{
    collections::HashMap,
    time::{Duration, Instant},
};

#[derive(Default)]
pub struct Store {
    inner: RwLock<HashMap<String, Vec<ProviderRecord>>>, // cid -> records
    default_ttl: Duration,
}

impl Store {
    pub fn new(default_ttl: Duration) -> Self {
        Self { inner: RwLock::new(HashMap::new()), default_ttl }
    }

    pub fn default_ttl(&self) -> Duration {
        self.default_ttl
    }

    /// RO:WHAT — Add/refresh a provider record (de-duped by node) for a CID.
    pub fn add(&self, cid: String, node: String, ttl: Option<Duration>) {
        let cid = normalize(&cid);
        let node = normalize(&node);
        let ttl = ttl.unwrap_or(self.default_ttl);
        let rec = ProviderRecord::new(cid.clone(), node, ttl);

        let mut g = self.inner.write();
        let v = g.entry(cid).or_default();
        // de-dup by node
        if let Some(pos) = v.iter().position(|r| r.node == rec.node) {
            v[pos] = rec;
        } else {
            v.push(rec);
        }
    }

    /// RO:WHAT — Read-only view of live providers (no mutation).
    pub fn get_live(&self, cid: &str) -> Vec<String> {
        let cid = normalize(cid);
        let now = Instant::now();
        let g = self.inner.read();
        if let Some(v) = g.get(&cid) {
            v.iter().filter(|r| !r.expired(now)).map(|r| r.node.clone()).collect()
        } else {
            Vec::new()
        }
    }

    /// RO:WHAT — Prune expired records; called by background pruner.
    pub fn purge_expired(&self) -> usize {
        let now = Instant::now();
        let mut g = self.inner.write();
        let mut purged = 0usize;
        for v in g.values_mut() {
            let before = v.len();
            v.retain(|r| !r.expired(now));
            purged += before.saturating_sub(v.len());
        }
        // drop empty CIDs
        g.retain(|_, v| !v.is_empty());
        purged
    }

    /// RO:WHAT — Debug snapshot: all CIDs with nodes and seconds-until-expiry.
    pub fn debug_snapshot(&self) -> Vec<DebugCid> {
        let now = Instant::now();
        let g = self.inner.read();
        let mut out = Vec::new();
        for (cid, recs) in g.iter() {
            let entries = recs
                .iter()
                .map(|r| DebugEntry {
                    node: r.node.clone(),
                    secs_left: r.expires_at.saturating_duration_since(now).as_secs_f64(),
                })
                .collect();
            out.push(DebugCid { cid: cid.clone(), entries });
        }
        out
    }
}

#[derive(serde::Serialize)]
pub struct DebugCid {
    pub cid: String,
    pub entries: Vec<DebugEntry>,
}

#[derive(serde::Serialize)]
pub struct DebugEntry {
    pub node: String,
    pub secs_left: f64,
}

fn normalize(s: &str) -> String {
    s.trim().to_string()
}

```

### crates/svc-dht/src/provider/ttl.rs
<a id="crates-svc-dht-src-provider-ttl-rs"></a>

```rust
//! RO:WHAT — Background TTL pruning worker
//! RO:WHY — Keeps store clean over time without external triggers

use super::Store;
use std::sync::Arc;
use tokio::time::{sleep, Duration};
use tracing::debug;

pub fn spawn_pruner(store: Arc<Store>) -> tokio::task::JoinHandle<()> {
    tokio::spawn(async move {
        // Small initial delay to avoid racing immediately after a provide with very short TTLs.
        sleep(Duration::from_secs(2)).await;
        loop {
            let n = store.purge_expired();
            if n > 0 {
                debug!(purged = n, "provider TTL pruned");
            }
            sleep(Duration::from_secs(1)).await;
        }
    })
}

```

### crates/svc-dht/src/readiness.rs
<a id="crates-svc-dht-src-readiness-rs"></a>

```rust
//! RO:WHAT — Readiness gate: flips when bootstrap quorum + min-fill thresholds met
//! RO:WHY — Prevents thundering herd; Concerns: RES/PERF
//! RO:INTERACTS — bootstrap, peer::table, /readyz
//! RO:INVARIANTS — set ready last; fail-closed on writes
//! RO:TEST — readiness_bootstrap.rs

use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;

#[derive(Default)]
pub struct ReadyGate {
    ready: AtomicBool,
}
impl ReadyGate {
    pub fn new() -> Self {
        Self { ready: AtomicBool::new(false) }
    }
    pub fn set_ready(&self) {
        self.ready.store(true, Ordering::Release);
    }
    pub fn is_ready(&self) -> bool {
        self.ready.load(Ordering::Acquire)
    }
}

pub type SharedReady = Arc<ReadyGate>;

```

### crates/svc-dht/src/rpc/bus.rs
<a id="crates-svc-dht-src-rpc-bus-rs"></a>

```rust
// rpc::bus - bus topic adapters (placeholder).

```

### crates/svc-dht/src/rpc/discv5.rs
<a id="crates-svc-dht-src-rpc-discv5-rs"></a>

```rust
// rpc::discv5 - peer discovery (placeholder).

```

### crates/svc-dht/src/rpc/http.rs
<a id="crates-svc-dht-src-rpc-http-rs"></a>

```rust
//! RO:WHAT — Admin endpoints + DHT demo endpoints (provide + find_providers via pipeline)
//! RO:WHY — Ops-first; Concerns: GOV/PERF/DX/SEC. Adds CID/node validation and stable errors.
//! RO:INTERACTS — metrics, provider::Store, pipeline::lookup, types::B3Cid.
//! RO:INVARIANTS — deny unknown fields; return 400 on bad input; no lock across .await.
//! RO:TEST — tests/provider_roundtrip.rs

use axum::{extract::Path, http::StatusCode, response::IntoResponse, Json};
use std::{
    sync::Arc,
    time::{Duration, Instant},
};

use crate::{
    metrics::DhtMetrics,
    pipeline::lookup::{LookupCtx, LookupRequest},
    provider::Store,
    readiness::ReadyGate,
    types::{validate_node_uri, B3Cid},
};
use ron_kernel::HealthState;
use serde::Deserialize;

#[derive(Clone)]
pub struct State {
    pub health: Arc<HealthState>,
    pub ready: Arc<ReadyGate>,
    pub metrics: Arc<DhtMetrics>,
    pub providers: Arc<Store>,

    // Pipeline knobs (from Config)
    pub alpha: usize,
    pub beta: usize,
    pub hop_budget: usize,
    pub default_deadline: Duration,
    pub hedge_stagger: Duration,
    pub min_leg_budget: Duration,

    // Pipeline context (rate limiter etc.)
    pub lookup_ctx: Arc<LookupCtx>,
}

impl State {
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        health: Arc<HealthState>,
        ready: Arc<ReadyGate>,
        metrics: Arc<DhtMetrics>,
        providers: Arc<Store>,
        alpha: usize,
        beta: usize,
        hop_budget: usize,
        default_deadline: Duration,
        hedge_stagger: Duration,
        min_leg_budget: Duration,
        lookup_ctx: Arc<LookupCtx>,
    ) -> Self {
        Self {
            health,
            ready,
            metrics,
            providers,
            alpha,
            beta,
            hop_budget,
            default_deadline,
            hedge_stagger,
            min_leg_budget,
            lookup_ctx,
        }
    }
}

pub async fn healthz(axum::extract::State(st): axum::extract::State<State>) -> impl IntoResponse {
    if st.health.all_ready() || st.ready.is_ready() {
        (StatusCode::OK, "ok").into_response()
    } else {
        (StatusCode::OK, "starting").into_response()
    }
}

pub async fn readyz(axum::extract::State(st): axum::extract::State<State>) -> impl IntoResponse {
    if st.ready.is_ready() {
        (StatusCode::OK, "ready").into_response()
    } else {
        (StatusCode::SERVICE_UNAVAILABLE, [("Retry-After", "1")], "booting").into_response()
    }
}

pub async fn version() -> impl IntoResponse {
    let sha = option_env!("BUILD_GIT_SHA").unwrap_or("unknown");
    let ts = option_env!("BUILD_TS").unwrap_or("unknown");
    Json(serde_json::json!({ "git": sha, "built": ts }))
}

pub async fn metrics() -> impl IntoResponse {
    match crate::metrics::DhtMetrics::encode() {
        Ok(text) => (StatusCode::OK, text),
        Err(_) => (StatusCode::INTERNAL_SERVER_ERROR, "encode error".to_string()),
    }
}

/// Demo: POST /dht/provide  {"cid":"b3:...","node":"nodeA","ttl_secs":600}
#[derive(Deserialize)]
#[serde(deny_unknown_fields)]
pub struct ProvideBody {
    pub cid: B3Cid,
    pub node: String,
    #[serde(default)]
    pub ttl_secs: Option<u64>,
}

pub async fn provide(
    axum::extract::State(st): axum::extract::State<State>,
    Json(body): Json<ProvideBody>,
) -> impl IntoResponse {
    if !validate_node_uri(&body.node) {
        return (StatusCode::BAD_REQUEST, Json(serde_json::json!({ "error": "invalid node URI" })))
            .into_response();
    }

    let ttl = body.ttl_secs.map(Duration::from_secs);
    let used_ttl = ttl.unwrap_or_else(|| st.providers.default_ttl());
    st.providers.add(body.cid.into_string(), body.node, Some(used_ttl));
    st.metrics.provides_total.inc();
    (
        StatusCode::OK,
        Json(serde_json::json!({
            "ok": true,
            "ttl_secs_used": used_ttl.as_secs()
        })),
    )
        .into_response()
}

/// GET /dht/find_providers/:cid — uses the lookup pipeline (α/β/hedge/deadline)
pub async fn find_providers(
    axum::extract::State(st): axum::extract::State<State>,
    Path(cid): Path<B3Cid>,
) -> impl IntoResponse {
    let t0 = Instant::now();

    let req = LookupRequest {
        cid: cid.to_string(),
        alpha: st.alpha,
        beta: st.beta,
        hop_budget: st.hop_budget,
        deadline: st.default_deadline,
        hedge_stagger: st.hedge_stagger,
        min_leg_budget: st.min_leg_budget,
    };

    match st.lookup_ctx.run(req).await {
        Ok(res) => {
            st.metrics.observe_lookup(t0.elapsed(), res.hops);
            Json(serde_json::json!({
                "cid": cid.to_string(),
                "providers": res.providers,
                "hops": res.hops,
                "elapsed_ms": res.elapsed.as_millis(),
            }))
            .into_response()
        }
        Err(e) => {
            st.metrics.observe_lookup(t0.elapsed(), 0);
            (StatusCode::GATEWAY_TIMEOUT, Json(serde_json::json!({ "error": e.to_string() })))
                .into_response()
        }
    }
}

/// Debug: GET /dht/_debug/list — full in-memory snapshot with TTL left
pub async fn debug_list(
    axum::extract::State(st): axum::extract::State<State>,
) -> impl IntoResponse {
    let snap = st.providers.debug_snapshot();
    Json(serde_json::json!(snap))
}

```

### crates/svc-dht/src/rpc/kad.rs
<a id="crates-svc-dht-src-rpc-kad-rs"></a>

```rust
//! RO:WHAT — Kad request/response DTOs and handlers (placeholder)
//! RO:WHY — Wire surface; Concerns: DX/RES
#[derive(serde::Serialize, serde::Deserialize)]
pub struct FindProviders {
    pub cid: String,
    pub limit: usize,
}
#[derive(serde::Serialize, serde::Deserialize)]
pub struct Providers {
    pub cid: String,
    pub nodes: Vec<String>,
}

```

### crates/svc-dht/src/rpc/mod.rs
<a id="crates-svc-dht-src-rpc-mod-rs"></a>

```rust
//! RO:WHAT — RPC surfaces: Kad + admin HTTP (MVP includes HTTP)
//! RO:WHY — Entry points; Concerns: DX/SEC
pub mod bus; // TODO phase 2
pub mod discv5;
pub mod http;
pub mod kad; // TODO phase 2

```

### crates/svc-dht/src/supervision/backoff.rs
<a id="crates-svc-dht-src-supervision-backoff-rs"></a>

```rust
//! RO:WHAT — Exponential backoff with jitter
//! RO:WHY — Prevents stampedes; Concerns: RES/PERF
pub fn next(prev_ms: u64) -> u64 {
    (prev_ms.saturating_mul(2)).min(30_000)
}

```

### crates/svc-dht/src/supervision/mod.rs
<a id="crates-svc-dht-src-supervision-mod-rs"></a>

```rust
//! RO:WHAT — Supervision helpers (backoff/signals)
//! RO:WHY — Crash-only discipline; Concerns: RES
pub mod backoff;
pub mod signals;

```

### crates/svc-dht/src/supervision/signals.rs
<a id="crates-svc-dht-src-supervision-signals-rs"></a>

```rust
//! RO:WHAT — Signal helpers (placeholder)
//! RO:WHY — Wiring space for future supervised tasks
pub fn install() {}

```

### crates/svc-dht/src/supervision/supervisor.rs
<a id="crates-svc-dht-src-supervision-supervisor-rs"></a>

```rust
// supervisor.rs (placeholder).

```

### crates/svc-dht/src/tracing.rs
<a id="crates-svc-dht-src-tracing-rs"></a>

```rust
//! RO:WHAT — Tracing initialization (env-filter aware)
//! RO:WHY — Uniform logs; Concerns: GOV/DX
//! RO:INTERACTS — all modules via tracing
//! RO:INVARIANTS — JSON optional; defaults to INFO

use tracing_subscriber::{fmt, layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};

pub fn init() {
    let filter =
        EnvFilter::try_from_default_env().unwrap_or_else(|_| EnvFilter::new("info,svc_dht=info"));
    tracing_subscriber::registry().with(filter).with(fmt::layer().with_target(false)).init();
}

```

### crates/svc-dht/src/transport/clients.rs
<a id="crates-svc-dht-src-transport-clients-rs"></a>

```rust
// transport::clients - pools & timeouts (placeholder).

```

### crates/svc-dht/src/transport/mod.rs
<a id="crates-svc-dht-src-transport-mod-rs"></a>

```rust
//! RO:WHAT — Thin wrapper around ron-transport clients
//! RO:WHY — Keep svc-dht transport-agnostic; Concerns: SEC/RES
pub mod clients; // TODO phase 2
#[cfg(feature = "arti")]
pub mod tor; // TODO phase 2

```

### crates/svc-dht/src/transport/tor.rs
<a id="crates-svc-dht-src-transport-tor-rs"></a>

```rust
// transport::tor - arti support (placeholder).

```

### crates/svc-dht/src/types.rs
<a id="crates-svc-dht-src-types-rs"></a>

```rust
//! RO:WHAT — Common types (B3Cid validator, NodeUri placeholder).
//! RO:WHY  — DX/SEC hardening: validate CIDs early; avoid junk through the pipeline.
//! RO:INTERACTS — rpc::http, provider::Store, pipeline::lookup.
//! RO:INVARIANTS — BLAKE3-256 only; lowercase hex; "b3:<64-hex>"; no locks across .await.
//! RO:SECURITY — Rejects malformed IDs with 400; prevents cache poisoning.
//! RO:TEST — unit in tests/provider_roundtrip.rs and rpc/http tests.

use std::fmt;
use std::str::FromStr;

/// Canonical content address: "b3:<64-lowercase-hex>" (BLAKE3-256)
#[derive(Clone, Debug, PartialEq, Eq, Hash)]
pub struct B3Cid(String);

impl B3Cid {
    pub fn as_str(&self) -> &str {
        &self.0
    }
    pub fn into_string(self) -> String {
        self.0
    }
}

impl fmt::Display for B3Cid {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.write_str(&self.0)
    }
}

impl FromStr for B3Cid {
    type Err = &'static str;
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        // Strict: exactly "b3:" + 64 lowercase hex chars.
        const PREFIX: &str = "b3:";
        if !s.starts_with(PREFIX) {
            return Err("bad-prefix");
        }
        let hex = &s[PREFIX.len()..];
        if hex.len() != 64 {
            return Err("bad-length");
        }
        if !hex.as_bytes().iter().all(|b| matches!(b, b'0'..=b'9'|b'a'..=b'f')) {
            return Err("bad-hex");
        }
        Ok(B3Cid(s.to_string()))
    }
}

// Serde glue so DTOs can use B3Cid directly.
impl<'de> serde::Deserialize<'de> for B3Cid {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        s.parse().map_err(serde::de::Error::custom)
    }
}
impl serde::Serialize for B3Cid {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        serializer.serialize_str(self.as_str())
    }
}

/// Very light Node URI checker (MVP): "<scheme>://<id>"
/// We only require non-empty and forbid whitespace; detailed validation left for transport layer.
pub fn validate_node_uri(s: &str) -> bool {
    let s = s.trim();
    if s.is_empty() {
        return false;
    }
    if s.contains(char::is_whitespace) {
        return false;
    }
    s.contains("://")
}

```

### crates/svc-dht/tests/api_smoke.rs
<a id="crates-svc-dht-tests-apismoke-rs"></a>

```rust
//! Happy-path handler smoke test (no sockets).
//! Verifies: provide → find_providers JSON shape + 400 on bad input.

use std::sync::{Arc, OnceLock};
use std::time::Duration;

use axum::extract::State as AxumState;
use axum::http::StatusCode;
use axum::response::IntoResponse;
use ron_kernel::HealthState;
use svc_dht::metrics::DhtMetrics;
use svc_dht::pipeline::lookup::LookupCtx;
use svc_dht::provider::Store;
use svc_dht::readiness::ReadyGate;
use svc_dht::rpc::http::{find_providers, provide, ProvideBody, State};
use svc_dht::types::B3Cid;

// ---- test-global metrics to avoid duplicate Prometheus registration
static METRICS: OnceLock<Arc<DhtMetrics>> = OnceLock::new();
fn metrics() -> Arc<DhtMetrics> {
    METRICS.get_or_init(|| Arc::new(DhtMetrics::new().expect("metrics"))).clone()
}

fn make_state() -> State {
    let health = Arc::new(HealthState::default());
    let ready = Arc::new(ReadyGate::new());
    ready.set_ready();

    let providers = Arc::new(Store::new(Duration::from_secs(60)));
    let lookup_ctx = Arc::new(LookupCtx::new(providers.clone(), 16));

    State::new(
        health,
        ready,
        metrics(),
        providers,
        3, // alpha
        1, // beta
        6, // hop_budget
        Duration::from_millis(300),
        Duration::from_millis(15),
        Duration::from_millis(50),
        lookup_ctx,
    )
}

#[tokio::test]
async fn provide_and_find_basic() {
    let st = make_state();

    // Provide a short-lived record.
    let cid: B3Cid =
        "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef".parse().unwrap();

    let body =
        ProvideBody { cid: cid.clone(), node: "local://nodeA".to_string(), ttl_secs: Some(2) };
    let resp = provide(AxumState(st.clone()), axum::Json(body)).await.into_response();
    assert_eq!(resp.status(), StatusCode::OK);

    // Find providers (should see exactly 1).
    let resp = find_providers(AxumState(st), axum::extract::Path(cid)).await.into_response();
    assert_eq!(resp.status(), StatusCode::OK);

    let body_bytes = axum::body::to_bytes(resp.into_body(), 1024 * 1024).await.expect("body bytes");
    let v: serde_json::Value = serde_json::from_slice(&body_bytes).expect("json");
    assert_eq!(
        v.get("providers").unwrap().as_array().unwrap().len(),
        1,
        "exactly one provider expected"
    );
}

#[tokio::test]
async fn provide_rejects_bad_node_uri() {
    let st = make_state();

    let cid: B3Cid =
        "b3:aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa".parse().unwrap();

    // Bad node URI should be rejected with 400.
    let bad = ProvideBody { cid, node: "not a uri".into(), ttl_secs: None };
    let resp = provide(AxumState(st), axum::Json(bad)).await.into_response();
    assert_eq!(resp.status(), StatusCode::BAD_REQUEST);
}

```

### crates/svc-dht/tests/asn_diversity.rs
<a id="crates-svc-dht-tests-asndiversity-rs"></a>

```rust
//! RO:WHAT — Local, self-contained test for "ASN diversity" selection logic.
//! RO:WHY  — We don’t have a real ASN guard yet; this models the policy in-test
//!           so we can lock behavior now and swap to the real guard later.
//! RO:NOTES — Pure test logic; no crate changes needed to pass.

use std::collections::HashSet;

/// Minimal stand-in for an "ASN diversity" filter:
/// Keep candidates while ensuring at least `min_unique_asn` distinct ASNs stay present.
/// Returns Err if impossible.
fn select_with_asn_diversity(
    mut candidates: Vec<(String, u32)>,
    min_unique_asn: usize,
    limit: usize,
) -> Result<Vec<(String, u32)>, &'static str> {
    // Greedy: first ensure we include one per ASN to hit the floor, then fill up to limit.
    candidates.sort_by_key(|(_, asn)| *asn);

    let mut seen = HashSet::new();
    let mut out = Vec::new();

    // Phase A: one per ASN until we hit the floor (or run out)
    for (node, asn) in candidates.iter().cloned() {
        if seen.insert(asn) {
            out.push((node, asn));
            if seen.len() >= min_unique_asn {
                break;
            }
        }
    }
    if seen.len() < min_unique_asn {
        return Err("asn_floor_unmet");
    }

    // Phase B: fill remainder by round-robin (here just linear pass) without ASN constraint
    for (node, asn) in candidates.into_iter() {
        if out.len() >= limit {
            break;
        }
        // allow duplicates of ASNs now
        if !out.iter().any(|(n, _)| *n == node) {
            out.push((node, asn));
        }
    }

    if out.len() > limit {
        out.truncate(limit);
    }
    Ok(out)
}

#[test]
fn rejects_all_same_asn_when_floor_gt1() {
    let candidates =
        vec![("n1".to_string(), 64512), ("n2".to_string(), 64512), ("n3".to_string(), 64512)];
    let res = select_with_asn_diversity(candidates, /*min_unique_asn*/ 2, /*limit*/ 2);
    assert!(res.is_err(), "should reject when all candidates share the same ASN");
}

#[test]
fn accepts_mix_and_meets_floor() {
    let candidates = vec![
        ("a".to_string(), 64512),
        ("b".to_string(), 64513),
        ("c".to_string(), 64512),
        ("d".to_string(), 64514),
    ];
    let out = select_with_asn_diversity(candidates, /*min_unique_asn*/ 2, /*limit*/ 3).unwrap();
    let unique_asn: HashSet<_> = out.iter().map(|(_, a)| *a).collect();
    assert!(unique_asn.len() >= 2, "expected ASN diversity floor met");
    assert!(out.len() <= 3);
}

```

### crates/svc-dht/tests/chaos/netem.rs
<a id="crates-svc-dht-tests-chaos-netem-rs"></a>

```rust
// chaos/netem.rs: latency/loss model tests (placeholder).

```

### crates/svc-dht/tests/chaos/partition.rs
<a id="crates-svc-dht-tests-chaos-partition-rs"></a>

```rust
// chaos/partition.rs: split-brain healing (placeholder).

```

### crates/svc-dht/tests/chaos/soak_churn.rs
<a id="crates-svc-dht-tests-chaos-soakchurn-rs"></a>

```rust
// chaos/soak_churn.rs: long soak & churn (placeholder).

```

### crates/svc-dht/tests/deadline_hedge.rs
<a id="crates-svc-dht-tests-deadlinehedge-rs"></a>

```rust
use std::time::Duration;
use svc_dht::pipeline::hedging::race_hedged;
use tokio::time::sleep;

#[tokio::test]
async fn hedger_respects_budget_and_stagger() {
    // NOTE: We intentionally set budget to 20ms and stagger to 5ms, then make the
    // primary slow and hedges fast. Expect total elapsed < ~25ms and Ok(()).

    let budget = Duration::from_millis(20);
    let stagger = Duration::from_millis(5);

    let started = std::time::Instant::now();

    let out = race_hedged::<_, _, (), ()>(2, stagger, budget, |leg_idx| async move {
        if leg_idx == 0 {
            sleep(Duration::from_millis(100)).await; // slow primary hits timeout → hedges win
        } else {
            sleep(Duration::from_millis(1)).await; // fast hedge
        }
        Ok(())
    })
    .await;

    let elapsed = started.elapsed();
    assert!(out.is_ok(), "hedged race should succeed via hedge");
    assert!(elapsed < Duration::from_millis(30), "elapsed too large: {elapsed:?}");
}

```

### crates/svc-dht/tests/kbucket_props.rs
<a id="crates-svc-dht-tests-kbucketprops-rs"></a>

```rust
//! RO:WHAT — Routing table properties that hold for the MVP implementation.
//! RO:WHY  — Catch regressions in bucket indexing and "closest N" behavior.
//! RO:INTERACTS — peer::{NodeId, RoutingTable}

use svc_dht::peer::{NodeId, RoutingTable};

fn nid(bytes: &[u8]) -> NodeId {
    // NodeId::from_pubkey() hashes input; that's fine for deterministic construction
    NodeId::from_pubkey(bytes)
}

#[test]
fn distance_xor_zero_for_identical_ids() {
    let a = nid(&[0xAA; 32]);
    let d = a.distance(&a);
    assert!(d.iter().all(|&b| b == 0), "distance(self,self) must be zero");
}

#[test]
fn closest_respects_limit_and_has_no_duplicates() {
    let me = nid(&[0x11; 32]);
    let rt = RoutingTable::new(/*k*/ 8);

    // Observe > 8 peers; closest(.., n) must never return more than n
    for i in 0..50u8 {
        let pk = [i; 32];
        rt.observe(me, nid(&pk));
    }

    let out = rt.closest(me, nid(&[0x22; 32]), 8);
    assert!(out.len() <= 8);

    // no duplicates
    let mut set = std::collections::HashSet::new();
    for id in &out {
        assert!(set.insert(id.clone()), "duplicate NodeId in closest()");
    }
}

#[test]
fn bucket_index_monotonicity_smoke() {
    // As distance grows, we *tend* to hit different buckets. We can't see buckets directly,
    // but we can at least ensure observe() doesn't panic and closest() is stable.
    let me = nid(&[0u8; 32]);
    let rt = RoutingTable::new(8);

    // Craft peers at different XOR distances
    let peers = [
        nid(&[0x00; 32]), // identical (distance 0)
        nid(&[0x80; 32]), // highest bit diff
        nid(&[0x7F; 32]), // many lower bits diff
        nid(&[0x01; 32]), // only LSB diff
        nid(&[0xFF; 32]), // all bits diff
    ];

    for p in peers {
        rt.observe(me, p);
    }

    let out = rt.closest(me, nid(&[0x10; 32]), 5);
    assert!(!out.is_empty());
}

```

### crates/svc-dht/tests/nodeid_and_store.rs
<a id="crates-svc-dht-tests-nodeidandstore-rs"></a>

```rust
use std::time::Duration;
use svc_dht::peer::id::NodeId;
use svc_dht::provider::Store;
use svc_dht::types::B3Cid;

#[test]
fn nodeid_distance_xor() {
    let a = NodeId::from_pubkey(b"A");
    let b = NodeId::from_pubkey(b"B");
    let d_ab = a.distance(&b);
    let d_ba = b.distance(&a);
    assert_eq!(d_ab, d_ba, "XOR is symmetric");
    assert_eq!(a.distance(&a), [0u8; 32], "distance to self is zero");
}

#[test]
fn provider_store_ttl_expiry() {
    let ttl = Duration::from_millis(20);
    let st = Store::new(ttl);
    let cid: B3Cid = "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"
        .parse()
        .unwrap();

    st.add(cid.clone(), "local://nodeA".into());
    let now = std::time::Instant::now();
    let got1 = st.get(&cid);
    assert_eq!(got1, vec!["local://nodeA".to_string()]);

    // wait out TTL and prune
    std::thread::sleep(ttl + Duration::from_millis(5));
    st.prune(now + ttl + Duration::from_millis(5));
    let got2 = st.get(&cid);
    assert!(got2.is_empty(), "expired provider should be pruned");
}

```

### crates/svc-dht/tests/provider_roundtrip.rs
<a id="crates-svc-dht-tests-providerroundtrip-rs"></a>

```rust
use std::time::Duration;
use svc_dht::provider::Store;

#[test]
fn provider_add_get_prune_roundtrip() {
    let store = Store::new(Duration::from_secs(2));
    let cid = "b3:deadbeef".to_string();

    // Add two providers; ensure de-dup by node works
    store.add(cid.clone(), "local://A".into(), Some(Duration::from_millis(250)));
    store.add(cid.clone(), "local://B".into(), Some(Duration::from_millis(250)));
    store.add(cid.clone(), "local://A".into(), Some(Duration::from_millis(250))); // refresh

    let mut live = store.get_live(&cid);
    live.sort();
    assert_eq!(live, vec!["local://A", "local://B"]);

    // After expiry window, purge removes both
    std::thread::sleep(Duration::from_millis(300));
    let purged = store.purge_expired();
    assert!(purged >= 1, "expected at least one purged; got {purged}");

    let live2 = store.get_live(&cid);
    assert!(live2.is_empty(), "expected no live providers after purge, got {live2:?}");
}

```

### crates/svc-dht/tests/readiness_bootstrap.rs
<a id="crates-svc-dht-tests-readinessbootstrap-rs"></a>

```rust
#[tokio::test]
async fn boot_and_ready() {
    // Smoke: start the server main() would, but here we just hit the handlers directly
    // (Integration rig lives in the crate’s examples in phase 2)
    assert!(true);
}

```

