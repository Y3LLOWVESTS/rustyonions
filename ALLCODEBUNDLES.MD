<!-- Generated by scripts/collect_codebundles.sh on 2025-11-22T17:50:21Z -->
# ALLCODEBUNDLES — Beta Crates

_This file aggregates CODEBUNDLE.MD from beta-complete crates for review/sharing._

**Included crates (order):**

- ron-kernel
- ron-bus
- ron-proto
- ron-metrics
- oap
- ron-transport
- ryker
- svc-overlay
- svc-dht
- ron-naming
- svc-storage
- svc-index
- ron-policy
- omnigate
- svc-gateway
- ron-kms
- svc-passport
- ron-auth
- micronode
- macronode
- svc-registry
- svc-edge
- ron-audit
- ron-app-sdk


---



# ron-kernel

_Source: crates/ron-kernel/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:47:24Z -->
# Code Bundle — `ron-kernel`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-kernel/.cargo/config.toml](#crates-ron-kernel--cargo-config-toml)
- [crates/ron-kernel/.github/workflows/kernel-ci.yml](#crates-ron-kernel--github-workflows-kernel-ci-yml)
- [crates/ron-kernel/.github/workflows/rust.yml](#crates-ron-kernel--github-workflows-rust-yml)
- [crates/ron-kernel/Cargo.toml](#crates-ron-kernel-Cargo-toml)
- [crates/ron-kernel/benches/a2_publish_many.rs](#crates-ron-kernel-benches-a2publishmany-rs)
- [crates/ron-kernel/benches/a3_autotune_cap.rs](#crates-ron-kernel-benches-a3autotunecap-rs)
- [crates/ron-kernel/benches/bus_batch.rs](#crates-ron-kernel-benches-busbatch-rs)
- [crates/ron-kernel/benches/bus_lag_vs_publish.rs](#crates-ron-kernel-benches-buslagvspublish-rs)
- [crates/ron-kernel/benches/bus_multi_subscribers.rs](#crates-ron-kernel-benches-busmultisubscribers-rs)
- [crates/ron-kernel/benches/bus_overflow_drop.rs](#crates-ron-kernel-benches-busoverflowdrop-rs)
- [crates/ron-kernel/benches/bus_publish.rs](#crates-ron-kernel-benches-buspublish-rs)
- [crates/ron-kernel/benches/bus_publish_matrix.rs](#crates-ron-kernel-benches-buspublishmatrix-rs)
- [crates/ron-kernel/benches/bus_soa.rs](#crates-ron-kernel-benches-bussoa-rs)
- [crates/ron-kernel/benches/metrics_encode.rs](#crates-ron-kernel-benches-metricsencode-rs)
- [crates/ron-kernel/benches/publish_edge_matrix.rs](#crates-ron-kernel-benches-publishedgematrix-rs)
- [crates/ron-kernel/benches/readiness_handler.rs](#crates-ron-kernel-benches-readinesshandler-rs)
- [crates/ron-kernel/deny.toml](#crates-ron-kernel-deny-toml)
- [crates/ron-kernel/examples/kernel_demo.rs](#crates-ron-kernel-examples-kerneldemo-rs)
- [crates/ron-kernel/examples/minimal_supervision.rs](#crates-ron-kernel-examples-minimalsupervision-rs)
- [crates/ron-kernel/examples/publish_smoke.rs](#crates-ron-kernel-examples-publishsmoke-rs)
- [crates/ron-kernel/fuzz/cfg_parser.rs](#crates-ron-kernel-fuzz-cfgparser-rs)
- [crates/ron-kernel/rust-toolchain.toml](#crates-ron-kernel-rust-toolchain-toml)
- [crates/ron-kernel/scripts/ci_public_api.sh](#crates-ron-kernel-scripts-cipublicapi-sh)
- [crates/ron-kernel/scripts/enforce_ro_headers.sh](#crates-ron-kernel-scripts-enforceroheaders-sh)
- [crates/ron-kernel/scripts/perf_gate.sh](#crates-ron-kernel-scripts-perfgate-sh)
- [crates/ron-kernel/scripts/render_mermaid.sh](#crates-ron-kernel-scripts-rendermermaid-sh)
- [crates/ron-kernel/scripts/ron_kernel_smoke.sh](#crates-ron-kernel-scripts-ronkernelsmoke-sh)
- [crates/ron-kernel/scripts/run_kernel_benches.sh](#crates-ron-kernel-scripts-runkernelbenches-sh)
- [crates/ron-kernel/scripts/run_mog_b1.sh](#crates-ron-kernel-scripts-runmogb1-sh)
- [crates/ron-kernel/src/amnesia.rs](#crates-ron-kernel-src-amnesia-rs)
- [crates/ron-kernel/src/bus/backoff.rs](#crates-ron-kernel-src-bus-backoff-rs)
- [crates/ron-kernel/src/bus/bounded.rs](#crates-ron-kernel-src-bus-bounded-rs)
- [crates/ron-kernel/src/bus/capacity.rs](#crates-ron-kernel-src-bus-capacity-rs)
- [crates/ron-kernel/src/bus/mod.rs](#crates-ron-kernel-src-bus-mod-rs)
- [crates/ron-kernel/src/bus/mog_edge_notify.rs](#crates-ron-kernel-src-bus-mogedgenotify-rs)
- [crates/ron-kernel/src/bus/soa.rs](#crates-ron-kernel-src-bus-soa-rs)
- [crates/ron-kernel/src/bus/test.rs](#crates-ron-kernel-src-bus-test-rs)
- [crates/ron-kernel/src/bus/topic.rs](#crates-ron-kernel-src-bus-topic-rs)
- [crates/ron-kernel/src/config/cell.rs](#crates-ron-kernel-src-config-cell-rs)
- [crates/ron-kernel/src/config/mod.rs](#crates-ron-kernel-src-config-mod-rs)
- [crates/ron-kernel/src/config/validation.rs](#crates-ron-kernel-src-config-validation-rs)
- [crates/ron-kernel/src/config/watcher.rs](#crates-ron-kernel-src-config-watcher-rs)
- [crates/ron-kernel/src/events.rs](#crates-ron-kernel-src-events-rs)
- [crates/ron-kernel/src/health/mod.rs](#crates-ron-kernel-src-health-mod-rs)
- [crates/ron-kernel/src/internal/constants.rs](#crates-ron-kernel-src-internal-constants-rs)
- [crates/ron-kernel/src/internal/mod.rs](#crates-ron-kernel-src-internal-mod-rs)
- [crates/ron-kernel/src/internal/types.rs](#crates-ron-kernel-src-internal-types-rs)
- [crates/ron-kernel/src/lib.rs](#crates-ron-kernel-src-lib-rs)
- [crates/ron-kernel/src/metrics/buffer.rs](#crates-ron-kernel-src-metrics-buffer-rs)
- [crates/ron-kernel/src/metrics/exporter.rs](#crates-ron-kernel-src-metrics-exporter-rs)
- [crates/ron-kernel/src/metrics/health.rs](#crates-ron-kernel-src-metrics-health-rs)
- [crates/ron-kernel/src/metrics/mod.rs](#crates-ron-kernel-src-metrics-mod-rs)
- [crates/ron-kernel/src/metrics/readiness.rs](#crates-ron-kernel-src-metrics-readiness-rs)
- [crates/ron-kernel/src/mog_autotune.rs](#crates-ron-kernel-src-mogautotune-rs)
- [crates/ron-kernel/src/shutdown.rs](#crates-ron-kernel-src-shutdown-rs)
- [crates/ron-kernel/src/supervisor/backoff.rs](#crates-ron-kernel-src-supervisor-backoff-rs)
- [crates/ron-kernel/src/supervisor/child.rs](#crates-ron-kernel-src-supervisor-child-rs)
- [crates/ron-kernel/src/supervisor/lifecycle.rs](#crates-ron-kernel-src-supervisor-lifecycle-rs)
- [crates/ron-kernel/src/supervisor/mod.rs](#crates-ron-kernel-src-supervisor-mod-rs)
- [crates/ron-kernel/testing/performance/publish_matrix.toml](#crates-ron-kernel-testing-performance-publishmatrix-toml)
- [crates/ron-kernel/tests/amnesia_label.rs](#crates-ron-kernel-tests-amnesialabel-rs)
- [crates/ron-kernel/tests/autotune_capacity.rs](#crates-ron-kernel-tests-autotunecapacity-rs)
- [crates/ron-kernel/tests/autotune_sanity.rs](#crates-ron-kernel-tests-autotunesanity-rs)
- [crates/ron-kernel/tests/bus_basics.rs](#crates-ron-kernel-tests-busbasics-rs)
- [crates/ron-kernel/tests/bus_bounded.rs](#crates-ron-kernel-tests-busbounded-rs)
- [crates/ron-kernel/tests/bus_close_semantics.rs](#crates-ron-kernel-tests-busclosesemantics-rs)
- [crates/ron-kernel/tests/bus_contract.rs](#crates-ron-kernel-tests-buscontract-rs)
- [crates/ron-kernel/tests/edge_notify_loom.rs](#crates-ron-kernel-tests-edgenotifyloom-rs)
- [crates/ron-kernel/tests/health_ready.rs](#crates-ron-kernel-tests-healthready-rs)
- [crates/ron-kernel/tests/loom_bus.rs](#crates-ron-kernel-tests-loombus-rs)
- [crates/ron-kernel/tests/metrics_amnesia.rs](#crates-ron-kernel-tests-metricsamnesia-rs)
- [crates/ron-kernel/tests/metrics_smoke.rs](#crates-ron-kernel-tests-metricssmoke-rs)
- [crates/ron-kernel/tests/property_config.rs](#crates-ron-kernel-tests-propertyconfig-rs)
- [crates/ron-kernel/tests/public_api.rs](#crates-ron-kernel-tests-publicapi-rs)
- [crates/ron-kernel/tests/readiness_degrades.rs](#crates-ron-kernel-tests-readinessdegrades-rs)
- [crates/ron-kernel/tests/soa_smoke.rs](#crates-ron-kernel-tests-soasmoke-rs)
- [crates/ron-kernel/tests/supervisor_backoff.rs](#crates-ron-kernel-tests-supervisorbackoff-rs)
- [crates/ron-kernel/tests/supervisor_backoff_integ.rs](#crates-ron-kernel-tests-supervisorbackoffinteg-rs)
- [crates/ron-kernel/tests/tls_type_invariance.rs](#crates-ron-kernel-tests-tlstypeinvariance-rs)
- [crates/ron-kernel/tests/watcher_integ.rs](#crates-ron-kernel-tests-watcherinteg-rs)

### crates/ron-kernel/.cargo/config.toml
<a id="crates-ron-kernel--cargo-config-toml"></a>

```toml
[build]
rustflags = []

[term]
verbose = false

```

### crates/ron-kernel/.github/workflows/kernel-ci.yml
<a id="crates-ron-kernel--github-workflows-kernel-ci-yml"></a>

```yaml
name: kernel-ci
on: [push, pull_request]
jobs:
  public-api:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - run: cargo install cargo-public-api || true
      - run: cargo public-api -p ron-kernel2 || true
  mermaid:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm i -g @mermaid-js/mermaid-cli
      - run: |
          for f in $(git ls-files 'crates/ron-kernel2/docs/*.mmd' 2>/dev/null); do
            mmdc -i "$f" -o "${f%.mmd}.svg"
          done

```

### crates/ron-kernel/.github/workflows/rust.yml
<a id="crates-ron-kernel--github-workflows-rust-yml"></a>

```yaml
name: rust
on: [push, pull_request]
jobs:
  test:
    strategy:
      matrix:
        amnesia: [off, on]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - name: Build
        run: cargo build -p ron-kernel2
      - name: Test
        run: AMNESIA=${{ matrix.amnesia }} cargo test -p ron-kernel2 --all-features
  loom:
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - name: Run loom tests (ignored)
        run: RUSTFLAGS="--cfg loom" cargo test -p ron-kernel2 -- --ignored

```

### crates/ron-kernel/Cargo.toml
<a id="crates-ron-kernel-Cargo-toml"></a>

```toml
[package]
name = "ron-kernel"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
publish = false

[lib]
name = "ron_kernel"
path = "src/lib.rs"

[features]
# Optional features can be added here (e.g., "kameo")
default = []
# Enable Loom model-checking tests with: cargo test -p ron-kernel --features loom
loom = ["dep:loom"]
#MOG - Phase A:
bus_edge_notify = []   # edge-triggered, coalesced wakeups per subscriber
bus_batch = []         # publish_many(&[T]) single-fence/notify
bus_autotune_cap = []  # cap defaults chosen by N subscribers, warn on oversized caps
metrics_buf = []       # per-thread metrics buffering with periodic flush
#MOG - Phase B: 
bus_soa = []           # SoA ring + per-slot ready bitmask (Arc<T> payload to keep 100% safe)
bus_interest = []      # variant/topic bitmask filtering per subscriber
bus_coalesce = []      # coalesce wakeups by K/Δt thresholds (optional latency trade)
local_dispatch = []    # example helpers/patterns; not a kernel core change


[dependencies]
# Core async
tokio = { version = "1", features = ["macros", "rt-multi-thread", "signal", "time", "io-util", "sync", "net", "fs"] }

# Loom must be optional because the 'loom' feature references it via dep:loom
loom = { version = "0.7", optional = true, default-features = false }

# HTTP stack (workspace standard pins implied)
axum = { version = "0.7", features = ["tokio", "http1", "http2", "json"], default-features = false }
tower = "0.5"
tower-http = { version = "0.6.6", features = ["trace"] }

# Metrics/obs
prometheus = "0.14"
once_cell = "1.19"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["fmt", "env-filter"] }

# Concurrency/locking
parking_lot = "0.12"

# Config & serde
serde = { version = "1.0", features = ["derive"] }
serde_json = "1"
toml = "0.8"

# Misc
anyhow = "1.0"
thiserror = "1.0"

# TLS is intentionally not enforced here (transport services handle it)
tokio-rustls = "0.26.2"
notify = "6"
rand = "0.9"
futures = "0.3"
humantime-serde = "1"

cfg-if = "1"


[dev-dependencies]
reqwest = { version = "0.12", features = ["rustls-tls-native-roots", "json"] }
# Enable "async" so benches can use b.to_async(&rt)
criterion = { version = "0.5", features = ["html_reports", "async"] }
tempfile = "3"
parking_lot = "0.12"

[[bench]]
name = "bus_publish"
harness = false

[[bench]]
name = "bus_lag_vs_publish"
harness = false

[[bench]]
name = "metrics_encode"
harness = false

[[bench]]
name = "bus_overflow_drop"
harness = false

[[bench]]
name = "readiness_handler"
harness = false

[[bench]]
name = "bus_multi_subscribers"
harness = false

[[bench]]
name = "bus_publish_matrix"
harness = false


[[bench]]
name = "bus_batch"
harness = false

[[bench]]
name = "a3_autotune_cap"
harness = false
required-features = ["bus_autotune_cap"]

[[bench]]
name = "a2_publish_many"
harness = false

[[bench]]
name = "bus_soa"
harness = false

```

### crates/ron-kernel/benches/a2_publish_many.rs
<a id="crates-ron-kernel-benches-a2publishmany-rs"></a>

```rust
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion, Throughput};
use ron_kernel::bus::bounded::Bus;
use std::time::Duration;
use tokio::sync::broadcast;

// Drain helper (same shape as other benches).
fn drain_now<T: Clone + Send + 'static>(rx: &mut broadcast::Receiver<T>) -> usize {
    use tokio::sync::broadcast::error::TryRecvError::*;
    let mut n = 0usize;
    loop {
        match rx.try_recv() {
            Ok(_) => n += 1,
            Err(Empty) => break,
            Err(Lagged(_)) => continue,
            Err(Closed) => break,
        }
    }
    n
}

fn bench_a2_batch_vs_single(c: &mut Criterion) {
    // single-threaded RT for stability
    let rt = tokio::runtime::Builder::new_current_thread()
        .enable_time()
        .build()
        .unwrap();

    let mut group = c.benchmark_group("a2_publish_many");
    let subs_set = [1usize, 4]; // focus where notify matters
    let cap = 64usize; // tuned sweet spot from MOG
    let bursts = [1usize, 1_000, 5_000, 10_000];

    for &subs in &subs_set {
        for &batch_len in &bursts {
            group.throughput(Throughput::Elements(batch_len as u64));

            // Baseline: single publishes in a loop (no bus_batch feature needed)
            group.bench_with_input(
                BenchmarkId::new(
                    "single_loop",
                    format!("subs={subs},cap={cap},n={batch_len}"),
                ),
                &(),
                |b, _| {
                    rt.block_on(async {
                        let bus: Bus<u64> = Bus::with_capacity(cap);
                        let mut rxs: Vec<_> = (0..subs).map(|_| bus.subscribe()).collect();

                        b.iter(|| {
                            for i in 0..batch_len as u64 {
                                let _ = bus.publish(i);
                            }
                            for rx in &mut rxs {
                                let _ = drain_now(rx);
                            }
                        });
                    });
                },
            );

            // A2: publish_many (feature-gated); when feature off, this target won’t exist
            #[cfg(feature = "bus_batch")]
            group.bench_with_input(
                BenchmarkId::new(
                    "publish_many",
                    format!("subs={subs},cap={cap},n={batch_len}"),
                ),
                &(),
                |b, _| {
                    rt.block_on(async {
                        let bus: Bus<u64> = Bus::with_capacity(cap);
                        let mut rxs: Vec<_> = (0..subs).map(|_| bus.subscribe()).collect();

                        // preallocate batch to avoid alloc noise in iter
                        let batch: Vec<u64> = (0..batch_len as u64).collect();

                        b.iter(|| {
                            let _ = bus.publish_many(&batch);
                            for rx in &mut rxs {
                                let _ = drain_now(rx);
                            }
                        });
                    });
                },
            );
        }
    }
    group.finish();
}

criterion_group! {
    name = benches;
    config = {
        Criterion::default()
            .measurement_time(Duration::from_secs(8))
            .warm_up_time(Duration::from_secs(3))
            .sample_size(20)
    };
    targets = bench_a2_batch_vs_single
}
criterion_main!(benches);

```

### crates/ron-kernel/benches/a3_autotune_cap.rs
<a id="crates-ron-kernel-benches-a3autotunecap-rs"></a>

```rust
#![cfg(feature = "bus_autotune_cap")]
use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion};
use ron_kernel::autotune_capacity;

fn bench_autotune_mapping(c: &mut Criterion) {
    let mut g = c.benchmark_group("a3_autotune_mapping");

    for &n in &[1usize, 4, 16, 64, 128] {
        g.bench_with_input(BenchmarkId::from_parameter(n), &n, |b, &n| {
            b.iter(|| {
                let mut s = 0usize;
                for _ in 0..1024 {
                    s ^= autotune_capacity(n, None);
                }
                black_box(s)
            })
        });
    }

    g.bench_function("override_192", |b| {
        b.iter(|| black_box(autotune_capacity(16, Some(192))))
    });

    g.finish();
}

criterion_group!(benches, bench_autotune_mapping);
criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_batch.rs
<a id="crates-ron-kernel-benches-busbatch-rs"></a>

```rust
//! RO:WHAT
//! Bench the bounded Bus<T> publish paths with and without batching.
//!
//! RO:WHY
//! A2 (bus_batch) should reduce notify/wake amplification and fence costs by
//! batching multiple publishes into one sweep with <=1 notify. This bench *must*
//! be env-configurable so we can sweep fanout/cap/burst from the shell.
//!
//! RO:INTERACTS
//! - Uses `ron_kernel::bus::bounded::Bus` directly.
//! - Feature flag `bus_batch` enables the batch path.
//! - Criterion for timing.
//!
//! RO:INVARIANTS
//! - Public API untouched (bench only).
//! - No panics under capacity pressure; drops are handled inside Bus.
//! - Single-threaded Tokio runtime for stability.

use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion, Throughput};
use std::env;
use std::time::Duration;

// We bench the kernel Bus<T> directly.
use ron_kernel::bus::bounded::Bus;

// A small POD event for hot-path measurement.
#[derive(Clone)]
#[allow(dead_code)]
struct Ev(u64);

fn getenv<T: std::str::FromStr>(key: &str, default: T) -> T {
    env::var(key)
        .ok()
        .and_then(|s| s.parse::<T>().ok())
        .unwrap_or(default)
}

// Drain helper: non-blocking, like our EdgeReceiver::try_recv_now_or_never().
fn drain_now<T: Clone + Send + 'static>(rx: &mut tokio::sync::broadcast::Receiver<T>) -> usize {
    use tokio::sync::broadcast::error::TryRecvError::*;
    let mut n = 0usize;
    loop {
        match rx.try_recv() {
            Ok(_) => {
                n += 1;
            }
            Err(Empty) => break,
            Err(Lagged(_)) => continue,
            Err(Closed) => break,
        }
    }
    n
}

fn bench_bus_batch(c: &mut Criterion) {
    // Env-driven configuration (defaults match previous behavior).
    let subs = getenv::<usize>("RON_BENCH_FANOUT", 4);
    let cap = getenv::<usize>("RON_BENCH_CAP", 64);
    let burst = getenv::<usize>("RON_BENCH_BURST", 128);

    eprintln!(
        "[bench cfg] subs={}, cap={}, burst={}  (set RON_BENCH_FANOUT/CAP/BURST to override)",
        subs, cap, burst
    );

    // Single-threaded runtime for stable numbers.
    let rt = tokio::runtime::Builder::new_current_thread()
        .enable_time()
        .build()
        .unwrap();

    let mut g = c.benchmark_group("bus_batch");

    // --- Single publish baseline ---------------------------------------------------------
    g.throughput(Throughput::Elements(10_000));
    g.measurement_time(Duration::from_secs(10));
    g.warm_up_time(Duration::from_secs(3));

    g.bench_with_input(
        BenchmarkId::new(
            "publish_single",
            format!("subs={subs},cap={cap},burst={burst}"),
        ),
        &(),
        |b, _| {
            rt.block_on(async {
                let bus: Bus<Ev> = Bus::with_capacity(cap);
                // spawn subscribers
                let mut rxs: Vec<_> = (0..subs).map(|_| bus.subscribe()).collect();
                b.iter(|| {
                    for i in 0..10_000u64 {
                        let _ = bus.publish(Ev(i));
                    }
                    // drain
                    for rx in &mut rxs {
                        let _ = drain_now(rx);
                    }
                    black_box(());
                });
            });
        },
    );

    // --- Batch publish (A2) --------------------------------------------------------------
    #[cfg(feature = "bus_batch")]
    {
        g.throughput(Throughput::Elements(10_000));
        g.bench_with_input(
            BenchmarkId::new(
                "publish_many",
                format!("subs={subs},cap={cap},burst={burst}"),
            ),
            &(),
            |b, _| {
                rt.block_on(async {
                    let bus: Bus<Ev> = Bus::with_capacity(cap);
                    let mut rxs: Vec<_> = (0..subs).map(|_| bus.subscribe()).collect();

                    let mut batch = Vec::with_capacity(burst.max(1));
                    b.iter(|| {
                        batch.clear();
                        // total elements = 10_000 per iter (≈ 10_000 / burst batches)
                        for i in 0..10_000u64 {
                            batch.push(Ev(i));
                            if batch.len() == burst {
                                let _ = bus.publish_many(&batch);
                                batch.clear();
                            }
                        }
                        if !batch.is_empty() {
                            let _ = bus.publish_many(&batch);
                            batch.clear();
                        }
                        // drain
                        for rx in &mut rxs {
                            let _ = drain_now(rx);
                        }
                        black_box(());
                    });
                });
            },
        );
    }

    g.finish();
}

criterion_group! {
    name = benches;
    config = Criterion::default()
        .measurement_time(Duration::from_secs(6))
        .warm_up_time(Duration::from_secs(2))
        .sample_size(40);
    targets = bench_bus_batch
}
criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_lag_vs_publish.rs
<a id="crates-ron-kernel-benches-buslagvspublish-rs"></a>

```rust
/*!
RO: benches/bus_lag_vs_publish.rs
WHAT: Compare publish throughput under no-subscriber vs single slow subscriber.
WHY : Validate non-blocking publish w/ slow receiver (bounded cost, drops on recv side).
NOTE: Group config tuned to avoid "unable to complete samples" warnings on many machines.
*/

use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion, SamplingMode};
use ron_kernel::{Bus, KernelEvent, Metrics};
use std::time::Duration;
use tokio::runtime::Builder;

const INNER_PUBLISHES: usize = 25_000;

fn bench_bus_lag_vs_publish(c: &mut Criterion) {
    let rt = Builder::new_multi_thread().enable_all().build().unwrap();

    let mut group = c.benchmark_group("bus_lag_vs_publish");
    group.sampling_mode(SamplingMode::Flat);
    group.sample_size(60);
    group.warm_up_time(Duration::from_secs(2));
    group.measurement_time(Duration::from_secs(8));

    // no_subscribers (upper-bound publish cost)
    group.bench_with_input(
        BenchmarkId::new("no_subscribers", INNER_PUBLISHES),
        &(),
        |b, _| {
            b.iter(|| {
                rt.block_on(async {
                    let metrics = Metrics::new(false);
                    let bus: Bus<KernelEvent> = metrics.make_bus(1024);
                    for i in 0..black_box(INNER_PUBLISHES) {
                        let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                    }
                });
            });
        },
    );

    // one_slow_subscriber (non-blocking publish should remain bounded)
    group.bench_with_input(
        BenchmarkId::new("one_slow_subscriber", INNER_PUBLISHES),
        &(),
        |b, _| {
            b.iter(|| {
                rt.block_on(async {
                    let metrics = Metrics::new(false);
                    let bus: Bus<KernelEvent> = metrics.make_bus(64);

                    let mut rx = bus.subscribe();
                    let slow = tokio::spawn(async move {
                        loop {
                            match rx.recv().await {
                                Ok(_e) => {
                                    tokio::time::sleep(Duration::from_micros(black_box(20))).await
                                }
                                Err(_) => break,
                            }
                        }
                    });

                    for i in 0..black_box(INNER_PUBLISHES) {
                        let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                    }

                    drop(bus);
                    let _ = slow.await;
                });
            });
        },
    );

    group.finish();
}

criterion_group!(benches, bench_bus_lag_vs_publish);
criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_multi_subscribers.rs
<a id="crates-ron-kernel-benches-busmultisubscribers-rs"></a>

```rust
/*!
RO: benches/bus_multi_subscribers.rs
WHAT: Publish throughput with 0, 1, and 16 draining subscribers.
WHY : Show fan-out cost growth as subscriber count rises.
*/

use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion, SamplingMode};
use ron_kernel::{Bus, KernelEvent, Metrics};
use std::time::Duration;
use tokio::runtime::Builder;

const INNER_PUBLISHES: usize = 10_000;

fn bench_bus_publish(c: &mut Criterion) {
    let rt = Builder::new_multi_thread().enable_all().build().unwrap();

    let mut group = c.benchmark_group("bus_publish");
    group.sampling_mode(SamplingMode::Flat);
    group.sample_size(60);
    group.warm_up_time(Duration::from_secs(2));
    group.measurement_time(Duration::from_secs(8));

    // 0 subscribers
    group.bench_with_input(
        BenchmarkId::new("0_subscribers", INNER_PUBLISHES),
        &(),
        |b, _| {
            b.iter(|| {
                rt.block_on(async {
                    let metrics = Metrics::new(false);
                    let bus: Bus<KernelEvent> = metrics.make_bus(1024);
                    for i in 0..black_box(INNER_PUBLISHES) {
                        let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                    }
                });
            });
        },
    );

    // 1 subscriber (draining)
    group.bench_with_input(
        BenchmarkId::new("1_subscriber", INNER_PUBLISHES),
        &(),
        |b, _| {
            b.iter(|| {
                rt.block_on(async {
                    let metrics = Metrics::new(false);
                    let bus: Bus<KernelEvent> = metrics.make_bus(1024);

                    let mut rx = bus.subscribe();
                    let drain = tokio::spawn(async move { while let Ok(_ev) = rx.recv().await {} });

                    for i in 0..black_box(INNER_PUBLISHES) {
                        let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                    }

                    drop(bus);
                    let _ = drain.await;
                });
            });
        },
    );

    // 16 subscribers (draining)
    group.bench_with_input(
        BenchmarkId::new("16_subscribers", INNER_PUBLISHES),
        &(),
        |b, _| {
            b.iter(|| {
                rt.block_on(async {
                    let metrics = Metrics::new(false);
                    let bus: Bus<KernelEvent> = metrics.make_bus(2048);

                    let mut joins = Vec::new();
                    for _ in 0..16 {
                        let mut rx = bus.subscribe();
                        joins.push(tokio::spawn(async move {
                            while let Ok(_ev) = rx.recv().await {}
                        }));
                    }

                    for i in 0..black_box(INNER_PUBLISHES) {
                        let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                    }

                    drop(bus);
                    for j in joins {
                        let _ = j.await;
                    }
                });
            });
        },
    );

    group.finish();
}

criterion_group!(benches, bench_bus_publish);
criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_overflow_drop.rs
<a id="crates-ron-kernel-benches-busoverflowdrop-rs"></a>

```rust
/*!
RO: benches/bus_overflow_drop.rs
WHAT: Stress bounded bus with a slow subscriber; ensure publish cost is bounded.
WHY : Validate overflow path keeps publisher fast (drops accounted on recv side).
*/

use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion, SamplingMode};
use ron_kernel::{Bus, KernelEvent, Metrics};
use std::time::Duration;
use tokio::runtime::Builder;

const INNER_PUBLISHES: usize = 50_000;

fn bench_overflow(c: &mut Criterion) {
    let rt = Builder::new_multi_thread().enable_all().build().unwrap();

    let mut group = c.benchmark_group("bus_overflow");
    group.sampling_mode(SamplingMode::Flat);
    group.sample_size(60);
    group.warm_up_time(Duration::from_secs(2));
    group.measurement_time(Duration::from_secs(8));

    group.bench_with_input(
        BenchmarkId::new("slow_single_subscriber", INNER_PUBLISHES),
        &(),
        |b, _| {
            b.iter(|| {
                rt.block_on(async {
                    let metrics = Metrics::new(false);
                    // Small capacity to induce overflow quickly
                    let bus: Bus<KernelEvent> = metrics.make_bus(32);

                    let mut rx = bus.subscribe();
                    let slow = tokio::spawn(async move {
                        loop {
                            match rx.recv().await {
                                Ok(_e) => {
                                    tokio::time::sleep(Duration::from_micros(black_box(50))).await
                                }
                                Err(_) => break,
                            }
                        }
                    });

                    for i in 0..black_box(INNER_PUBLISHES) {
                        let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                    }

                    drop(bus);
                    let _ = slow.await;
                });
            });
        },
    );

    group.finish();
}

criterion_group!(benches, bench_overflow);
criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_publish.rs
<a id="crates-ron-kernel-benches-buspublish-rs"></a>

```rust
//! RO:WHAT — Bus publish perf: steady-state + bursty (classic vs edge, fanout, tunable caps).
//! RO:WHY  — Show real-world wins by:
//!           • steady-state apples-to-apples,
//!           • burst benches with draining + configurable fanout,
//!           • optional publisher epoch (yield between bursts),
//!           • configurable bus cap to avoid queue backpressure (critical).
//! RO:NOTE — Only `publish()`/`publish_many()` are timed; setup/drain outside hot loops.

use std::{env, time::Duration};

#[cfg(feature = "bus_batch")]
use criterion::BatchSize;
use criterion::{
    black_box, criterion_group, criterion_main, BenchmarkId, Criterion, SamplingMode, Throughput,
};

use ron_kernel::{KernelEvent, Metrics};
use tokio::sync::broadcast::error::RecvError;

// ----------------------------- Env toggles -----------------------------

fn getenv_usize(keys: &[&str], default_: usize) -> usize {
    for k in keys {
        if let Ok(v) = env::var(k) {
            if let Ok(n) = v.parse::<usize>() {
                if n > 0 {
                    return n;
                }
            }
        }
    }
    default_
}

fn getenv_bool(keys: &[&str]) -> bool {
    for k in keys {
        if let Ok(v) = env::var(k) {
            let s = v.to_ascii_lowercase();
            if s == "1" || s == "true" || s == "yes" || s == "on" {
                return true;
            }
            if s == "0" || s == "false" || s == "no" || s == "off" {
                return false;
            }
        }
    }
    false
}

// Accept both RON_* and plain keys (your earlier runs used BURST/CAP).
fn burst_size() -> usize {
    getenv_usize(&["RON_BURST", "BURST", "RON_BENCH_BURST"], 256)
}
fn fanout() -> usize {
    getenv_usize(&["RON_FANOUT", "FANOUT", "RON_BENCH_FANOUT"], 4)
}
fn pub_epoch_yield() -> bool {
    getenv_bool(&["RON_BENCH_PUB_YIELD", "PUB_YIELD"])
}
fn burst_cap() -> usize {
    getenv_usize(&["RON_CAP", "CAP", "RON_BENCH_CAP"], 2048)
}
fn tls_flush_threshold() -> usize {
    getenv_usize(&["RON_TLS_FLUSH_THRESHOLD", "TLS_THRESH"], 64)
}

// ------------------------------ Utilities -----------------------------

#[inline(always)]
fn publish_burst<B: Publisher<KernelEvent>>(bus: &B, n: usize) {
    for _ in 0..n {
        let _ = black_box(bus.publish(KernelEvent::Shutdown));
    }
}

trait Publisher<T> {
    fn publish(&self, t: T) -> usize;
}
impl Publisher<KernelEvent> for ron_kernel::bus::bounded::Bus<KernelEvent> {
    #[inline(always)]
    fn publish(&self, t: KernelEvent) -> usize {
        self.publish(t)
    }
}

fn spawn_classic_drains(
    rt: &tokio::runtime::Runtime,
    bus: &ron_kernel::bus::bounded::Bus<KernelEvent>,
    n: usize,
) {
    for _ in 0..n {
        let mut rx = bus.subscribe();
        rt.spawn(async move {
            loop {
                match rx.recv().await {
                    Ok(_msg) => {}
                    Err(RecvError::Lagged(_)) => continue,
                    Err(RecvError::Closed) => break,
                }
            }
        });
    }
}

#[cfg(feature = "bus_edge_notify")]
fn spawn_edge_drains(
    rt: &tokio::runtime::Runtime,
    bus: &ron_kernel::bus::bounded::Bus<KernelEvent>,
    n: usize,
) {
    use ron_kernel::bus::bounded::EdgeReceiver;
    for idx in 0..n {
        let mut sub: EdgeReceiver<KernelEvent> = bus.subscribe_edge();
        rt.spawn(async move {
            sub.run_drain_loop(idx).await;
        });
    }
}

// -------------------------------- Benches -----------------------------

fn bench_publish(c: &mut Criterion) {
    // Log config once per run so threshold sweeps are easy to map in output.
    let tls_thresh = tls_flush_threshold();
    let burst = burst_size();
    let fanout_n = fanout();
    let cap = burst_cap();
    eprintln!(
        "[bench cfg] RON_TLS_FLUSH_THRESHOLD={}, burst={}, fanout={}, cap={}",
        tls_thresh, burst, fanout_n, cap
    );

    // ============ Group 1: steady-state (classic, idle subscriber) ============
    let mut steady = c.benchmark_group(format!("bus_publish_steady (tls_thresh={})", tls_thresh));
    steady.sampling_mode(SamplingMode::Flat);
    steady.sample_size(80);
    steady.warm_up_time(Duration::from_secs(1));
    steady.measurement_time(Duration::from_secs(6));

    // (A) no subscribers — cap=64 (small, stable)
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(64);
        steady.bench_with_input(
            BenchmarkId::new("no_subscribers", "publish()"),
            &(),
            |b, _| {
                b.iter(|| {
                    let _ = black_box(bus.publish(KernelEvent::Shutdown));
                });
            },
        );
    }

    // (B) one subscriber (idle; no recv) — cap=64
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(64);
        let _rx = bus.subscribe(); // keep alive; no recv()
        steady.bench_with_input(
            BenchmarkId::new("one_subscriber", "publish()"),
            &(),
            |b, _| {
                b.iter(|| {
                    let _ = black_box(bus.publish(KernelEvent::Shutdown));
                });
            },
        );
    }

    // (C) lagged subscriber (cap=1; no recv)
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(1);
        let _rx = bus.subscribe(); // keep alive; no recv()
        steady.bench_with_input(
            BenchmarkId::new("lagged_subscriber_cap1", "publish()"),
            &(),
            |b, _| {
                b.iter(|| {
                    let _ = black_box(bus.publish(KernelEvent::Shutdown));
                });
            },
        );
    }
    steady.finish();

    // Runtime for burst groups
    let rt = tokio::runtime::Builder::new_multi_thread()
        .enable_all()
        .build()
        .expect("tokio rt");

    // ============ Group 2: Bursty — CLASSIC recv drain (fanout) ============
    let mut bursty_classic = c.benchmark_group(format!(
        "bus_publish_bursty_classic (tls_thresh={})",
        tls_thresh
    ));
    bursty_classic.sampling_mode(SamplingMode::Flat);
    bursty_classic.sample_size(60);
    bursty_classic.warm_up_time(Duration::from_secs(1));
    bursty_classic.measurement_time(Duration::from_secs(6));

    let label = format!("burst{}_fanout{}_cap{}", burst, fanout_n, cap);

    // (C1) classic fanout; cap=CAP (avoid backpressure)
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(cap);
        spawn_classic_drains(&rt, &bus, fanout_n);

        bursty_classic.throughput(Throughput::Elements(burst as u64));
        bursty_classic.bench_with_input(BenchmarkId::new("classic_fanout", &label), &(), |b, _| {
            b.iter(|| {
                publish_burst(&bus, burst);
                if pub_epoch_yield() {
                    rt.block_on(async { tokio::task::yield_now().await });
                }
            });
        });

        rt.block_on(async { tokio::task::yield_now().await });
    }

    // (C2) classic lagged fanout; cap=1 (pressure path)
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(1);
        spawn_classic_drains(&rt, &bus, fanout_n);

        let label_lag = format!("burst{}_fanout{}_cap{}", burst, fanout_n, 1);
        bursty_classic.throughput(Throughput::Elements(burst as u64));
        bursty_classic.bench_with_input(
            BenchmarkId::new("classic_lagged_fanout", &label_lag),
            &(),
            |b, _| {
                b.iter(|| {
                    publish_burst(&bus, burst);
                    if pub_epoch_yield() {
                        rt.block_on(async { tokio::task::yield_now().await });
                    }
                });
            },
        );

        rt.block_on(async { tokio::task::yield_now().await });
    }

    bursty_classic.finish();

    // ============ Group 3: Bursty — EDGE recv drain (fanout, gated) ============
    #[cfg(feature = "bus_edge_notify")]
    {
        let mut bursty_edge = c.benchmark_group(format!(
            "bus_publish_bursty_edge (tls_thresh={})",
            tls_thresh
        ));
        bursty_edge.sampling_mode(SamplingMode::Flat);
        bursty_edge.sample_size(60);
        bursty_edge.warm_up_time(Duration::from_secs(1));
        bursty_edge.measurement_time(Duration::from_secs(6));

        let burst = burst_size();
        let fanout_n = fanout();
        let cap = burst_cap();
        let label = format!("burst{}_fanout{}_cap{}", burst, fanout_n, cap);

        // (E1) edge fanout; cap=CAP
        {
            let metrics = Metrics::new(true);
            let bus = metrics.make_bus::<KernelEvent>(cap);
            spawn_edge_drains(&rt, &bus, fanout_n);

            bursty_edge.throughput(Throughput::Elements(burst as u64));
            bursty_edge.bench_with_input(BenchmarkId::new("edge_fanout", &label), &(), |b, _| {
                b.iter(|| {
                    publish_burst(&bus, burst);
                    if pub_epoch_yield() {
                        rt.block_on(async { tokio::task::yield_now().await });
                    }
                });
            });

            rt.block_on(async { tokio::task::yield_now().await });
        }

        // (E2) edge lagged fanout; cap=1
        {
            let metrics = Metrics::new(true);
            let bus = metrics.make_bus::<KernelEvent>(1);
            spawn_edge_drains(&rt, &bus, fanout_n);

            let label_lag = format!("burst{}_fanout{}_cap{}", burst, fanout_n, 1);
            bursty_edge.throughput(Throughput::Elements(burst as u64));
            bursty_edge.bench_with_input(
                BenchmarkId::new("edge_lagged_fanout", &label_lag),
                &(),
                |b, _| {
                    b.iter(|| {
                        publish_burst(&bus, burst);
                        if pub_epoch_yield() {
                            rt.block_on(async { tokio::task::yield_now().await });
                        }
                    });
                },
            );

            rt.block_on(async { tokio::task::yield_now().await });
        }

        bursty_edge.finish();
    }
}

#[cfg(feature = "bus_batch")]
fn bench_publish_batched(c: &mut Criterion) {
    // ========= Group 4: Bursty — **BATCHED** publish_many (fanout), real A2 path =========
    let tls_thresh = tls_flush_threshold();
    let mut bursty_batched = c.benchmark_group(format!(
        "bus_publish_bursty_batched (tls_thresh={})",
        tls_thresh
    ));
    bursty_batched.sampling_mode(SamplingMode::Flat);
    bursty_batched.sample_size(60);
    bursty_batched.warm_up_time(Duration::from_secs(1));
    bursty_batched.measurement_time(Duration::from_secs(6));

    let rt = tokio::runtime::Builder::new_multi_thread()
        .enable_all()
        .build()
        .expect("tokio rt");

    let burst = burst_size();
    let fanout_n = fanout();
    let cap = burst_cap();
    let label = format!("burst{}_fanout{}_cap{}", burst, fanout_n, cap);

    // (B1) batched fanout; cap=CAP (no backpressure)
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(cap);
        spawn_classic_drains(&rt, &bus, fanout_n);

        bursty_batched.throughput(Throughput::Elements(burst as u64));
        bursty_batched.bench_with_input(BenchmarkId::new("batched_fanout", &label), &(), |b, _| {
            // Prepare per-iter batch without timing the setup (A2 hot path only):
            b.iter_batched_ref(
                || {
                    let mut v = Vec::with_capacity(burst);
                    v.resize(burst, KernelEvent::Shutdown);
                    v
                },
                |batch| {
                    #[allow(unused_must_use)]
                    {
                        bus.publish_many(black_box(&mut batch[..]));
                    }
                    if pub_epoch_yield() {
                        rt.block_on(async { tokio::task::yield_now().await });
                    }
                },
                BatchSize::SmallInput,
            );
        });

        rt.block_on(async { tokio::task::yield_now().await });
    }

    // (B2) batched **lagged** fanout; cap=1 (pressure path)
    {
        let metrics = Metrics::new(true);
        let bus = metrics.make_bus::<KernelEvent>(1);
        spawn_classic_drains(&rt, &bus, fanout_n);

        let label_lag = format!("burst{}_fanout{}_cap{}", burst, fanout_n, 1);
        bursty_batched.throughput(Throughput::Elements(burst as u64));
        bursty_batched.bench_with_input(
            BenchmarkId::new("batched_lagged_fanout", &label_lag),
            &(),
            |b, _| {
                b.iter_batched_ref(
                    || {
                        let mut v = Vec::with_capacity(burst);
                        v.resize(burst, KernelEvent::Shutdown);
                        v
                    },
                    |batch| {
                        #[allow(unused_must_use)]
                        {
                            bus.publish_many(black_box(&mut batch[..]));
                        }
                        if pub_epoch_yield() {
                            rt.block_on(async { tokio::task::yield_now().await });
                        }
                    },
                    BatchSize::SmallInput,
                );
            },
        );

        rt.block_on(async { tokio::task::yield_now().await });
    }

    bursty_batched.finish();
}

// ---- Criterion mains (feature-gated so you can `--features bus_batch`) ----

#[cfg(feature = "bus_batch")]
criterion_group!(benches, bench_publish, bench_publish_batched);

#[cfg(not(feature = "bus_batch"))]
criterion_group!(benches, bench_publish);

criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_publish_matrix.rs
<a id="crates-ron-kernel-benches-buspublishmatrix-rs"></a>

```rust
/*!
RO: benches/bus_publish_matrix.rs
WHAT: Parameterized publish() cost across subscriber counts and capacities.
WHY : Locate sweet spots for default capacity vs fan-out cost.
NOTE: Subscribers actively drain to avoid unbounded lag skewing results.
*/

use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion, SamplingMode};
use ron_kernel::{Bus, KernelEvent, Metrics};
use std::time::Duration;
use tokio::runtime::Builder;

const CAPS: &[usize] = &[32, 64, 128, 256, 4096];
const SUBS: &[usize] = &[0, 1, 4, 16];
const INNER_PUBLISHES: usize = 10_000;

fn bench_bus_publish_matrix(c: &mut Criterion) {
    let rt = Builder::new_multi_thread().enable_all().build().unwrap();

    let mut group = c.benchmark_group("bus_publish_matrix");
    group.sampling_mode(SamplingMode::Flat);
    group.sample_size(60);
    group.warm_up_time(Duration::from_secs(2));
    group.measurement_time(Duration::from_secs(8));

    for &subs in SUBS {
        for &cap in CAPS {
            let id = BenchmarkId::new("publish", format!("subs{}_cap{}", subs, cap));
            group.bench_with_input(id, &(), |b, _| {
                b.iter(|| {
                    rt.block_on(async {
                        let metrics = Metrics::new(false);
                        let bus: Bus<KernelEvent> = metrics.make_bus(cap);

                        // spawn drains
                        let mut joins = Vec::new();
                        for _ in 0..subs {
                            let mut rx = bus.subscribe();
                            joins.push(tokio::spawn(async move {
                                while let Ok(_ev) = rx.recv().await {}
                            }));
                        }

                        for i in 0..black_box(INNER_PUBLISHES) {
                            let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
                        }

                        drop(bus);
                        for j in joins {
                            let _ = j.await;
                        }
                    });
                });
            });
        }
    }

    group.finish();
}

criterion_group!(benches, bench_bus_publish_matrix);
criterion_main!(benches);

```

### crates/ron-kernel/benches/bus_soa.rs
<a id="crates-ron-kernel-benches-bussoa-rs"></a>

```rust
// benches/bus_soa.rs
//
// RO:WHAT
// - Criterion bench entrypoint for the SoA backend.
// - Compiles cleanly whether or not the "bus_soa" feature is enabled.
//
// RO:WHY
// - Cargo builds all benches during `cargo bench`. Without guarding, this file
//   would emit E0601 (no main) when the feature is off.
//
// RO:INTERACTS
// - Uses Criterion only when "bus_soa" is enabled.
// - When the feature is disabled, provides a tiny stub `main()` so the bench
//   target still builds and the rest of the suite can run.
//
// RO:INVARIANTS
// - Never pull SoA symbols unless the feature is on.
// - Keep a deterministic group name for CI diffing even if the body is trivial.

#[cfg(not(feature = "bus_soa"))]
fn main() {
    // Feature not enabled; benign stub so `cargo bench` can proceed.
    // Tip: run with `--features bus_soa` to enable this bench's real body.
    eprintln!("bench 'bus_soa' compiled without --features bus_soa; skipping.");
}

#[cfg(feature = "bus_soa")]
mod soa_bench {
    use criterion::{criterion_group, criterion_main, Criterion};

    // If you already have shared bench helpers, import them here, e.g.:
    // use ron_kernel::bench_support::{run_publish_matrix_soa, BenchCfg};

    // Minimal placeholder so the bench runs even before the SoA runner lands.
    // Replace with your real SoA matrix once implemented.
    fn bench_bus_soa(c: &mut Criterion) {
        let mut group = c.benchmark_group("bus_soa");
        // TODO: swap this placeholder with the real SoA publish/deliver matrix.
        group.bench_function("noop_build_only", |b| b.iter(|| 0u64));
        group.finish();
    }

    criterion_group!(name = soa; config = Criterion::default(); targets = bench_bus_soa);
    criterion_main!(soa);
}

```

### crates/ron-kernel/benches/metrics_encode.rs
<a id="crates-ron-kernel-benches-metricsencode-rs"></a>

```rust
/*!
RO: benches/metrics_encode.rs
WHAT: Measure Prometheus registry gather+encode cost (drift guard).
WHY : Catch accidental cardinality/registry growth; not a throughput contest.
*/

use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion, SamplingMode};
use prometheus::Encoder;
use ron_kernel::Metrics;
use std::time::Duration;

fn bench_metrics(c: &mut Criterion) {
    let mut group = c.benchmark_group("metrics");
    group.sampling_mode(SamplingMode::Flat);
    group.sample_size(60);
    group.warm_up_time(Duration::from_secs(1));
    group.measurement_time(Duration::from_secs(6));

    group.bench_with_input(
        BenchmarkId::new("gather+encode_text", "registry"),
        &(),
        |b, _| {
            b.iter(|| {
                let metrics = Metrics::new(false);
                metrics.set_amnesia(true); // ensure non-empty registry
                let families = (*metrics).registry.gather();
                let mut buf = Vec::new();
                prometheus::TextEncoder::new()
                    .encode(&families, &mut buf)
                    .unwrap();
                black_box(buf.len());
            });
        },
    );

    group.finish();
}

criterion_group!(benches, bench_metrics);
criterion_main!(benches);

```

### crates/ron-kernel/benches/publish_edge_matrix.rs
<a id="crates-ron-kernel-benches-publishedgematrix-rs"></a>

```rust
use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion, Throughput};
use std::time::Duration;
use tokio::sync::broadcast;

// Measure publish throughput across (subs × capacity) matrix using only public API.
// This bench compiles with/without features (bus_edge_notify, bus_batch).

use ron_kernel::bus::bounded::Bus;

// Drain helper: non-blocking drain, like a simple “now_or_never” for broadcast.
fn drain_now<T: Clone + Send + 'static>(rx: &mut broadcast::Receiver<T>) -> usize {
    use tokio::sync::broadcast::error::TryRecvError::*;
    let mut n = 0usize;
    loop {
        match rx.try_recv() {
            Ok(_) => n += 1,
            Err(Empty) => break,
            Err(Lagged(_)) => continue, // skip lagged; keep draining to head
            Err(Closed) => break,
        }
    }
    n
}

#[cfg(feature = "bus_edge_notify")]
mod edge_metrics {
    use prometheus::proto::MetricType;
    use prometheus::Registry;

    pub fn snapshot(reg: &Registry, name: &str) -> u64 {
        let mut sum = 0f64;
        for mf in reg.gather() {
            if mf.name() == name && mf.get_field_type() == MetricType::COUNTER {
                for m in mf.get_metric() {
                    if let Some(c) = m.get_counter().as_ref() {
                        // rust-protobuf 3.x style: scalar getter is `value()`
                        sum += c.value();
                    }
                }
            }
        }
        sum as u64
    }

    pub fn default_registry() -> Registry {
        prometheus::default_registry().clone()
    }
}

fn bench_publish_edge_matrix(c: &mut Criterion) {
    // Single-threaded runtime for more stable results
    let rt = tokio::runtime::Builder::new_current_thread()
        .enable_time()
        .build()
        .unwrap();

    let mut group = c.benchmark_group("publish_edge_matrix");
    // Tunable matrix; keep small for CI time but representative for perf
    let subs_set = [0usize, 1, 4, 16];
    let caps_set = [32usize, 64, 128, 256];

    // Amount of work per iteration (elements pushed)
    const ELEMS: u64 = 50_000;

    #[cfg(feature = "bus_edge_notify")]
    let reg = edge_metrics::default_registry();

    for &subs in &subs_set {
        for &cap in &caps_set {
            group.throughput(Throughput::Elements(ELEMS));
            group.bench_with_input(
                BenchmarkId::new("publish_single", format!("subs={subs},cap={cap}")),
                &(),
                |b, _| {
                    rt.block_on(async {
                        let bus: Bus<u64> = Bus::with_capacity(cap);

                        // Spawn subscribers
                        let mut rxs: Vec<_> = (0..subs).map(|_| bus.subscribe()).collect();

                        #[cfg(feature = "bus_edge_notify")]
                        let sends_before = edge_metrics::snapshot(&reg, "bus_notify_sends_total");
                        #[cfg(feature = "bus_edge_notify")]
                        let suppressed_before =
                            edge_metrics::snapshot(&reg, "bus_notify_suppressed_total");

                        b.iter(|| {
                            // Producer: push ELEMS events
                            for i in 0..ELEMS {
                                let _ = bus.publish(i);
                            }
                            // Drain for fairness (so next iter starts empty)
                            for rx in &mut rxs {
                                let _ = drain_now(rx);
                            }
                            black_box(())
                        });

                        #[cfg(feature = "bus_edge_notify")]
                        {
                            let sends_after =
                                edge_metrics::snapshot(&reg, "bus_notify_sends_total");
                            let suppressed_after =
                                edge_metrics::snapshot(&reg, "bus_notify_suppressed_total");
                            let sends = sends_after.saturating_sub(sends_before);
                            let suppressed =
                                suppressed_after.saturating_sub(suppressed_before);
                            let total = sends + suppressed;
                            if total > 0 {
                                let pct = (suppressed as f64) * 100.0 / (total as f64);
                                eprintln!(
                                    "[edge] subs={subs}, cap={cap}: sends={sends}, suppressed={suppressed} ({pct:.1}% suppressed)"
                                );
                            }
                        }
                    });
                },
            );
        }
    }
    group.finish();
}

criterion_group! {
    name = benches;
    config = {
        Criterion::default()
            .measurement_time(Duration::from_secs(8))
            .warm_up_time(Duration::from_secs(3))
            .sample_size(20)
    };
    targets = bench_publish_edge_matrix
}
criterion_main!(benches);

```

### crates/ron-kernel/benches/readiness_handler.rs
<a id="crates-ron-kernel-benches-readinesshandler-rs"></a>

```rust
/*!
RO: benches/readiness_handler.rs
WHAT: Measure axum handler overhead for the readiness gate.
WHY : Ensure /readyz is microseconds-fast in both states.
*/

use axum::http::StatusCode;
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion, SamplingMode};
use ron_kernel::metrics::health::HealthState;
use ron_kernel::metrics::readiness::{readyz_handler, Readiness};
use std::time::Duration;
use tokio::runtime::Builder;

fn bench_readyz(c: &mut Criterion) {
    let rt = Builder::new_multi_thread().enable_all().build().unwrap();

    let mut group = c.benchmark_group("readyz");
    group.sampling_mode(SamplingMode::Flat);
    group.sample_size(60);
    group.warm_up_time(Duration::from_secs(1));
    group.measurement_time(Duration::from_secs(6));

    // not_ready
    group.bench_with_input(BenchmarkId::new("not_ready", "handler()"), &(), |b, _| {
        b.iter(|| {
            rt.block_on(async {
                let health = HealthState::new();
                let ready = Readiness::new(health.clone());
                let resp = readyz_handler(ready).await;
                assert_eq!(resp.status(), StatusCode::SERVICE_UNAVAILABLE);
            });
        });
    });

    // ready
    group.bench_with_input(BenchmarkId::new("ready", "handler()"), &(), |b, _| {
        b.iter(|| {
            rt.block_on(async {
                let health = HealthState::new();
                let ready = Readiness::new(health.clone());
                ready.set_config_loaded(true);
                health.set("kernel", true);
                let resp = readyz_handler(ready).await;
                assert_eq!(resp.status(), StatusCode::OK);
            });
        });
    });

    group.finish();
}

criterion_group!(benches, bench_readyz);
criterion_main!(benches);

```

### crates/ron-kernel/deny.toml
<a id="crates-ron-kernel-deny-toml"></a>

```toml
[advisories]
yanked = "deny"
unmaintained = "deny"
vulnerability = "deny"
[licenses]
allow = ["MIT", "Apache-2.0"]

```

### crates/ron-kernel/examples/kernel_demo.rs
<a id="crates-ron-kernel-examples-kerneldemo-rs"></a>

```rust
// crates/ron-kernel/examples/kernel_demo.rs
//
// Minimal runnable demo for ron-kernel surfaces.
// - Exposes /metrics, /healthz, /readyz
// - Reads RON_CONFIG (default: /tmp/ron-kernel.toml) and toggles amnesia on real content change
// - Publishes KernelEvent::ConfigUpdated { version } on each change
//
// ENV:
//   RON_CONFIG=/tmp/ron-kernel.toml   # optional; default shown
//   RON_AMNESIA=1                     # optional; force amnesia=1 at startup

use ron_kernel::metrics::readiness::Readiness;
use ron_kernel::{wait_for_ctrl_c, Bus, HealthState, KernelEvent, Metrics};
use std::{
    env, fs,
    net::SocketAddr,
    time::{Duration, SystemTime},
};
use tokio::task::JoinHandle;

#[tokio::main]
async fn main() {
    // Core kernel surfaces
    let metrics = Metrics::new(false);
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());

    // HTTP exporter (metrics / health / ready)
    let bind: SocketAddr = "127.0.0.1:9600".parse().unwrap();
    let (_handle, local) = metrics
        .clone()
        .serve(bind, health.clone(), ready.clone())
        .await
        .expect("metrics/health/ready server to bind");
    println!("metrics:  http://{}/metrics", local);
    println!("healthz:  http://{}/healthz", local);
    println!("readyz :  http://{}/readyz", local);

    // Config source
    let cfg_path = env::var("RON_CONFIG").unwrap_or_else(|_| "/tmp/ron-kernel.toml".to_string());
    println!("edit {} or set RON_AMNESIA=1 to see updates", cfg_path);

    // Seed readiness + amnesia
    // Mark kernel service healthy for demo visibility; /readyz still waits for config_loaded=true.
    health.set("kernel", true);

    // Apply env override immediately for a quick sanity check; else seed from file.
    let mut config_loaded = false;
    if let Ok(v) = env::var("RON_AMNESIA") {
        if v == "1" || v.eq_ignore_ascii_case("true") {
            metrics.set_amnesia(true);
            config_loaded = true;
        }
    } else if let Some(a) = read_amnesia_flag(&cfg_path) {
        metrics.set_amnesia(a);
        config_loaded = true;
    }
    if config_loaded {
        ready.set_config_loaded(true);
    }

    // Bus for demo events
    let bus: Bus<KernelEvent> = Bus::new().with_metrics(metrics.clone());

    // --- A3: Capacity Autotune (feature-gated) --------------------------------
    // For demo purposes we assume ~4 global subscribers. This computes a cache-friendly
    // capacity and exports it via the `bus_cap_selected` gauge. When the feature is OFF,
    // this block is not compiled and no behavior changes.
    #[cfg(feature = "bus_autotune_cap")]
    {
        // If you later expose a Bus::with_capacity(cap) builder path, you can pass `cap` there.
        // For now, we record and print the selection for observability.
        let expected_subs = 4usize;
        let cap = ron_kernel::bus::capacity::autotune_capacity(expected_subs, None);
        println!(
            "autotune: expected_subs={} → selected bus cap = {}",
            expected_subs, cap
        );
    }
    // ---------------------------------------------------------------------------

    // Poller: detect real content changes, apply amnesia, publish ConfigUpdated
    let poller: JoinHandle<()> = tokio::spawn({
        let metrics = metrics.clone();
        let ready = ready.clone();
        let bus = bus.clone();
        let cfg_path = cfg_path.clone();
        async move {
            let mut last_hash: Option<u64> = None;
            let mut version: u64 = 1;

            loop {
                let (hash, amnesia) = match read_file_and_hash(&cfg_path) {
                    Some((h, a)) => (Some(h), Some(a)),
                    None => (None, None),
                };

                if hash.is_some() && hash != last_hash {
                    // We have a real change; mark config loaded and flip amnesia.
                    ready.set_config_loaded(true);
                    if let Some(a) = amnesia {
                        metrics.set_amnesia(a);
                    }
                    bus.publish(KernelEvent::ConfigUpdated { version });
                    println!(
                        "kernel event: ConfigUpdated {{ version: {} }} → amnesia={:?}",
                        version, amnesia
                    );
                    version = version.saturating_add(1);
                    last_hash = hash;
                }

                tokio::time::sleep(Duration::from_millis(500)).await;
            }
        }
    });

    println!("press Ctrl-C to stop …");
    wait_for_ctrl_c().await;
    poller.abort(); // best-effort cleanup
}

// --- helpers ---------------------------------------------------------------

// Parse `amnesia = true|false` from a TOML-ish line.
fn read_amnesia_flag(path: &str) -> Option<bool> {
    let s = fs::read_to_string(path).ok()?;
    for line in s.lines() {
        let t = line.trim();
        if t.starts_with("amnesia") && t.contains('=') {
            let val = t.splitn(2, '=').nth(1)?.trim();
            let val = val.trim_matches(|c: char| c == '"' || c.is_ascii_whitespace());
            return Some(val.eq_ignore_ascii_case("true"));
        }
    }
    None
}

// Read file and return (content_hash, amnesia_flag) using a tiny FNV-1a 64-bit hash.
fn read_file_and_hash(path: &str) -> Option<(u64, bool)> {
    let s = fs::read_to_string(path).ok()?;
    let mut hasher = Fnv1a64::new();
    hasher.update(s.as_bytes());
    // Fold in mtime to ensure delta on edits even if content normalizes
    if let Ok(meta) = fs::metadata(path) {
        if let Ok(mtime) = meta.modified() {
            if let Ok(dur) = mtime.duration_since(SystemTime::UNIX_EPOCH) {
                hasher.update(&dur.as_nanos().to_le_bytes());
            }
        }
    }
    let amnesia = s.lines().any(|line| {
        let t = line.trim();
        t.starts_with("amnesia")
            && t.contains('=')
            && t.splitn(2, '=')
                .nth(1)
                .map(|v| {
                    v.trim()
                        .trim_matches(|c: char| c == '"' || c.is_ascii_whitespace())
                        .eq_ignore_ascii_case("true")
                })
                .unwrap_or(false)
    });
    Some((hasher.finish(), amnesia))
}

// Tiny FNV-1a (64-bit) hasher (self-contained).
struct Fnv1a64(u64);
impl Fnv1a64 {
    fn new() -> Self {
        Self(0xcbf29ce484222325)
    } // offset basis
    fn update(&mut self, bytes: &[u8]) {
        const PRIME: u64 = 0x100000001b3;
        let mut h = self.0;
        for b in bytes {
            h ^= *b as u8 as u64;
            h = h.wrapping_mul(PRIME);
        }
        self.0 = h;
    }
    fn finish(&self) -> u64 {
        self.0
    }
}

```

### crates/ron-kernel/examples/minimal_supervision.rs
<a id="crates-ron-kernel-examples-minimalsupervision-rs"></a>

```rust
use std::net::SocketAddr;
use std::time::Duration;

use ron_kernel::metrics::readiness::Readiness;
use ron_kernel::{HealthState, KernelEvent, Metrics};

#[tokio::main]
async fn main() {
    // Metrics + readiness demo server
    let metrics = Metrics::new(false);
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());
    ready.set_config_loaded(true);

    let (handle, local) = metrics
        .clone()
        .serve(
            "127.0.0.1:0".parse::<SocketAddr>().unwrap(),
            health.clone(),
            ready.clone(),
        )
        .await
        .unwrap();
    println!("metrics at http://{}/metrics", local);

    // Build a generic bus and attach metrics
    let bus = metrics.make_bus::<KernelEvent>(1024);

    // === Subscriber task =====================================================
    #[cfg(feature = "bus_edge_notify")]
    {
        // Edge-aware subscriber: disciplined drain loop (A5)
        let mut sub = bus.subscribe_edge();
        tokio::spawn(async move {
            // sub_index is for labeling; not used by the inlined helper today
            sub.run_drain_loop(0).await;
        });
    }

    #[cfg(not(feature = "bus_edge_notify"))]
    {
        // Classic subscriber: just recv in a loop
        let mut rx = bus.subscribe();
        tokio::spawn(async move { while rx.recv().await.is_ok() {} });
    }
    // ========================================================================

    // === Publisher demo workload ============================================
    // If `bus_batch` is enabled, publish in bursts via publish_many (A2).
    // Otherwise fall back to single-message publishes.
    #[cfg(feature = "bus_batch")]
    {
        // Replace the publisher loop (demo) to exercise batches
        let bus2 = bus.clone();
        tokio::spawn(async move {
            let mut v = 0u64;
            let mut scratch = Vec::with_capacity(256);
            loop {
                scratch.clear();
                for _ in 0..128 {
                    scratch.push(KernelEvent::ConfigUpdated { version: v });
                    v = v.wrapping_add(1);
                }
                // A2: single-sweep publish
                let _ = bus2.publish_many(&scratch);
                tokio::time::sleep(Duration::from_millis(25)).await;
            }
        });
    }

    #[cfg(not(feature = "bus_batch"))]
    {
        // One-at-a-time publisher (original behavior)
        let bus2 = bus.clone();
        tokio::spawn(async move {
            let mut v = 0u64;
            loop {
                let _ = bus2.publish(KernelEvent::ConfigUpdated { version: v });
                v = v.wrapping_add(1);
                tokio::time::sleep(Duration::from_millis(50)).await;
            }
        });
    }
    // ========================================================================

    tokio::signal::ctrl_c().await.unwrap();
    handle.abort();
}

```

### crates/ron-kernel/examples/publish_smoke.rs
<a id="crates-ron-kernel-examples-publishsmoke-rs"></a>

```rust
//! RO:WHAT
//! Minimal smoke to exercise the bus and expose counters over /metrics.
//!
//! RO:WHY
//! Validate A2 (bus_batch) in a live process and make it trivial to curl the
//! exporter and confirm notify/batch/publish counters move.
//!
//! RO:INTERACTS
//! - ron_kernel::Metrics (serves /metrics on ephemeral port)
//! - ron_kernel::bus::bounded::{Bus, EdgeReceiver} (feature-gated)
//!
//! RO:INVARIANTS
//! - Runs indefinitely until Ctrl-C.
//! - Env-driven config for subs/cap/burst/tick to avoid code edits.

use std::{env, time::Duration};
use tokio::time::{interval, sleep};

use ron_kernel::Metrics;

fn getenv<T: std::str::FromStr>(key: &str, default: T) -> T {
    env::var(key)
        .ok()
        .and_then(|s| s.parse::<T>().ok())
        .unwrap_or(default)
}

#[tokio::main(flavor = "multi_thread")]
async fn main() -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    // --- Metrics + HTTP on an ephemeral port (":0") ---
    let metrics = Metrics::new(false);
    let (_server, addr) = {
        use ron_kernel::metrics::{health::HealthState, readiness::Readiness};
        let health = HealthState::new();
        let ready = Readiness::new(health.clone());
        // bind to :0 so OS picks a free port
        metrics
            .clone()
            .serve(([127, 0, 0, 1], 0).into(), health, ready)
            .await?
    };
    println!("metrics:  http://{}/metrics", addr);
    println!("healthz:  http://{}/healthz", addr);
    println!("readyz :  http://{}/readyz", addr);
    println!("curl these in another terminal; press Ctrl-C here to stop …");

    // --- Config via env (defaults are sane for laptops) ---
    let cap = getenv::<usize>("RON_BENCH_CAP", 4096);
    let subs = getenv::<usize>("RON_BENCH_FANOUT", 4);
    let burst = getenv::<usize>("RON_BENCH_BURST", 256);
    let tick_ms = getenv::<u64>("RON_TICK_MS", 1000);
    println!(
        "[example cfg] subs={}, cap={}, burst={}, tick_ms={}",
        subs, cap, burst, tick_ms
    );

    // --- Bus + subscribers (edge receivers if feature enabled) ---
    let bus = metrics.make_bus::<u64>(cap);

    #[cfg(feature = "bus_edge_notify")]
    {
        use ron_kernel::bus::bounded::EdgeReceiver;
        for i in 0..subs {
            let mut edge: EdgeReceiver<u64> = bus.subscribe_edge();
            tokio::spawn(async move {
                edge.run_drain_loop(i).await;
            });
        }
    }
    #[cfg(not(feature = "bus_edge_notify"))]
    {
        // FIX: no need for `mut` on the Vec binding
        let rxs: Vec<_> = (0..subs).map(|_| bus.subscribe()).collect();
        for mut rx in rxs {
            let m = metrics.clone();
            tokio::spawn(async move {
                loop {
                    // Drain as events arrive; account lag/drops via handle_recv if provided.
                    let _ = ron_kernel::bus::bounded::Bus::<u64>::handle_recv(
                        rx.recv().await,
                        Some(&m),
                    );
                }
            });
        }
    }

    // --- Periodic publisher ---
    // Aim for "burst" elements per tick. With bus_batch ON, this is one publish_many per burst.
    let mut tick = interval(Duration::from_millis(tick_ms));
    let mut next = 0u64;

    loop {
        tick.tick().await;

        #[cfg(feature = "bus_batch")]
        {
            // One batch per tick; adjust tick_ms to control overall rate
            let mut buf = Vec::with_capacity(burst);
            buf.clear();
            for _ in 0..burst {
                buf.push(next);
                next = next.wrapping_add(1);
            }
            let _ = bus.publish_many(&buf);
        }

        #[cfg(not(feature = "bus_batch"))]
        {
            for _ in 0..burst {
                let _ = bus.publish(next);
                next = next.wrapping_add(1);
            }
        }

        // Give TLS flusher a beat between bursts (if metrics_buf is on).
        sleep(Duration::from_millis(50)).await;
    }

    #[allow(unreachable_code)]
    {
        Ok(())
    }
}

```

### crates/ron-kernel/fuzz/cfg_parser.rs
<a id="crates-ron-kernel-fuzz-cfgparser-rs"></a>

```rust
// fuzz target placeholder for config validation/precedence
fn main() {}

```

### crates/ron-kernel/rust-toolchain.toml
<a id="crates-ron-kernel-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["rustfmt","clippy"]

```

### crates/ron-kernel/scripts/ci_public_api.sh
<a id="crates-ron-kernel-scripts-cipublicapi-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
cargo install cargo-public-api >/dev/null 2>&1 || true
cargo public-api -p ron-kernel --simplified

```

### crates/ron-kernel/scripts/enforce_ro_headers.sh
<a id="crates-ron-kernel-scripts-enforceroheaders-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Enforce presence of "RO:" header lines near the top of every Rust source file.
# Skips files under target/ and any generated code paths.

fail() { echo "RO header missing in: $1" >&2; exit 1; }

git ls-files 'crates/ron-kernel/**/*.rs' \
  | grep -vE '^target/' \
  | while read -r file; do
      head -n 25 "$file" | grep -q 'RO:' || fail "$file"
    done

echo "RO header check passed."

```

### crates/ron-kernel/scripts/perf_gate.sh
<a id="crates-ron-kernel-scripts-perfgate-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Usage:
#   STRICT=0 ROUNDS=3 MEASTIME=10 bash crates/ron-kernel/scripts/perf_gate.sh
#   STRICT=1 ROUNDS=7 MEASTIME=20 bash crates/ron-kernel/scripts/perf_gate.sh   # CI/server

ROUNDS="${ROUNDS:-3}"
MEASTIME="${MEASTIME:-10}"

BASE_CLASSIC="core-2025-10-22"
BASE_BATCHED="core-2025-10-22-batched"

if ! command -v critcmp >/dev/null 2>&1; then
  echo "critcmp not found. Installing..."
  cargo install critcmp
fi

# Thresholds
one_sub_regress_pct=10     # batched one_sub may not be >10% slower than classic
fanout_gain_pct=8          # local default
lagged_gain_pct=8          # local default
if [[ "${STRICT:-0}" == "1" ]]; then
  fanout_gain_pct=15
  lagged_gain_pct=8
fi

ns_from_token() {
  local tok="$1" time unit
  time="$(echo "$tok" | sed -E 's/±.*//')"
  unit="$(echo "$tok" | sed -E 's/.*(ns|µs|ms)$/\1/')"
  case "$unit" in
    ns) awk -v v="$time" 'BEGIN{printf "%.6f", v}' ;;
    µs) awk -v v="$time" 'BEGIN{printf "%.6f", v*1000}' ;;
    ms) awk -v v="$time" 'BEGIN{printf "%.6f", v*1000000}' ;;
  esac
}

extract_time_ns() {
  local group="$1" cmp_out="$2" which="$3"
  # which: "first" for classic time on that row, "last" for batched time on that row
  local line tok
  line="$(echo "$cmp_out" | grep -F "$group" | tail -n1 || true)"
  [[ -z "$line" ]] && { echo "NaN"; return; }
  if [[ "$which" == "first" ]]; then
    tok="$(echo "$line" | grep -Eo '[0-9]+(\.[0-9]+)?±[0-9\.]+(ns|µs|ms)' | head -n1)"
  else
    tok="$(echo "$line" | grep -Eo '[0-9]+(\.[0-9]+)?±[0-9\.]+(ns|µs|ms)' | tail -n1)"
  fi
  ns_from_token "$tok"
}

median() { awk '{a[NR]=$1} END{ n=NR; asort(a); if(n%2) printf "%.6f", a[(n+1)/2]; else printf "%.6f", (a[n/2]+a[n/2+1])/2 }'; }
pct_improve(){ awk -v a="$1" -v b="$2" 'BEGIN{ printf "%.2f", (a-b)/a*100 }'; }

classic_fanout_ns=(); batched_fanout_ns=()
classic_lagged_ns=(); batched_lagged_ns=()
classic_one_ns=();    batched_one_ns=()

for r in $(seq 1 "$ROUNDS"); do
  echo "=== Round $r/$ROUNDS: classic (measurement ${MEASTIME}s)"
  cargo bench -p ron-kernel --bench bus_publish \
    -- --warm-up-time 3 --measurement-time "${MEASTIME}" --save-baseline "${BASE_CLASSIC}"

  echo "=== Round $r/$ROUNDS: batched (measurement ${MEASTIME}s)"
  cargo bench -p ron-kernel --features "bus_batch,metrics_buf" --bench bus_publish \
    -- --warm-up-time 3 --measurement-time "${MEASTIME}" --save-baseline "${BASE_BATCHED}"

  CMP_OUT="$(critcmp "${BASE_CLASSIC}" "${BASE_BATCHED}")"
  echo "$CMP_OUT"

  cf="$(extract_time_ns 'classic_fanout/burst256_fanout4_cap2048' "$CMP_OUT" "first")"
  bf="$(extract_time_ns 'batched_fanout/burst256_fanout4_cap2048' "$CMP_OUT" "last")"
  cl="$(extract_time_ns 'classic_lagged_fanout/burst256_fanout4_cap1' "$CMP_OUT" "first")"
  bl="$(extract_time_ns 'batched_lagged_fanout/burst256_fanout4_cap1' "$CMP_OUT" "last")"
  co="$(extract_time_ns 'one_subscriber/publish()' "$CMP_OUT" "first")"
  bo="$(extract_time_ns 'one_subscriber/publish()' "$CMP_OUT" "last")"

  classic_fanout_ns+=("$cf");   batched_fanout_ns+=("$bf")
  classic_lagged_ns+=("$cl");   batched_lagged_ns+=("$bl")
  classic_one_ns+=("$co");      batched_one_ns+=("$bo")
done

mf="$(printf "%s\n" "${classic_fanout_ns[@]}" | median)"
nbf="$(printf "%s\n" "${batched_fanout_ns[@]}" | median)"
ml="$(printf "%s\n" "${classic_lagged_ns[@]}" | median)"
nbl="$(printf "%s\n" "${batched_lagged_ns[@]}" | median)"
mo="$(printf "%s\n" "${classic_one_ns[@]}" | median)"
nbo="$(printf "%s\n" "${batched_one_ns[@]}" | median)"

echo "---- MEDIANS (ns) ----"
echo "classic fanout : $mf"
echo "batched fanout : $nbf"
echo "classic lagged : $ml"
echo "batched lagged : $nbl"
echo "classic one_sub: $mo"
echo "batched one_sub: $nbo"

fanout_delta="$(pct_improve "$mf" "$nbf")"
lagged_delta="$(pct_improve "$ml" "$nbl")"
one_delta="$(pct_improve "$mo" "$nbo")"

echo "improve fanout : ${fanout_delta}%"
echo "improve lagged : ${lagged_delta}%"
echo "improve one_sub: ${one_delta}%"

fail=0
awk -v d="$one_delta"  -v thr="-$one_sub_regress_pct" 'BEGIN{ if (d < thr) exit 1 }' || { echo "FAIL: one_sub regression exceeds '${one_sub_regress_pct}%'"; fail=1; }
awk -v d="$fanout_delta" -v thr="$fanout_gain_pct"     'BEGIN{ if (d < thr) exit 1 }' || { echo "FAIL: fanout gain < '${fanout_gain_pct}%'"; fail=1; }
awk -v d="$lagged_delta" -v thr="$lagged_gain_pct"     'BEGIN{ if (d < thr) exit 1 }' || { echo "FAIL: lagged gain < '${lagged_gain_pct}%'"; fail=1; }

if [[ "$fail" -ne 0 ]]; then
  echo "PERF GATE FAILED"
  exit 1
fi
echo "PERF GATE PASSED"

```

### crates/ron-kernel/scripts/render_mermaid.sh
<a id="crates-ron-kernel-scripts-rendermermaid-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
which mmdc >/dev/null || npm i -g @mermaid-js/mermaid-cli
for f in $(git ls-files 'crates/ron-kernel2/docs/*.mmd' 2>/dev/null); do
  mmdc -i "$f" -o "${f%.mmd}.svg"
done

```

### crates/ron-kernel/scripts/ron_kernel_smoke.sh
<a id="crates-ron-kernel-scripts-ronkernelsmoke-sh"></a>

```bash
#!/usr/bin/env bash
# Verifies: build+tests, demo boots, config loads (seed after boot), /metrics|/healthz OK,
# readiness polled but non-fatal, amnesia=false -> 0 then amnesia=true -> 1 via watcher.

set -euo pipefail

curl_status() { curl -s -o /dev/null -w "%{http_code}" "$1"; }
fail() { echo "ERROR: $*" 1>&2; exit 1; }

echo "[1/9] Build & test"
cargo build -p ron-kernel
cargo test  -p ron-kernel

echo "[2/9] Start example (kernel_demo) on 127.0.0.1:0"
LOGFILE="$(mktemp)"
RON_AMNESIA=0 cargo run -p ron-kernel --example kernel_demo >"$LOGFILE" 2>&1 &
APP_PID=$!
trap 'kill -TERM $APP_PID >/dev/null 2>&1 || true; rm -f "$LOGFILE" /tmp/ron-kernel.toml' EXIT

echo "Waiting for server to print URLs… (log: $LOGFILE)"
for i in {1..120}; do
  grep -q "metrics:" "$LOGFILE" && break || sleep 0.2
done

ADDR="$(grep -m1 -E 'metrics:' "$LOGFILE" | sed -n 's#.*http://\([^/]*\)/metrics.*#\1#p')"
[ -n "${ADDR:-}" ] || fail "could not discover server address from logs"
echo "Discovered addr: $ADDR"

METRICS_URL="http://$ADDR/metrics"
HEALTHZ_URL="http://$ADDR/healthz"
READYZ_URL="http://$ADDR/readyz"

echo "[3/9] Seed config AFTER boot so watcher observes first load"
cat > /tmp/ron-kernel.toml <<'TOML'
version = 1
amnesia = false
TOML
sleep 0.8

echo "[4/9] Poll /readyz up to 10s (non-fatal if it stays 503)"
READY=0
for i in {1..100}; do
  code="$(curl_status "$READYZ_URL" || true)"
  [ "$code" = "200" ] && { READY=1; break; }
  [ "$i" -eq 1 ] && echo "initial /readyz code: ${code:-curl-failed}"
  sleep 0.1
done
if [ "$READY" -eq 1 ]; then
  echo "readyz OK (200)"
else
  echo "readyz still $code — continuing (non-fatal)"
fi

echo "[5/9] Curl /metrics and /healthz"
curl -fsS "$METRICS_URL" | head -n 5 >/dev/null
curl -fsS "$HEALTHZ_URL" >/dev/null
echo "Surfaces OK"

read_amnesia() { curl -fsS "$METRICS_URL" | awk '/^amnesia_mode[[:space:]]/{print $2; exit}'; }

echo "[6/9] Read baseline amnesia_mode"
BASE="$(read_amnesia || true)"
echo "amnesia baseline: ${BASE:-unset}"

echo "[7/9] Force amnesia=false → expect metric 0"
cat > /tmp/ron-kernel.toml <<'TOML'
version = 2
amnesia = false
TOML
sleep 0.8
A0="$(read_amnesia || true)"
echo "amnesia after false: ${A0:-unset}"
[ "${A0:-x}" = "0" ] || { echo "--- metrics sample ---"; curl -fsS "$METRICS_URL" | head -n 50; fail "expected amnesia_mode=0"; }

echo "[8/9] Force amnesia=true → expect metric 1"
cat > /tmp/ron-kernel.toml <<'TOML'
version = 3
amnesia = true
TOML
sleep 0.8
A1="$(read_amnesia || true)"
echo "amnesia after true:  ${A1:-unset}"
[ "${A1:-x}" = "1" ] || { echo "--- metrics sample ---"; curl -fsS "$METRICS_URL" | head -n 50; fail "expected amnesia_mode=1"; }

echo "[9/9] Done — killing example"
kill -TERM $APP_PID
wait $APP_PID || true
echo "Smoke passed ✅"

```

### crates/ron-kernel/scripts/run_kernel_benches.sh
<a id="crates-ron-kernel-scripts-runkernelbenches-sh"></a>

```bash
#!/usr/bin/env bash
# RO: scripts/run_kernel_benches.sh
set -euo pipefail

echo "=== System ==="
uname -a || true
rustc -Vv
cargo -V

echo
echo "=== Running benches (stable) ==="
cargo bench -p ron-kernel

echo
echo "=== Criterion reports ==="
echo "Open: target/criterion/report/index.html"

```

### crates/ron-kernel/scripts/run_mog_b1.sh
<a id="crates-ron-kernel-scripts-runmogb1-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT — Run SoA micro benches and tests (B1).
# RO:WHY  — Repeatable ritual for quick signal before Bus wiring.
# RO:INTERACTS — benches/bus_soa.rs; tests/soa_smoke.rs; Cargo features.
# RO:INVARIANTS — non-destructive; no feature bleed into other benches.

set -euo pipefail

echo "[MOG B1] build+test (feature=bus_soa)"
cargo test -p ron-kernel --features bus_soa -- tests:: # narrow run
cargo test -p ron-kernel --features bus_soa

echo "[MOG B1] benches (feature=bus_soa)"
cargo bench -p ron-kernel --features bus_soa --bench bus_soa

```

### crates/ron-kernel/src/amnesia.rs
<a id="crates-ron-kernel-src-amnesia-rs"></a>

```rust
//! RO:WHAT — Amnesia mode: single source of truth + metrics hook.
//! RO:WHY  — Pillar 1 (Kernel): central flag for RAM-first ops; SEC/RES concern.
//! RO:INTERACTS — metrics::exporter::Metrics (amnesia gauge), config::watcher/apply, readiness (orthogonal).
//! RO:INVARIANTS — lock-free reads; coherent under races; never gates readiness; updates metrics atomically.
//! RO:METRICS/LOGS — metrics.amnesia_mode (0/1 or label on="true|false") kept in sync on set().
//! RO:CONFIG — toggled by ConfigUpdated (from watcher); env RON_AMNESIA may also flip it.
//! RO:SECURITY — no secrets; boolean only.
//! RO:TEST HOOKS — unit: toggle coherency; integ: watcher flip updates gauge.

use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc,
};

use crate::metrics::exporter::Metrics;

/// Amnesia flag with atomic semantics and metrics synchronization.
#[derive(Clone, Debug)]
pub struct Amnesia(Arc<AtomicBool>);

impl Amnesia {
    /// Create with initial state.
    pub fn new(initial: bool) -> Self {
        Self(Arc::new(AtomicBool::new(initial)))
    }

    /// Read current state (lock-free).
    #[inline]
    pub fn get(&self) -> bool {
        self.0.load(Ordering::Relaxed)
    }

    /// Set state and synchronize the exported gauge.
    ///
    /// Never blocks; safe to call from config apply or env poller.
    pub fn set(&self, on: bool, metrics: &Metrics) {
        self.0.store(on, Ordering::Relaxed);
        metrics.set_amnesia(on);
    }
}

```

### crates/ron-kernel/src/bus/backoff.rs
<a id="crates-ron-kernel-src-bus-backoff-rs"></a>

```rust
//! Two-phase backoff helper for publisher slow paths (bench/SoA use).
//! Default is ultra-light: short spin (16) then yield. Tunable via env:
//!   RON_PUB_SPIN   => u32 spins (max 256; default 16)
//!   RON_PUB_YIELD  => "0" disables yield, anything else enables (default ON)

use std::cell::Cell;
use std::sync::OnceLock;
use std::thread;

#[derive(Copy, Clone)]
pub struct TwoPhaseBackoff {
    spins_left: Cell<u32>,
    yield_enabled: bool,
}

impl TwoPhaseBackoff {
    #[inline]
    pub fn new() -> Self {
        static SPINS: OnceLock<u32> = OnceLock::new();
        static YIELD: OnceLock<bool> = OnceLock::new();

        let spins = *SPINS.get_or_init(|| {
            std::env::var("RON_PUB_SPIN")
                .ok()
                .and_then(|v| v.parse::<u32>().ok())
                .filter(|&n| n <= 256)
                .unwrap_or(16)
        });
        let yield_enabled = *YIELD.get_or_init(|| {
            std::env::var("RON_PUB_YIELD").map(|v| v != "0").unwrap_or(true)
        });

        Self { spins_left: Cell::new(spins), yield_enabled }
    }

    /// Call when publish cannot immediately progress (slot full/lagged).
    #[inline]
    pub fn tick(&self) {
        let left = self.spins_left.get();
        if left > 0 {
            std::hint::spin_loop();
            self.spins_left.set(left - 1);
        } else if self.yield_enabled {
            thread::yield_now();
        } else {
            std::hint::spin_loop();
        }
    }

    #[inline]
    pub fn reset(&self) {
        self.spins_left.set(16);
    }
}

```

### crates/ron-kernel/src/bus/bounded.rs
<a id="crates-ron-kernel-src-bus-bounded-rs"></a>

```rust
//! Bounded, non-blocking in-process broadcast bus.
//!
//! MOG (features):
//! - `bus_edge_notify`: coalesced per-subscriber wake via `pending` bit + disciplined drain.
//! - `bus_batch`: batch publishing API with single notify sweep (A2).
//! - `metrics_buf`: thread-local buffering for hot-path counters (publish/notify).

use std::sync::Arc;

use tokio::sync::broadcast;
use tokio::sync::broadcast::error::RecvError;

#[cfg(feature = "bus_edge_notify")]
use {
    std::sync::{Mutex, Weak},
    tokio::sync::Notify,
};

use crate::Metrics;

#[cfg(feature = "bus_edge_notify")]
use crate::bus::mog_edge_notify::{prom_metrics::PromMetrics, EdgeNotify};

/// Kernel bus wrapper around `tokio::broadcast`.
#[derive(Clone)]
pub struct Bus<T: Clone + Send + 'static> {
    tx: broadcast::Sender<T>,
    metrics: Option<Arc<Metrics>>,

    #[cfg(feature = "bus_edge_notify")]
    edge: Arc<EdgeRegistry>,
}

impl<T: Clone + Send + 'static> Bus<T> {
    pub fn new() -> Self {
        let (tx, _rx) = broadcast::channel::<T>(1024);
        Self {
            tx,
            metrics: None,
            #[cfg(feature = "bus_edge_notify")]
            edge: Arc::new(EdgeRegistry::default()),
        }
    }

    pub fn with_capacity(capacity: usize) -> Self {
        let (tx, _rx) = broadcast::channel::<T>(capacity);
        Self {
            tx,
            metrics: None,
            #[cfg(feature = "bus_edge_notify")]
            edge: Arc::new(EdgeRegistry::default()),
        }
    }

    pub fn with_metrics(mut self, metrics: Arc<Metrics>) -> Self {
        self.metrics = Some(metrics);
        self
    }

    #[inline]
    pub fn receiver_count(&self) -> usize {
        self.tx.receiver_count()
    }

    /// Single publish (existing path), with optional TLS metrics buffering.
    pub fn publish(&self, msg: T) -> usize {
        let receivers = self.tx.receiver_count();

        if receivers == 0 {
            if let Some(m) = &self.metrics {
                // Count as "published attempt" + explicit "no receivers".
                #[cfg(feature = "metrics_buf")]
                {
                    if let Some(hot) = m.hot() {
                        hot.inc_published();
                    }
                }
                #[cfg(not(feature = "metrics_buf"))]
                {
                    m.bus_published_total.inc();
                }
                m.bus_no_receivers_total.inc();
            }
            return 0;
        }

        match self.tx.send(msg) {
            Ok(_) => {
                // Account publish on the hot path.
                if let Some(m) = &self.metrics {
                    #[cfg(feature = "metrics_buf")]
                    {
                        if let Some(hot) = m.hot() {
                            hot.inc_published();
                        }
                    }
                    #[cfg(not(feature = "metrics_buf"))]
                    {
                        m.bus_published_total.inc();
                    }
                }

                // Coalesced edge-notify sweep if enabled.
                #[cfg(feature = "bus_edge_notify")]
                self.edge_sweep();

                receivers
            }
            Err(_e) => {
                if let Some(m) = &self.metrics {
                    m.bus_dropped_total.inc();
                }
                0
            }
        }
    }

    /// A2: Batch publish with one notify sweep at the end (feature-gated).
    #[cfg(feature = "bus_batch")]
    pub fn publish_many(&self, batch: &[T]) -> usize {
        if batch.is_empty() {
            return 0;
        }

        let receivers = self.tx.receiver_count();
        if receivers == 0 {
            if let Some(m) = &self.metrics {
                // Visibility: attempted to publish N items with no listeners.
                #[cfg(feature = "metrics_buf")]
                {
                    if let Some(hot) = m.hot() {
                        hot.add_published(batch.len() as u64);
                    }
                }
                #[cfg(not(feature = "metrics_buf"))]
                {
                    m.bus_published_total.inc_by(batch.len() as u64);
                }
                m.bus_no_receivers_total.inc_by(batch.len() as u64);
                m.bus_batch_publish_total.inc();
                m.bus_batch_len_histogram.observe(batch.len() as f64);
            }
            return 0;
        }

        // Send all elements; if any send fails (closed), account drop and stop.
        let mut sent = 0usize;
        for item in batch {
            match self.tx.send(item.clone()) {
                Ok(_) => sent += 1,
                Err(_e) => {
                    if let Some(m) = &self.metrics {
                        m.bus_dropped_total.inc();
                    }
                    break;
                }
            }
        }

        // One coalesced edge-notify sweep (A2).
        #[cfg(feature = "bus_edge_notify")]
        self.edge_sweep();

        if let Some(m) = &self.metrics {
            if sent > 0 {
                #[cfg(feature = "metrics_buf")]
                {
                    if let Some(hot) = m.hot() {
                        hot.add_published(sent as u64);
                    }
                }
                #[cfg(not(feature = "metrics_buf"))]
                {
                    m.bus_published_total.inc_by(sent as u64);
                }
            }
            m.bus_batch_publish_total.inc();
            m.bus_batch_len_histogram.observe(batch.len() as f64);
        }

        receivers
    }

    /// Subscribe and get a classical broadcast `Receiver<T>` (feature-agnostic).
    pub fn subscribe(&self) -> broadcast::Receiver<T> {
        self.tx.subscribe()
    }

    pub fn handle_recv(
        res: Result<T, broadcast::error::RecvError>,
        metrics: Option<&Metrics>,
    ) -> Option<T> {
        match res {
            Ok(v) => Some(v),
            Err(broadcast::error::RecvError::Lagged(n)) => {
                if let Some(m) = metrics {
                    m.bus_receiver_lag_total.inc_by(n as u64);
                }
                None
            }
            Err(broadcast::error::RecvError::Closed) => None,
        }
    }

    // === Internal: one sweep across live subscribers to deliver a single notify per sub ======

    #[cfg(feature = "bus_edge_notify")]
    fn edge_sweep(&self) {
        // Prometheus metrics for A1/A5 (counters + per-sub pending gauge internally updated
        // by the receiver drain loops). Small, stateless helper.
        let prom = PromMetrics::default();

        let mut sent = 0u64;
        let mut suppressed = 0u64;

        self.edge.with_signals(|signals| {
            signals.retain(|w| w.upgrade().is_some());
            for w in signals.iter() {
                if let Some(sig) = w.upgrade() {
                    // RELAXED is sufficient: visibility is handled by ring fences.
                    if EdgeNotify::maybe_mark_pending_and_should_wake_metrics(&sig.pending, &prom) {
                        sig.notify.notify_one();
                        sent += 1;
                    } else {
                        suppressed += 1;
                    }
                }
            }
        });

        if let Some(m) = &self.metrics {
            // Route 'sends' through TLS buffer when enabled; 'suppressed' stays direct.
            #[cfg(feature = "metrics_buf")]
            {
                if sent > 0 {
                    if let Some(hot) = m.hot() {
                        // Count one notify per sweep (keep it simple on hot path).
                        hot.inc_notify();
                    }
                }
            }
            #[cfg(not(feature = "metrics_buf"))]
            {
                if sent > 0 {
                    m.bus_notify_sends_total.inc_by(sent);
                }
            }

            if suppressed > 0 {
                m.bus_notify_suppressed_total.inc_by(suppressed);
            }
        }
    }

    // === MOG subscriber helpers (feature-gated) ============================================

    /// Subscribe with an internal edge signal (pending bit + Notify) used to coalesce wakes.
    #[cfg(feature = "bus_edge_notify")]
    pub fn subscribe_edge(&self) -> EdgeReceiver<T> {
        let rx = self.tx.subscribe();
        let signal = Arc::new(EdgeSignal::default());
        self.edge.register_signal(&signal);
        EdgeReceiver {
            signal,
            rx,
            metrics: self.metrics.clone(),
        }
    }
}

/// Receiver wrapper (unchanged shape).
pub struct Receiver<T: Clone + Send + 'static> {
    inner: broadcast::Receiver<T>,
    metrics: Option<Arc<Metrics>>,
}

impl<T: Clone + Send + 'static> Receiver<T> {
    pub fn new(inner: broadcast::Receiver<T>, metrics: Option<Arc<Metrics>>) -> Self {
        Self { inner, metrics }
    }

    pub async fn recv(&mut self) -> Option<T> {
        loop {
            match self.inner.recv().await {
                Ok(v) => return Some(v),
                Err(RecvError::Lagged(n)) => {
                    if let Some(m) = &self.metrics {
                        m.bus_receiver_lag_total.inc_by(n as u64);
                    }
                    continue;
                }
                Err(RecvError::Closed) => return None,
            }
        }
    }
}

/* ======== MOG helpers and types (feature-gated; minimal, generic-safe) ==================== */

#[cfg(feature = "bus_edge_notify")]
#[derive(Default)]
struct EdgeRegistry {
    signals: Mutex<Vec<Weak<EdgeSignal>>>,
}

#[cfg(feature = "bus_edge_notify")]
impl EdgeRegistry {
    fn register_signal(&self, sig: &Arc<EdgeSignal>) {
        self.signals.lock().unwrap().push(Arc::downgrade(sig));
    }
    fn with_signals<F: FnOnce(&mut Vec<Weak<EdgeSignal>>) -> ()>(&self, f: F) {
        let mut guard = self.signals.lock().unwrap();
        f(&mut guard);
    }
}

#[cfg(feature = "bus_edge_notify")]
#[derive(Default)]
struct EdgeSignal {
    pending: std::sync::atomic::AtomicBool,
    notify: Notify,
}

#[cfg(feature = "bus_edge_notify")]
pub struct EdgeReceiver<T: Clone + Send + 'static> {
    signal: Arc<EdgeSignal>,
    rx: broadcast::Receiver<T>,
    metrics: Option<Arc<Metrics>>,
}

#[cfg(feature = "bus_edge_notify")]
impl<T: Clone + Send + 'static> EdgeReceiver<T> {
    #[inline]
    pub fn try_recv_now_or_never(&mut self) -> usize {
        use tokio::sync::broadcast::error::TryRecvError::*;
        let mut drained = 0usize;
        loop {
            match self.rx.try_recv() {
                Ok(_msg) => drained += 1,
                Err(Empty) => break,
                Err(Lagged(n)) => {
                    if let Some(m) = &self.metrics {
                        m.bus_receiver_lag_total.inc_by(n as u64);
                    }
                }
                Err(Closed) => break,
            }
        }
        drained
    }

    #[inline]
    pub async fn await_notify(&self) {
        self.signal.notify.notified().await;
    }

    #[inline]
    pub fn pending(&self) -> &std::sync::atomic::AtomicBool {
        &self.signal.pending
    }
    #[inline]
    pub fn notify(&self) -> &Notify {
        &self.signal.notify
    }

    /// Disciplined drain loop (A5) with race check and per-sub pending gauge.
    pub async fn run_drain_loop(&mut self, sub_index: usize) {
        // Prom metrics handle `bus_sub_pending{sub}` updates.
        let prom = PromMetrics::default();

        loop {
            // Drain in bounded bursts to amortize wakes while keeping latency tight.
            let mut drained = 0usize;
            loop {
                let n = self.try_recv_now_or_never();
                if n == 0 {
                    break;
                }
                drained += n;
                if drained >= 1024 {
                    break;
                }
            }

            // Race check — if a publish raced our clear, keep draining (skip await).
            if EdgeNotify::after_drain_race_check(self.pending(), &prom, sub_index) {
                continue;
            }

            // Await next wake to avoid ping-pong.
            self.await_notify().await;
        }
    }
}

```

### crates/ron-kernel/src/bus/capacity.rs
<a id="crates-ron-kernel-src-bus-capacity-rs"></a>

```rust
//! RO:WHAT
//!   Capacity autotune helper for the bounded bus ring.
//!
//! RO:WHY
//!   Picking a too-large cap is cache-hostile; too-small can increase churn/drops.
//!   This feature-gated helper chooses a sweet-spot cap from expected subscriber
//!   count with guardrails and observability (Prometheus counters/gauges).
//!
//! RO:INTERACTS
//!   - Used by examples (kernel_demo) and callers that want reasonable defaults.
//!   - Exposes Prometheus metrics via the *default* registry.
//!
//! RO:INVARIANTS
//!   - Public kernel API remains frozen; this is an internal helper.
//!   - When feature `bus_autotune_cap` is OFF, callers should not reference it.
//!   - Caps returned are restricted to {64, 128, 256} unless explicitly overridden.
//!
//! RO:TESTS
//!   - Unit: mapping for key N (0,1,4,5,16,17,64,128)
//!   - Property: monotone in N; override respected; warnings on >256
//!
//! RO:SAFETY
//!   - No `unsafe`. Pure computation + metrics.
//!
//! RO:METRICS
//!   - `bus_autotune_warn_total{reason="cap_gt_256"}`
//!   - `bus_cap_selected` (gauge)

#![cfg(feature = "bus_autotune_cap")]

use once_cell::sync::Lazy;
use prometheus::{opts, register_gauge, register_int_counter_vec, Gauge, IntCounterVec};

/// Warn counter for guardrails.
static AUTOTUNE_WARN_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        opts!("bus_autotune_warn_total", "Autotune guardrail warnings"),
        &["reason"]
    )
    .expect("register bus_autotune_warn_total")
});

/// Last selected cap (observability).
static BUS_CAP_SELECTED: Lazy<Gauge> = Lazy::new(|| {
    register_gauge!(
        "bus_cap_selected",
        "Current bus capacity selected by autotune"
    )
    .expect("register bus_cap_selected")
});

/// Choose a cache-friendly capacity from an expected subscriber count `expected_subs`.
/// If `override_cap` is provided, it always wins (and may be any power-of-two the caller desires).
/// Guardrail: when the *effective* cap exceeds 256, we emit a warning counter.
///
/// Mapping (when `override_cap` is `None`):
///   - N ≤ 4   → 64
///   - N ≤ 16  → 128
///   - else    → 256 (warn if caller later uses >256)
pub fn autotune_capacity(expected_subs: usize, override_cap: Option<usize>) -> usize {
    let cap = match override_cap {
        Some(c) => c,
        None => {
            if expected_subs <= 4 {
                64
            } else if expected_subs <= 16 {
                128
            } else {
                256
            }
        }
    };

    if cap > 256 {
        AUTOTUNE_WARN_TOTAL.with_label_values(&["cap_gt_256"]).inc();
    }

    BUS_CAP_SELECTED.set(cap as f64);
    cap
}

/// Helper for tests/benches to reset gauge (kept for internal use).
#[cfg(test)]
pub fn __test_reset_metrics() {
    BUS_CAP_SELECTED.set(0.0);
}

```

### crates/ron-kernel/src/bus/mod.rs
<a id="crates-ron-kernel-src-bus-mod-rs"></a>

```rust
//! Bus module index.
//!
//! Layout:
//! - `bounded.rs`          : tokio::broadcast/AoS backend (default)
//! - `soa.rs`              : SoA ring backend (feature: bus_soa)
//! - `mog_edge_notify.rs`  : A1/A5 helpers (edge-triggered notify + disciplined drain)
//! - `capacity.rs`         : A3 autotune helper (feature: bus_autotune_cap)
//!
//! RO:WHAT
//!   Central selector + feature-gated helpers for the kernel bus.
//!
//! RO:WHY
//!   Keep call-sites stable while we experiment with a SoA backend.
//!   When `bus_soa` is enabled, we re-export SoA *under* a `bounded`-shaped
//!   module so existing paths (`crate::bus::bounded::Bus`) remain valid.
//!
//! RO:INVARIANTS
//!   - Public API stays stable; features are OFF-by-default.
//!   - No `unsafe` here.
//!   - `crate::bus::bounded::Bus` always exists and compiles.
//!
//! RO:INTERACTS
//!   - `bounded.rs` (default AoS) or `soa.rs` (feature=bus_soa) as the active backend.
//!   - `mog_edge_notify.rs` when feature `bus_edge_notify` is on.
//!   - `capacity.rs` when feature `bus_autotune_cap` is on.

#![allow(clippy::module_inception)] // for the bounded re-export wrapper when bus_soa is on

/// A3: Capacity autotune helper (feature-gated).
#[cfg(feature = "bus_autotune_cap")]
pub mod capacity;

#[cfg(feature = "bus_autotune_cap")]
pub use capacity::autotune_capacity;

/// Default backend (`bounded`) when SoA is NOT enabled.
#[cfg(not(feature = "bus_soa"))]
pub mod bounded;

/// Optional SoA backend (feature: bus_soa).
#[cfg(feature = "bus_soa")]
pub mod soa;

/// When `bus_soa` is ON, re-export SoA items under a `bounded`-shaped module
/// so `crate::bus::bounded::Bus` remains valid at existing call-sites.
/// We keep `pub mod soa;` above so advanced users can still import `soa::*`
/// explicitly if they want to.
#[cfg(feature = "bus_soa")]
pub mod bounded {
    pub use super::soa::*;
}

/// A1/A5 helpers (edge-triggered notify + disciplined drain).
#[cfg(feature = "bus_edge_notify")]
pub mod mog_edge_notify;

// ---------------------------------------------------------------------------
// Convenience re-exports (non-breaking):
//   - These make `use crate::bus::Bus;` work regardless of backend.
//   - Purely additive; they do not remove or rename any existing items.
// ---------------------------------------------------------------------------

pub use bounded::{Bus, Receiver};

#[cfg(feature = "bus_edge_notify")]
pub use bounded::EdgeReceiver;

```

### crates/ron-kernel/src/bus/mog_edge_notify.rs
<a id="crates-ron-kernel-src-bus-mogedgenotify-rs"></a>

```rust
// crates/ron-kernel/src/bus/mog_edge_notify.rs

/*!
MOG A1 + A5 — Edge-Triggered Notify + Disciplined Drain
Feature: `bus_edge_notify`

Internal helpers:
- Coalesce wakeups per subscriber using a `pending` bit (A1).
- Disciplined drain loop that clears `pending` safely and avoids ping-pong wakes (A5).

Public API: **None** (internal only). Wire these helpers into the bus internals.
Zero behavior change unless the bus calls into this module under the `bus_edge_notify` feature.
*/

#![cfg(feature = "bus_edge_notify")]
#![deny(unsafe_code)]

use core::sync::atomic::{AtomicBool, Ordering};

/// Minimal metrics hook used by this module.
/// Keep it decoupled; provide a Prometheus impl below (optional).
pub trait EdgeMetrics: Send + Sync + 'static {
    fn inc_notify_sent(&self) {}
    fn inc_notify_suppressed(&self) {}
    fn set_sub_pending(&self, _sub_idx: usize, _val: bool) {}
}
impl EdgeMetrics for () {}

/// Per-subscriber edge notifier (stateless; state lives in passed-in atomics).
#[derive(Default, Debug)]
pub struct EdgeNotify;

impl EdgeNotify {
    /// Publisher-side: set `pending` to true. If we transitioned 0→1, caller should send a wake.
    /// (Legacy signature — no metrics.)
    #[inline(always)]
    pub fn maybe_mark_pending_and_should_wake(pending: &AtomicBool) -> bool {
        // Relaxed is sufficient: message visibility comes from the ring’s Release/Acquire.
        let prev = pending.swap(true, Ordering::Relaxed);
        !prev
    }

    /// Publisher-side (metrics-aware): increments sends/suppressed counters.
    #[inline(always)]
    pub fn maybe_mark_pending_and_should_wake_metrics<M: EdgeMetrics>(
        pending: &AtomicBool,
        metrics: &M,
    ) -> bool {
        let prev = pending.swap(true, Ordering::Relaxed);
        if !prev {
            metrics.inc_notify_sent();
            true
        } else {
            metrics.inc_notify_suppressed();
            false
        }
    }

    /// Subscriber-side (legacy): clear `pending=false` after draining and perform a race check.
    /// Returns `true` if new work arrived during/after the clear.
    ///
    /// NOTE: Kept for compatibility, but prefer `after_drain_race_check()` below,
    /// which uses a stronger detection pattern.
    #[inline(always)]
    pub fn clear_pending_and_race_check(pending: &AtomicBool) -> bool {
        let _was_set = pending.swap(false, Ordering::Relaxed);
        pending.load(Ordering::Relaxed)
    }

    /// Subscriber-side: disciplined race-check after draining.
    ///
    /// Pattern:
    ///   drain_all();
    ///   if EdgeNotify::after_drain_race_check(pending, metrics, sub_idx) { continue; }
    ///   await_notify();
    ///
    /// Returns `true` if a publish raced after we cleared pending — the caller should
    /// skip awaiting and re-enter the drain loop immediately.
    #[inline(always)]
    pub fn after_drain_race_check<M: EdgeMetrics>(
        pending: &AtomicBool,
        metrics: &M,
        sub_idx: usize,
    ) -> bool {
        // 1) Clear pending (we are about to await).
        pending.store(false, Ordering::Relaxed);
        metrics.set_sub_pending(sub_idx, false);

        // 2) Race detect: if a publisher set it after our clear, swap(false) returns true.
        let raced = pending.swap(false, Ordering::Relaxed);
        if raced {
            // Re-arm to true so subsequent publishers get suppression (coalescing continues).
            pending.store(true, Ordering::Relaxed);
            metrics.set_sub_pending(sub_idx, true);
        }
        raced
    }

    /// Subscriber-side: disciplined drain loop.
    ///
    /// - `try_recv_now` must drain ALL available items and return the number drained.
    /// - `await_notify` waits for a single notification (e.g., `notify.notified().await`).
    pub async fn drain_loop<TryNow, AwaitFut, M>(
        &self,
        sub_idx: usize,
        pending: &AtomicBool,
        mut try_recv_now: TryNow,
        mut await_notify: impl FnMut() -> AwaitFut,
        metrics: &M,
    ) where
        TryNow: FnMut() -> usize,
        AwaitFut: core::future::Future<Output = ()>,
        M: EdgeMetrics,
    {
        metrics.set_sub_pending(sub_idx, true);
        loop {
            // 1) Drain everything currently available.
            loop {
                let n = try_recv_now();
                if n == 0 {
                    break;
                }
            }

            // 2) Clear pending + race check. If raced, keep draining (skip await).
            if Self::after_drain_race_check(pending, metrics, sub_idx) {
                continue;
            }

            // 3) Await next wake to avoid ping-pong.
            await_notify().await;
            metrics.set_sub_pending(sub_idx, true);
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use core::sync::atomic::AtomicBool;

    #[test]
    fn publisher_edges_are_coalesced() {
        let pending = AtomicBool::new(false);

        // First mark triggers a wake
        assert!(EdgeNotify::maybe_mark_pending_and_should_wake(&pending));
        // Further marks coalesce (no additional wakes)
        assert!(!EdgeNotify::maybe_mark_pending_and_should_wake(&pending));
        assert!(!EdgeNotify::maybe_mark_pending_and_should_wake(&pending));

        // After a normal after-drain race check with no race, we should be clear
        let raced = EdgeNotify::after_drain_race_check(&pending, &(), 0);
        assert!(!raced);

        // Next publish becomes a new edge again
        assert!(EdgeNotify::maybe_mark_pending_and_should_wake(&pending));
    }

    #[test]
    fn after_drain_no_race_returns_false() {
        let pending = AtomicBool::new(true);
        // Simulate: we drained; now we do the after-drain check; no concurrent publisher
        let raced = EdgeNotify::after_drain_race_check(&pending, &(), 0);
        assert!(!raced, "no publisher raced; should return false");
        assert!(!pending.load(Ordering::Relaxed), "pending remains false");
    }
}

/// Optional: Prometheus-backed metrics for A1/A5 (counters + per-sub gauge).
/// Enable by constructing `PromMetrics` and passing &PromMetrics to drain/publish paths.
#[cfg(feature = "bus_edge_notify")]
pub mod prom_metrics {
    use super::EdgeMetrics;
    use once_cell::sync::Lazy;
    use prometheus::{opts, register_int_counter, register_int_gauge_vec, IntCounter, IntGaugeVec};

    static NOTIFY_SENDS_TOTAL: Lazy<IntCounter> = Lazy::new(|| {
        register_int_counter!(opts!(
            "bus_notify_sends_total",
            "Notify calls performed on 0→1 edges"
        ))
        .expect("register bus_notify_sends_total")
    });

    static NOTIFY_SUPPRESSED_TOTAL: Lazy<IntCounter> = Lazy::new(|| {
        register_int_counter!(opts!(
            "bus_notify_suppressed_total",
            "Notify attempts suppressed because subscriber was already pending"
        ))
        .expect("register bus_notify_suppressed_total")
    });

    static SUB_PENDING: Lazy<IntGaugeVec> = Lazy::new(|| {
        register_int_gauge_vec!(
            "bus_sub_pending",
            "Pending bit per subscriber (0|1)",
            &["sub"]
        )
        .expect("register bus_sub_pending")
    });

    /// Prometheus-backed EdgeMetrics. Label is `sub` with the numeric index.
    #[derive(Clone, Default)]
    pub struct PromMetrics;

    impl EdgeMetrics for PromMetrics {
        #[inline(always)]
        fn inc_notify_sent(&self) {
            NOTIFY_SENDS_TOTAL.inc();
        }
        #[inline(always)]
        fn inc_notify_suppressed(&self) {
            NOTIFY_SUPPRESSED_TOTAL.inc();
        }
        #[inline(always)]
        fn set_sub_pending(&self, sub_idx: usize, val: bool) {
            SUB_PENDING
                .with_label_values(&[&format!("{sub_idx}")])
                .set(if val { 1 } else { 0 });
        }
    }
}

```

### crates/ron-kernel/src/bus/soa.rs
<a id="crates-ron-kernel-src-bus-soa-rs"></a>

```rust
#![cfg(feature = "bus_soa")]

//! SoA (Structure-of-Arrays) ring backend for the in-process bus.

use core::sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering};
use std::sync::Arc;
use tokio::sync::Notify;

use crate::Metrics;
use tokio::sync::broadcast::error::RecvError;

#[cfg(feature = "bus_edge_notify")]
mod edge_helper {
    use core::sync::atomic::{AtomicBool, AtomicUsize, Ordering};
    use std::sync::{Arc, Weak};
    use tokio::sync::Notify;

    #[derive(Default)]
    pub struct EdgeSignal {
        pub notify: Notify,
        pub pending: AtomicBool,
    }

    pub struct EdgeNotify;

    impl EdgeNotify {
        #[inline]
        pub fn set_pending_and_notify(sig: &Arc<EdgeSignal>) -> bool {
            let prev = sig.pending.swap(true, Ordering::AcqRel);
            if !prev {
                sig.notify.notify_one();
            }
            !prev
        }
        #[inline]
        pub fn clear_pending_and_race_check(pending: &AtomicBool) -> bool {
            let _was_set = pending.swap(false, Ordering::AcqRel);
            pending.load(Ordering::Relaxed)
        }
    }

    /// Reader-friendly registry with occasional GC and O(1) "is there anyone?" fast-path.
    #[derive(Default)]
    pub struct EdgeRegistry {
        pub signals: parking_lot::RwLock<Vec<Weak<EdgeSignal>>>,
        pub gc_tick: AtomicUsize,
        pub active: AtomicUsize, // count of live edge subscribers
    }

    impl EdgeRegistry {
        pub fn register(&self, sig: &Arc<EdgeSignal>) {
            let mut w = self.signals.write();
            w.push(Arc::downgrade(sig));
            self.active.fetch_add(1, Ordering::Relaxed);
        }

        pub fn deregister(&self) {
            self.active.fetch_sub(1, Ordering::Relaxed);
        }

        /// Iterate with a read-lock. Return `true` if any dead Weak were seen.
        pub fn for_each_with_read<F: FnMut(&Arc<EdgeSignal>)>(&self, mut f: F) -> bool {
            let r = self.signals.read();
            let mut saw_dead = false;
            for w in r.iter() {
                if let Some(sig) = w.upgrade() {
                    f(&sig);
                } else {
                    saw_dead = true;
                }
            }
            saw_dead
        }

        /// Occasionally compact dead entries. Called rarely to avoid write-lock churn.
        pub fn maybe_gc(&self, saw_dead: bool) {
            if !saw_dead {
                return;
            }
            let tick = self.gc_tick.fetch_add(1, Ordering::Relaxed);
            if (tick & 63) != 0 {
                return;
            }
            let mut w = self.signals.write();
            w.retain(|weak| weak.strong_count() > 0);
        }
    }
}
#[cfg(feature = "bus_edge_notify")]
use edge_helper::{EdgeNotify, EdgeRegistry, EdgeSignal};

// ===== Slot ==================================================================

// Keep it lean: no per-message Arc; clone T under a Mutex like the bounded backend.
pub(crate) struct Slot<T> {
    seq: AtomicU64,
    msg: parking_lot::Mutex<Option<T>>,
    ready_mask: AtomicU64,
}
impl<T> Slot<T> {
    fn new() -> Self {
        Self {
            seq: AtomicU64::new(0),
            msg: parking_lot::Mutex::new(None),
            ready_mask: AtomicU64::new(0),
        }
    }
}

// ===== Bus ===================================================================

pub struct Bus<T: Clone + Send + 'static> {
    cap: usize,
    seq: Arc<AtomicU64>,
    slots: Arc<Vec<Slot<T>>>,

    subs_in_use: Arc<parking_lot::Mutex<[bool; 64]>>,
    sub_count: Arc<parking_lot::Mutex<usize>>,

    global_notify: Arc<Notify>,

    publishers: Arc<AtomicUsize>,
    closed: Arc<AtomicBool>,

    metrics: Option<Arc<Metrics>>,

    #[cfg(feature = "bus_edge_notify")]
    edge: Arc<EdgeRegistry>,
}

impl<T: Clone + Send + 'static> Bus<T> {
    pub fn new() -> Self {
        Self::with_capacity(1024)
    }

    pub fn with_capacity(cap: usize) -> Self {
        let mut v = Vec::with_capacity(cap);
        for _ in 0..cap {
            v.push(Slot::new());
        }
        Self {
            cap,
            seq: Arc::new(AtomicU64::new(0)),
            slots: Arc::new(v),
            subs_in_use: Arc::new(parking_lot::Mutex::new([false; 64])),
            sub_count: Arc::new(parking_lot::Mutex::new(0)),
            global_notify: Arc::new(Notify::new()),
            publishers: Arc::new(AtomicUsize::new(1)),
            closed: Arc::new(AtomicBool::new(false)),
            metrics: None,
            #[cfg(feature = "bus_edge_notify")]
            edge: Arc::new(EdgeRegistry::default()),
        }
    }

    pub fn with_metrics(mut self, metrics: Arc<Metrics>) -> Self {
        self.metrics = Some(metrics);
        self
    }

    #[inline]
    pub fn receiver_count(&self) -> usize {
        *self.sub_count.lock()
    }

    #[inline]
    fn current_mask(&self) -> u64 {
        let subs = self.subs_in_use.lock();
        let mut mask: u64 = 0;
        for bit in 0..64 {
            if subs[bit] {
                mask |= 1u64 << bit;
            }
        }
        mask
    }

    /// Writer order:
    /// 1) payload -> msg (under lock)
    /// 2) ready_mask.store(mask, Release)
    /// 3) seq.store(next, Release)
    #[inline]
    fn publish_inner(&self, val: T, mask: u64, do_wake: bool) -> usize {
        let rc = self.receiver_count();
        if rc == 0 {
            if let Some(m) = &self.metrics {
                m.bus_no_receivers_total.inc();
            }
            return 0;
        }

        let next = self.seq.fetch_add(1, Ordering::AcqRel) + 1;
        let idx = (next as usize) % self.cap;

        {
            let mut guard = self.slots[idx].msg.lock();
            *guard = Some(val);
        }
        self.slots[idx].ready_mask.store(mask, Ordering::Release);
        self.slots[idx].seq.store(next, Ordering::Release);

        if let Some(m) = &self.metrics {
            m.bus_published_total.inc();
        }

        if do_wake {
            #[cfg(feature = "bus_edge_notify")]
            {
                // O(1) fast-path: if no edge subscribers, skip the whole sweep.
                if self.edge.active.load(Ordering::Relaxed) != 0 {
                    self.edge_sweep();
                }
            }
            #[cfg(not(feature = "bus_edge_notify"))]
            self.global_notify.notify_waiters();
        }

        rc
    }

    pub fn publish(&self, msg: T) -> usize {
        let mask = self.current_mask();
        self.publish_inner(msg, mask, true)
    }

    #[cfg(feature = "bus_batch")]
    pub fn publish_many(&self, batch: &[T]) -> usize {
        if batch.is_empty() {
            return 0;
        }
        let rc = self.receiver_count();
        if rc == 0 {
            if let Some(m) = &self.metrics {
                m.bus_no_receivers_total.inc_by(batch.len() as u64);
                m.bus_batch_publish_total.inc();
                m.bus_batch_len_histogram.observe(batch.len() as f64);
            }
            return 0;
        }
        let mask = self.current_mask();
        for item in batch {
            let _ = self.publish_inner(item.clone(), mask, false);
        }

        #[cfg(feature = "bus_edge_notify")]
        {
            if self.edge.active.load(Ordering::Relaxed) != 0 {
                self.edge_sweep();
            }
        }
        #[cfg(not(feature = "bus_edge_notify"))]
        self.global_notify.notify_waiters();

        if let Some(m) = &self.metrics {
            m.bus_batch_publish_total.inc();
            m.bus_batch_len_histogram.observe(batch.len() as f64);
        }
        rc
    }

    pub fn subscribe(&self) -> Receiver<T> {
        let (id, _count) = {
            let mut used = self.subs_in_use.lock();
            let mut idx: Option<usize> = None;
            for i in 0..64 {
                if !used[i] {
                    used[i] = true;
                    idx = Some(i);
                    break;
                }
            }
            let mut sc = self.sub_count.lock();
            if idx.is_some() {
                *sc += 1;
            }
            (idx.expect("up to 64 subscribers"), *sc)
        };

        let tail = self.seq.load(Ordering::Acquire);
        Receiver {
            bus_cap: self.cap,
            ring: self.slots.clone(),
            tail,
            id: id as u8,
            global_notify: self.global_notify.clone(),
            _metrics: self.metrics.clone(),
            subs_in_use: Arc::clone(&self.subs_in_use),
            sub_count: Arc::clone(&self.sub_count),
            closed: Arc::clone(&self.closed),
            seq: Arc::clone(&self.seq),
        }
    }

    #[cfg(feature = "bus_edge_notify")]
    pub fn subscribe_edge(&self) -> EdgeReceiver<T> {
        let inner = self.subscribe();
        let signal = Arc::new(EdgeSignal::default());
        self.edge.register(&signal);
        EdgeReceiver {
            inner,
            signal,
            registry: Arc::clone(&self.edge),
        }
    }

    #[inline]
    pub fn handle_recv(res: Result<T, RecvError>, metrics: Option<&Metrics>) -> Option<T> {
        match res {
            Ok(v) => Some(v),
            Err(RecvError::Lagged(_)) => {
                if let Some(m) = metrics {
                    m.bus_receiver_lag_total.inc_by(1);
                }
                None
            }
            Err(RecvError::Closed) => None,
        }
    }

    #[cfg(feature = "bus_edge_notify")]
    fn edge_sweep(&self) {
        let mut sent = 0u64;
        let mut suppressed = 0u64;

        let saw_dead = self.edge.for_each_with_read(|sig| {
            if EdgeNotify::set_pending_and_notify(sig) {
                sent += 1;
            } else {
                suppressed += 1;
            }
        });
        self.edge.maybe_gc(saw_dead);

        if let Some(m) = &self.metrics {
            if sent > 0 {
                m.bus_notify_sends_total.inc_by(sent);
            }
            if suppressed > 0 {
                m.bus_notify_suppressed_total.inc_by(suppressed);
            }
        }
    }
}

impl<T: Clone + Send + 'static> Clone for Bus<T> {
    fn clone(&self) -> Self {
        self.publishers.fetch_add(1, Ordering::AcqRel);
        Self {
            cap: self.cap,
            seq: Arc::clone(&self.seq),
            slots: Arc::clone(&self.slots),
            subs_in_use: Arc::clone(&self.subs_in_use),
            sub_count: Arc::clone(&self.sub_count),
            global_notify: Arc::clone(&self.global_notify),
            publishers: Arc::clone(&self.publishers),
            closed: Arc::clone(&self.closed),
            metrics: self.metrics.clone(),
            #[cfg(feature = "bus_edge_notify")]
            edge: Arc::clone(&self.edge),
        }
    }
}

impl<T: Clone + Send + 'static> Drop for Bus<T> {
    fn drop(&mut self) {
        if self.publishers.fetch_sub(1, Ordering::AcqRel) == 1 {
            self.closed.store(true, Ordering::Release);
            self.global_notify.notify_waiters();
        }
    }
}

// ===== Receiver ==============================================================

pub struct Receiver<T: Clone + Send + 'static> {
    pub(crate) bus_cap: usize,
    pub(crate) ring: Arc<Vec<Slot<T>>>,
    pub(crate) tail: u64,
    pub(crate) id: u8,
    pub(crate) global_notify: Arc<Notify>,
    pub(crate) _metrics: Option<Arc<Metrics>>,
    pub(crate) subs_in_use: Arc<parking_lot::Mutex<[bool; 64]>>,
    pub(crate) sub_count: Arc<parking_lot::Mutex<usize>>,
    pub(crate) closed: Arc<AtomicBool>,
    pub(crate) seq: Arc<AtomicU64>,
}

impl<T: Clone + Send + 'static> Receiver<T> {
    pub async fn recv(&mut self) -> Result<T, RecvError> {
        loop {
            let next = self.tail + 1;
            let idx = (next as usize) % self.bus_cap;
            let slot = &self.ring[idx];

            let slot_seq = slot.seq.load(Ordering::Acquire);

            if slot_seq > next {
                let delta = slot_seq - next;
                self.tail = slot_seq - 1;
                return Err(RecvError::Lagged(delta));
            }

            if slot_seq == 0 || slot_seq < next {
                if self.closed.load(Ordering::Acquire) {
                    let cur = self.seq.load(Ordering::Acquire);
                    if cur < next {
                        return Err(RecvError::Closed);
                    }
                }
                self.global_notify.notified().await;
                continue;
            }

            let bit = 1u64 << (self.id as u64);
            let prev_mask = slot.ready_mask.fetch_and(!bit, Ordering::AcqRel);
            if (prev_mask & bit) == 0 {
                self.tail = slot_seq;
                return Err(RecvError::Lagged(1));
            }

            let cloned = {
                let guard = slot.msg.lock();
                let v = guard.as_ref().expect("payload must exist if bit was set");
                v.clone()
            };

            self.tail = slot_seq;
            return Ok(cloned);
        }
    }
}

impl<T: Clone + Send + 'static> Drop for Receiver<T> {
    fn drop(&mut self) {
        let mut used = self.subs_in_use.lock();
        used[self.id as usize] = false;
        let mut c = self.sub_count.lock();
        *c = c.saturating_sub(1);
    }
}

// ===== Edge Receiver =========================================================

#[cfg(feature = "bus_edge_notify")]
pub struct EdgeReceiver<T: Clone + Send + 'static> {
    pub(crate) inner: Receiver<T>,
    pub(crate) signal: Arc<EdgeSignal>,
    pub(crate) registry: Arc<EdgeRegistry>,
}

#[cfg(feature = "bus_edge_notify")]
impl<T: Clone + Send + 'static> EdgeReceiver<T> {
    #[inline]
    pub fn try_recv_now_or_never(&mut self) -> usize {
        let mut drained = 0usize;
        loop {
            let next = self.inner.tail + 1;
            let idx = (next as usize) % self.inner.bus_cap;
            let slot = &self.inner.ring[idx];

            let slot_seq = slot.seq.load(Ordering::Acquire);
            if slot_seq == 0 || slot_seq < next {
                break;
            }
            if slot_seq > next {
                self.inner.tail = slot_seq - 1;
                continue;
            }

            let bit = 1u64 << (self.inner.id as u64);
            let prev_mask = slot.ready_mask.fetch_and(!bit, Ordering::AcqRel);
            if (prev_mask & bit) == 0 {
                self.inner.tail = slot_seq;
                continue;
            }

            {
                let guard = slot.msg.lock();
                let _ = guard.as_ref().expect("payload must exist if bit was set");
            }

            self.inner.tail = slot_seq;
            drained += 1;
        }
        drained
    }

    pub async fn run_drain_loop(&mut self, _sub_index: usize) {
        loop {
            let mut total = 0usize;
            loop {
                let n = self.try_recv_now_or_never();
                if n == 0 {
                    break;
                }
                total += n;
                if total >= 1024 {
                    break;
                }
            }
            let raced = edge_helper::EdgeNotify::clear_pending_and_race_check(&self.signal.pending);
            if raced {
                continue;
            }
            if total == 0 {
                self.signal.notify.notified().await;
                continue;
            }
            self.signal.notify.notified().await;
        }
    }

    pub async fn drain(&mut self, max: usize) -> usize {
        if max == 0 {
            return 0;
        }
        let mut drained = 0usize;
        while drained < max {
            match self.inner.recv().await {
                Ok(_v) => drained += 1,
                Err(RecvError::Lagged(_)) => {}
                Err(RecvError::Closed) => break,
            }
        }
        drained
    }

    #[inline]
    pub async fn await_notify(&self) {
        self.signal.notify.notified().await;
    }
    pub fn pending(&self) -> &core::sync::atomic::AtomicBool {
        &self.signal.pending
    }
}

#[cfg(feature = "bus_edge_notify")]
impl<T: Clone + Send + 'static> Drop for EdgeReceiver<T> {
    fn drop(&mut self) {
        // Mark one fewer active edge subscriber; Weak will GC later.
        self.registry.deregister();
    }
}

```

### crates/ron-kernel/src/bus/test.rs
<a id="crates-ron-kernel-src-bus-test-rs"></a>

```rust
/*!
Unit tests for the Bus contract (lives next to the implementation so it runs with unit tests too).

Contract under test:
- Zero subscribers: publish returns 0 and increments bus_no_receivers_total.
- One subscriber: publish returns 1 and does NOT increment bus_no_receivers_total again.

These are intentionally minimal: they do not receive messages; they only validate publish semantics + metrics.
*/

#![cfg(test)]

use crate::events::KernelEvent;
use crate::Metrics;

#[test]
fn publish_with_zero_subscribers_returns_zero_and_counts_metric() {
    let metrics = Metrics::new(false);
    let bus = metrics.make_bus(8);

    let before = metrics.bus_no_receivers_total.get();
    let delivered = bus.publish(KernelEvent::ConfigUpdated { version: 1 });
    assert_eq!(delivered, 0, "zero subscribers must yield 0");
    let after = metrics.bus_no_receivers_total.get();
    assert_eq!(
        after,
        before + 1,
        "bus_no_receivers_total must increment on publish with zero subscribers"
    );
}

#[test]
fn publish_with_one_subscriber_returns_one_and_metric_stays_flat() {
    let metrics = Metrics::new(false);
    let bus = metrics.make_bus(8);

    // establish baseline and add one subscriber
    let base = metrics.bus_no_receivers_total.get();
    let _rx = bus.subscribe();

    // publish and assert 1
    let delivered = bus.publish(KernelEvent::ConfigUpdated { version: 2 });
    assert_eq!(delivered, 1, "one subscriber must yield 1");

    // metric must not increment in this case
    let now = metrics.bus_no_receivers_total.get();
    assert_eq!(
        now, base,
        "bus_no_receivers_total must NOT increment when at least one subscriber exists"
    );
}

```

### crates/ron-kernel/src/bus/topic.rs
<a id="crates-ron-kernel-src-bus-topic-rs"></a>

```rust
//! RO:WHAT — Topic-scoped buses (internal utility).
//! RO:WHY  — Allows internal modules/tests to use name-scoped buses without changing public API.
//! RO:INTERACTS — bus::bounded::Bus, metrics (optional).
//! RO:INVARIANTS — No cross-topic delivery; lazy create; no external re-export.
//! RO:METRICS/LOGS — bus_topics_total (gauge).
//! RO:CONFIG — N/A.
//! RO:SECURITY — N/A.

#![allow(dead_code)]

use std::{collections::HashMap, sync::Arc};
use parking_lot::RwLock;

use super::bounded::Bus;
use crate::metrics::exporter::Metrics;

pub type Topic = &'static str;

#[derive(Default)]
pub struct TopicBus<T: Clone + Send + 'static> {
    inner: RwLock<HashMap<Topic, Bus<T>>>,
    metrics: Option<Arc<Metrics>>,
}

impl<T: Clone + Send + 'static> TopicBus<T> {
    pub fn new() -> Self {
        Self {
            inner: RwLock::new(HashMap::new()),
            metrics: None,
        }
    }

    pub fn with_metrics(mut self, metrics: Arc<Metrics>) -> Self {
        self.metrics = Some(metrics);
        self
    }

    pub fn topic(&self, name: Topic) -> Bus<T> {
        let mut guard = self.inner.write();
        if let Some(bus) = guard.get(name) {
            return bus.clone();
        }
        let bus = match &self.metrics {
            Some(m) => Bus::new().with_metrics(m.clone()),
            None => Bus::new(),
        };
        guard.insert(name, bus.clone());
        if let Some(m) = &self.metrics {
            // FIX: use the correct gauge field name from Metrics
            m.bus_topics_total.set(guard.len() as i64);
        }
        bus
    }
}

```

### crates/ron-kernel/src/config/cell.rs
<a id="crates-ron-kernel-src-config-cell-rs"></a>

```rust
//! RO:WHAT — Tiny interior-mutable holder for `Config` with get/set.
//! RO:WHY  — Several subsystems (watcher, HTTP surfaces) need a shared view.
//! RO:INTERACTS — Used by `config::watcher` to apply hot-reloads.
//! RO:INVARIANTS — Reads are lock-free clone; writes replace atomically.

use parking_lot::RwLock;
use std::sync::Arc;

use super::Config;

#[derive(Clone)]
pub struct ConfigCell {
    inner: Arc<RwLock<Config>>,
}

impl ConfigCell {
    pub fn new(init: Config) -> Self {
        Self {
            inner: Arc::new(RwLock::new(init)),
        }
    }

    /// Snapshot the current config (cheap clone).
    #[inline]
    pub fn get(&self) -> Config {
        self.inner.read().clone()
    }

    /// Replace with a new config, returning the old snapshot.
    #[inline]
    pub fn set(&self, new_cfg: Config) -> Config {
        let mut w = self.inner.write();
        let old = w.clone();
        *w = new_cfg;
        old
    }
}

```

### crates/ron-kernel/src/config/mod.rs
<a id="crates-ron-kernel-src-config-mod-rs"></a>

```rust
/*!
Config — load + hot-reload + event emission.

Rules:
- Precedence: ENV > FILE > DEFAULTS.
- Autobump version if a semantic toggle (e.g., amnesia) changes without explicit version.
- No-op writes do not emit `ConfigUpdated`.

Surface (kept minimal/by-canon):
- `Config` — current kernel config (version, amnesia).
- `ConfigUpdated` — DTO used by reload/apply decision paths.
- `ConfigCell` — tiny Arc<RwLock<Config>> for shared access (watcher/HTTP/etc.).
- `validation` — guardrails for field sanity.
- `watcher` — polling file-watcher that applies hot-reloads and emits events.
*/

use anyhow::{Context, Result};
use serde::{Deserialize, Serialize};
use std::{env, fs, path::Path};

// Submodules (exported)
pub mod cell;
pub mod validation;
pub mod watcher;

pub use cell::ConfigCell;

/// Kernel configuration loaded from file/env with sane defaults.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct Config {
    /// Monotonically increasing config version used to order updates.
    pub version: u64,
    /// When `true`, run in amnesia mode (RAM-only posture surfaced to metrics).
    pub amnesia: bool,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            version: 1,
            amnesia: true, // keep your current default; demo flips this live via watcher/ENV
        }
    }
}

/// DTO published on the bus when a new configuration becomes active.
#[derive(Debug, Clone)]
pub struct ConfigUpdated {
    /// Version that became active after reload/autobump.
    pub version: u64,
}

/// Load configuration from `path` (if it exists), then apply ENV overrides.
///
/// ENV precedence:
/// - `RON_AMNESIA` — truthy strings: `1|true|on|yes` (case-insensitive)
/// - `RON_VERSION` — `u64` parse
pub fn load_from(path: impl AsRef<Path>) -> Result<Config> {
    // Defaults
    let mut cfg = Config::default();

    // File
    if path.as_ref().exists() {
        let raw = fs::read_to_string(path.as_ref()).with_context(|| "read config file")?;
        let from_file: Config = toml::from_str(&raw).with_context(|| "parse toml")?;
        cfg = from_file;
    }

    // ENV overrides
    if let Ok(s) = env::var("RON_AMNESIA") {
        cfg.amnesia = is_truthy(&s);
    }

    if let Ok(v) = env::var("RON_VERSION") {
        cfg.version = v.parse::<u64>().with_context(|| "RON_VERSION parse")?;
    }

    // Final guardrails
    validation::validate(&cfg)?;

    Ok(cfg)
}

/// Compare `old` vs `new` and decide if we should emit `ConfigUpdated`.
///
/// Logic:
/// - No-op (identical) → `None`
/// - Only `amnesia` flipped and version unchanged → **autobump** and emit
/// - Any change with version increase → emit
pub fn apply_reload(old: &Config, mut new: Config) -> Option<ConfigUpdated> {
    if new == *old {
        return None;
    }

    // Guardrails (defensive): keep decisions on validated data.
    if validation::validate(&new).is_err() {
        // Invalid new config ⇒ do not emit; caller may log/telemetry an error.
        return None;
    }

    let amnesia_changed = new.amnesia != old.amnesia;
    let version_increased = new.version > old.version;

    if amnesia_changed && !version_increased {
        // Autobump: preserve monotonic versioning on semantic-only flips.
        new.version = old.version.saturating_add(1);
        return Some(ConfigUpdated {
            version: new.version,
        });
    }

    if version_increased || amnesia_changed {
        return Some(ConfigUpdated {
            version: new.version,
        });
    }

    None
}

/// Accepts "1|true|on|yes" (case-insensitive) as truthy; everything else is false.
#[inline]
fn is_truthy(s: &str) -> bool {
    matches!(
        s.trim().to_ascii_lowercase().as_str(),
        "1" | "true" | "on" | "yes"
    )
}

```

### crates/ron-kernel/src/config/validation.rs
<a id="crates-ron-kernel-src-config-validation-rs"></a>

```rust
//! RO:WHAT — Pure validation/sanitization for `Config`.
//! RO:WHY  — Keeps I/O out of validation; enables property/fuzz tests; SEC/RES concern.
//! RO:INTERACTS — config::watcher (apply), metrics/readiness (config_loaded), events.
//! RO:INVARIANTS — Deterministic; no side effects; clamps to safe ranges; deny unknown fields on struct.
//! RO:METRICS/LOGS — N/A.
//! RO:CONFIG — Validates {version, amnesia}; extend as struct grows.
//! RO:SECURITY — Reject malformed values early.
//! RO:TEST HOOKS — table tests; property: idempotent sanitize.

use crate::Config; // expected re-export at crate root per project notes

#[derive(thiserror::Error, Debug)]
pub enum ConfigError {
    #[error("version must be >= {0}")]
    InvalidVersion(u64),
}

const VERSION_MIN: u64 = 1;

/// Validate a config snapshot against canonical guardrails.
///
/// Current canon:
/// - `version` must be >= 1 (monotonic sequence used for ordering reloads)
/// - `amnesia` is a boolean (always valid)
pub fn validate(cfg: &Config) -> Result<(), ConfigError> {
    if cfg.version < VERSION_MIN {
        return Err(ConfigError::InvalidVersion(VERSION_MIN));
    }
    Ok(())
}

/// Sanitize a config by clamping to safe ranges, preserving semantics.
/// Idempotent: calling twice yields the same result.
///
/// Current canon:
/// - Clamp `version` to at least 1
/// - `amnesia` unchanged (boolean)
pub fn sanitize(mut cfg: Config) -> Result<Config, ConfigError> {
    if cfg.version < VERSION_MIN {
        cfg.version = VERSION_MIN;
    }
    // `amnesia` requires no changes.
    validate(&cfg)?;
    Ok(cfg)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn validate_ok() {
        let cfg = Config {
            version: 1,
            amnesia: false,
        };
        assert!(validate(&cfg).is_ok());
    }

    #[test]
    fn validate_rejects_version_zero() {
        let cfg = Config {
            version: 0,
            amnesia: true,
        };
        assert!(validate(&cfg).is_err());
    }

    #[test]
    fn sanitize_clamps_version_and_is_idempotent() {
        let cfg = Config {
            version: 0,
            amnesia: true,
        };
        let a = sanitize(cfg).unwrap();
        assert_eq!(a.version, 1);
        assert!(a.amnesia);

        let b = sanitize(a.clone()).unwrap();
        assert_eq!(a, b); // idempotent
    }
}

```

### crates/ron-kernel/src/config/watcher.rs
<a id="crates-ron-kernel-src-config-watcher-rs"></a>

```rust
//! RO:WHAT — Config watchers: filesystem (TOML) + env poller.
//! RO:WHY  — Hot-reload posture without blocking; keep amnesia gauge in sync.
//! RO:INVARIANTS — Non-blocking; no locks across .await; errors are logged and ignored; only emit on real change.

use anyhow::Context;
use notify::{
    Config as NotifyConfig, Event, EventKind, RecommendedWatcher, RecursiveMode, Watcher,
};
use std::{env, path::PathBuf, sync::Arc};
use tokio::{fs, sync::mpsc, task};

use super::{validation::validate, Config, ConfigCell};
use crate::bus::bounded::Bus;
use crate::events::KernelEvent;
use crate::Metrics;

/// Spawn a file watcher on a TOML file. On write/create, parse and apply if changed.
pub fn spawn_file_watcher(
    path: PathBuf,
    cell: ConfigCell,
    bus: Bus<KernelEvent>,
    metrics: Arc<Metrics>,
    autobump: bool,
) {
    let (tx, mut rx) = mpsc::unbounded_channel::<()>();

    // Blocking thread for notify (keeps OS handle alive).
    let path_clone = path.clone();
    let _handle = task::spawn_blocking(move || {
        let tx_inner = tx.clone();
        let mut watcher: RecommendedWatcher = RecommendedWatcher::new(
            move |res: Result<Event, notify::Error>| {
                if let Ok(event) = res {
                    match event.kind {
                        EventKind::Create(_) | EventKind::Modify(_) => {
                            let _ = tx_inner.send(());
                        }
                        _ => {}
                    }
                }
            },
            NotifyConfig::default(),
        )
        .expect("create watcher");

        watcher
            .watch(&path_clone, RecursiveMode::NonRecursive)
            .expect("watch path");

        loop {
            std::thread::park();
        }
    });

    // Async side: on signal, reload and apply.
    tokio::spawn(async move {
        while let Some(()) = rx.recv().await {
            if let Err(e) = reload_from_file(&path, &cell, &bus, &metrics, autobump).await {
                eprintln!("[kernel.config] failed to reload {:?}: {e:#}", path);
            }
        }
    });
}

/// Reload the config from TOML and apply it (only if changed). May autobump version.
async fn reload_from_file(
    path: &PathBuf,
    cell: &ConfigCell,
    bus: &Bus<KernelEvent>,
    metrics: &Arc<Metrics>,
    autobump: bool,
) -> anyhow::Result<()> {
    let bytes = fs::read(path)
        .await
        .with_context(|| format!("read {:?}", path))?;
    let text = String::from_utf8_lossy(&bytes);
    let mut file_cfg: Config =
        toml::from_str(&text).with_context(|| format!("parse TOML {:?}", path))?;

    // Validate before touching shared state.
    validate(&file_cfg).with_context(|| "validate file config")?;

    let old = cell.get();

    // CONTENT-based change: in our minimal config, content == {amnesia}
    let content_changed = old.amnesia != file_cfg.amnesia;

    if !autobump {
        // Strict mode: apply only when the whole struct differs.
        if old == file_cfg {
            return Ok(());
        }
        // Apply as-is (file controls version).
        cell.set(file_cfg.clone());
        metrics.set_amnesia(file_cfg.amnesia);
        let _ = bus.publish(KernelEvent::ConfigUpdated {
            version: file_cfg.version,
        });
        return Ok(());
    }

    // Autobump mode: apply only when content changes; set version = max(file.version, old.version + 1).
    if content_changed {
        if file_cfg.version <= old.version {
            file_cfg.version = old.version.saturating_add(1);
        }
        cell.set(file_cfg.clone());
        metrics.set_amnesia(file_cfg.amnesia);
        let _ = bus.publish(KernelEvent::ConfigUpdated {
            version: file_cfg.version,
        });
        return Ok(());
    }

    // No content change. Optionally adopt a higher version from file (no event).
    if file_cfg.version > old.version {
        let mut next = old.clone();
        next.version = file_cfg.version;
        cell.set(next);
        // No event — content unchanged; version-only bump is local bookkeeping.
    }

    Ok(())
}

/// Spawn an env poller that checks a single key and toggles amnesia on change.
/// Values: on|off|true|false|1|0 (case-insensitive). Emits only on real change; may autobump.
pub fn spawn_env_poller(
    key: &'static str,
    poll_secs: u64,
    cell: ConfigCell,
    bus: Bus<KernelEvent>,
    metrics: Arc<Metrics>,
    autobump: bool,
) {
    tokio::spawn(async move {
        // Seed from env on boot, if present.
        if let Some(v) = read_bool_env(key) {
            let old = cell.get();
            if old.amnesia != v {
                let mut next = old.clone();
                next.amnesia = v;
                if autobump {
                    next.version = next.version.saturating_add(1);
                }
                // Validate the prospective config before apply (should always pass).
                if validate(&next).is_ok() {
                    cell.set(next.clone());
                    metrics.set_amnesia(next.amnesia);
                    let _ = bus.publish(KernelEvent::ConfigUpdated {
                        version: next.version,
                    });
                }
            }
        }

        let mut last = read_bool_env(key);
        let mut interval = tokio::time::interval(std::time::Duration::from_secs(poll_secs));
        loop {
            interval.tick().await;
            let curr = read_bool_env(key);
            if curr != last {
                last = curr;
                if let Some(v) = curr {
                    let old = cell.get();
                    if old.amnesia != v {
                        let mut next = old.clone();
                        next.amnesia = v;
                        if autobump {
                            next.version = next.version.saturating_add(1);
                        }
                        if validate(&next).is_ok() {
                            cell.set(next.clone());
                            metrics.set_amnesia(next.amnesia);
                            let _ = bus.publish(KernelEvent::ConfigUpdated {
                                version: next.version,
                            });
                        }
                    }
                }
            }
        }
    });
}

/// Parse boolean-ish env values.
fn read_bool_env(key: &str) -> Option<bool> {
    env::var(key)
        .ok()
        .and_then(|s| match s.to_ascii_lowercase().as_str() {
            "1" | "true" | "on" | "yes" => Some(true),
            "0" | "false" | "off" | "no" => Some(false),
            _ => None,
        })
}

```

### crates/ron-kernel/src/events.rs
<a id="crates-ron-kernel-src-events-rs"></a>

```rust
//! RO:WHAT — KernelEvent enum shared across the kernel bus.
//! RO:WHY  — Central, stable event vocabulary for kernel interactions.
//! RO:INVARIANTS — Backward-compatible additions only; no breaking renames.

/// Events published on the kernel bus.
#[derive(Debug, Clone)]
pub enum KernelEvent {
    /// Health probe from a service (declarative signal).
    Health {
        /// Service name emitting the health status.
        service: String,
        /// Whether the service currently reports healthy.
        ok: bool,
    },
    /// Configuration updated to a monotonic version.
    ConfigUpdated {
        /// Version that became active.
        version: u64,
    },
    /// A supervised service crashed (supervisor should record+restart).
    ServiceCrashed {
        /// Service name that crashed.
        service: String,
    },
    /// Request orderly shutdown of the kernel.
    Shutdown,
}

```

### crates/ron-kernel/src/health/mod.rs
<a id="crates-ron-kernel-src-health-mod-rs"></a>

```rust
/*!
Health state — liveness vs readiness (degrade-first).

- Uses `parking_lot::RwLock` (faster, no poisoning).
- `all_ready()` governs `/readyz` (true → 200, false → 503 + `Retry-After: 1`).
- `missing()` returns a stable list for `/readyz` body.
*/

use parking_lot::RwLock;
use serde::{Deserialize, Serialize};
use std::sync::Arc;

/// Snapshot of coarse-grained health used by kernel/demo routes.
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct HealthSnapshot {
    /// True when essential services are running (supervisors satisfied).
    pub services_ok: bool,
    /// True when configuration load completed and is valid.
    pub config_loaded: bool,
    /// Current amnesia posture (observable; not part of readiness truth).
    pub amnesia: bool,
}

/// Mutable health state with cheap readers and exclusive writers.
#[derive(Debug, Default)]
pub struct HealthState {
    inner: RwLock<HealthSnapshot>,
}

impl HealthState {
    /// Construct a new health state wrapped in `Arc`.
    pub fn new() -> Arc<Self> {
        Arc::new(Self {
            inner: RwLock::new(HealthSnapshot::default()),
        })
    }

    /// Mutate the snapshot in place.
    pub fn set(&self, f: impl FnOnce(&mut HealthSnapshot)) {
        let mut guard = self.inner.write();
        f(&mut guard);
    }

    /// Obtain a cheap cloned snapshot.
    pub fn snapshot(&self) -> HealthSnapshot {
        self.inner.read().clone()
    }

    /// Readiness policy: *both* services and config must be OK.
    pub fn all_ready(&self) -> bool {
        let s = self.inner.read();
        s.services_ok && s.config_loaded
    }

    /// Names of components that currently prevent readiness.
    pub fn missing(&self) -> Vec<String> {
        let s = self.inner.read();
        let mut out = Vec::new();
        if !s.services_ok {
            out.push("services".to_string());
        }
        if !s.config_loaded {
            out.push("config".to_string());
        }
        out
    }
}

```

### crates/ron-kernel/src/internal/constants.rs
<a id="crates-ron-kernel-src-internal-constants-rs"></a>

```rust
//! RO:WHAT — Centralized constants for kernel tuning and invariants.
//! RO:WHY  — Keep perf/backpressure and retry limits consistent with blueprints (avoid drift).
//! RO:INTERACTS — bus capacity (bus::Bus), supervisor backoff (supervisor), readiness (metrics).
//! RO:INVARIANTS — bounded queues; backoff caps; no unbounded growth anywhere.

/// Default broadcast capacity per sender (bounded).
#[allow(dead_code)]
pub const DEFAULT_BUS_CAPACITY: usize = 4096;

/// Supervisor backoff: initial delay in milliseconds.
pub const SUP_BACKOFF_MS_START: u64 = 100;

/// Supervisor backoff cap in milliseconds (jittered up to this).
pub const SUP_BACKOFF_MS_CAP: u64 = 30_000;

```

### crates/ron-kernel/src/internal/mod.rs
<a id="crates-ron-kernel-src-internal-mod-rs"></a>

```rust
//! RO:WHAT — Internal glue (non-public) for kernel constants and helpers.
//! RO:WHY  — Keep public surface frozen; avoid leaking new types.
//! RO:INTERACTS — constants used by bus/supervisor; not re-exported.
pub mod constants;

```

### crates/ron-kernel/src/internal/types.rs
<a id="crates-ron-kernel-src-internal-types-rs"></a>

```rust
//! RO:WHAT — Internal shared type aliases and small enums.
//! RO:WHY  — Reduces duplication and drift across modules; GOV/RES concern.
//! RO:INTERACTS — supervisor, metrics, bus, readiness, config.
//! RO:INVARIANTS — No heavy deps; stable aliases only; no cross-await locks introduced.
//! RO:METRICS/LOGS — N/A.
//! RO:CONFIG — N/A.
//! RO:SECURITY — N/A.
//! RO:TEST HOOKS — Type-only; covered transitively by module tests.

use std::time::Duration;

pub type ServiceName = &'static str;
pub type Version = u64;
pub type Millis = u64;
pub type BoxError = Box<dyn std::error::Error + Send + Sync + 'static>;

/// Default bounded channel capacity for the in-process bus.
pub const DEFAULT_BUS_CAPACITY: usize = 1024;

/// Reason a supervised child stopped.
#[derive(Debug, Clone)]
pub enum CrashReason {
    Panic(String),
    Exit(i32),
    Oom,
    Error(String),
    Unknown,
}

/// Jitter bounds helper.
#[inline]
pub fn clamp_duration(v: Duration, min: Duration, max: Duration) -> Duration {
    if v < min {
        min
    } else if v > max {
        max
    } else {
        v
    }
}

```

### crates/ron-kernel/src/lib.rs
<a id="crates-ron-kernel-src-lib-rs"></a>

```rust
//! # ron-kernel — microkernel core
//!
//! RO:WHAT
//!   Crate root for the RustyOnions microkernel. Exposes the frozen public API:
//!   `Bus`, `KernelEvent`, `Metrics`, `HealthState`, `Config`, and `wait_for_ctrl_c()`.
//!
//! RO:WHY
//!   Provide lifecycle/supervision, readiness gates, config hot-reload, bounded event bus,
//!   and canonical observability surfaces (/metrics, /healthz, /readyz) for nodes.
//!
//! RO:INVARIANTS
//!   - Public API is semver-guarded; perf toggles live behind features and default OFF.
//!   - Readiness contract: `/readyz` returns 503 until BOTH (config_loaded && services_healthy).
//!   - Concurrency: no locks across `.await`; bounded channels; one receiver per task.
//!   - Amnesia mode surfaced via metrics (`amnesia_mode` gauge) and events.
//!
//! See: `examples/kernel_demo` for an integration sanity run.
#![forbid(unsafe_code)]
#![deny(clippy::all, clippy::pedantic)]
#![allow(clippy::module_name_repetitions)]

/// A3 helper — capacity autotune — re-exported at crate root for stable imports in tests/benches.
#[cfg(feature = "bus_autotune_cap")]
pub use crate::bus::autotune_capacity;

// -----------------------------------------------------------------------------
// Internal structure
// -----------------------------------------------------------------------------

pub mod internal {
    pub mod types;
}

pub mod amnesia;

pub mod events; // KernelEvent enum
pub mod shutdown; // wait_for_ctrl_c()

// IMPORTANT: use the directory module so we pick up `bus/mod.rs` and its feature wiring.
// (Previously this was an inline `pub mod bus { ... }`, which prevented `bus/mod.rs` from loading.)
pub mod bus;

pub mod metrics;

// Use your existing config module (which itself may declare submodules like watcher/validation)
pub mod config;

// Supervision
pub mod supervisor {
    pub mod backoff;
    pub mod child;
    pub mod lifecycle;
}

// -----------------------------------------------------------------------------
// Frozen public API re-exports (SemVer-guarded)
// -----------------------------------------------------------------------------
pub use crate::bus::bounded::Bus;
pub use crate::config::Config;
pub use crate::events::KernelEvent;
pub use crate::metrics::exporter::Metrics;
pub use crate::metrics::health::HealthState;
pub use crate::shutdown::wait_for_ctrl_c;

// If you maintain an experimental MOG helper module at crate root, keep this.
// If it doesn't exist in your tree, comment/remove the next line to avoid compile errors.
pub mod mog_autotune;

```

### crates/ron-kernel/src/metrics/buffer.rs
<a id="crates-ron-kernel-src-metrics-buffer-rs"></a>

```rust
//! RO:WHAT — Thread-local metric buffers for hot-path counters (feature: metrics_buf).
//! RO:WHY  — PERF: remove atomics from publish path; flush deltas on a timer or threshold.
//! RO:INTERACTS — metrics::exporter::Metrics (Prometheus registry)
//! RO:INVARIANTS — no locks across .await on hot path; best-effort flush on drop
//! RO:METRICS — bus_metrics_tls_flush_total (+ existing counters)
//! RO:CONFIG — flush interval (ms), flush threshold (events)
//! RO:TEST — unit: tls_no_loss_on_drop(); fuzz: interleaved_flush_ordering()

#![cfg(feature = "metrics_buf")]

use prometheus::IntCounter;
use std::{cell::Cell, sync::Arc};
use tokio::sync::Mutex;

thread_local! {
    static PUBLISHED_BUF: Cell<u64> = const { Cell::new(0) };
    static NOTIFY_BUF:    Cell<u64> = const { Cell::new(0) };
}

// Shared sinks owned by the exporter; hot path writes to TLS cells and we flush into these.
#[derive(Clone)]
pub struct BufferedSinks {
    pub published: IntCounter,
    pub notify: IntCounter,
    pub tls_flush_total: IntCounter,
    // threshold for flushing TLS buffers
    flush_threshold: Arc<usize>,
}

impl BufferedSinks {
    pub fn new(
        published: IntCounter,
        notify: IntCounter,
        tls_flush_total: IntCounter,
        flush_threshold: usize,
    ) -> Self {
        // Guardrail: enforce a minimum of 64 to avoid per-message flush in prod.
        Self {
            published,
            notify,
            tls_flush_total,
            flush_threshold: Arc::new(flush_threshold.max(64)),
        }
    }

    #[inline]
    pub fn add_published(&self, n: u64) {
        if n == 0 {
            return;
        }
        PUBLISHED_BUF.with(|c| c.set(c.get().saturating_add(n)));
        self.maybe_flush();
    }

    #[inline]
    pub fn add_notify(&self, n: u64) {
        if n == 0 {
            return;
        }
        NOTIFY_BUF.with(|c| c.set(c.get().saturating_add(n)));
        self.maybe_flush();
    }

    #[inline]
    fn maybe_flush(&self) {
        let thr = *self.flush_threshold as u64;
        let mut do_flush = false;
        PUBLISHED_BUF.with(|c| {
            if c.get() >= thr {
                do_flush = true;
            }
        });
        NOTIFY_BUF.with(|c| {
            if c.get() >= thr {
                do_flush = true;
            }
        });
        if do_flush {
            self.flush();
        }
    }

    pub fn flush(&self) {
        let mut p = 0u64;
        let mut n = 0u64;
        PUBLISHED_BUF.with(|c| {
            p = c.get();
            c.set(0);
        });
        NOTIFY_BUF.with(|c| {
            n = c.get();
            c.set(0);
        });
        if p != 0 {
            self.published.inc_by(p);
        }
        if n != 0 {
            self.notify.inc_by(n);
        }
        if p != 0 || n != 0 {
            self.tls_flush_total.inc();
        }
    }
}

// Background pump handle (periodically flush TLS buffers into shared counters).
#[derive(Clone)]
pub struct FlushPump {
    sinks: BufferedSinks,
    // keep a stop latch if you want (not strictly required in the kernel's long-lived proc)
    stop: Arc<Mutex<bool>>,
}

impl FlushPump {
    pub fn new(sinks: BufferedSinks) -> Self {
        Self {
            sinks,
            stop: Arc::new(Mutex::new(false)),
        }
    }

    /// Convenience for exporter: build a pump from the hot counters facade.
    pub fn new_from_hot(hot: Arc<HotCounters>) -> Self {
        // Same module, can access the inner to clone sinks.
        Self::new(hot.0.clone())
    }

    pub async fn run(self, interval_ms: u64) {
        let mut ticker =
            tokio::time::interval(std::time::Duration::from_millis(interval_ms.max(1)));
        loop {
            ticker.tick().await;
            if *self.stop.lock().await {
                break;
            }
            self.sinks.flush();
        }
    }
}

// Public facade used by the bus (hot path).
#[derive(Clone)]
pub struct HotCounters(pub(super) BufferedSinks);

impl HotCounters {
    pub fn new(sinks: BufferedSinks) -> Self {
        Self(sinks)
    }
    #[inline]
    pub fn inc_published(&self) {
        self.0.add_published(1);
    }
    #[inline]
    pub fn add_published(&self, n: u64) {
        self.0.add_published(n);
    }
    #[inline]
    pub fn inc_notify(&self) {
        self.0.add_notify(1);
    }
}

/// Best-effort drop flush to avoid counter loss on thread teardown.
impl Drop for HotCounters {
    fn drop(&mut self) {
        self.0.flush();
    }
}

```

### crates/ron-kernel/src/metrics/exporter.rs
<a id="crates-ron-kernel-src-metrics-exporter-rs"></a>

```rust
//! RO:WHAT — Prometheus exporter + metrics registry; mounts /metrics, /healthz, /readyz.
//! RO:WHY  — Observability pillar; RED metrics and kernel signals for ops; PERF/RES concerns.
//! RO:PERF — Optional thread-local metrics buffering (feature: `metrics_buf`) removes atomics from the hot path.
//! RO:MOG  — A1/A5 edge notify counters; A2 batch publish counters; TLS buffer flush counter.

use std::{net::SocketAddr, sync::Arc};

use axum::{routing::get, Router};
use prometheus::{
    Encoder, Histogram, HistogramOpts, IntCounter, IntCounterVec, IntGauge, Opts, Registry,
    TextEncoder,
};
use tokio::{net::TcpListener, task::JoinHandle};

use crate::internal::types::{BoxError, ServiceName};
use crate::metrics::{health::HealthState, readiness::Readiness};
use crate::Bus;

#[cfg(feature = "metrics_buf")]
use crate::metrics::buffer::{BufferedSinks, FlushPump, HotCounters};

/// Kernel metrics registry and handles.
#[derive(Clone)]
pub struct Metrics {
    pub registry: Registry,
    pub request_latency_seconds: Histogram,

    pub service_restarts_total: IntCounterVec,

    // Bus counters/gauges
    pub bus_published_total: IntCounter,
    pub bus_no_receivers_total: IntCounter,
    pub bus_receiver_lag_total: IntCounter,
    pub bus_dropped_total: IntCounter,
    pub bus_topics_total: IntGauge,

    // MOG A1/A5 telemetry
    pub bus_notify_sends_total: IntCounter,
    pub bus_notify_suppressed_total: IntCounter,

    // MOG A2 telemetry
    pub bus_batch_publish_total: IntCounter,
    pub bus_batch_len_histogram: Histogram,

    // TLS metrics buffering visibility
    #[cfg(feature = "metrics_buf")]
    pub bus_metrics_tls_flush_total: IntCounter,

    // Expose configured TLS threshold as a gauge for easy verification
    #[cfg(feature = "metrics_buf")]
    pub bus_metrics_tls_threshold: IntGauge,

    pub amnesia_mode: IntGauge,

    // Hot-path counters facade (kept behind Arc to avoid per-call Drop)
    #[cfg(feature = "metrics_buf")]
    hot: Option<Arc<HotCounters>>,
}

impl Metrics {
    pub fn new(initial_amnesia: bool) -> Arc<Self> {
        let registry = Registry::new();

        let request_latency_seconds = Histogram::with_opts(
            HistogramOpts::new(
                "request_latency_seconds",
                "Kernel request latency (seconds)",
            )
            .buckets(vec![
                0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0,
            ]),
        )
        .expect("histogram");

        let service_restarts_total = IntCounterVec::new(
            Opts::new(
                "service_restarts_total",
                "Total restarts of supervised services",
            ),
            &["service"],
        )
        .expect("counter vec");

        let bus_published_total = IntCounter::with_opts(Opts::new(
            "bus_published_total",
            "Total messages published on kernel bus",
        ))
        .unwrap();
        let bus_no_receivers_total = IntCounter::with_opts(Opts::new(
            "bus_no_receivers_total",
            "Publishes with zero receivers",
        ))
        .unwrap();
        let bus_receiver_lag_total = IntCounter::with_opts(Opts::new(
            "bus_receiver_lag_total",
            "Lagged/missed messages observed by receivers",
        ))
        .unwrap();
        let bus_dropped_total = IntCounter::with_opts(Opts::new(
            "bus_dropped_total",
            "Messages dropped due to closed/overrun channel",
        ))
        .unwrap();
        let bus_topics_total = IntGauge::with_opts(Opts::new(
            "bus_topics_total",
            "Number of distinct topic buses",
        ))
        .unwrap();

        // A1/A5
        let bus_notify_sends_total = IntCounter::with_opts(Opts::new(
            "bus_notify_sends_total",
            "Edge-triggered notifies sent to subscribers",
        ))
        .unwrap();
        let bus_notify_suppressed_total = IntCounter::with_opts(Opts::new(
            "bus_notify_suppressed_total",
            "Notifies suppressed by pending=true (coalesced)",
        ))
        .unwrap();

        // A2
        let bus_batch_publish_total = IntCounter::with_opts(Opts::new(
            "bus_batch_publish_total",
            "Calls to publish_many (A2)",
        ))
        .unwrap();
        let bus_batch_len_histogram = Histogram::with_opts(
            HistogramOpts::new("bus_batch_len_histogram", "publish_many batch sizes (A2)").buckets(
                vec![
                    1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0, 512.0, 1024.0,
                ],
            ),
        )
        .expect("histogram");

        // Amnesia gauge
        let amnesia_mode =
            IntGauge::with_opts(Opts::new("amnesia_mode", "1 when amnesia mode is enabled"))
                .unwrap();

        // Register all
        registry
            .register(Box::new(request_latency_seconds.clone()))
            .unwrap();
        registry
            .register(Box::new(service_restarts_total.clone()))
            .unwrap();
        registry
            .register(Box::new(bus_published_total.clone()))
            .unwrap();
        registry
            .register(Box::new(bus_no_receivers_total.clone()))
            .unwrap();
        registry
            .register(Box::new(bus_receiver_lag_total.clone()))
            .unwrap();
        registry
            .register(Box::new(bus_dropped_total.clone()))
            .unwrap();
        registry
            .register(Box::new(bus_topics_total.clone()))
            .unwrap();
        registry
            .register(Box::new(bus_notify_sends_total.clone()))
            .unwrap();
        registry
            .register(Box::new(bus_notify_suppressed_total.clone()))
            .unwrap();
        registry
            .register(Box::new(bus_batch_publish_total.clone()))
            .unwrap();
        registry
            .register(Box::new(bus_batch_len_histogram.clone()))
            .unwrap();
        registry.register(Box::new(amnesia_mode.clone())).unwrap();

        // TLS buffering metrics
        #[cfg(feature = "metrics_buf")]
        let bus_metrics_tls_flush_total = {
            let c = IntCounter::with_opts(Opts::new(
                "bus_metrics_tls_flush_total",
                "TLS metrics buffer flushes (visibility when buffering is enabled)",
            ))
            .unwrap();
            registry.register(Box::new(c.clone())).ok();
            c
        };

        #[cfg(feature = "metrics_buf")]
        let bus_metrics_tls_threshold = {
            let g = IntGauge::with_opts(Opts::new(
                "bus_metrics_tls_threshold",
                "Configured TLS flush threshold",
            ))
            .unwrap();
            registry.register(Box::new(g.clone())).ok();
            g
        };

        // Choose and publish the threshold; construct sinks + hot facade.
        #[cfg(feature = "metrics_buf")]
        let (hot, chosen_threshold) = {
            let threshold: usize = 64; // tune under benches (64..512)
            let sinks = BufferedSinks::new(
                bus_published_total.clone(),
                bus_notify_sends_total.clone(),
                bus_metrics_tls_flush_total.clone(),
                threshold,
            );
            (Some(Arc::new(HotCounters::new(sinks))), threshold)
        };

        #[cfg(feature = "metrics_buf")]
        {
            bus_metrics_tls_threshold.set(chosen_threshold as i64);
            tracing::info!(
                threshold = chosen_threshold,
                "metrics_buf enabled; TLS flush threshold configured"
            );
        }

        let me = Arc::new(Self {
            registry,
            request_latency_seconds,
            service_restarts_total,
            bus_published_total,
            bus_no_receivers_total,
            bus_receiver_lag_total,
            bus_dropped_total,
            bus_topics_total,
            bus_notify_sends_total,
            bus_notify_suppressed_total,
            bus_batch_publish_total,
            bus_batch_len_histogram,
            #[cfg(feature = "metrics_buf")]
            bus_metrics_tls_flush_total,
            #[cfg(feature = "metrics_buf")]
            bus_metrics_tls_threshold,
            amnesia_mode,
            #[cfg(feature = "metrics_buf")]
            hot,
        });

        me.set_amnesia(initial_amnesia);
        me
    }

    pub fn set_amnesia(&self, on: bool) {
        self.amnesia_mode.set(if on { 1 } else { 0 });
    }

    /// Start HTTP server exposing /metrics, /healthz, /readyz.
    pub async fn serve(
        self: Arc<Self>,
        addr: SocketAddr,
        health: HealthState,
        ready: Readiness,
    ) -> Result<(JoinHandle<()>, SocketAddr), BoxError> {
        let listener = TcpListener::bind(addr).await?;
        let local = listener.local_addr()?;

        let registry = self.registry.clone();
        let app = Router::new()
            .route(
                "/metrics",
                get(move || {
                    let registry = registry.clone();
                    async move {
                        let mf = registry.gather();
                        let mut buf = Vec::new();
                        TextEncoder::new().encode(&mf, &mut buf).unwrap();
                        (axum::http::StatusCode::OK, buf)
                    }
                }),
            )
            .route(
                "/healthz",
                get({
                    let health = health.clone();
                    move || crate::metrics::health::healthz_handler(health.clone())
                }),
            )
            .route(
                "/readyz",
                get({
                    let ready = ready.clone();
                    move || crate::metrics::readiness::readyz_handler(ready.clone())
                }),
            );

        let handle = tokio::spawn(async move {
            axum::serve(listener, app).await.ok();
        });

        #[cfg(feature = "metrics_buf")]
        if let Some(hot) = self.hot.clone() {
            let pump = FlushPump::new_from_hot(hot);
            tokio::spawn(async move { pump.run(200).await }); // ~200ms cadence
        }

        Ok((handle, local))
    }

    pub fn inc_restart(&self, service: ServiceName) {
        self.service_restarts_total
            .with_label_values(&[service])
            .inc();
    }

    pub fn make_bus<T: Clone + Send + 'static>(self: &Arc<Self>, capacity: usize) -> Bus<T> {
        use crate::bus::bounded::Bus;
        Bus::with_capacity(capacity).with_metrics(self.clone())
    }

    #[cfg(feature = "metrics_buf")]
    #[inline]
    pub fn hot(&self) -> Option<&HotCounters> {
        self.hot.as_deref()
    }
}

```

### crates/ron-kernel/src/metrics/health.rs
<a id="crates-ron-kernel-src-metrics-health-rs"></a>

```rust
use std::collections::BTreeMap;
use std::sync::Arc;

use axum::{response::IntoResponse, Json};
use parking_lot::RwLock;

use crate::internal::types::ServiceName;

#[derive(Clone)]
pub struct HealthState {
    inner: Arc<RwLock<BTreeMap<ServiceName, bool>>>,
}

impl HealthState {
    pub fn new() -> Self {
        Self {
            inner: Arc::new(RwLock::new(BTreeMap::new())),
        }
    }

    pub fn set(&self, service: ServiceName, ok: bool) {
        let mut w = self.inner.write();
        w.insert(service, ok);
    }

    pub fn snapshot(&self) -> BTreeMap<ServiceName, bool> {
        self.inner.read().clone()
    }

    pub fn all_ready(&self) -> bool {
        // Not ready until at least one service has reported AND all are healthy.
        let r = self.inner.read();
        !r.is_empty() && r.values().all(|v| *v)
    }
}

pub async fn healthz_handler(state: HealthState) -> impl IntoResponse {
    if state.all_ready() {
        let body = serde_json::to_value(state.snapshot()).unwrap();
        (axum::http::StatusCode::OK, Json(body))
    } else {
        let body = state
            .snapshot()
            .into_iter()
            .filter(|(_, ok)| !*ok)
            .map(|(k, _)| k)
            .collect::<Vec<_>>();
        (
            axum::http::StatusCode::SERVICE_UNAVAILABLE,
            Json(serde_json::json!({ "unhealthy": body })),
        )
    }
}

impl Default for HealthState {
    fn default() -> Self {
        Self::new()
    }
}

```

### crates/ron-kernel/src/metrics/mod.rs
<a id="crates-ron-kernel-src-metrics-mod-rs"></a>

```rust
//! RO:WHAT — Metrics module index and re-exports for RON-CORE.
//! RO:WHY  — Centralize exporter + health + readiness; expose optional TLS buffering at `metrics::buffer`.

pub mod exporter;
pub mod health;
pub mod readiness;

// Declare the submodule *unconditionally* so the name `crate::metrics::buffer` always exists.
// The file itself is feature-gated internally, so this is safe in all builds.
pub mod buffer;

// Re-export the primary metrics type so call-sites can use `crate::metrics::Metrics`.
pub use exporter::Metrics;

// Convenience re-exports (common call-sites).
pub use health::HealthState;
pub use readiness::Readiness;

```

### crates/ron-kernel/src/metrics/readiness.rs
<a id="crates-ron-kernel-src-metrics-readiness-rs"></a>

```rust
use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc,
};

use axum::{response::IntoResponse, Json};

use crate::metrics::health::HealthState;

#[derive(Clone)]
pub struct Readiness {
    health: HealthState,
    config_loaded: Arc<AtomicBool>,
}

impl Readiness {
    pub fn new(health: HealthState) -> Self {
        Self {
            health,
            config_loaded: Arc::new(AtomicBool::new(false)),
        }
    }

    pub fn set_config_loaded(&self, yes: bool) {
        self.config_loaded.store(yes, Ordering::Relaxed);
    }

    pub fn ready(&self) -> bool {
        self.config_loaded.load(Ordering::Relaxed) && self.health.all_ready()
    }
}

pub async fn readyz_handler(state: Readiness) -> axum::response::Response {
    if state.ready() {
        (
            axum::http::StatusCode::OK,
            Json(serde_json::json!({ "ready": true })),
        )
            .into_response()
    } else {
        let mut missing = vec![];
        if !state
            .config_loaded
            .load(std::sync::atomic::Ordering::Relaxed)
        {
            missing.push("config");
        }
        if !state.health.all_ready() {
            missing.push("services");
        }
        let mut resp = axum::response::Response::new(
            serde_json::to_vec(&serde_json::json!({ "missing": missing }))
                .unwrap()
                .into(),
        );
        *resp.status_mut() = axum::http::StatusCode::SERVICE_UNAVAILABLE;
        resp.headers_mut()
            .insert("Retry-After", axum::http::HeaderValue::from_static("3"));
        resp
    }
}

```

### crates/ron-kernel/src/mog_autotune.rs
<a id="crates-ron-kernel-src-mogautotune-rs"></a>

```rust
/*!
MOG A3 — Capacity Autotune + Guardrails (feature: `bus_autotune_cap`)

Purpose:
- Provide a safe, side-effect free helper to pick a ring/channel capacity from the expected load.
- This does NOT mutate global state; callers must opt-in to use it.

Integration:
- Call `autotune_capacity(expected_subs, override_cap)` from your Bus builder.
- If `override_cap` is `Some`, it wins (after normalization).
- Otherwise (feature ON) we choose plateaus: <=4 → 64, <=16 → 128, else → 256.
- Feature OFF: conservative 128 default.

Observability:
- Warn if finalized capacity >256 (cache-hostile territory for typical workloads).

Safety:
- No panics. Always returns >= 2. Overrides are rounded to power-of-two and clamped.
*/

#![allow(dead_code)] // until wired in by a builder

use core::cmp::{max, min};

/// Guardrail constants.
const MIN_CAP: usize = 2;
const MAX_CAP: usize = 65_536;

// Plateau levels (power-of-two, cache-friendly)
const PLATEAU_SMALL: usize = 64;
const PLATEAU_MED: usize = 128;
const PLATEAU_LARGE: usize = 256;

/// Returns a recommended capacity given the expected subscriber count
/// and an optional explicit override.
///
/// Feature gating:
/// - `bus_autotune_cap` **enabled**: use plateau heuristic when `override_cap` is None.
/// - Feature **disabled**: honor override (normalized) or fall back to 128.
///
/// Invariants:
/// - Never returns < 2.
/// - Final result is rounded to the next power-of-two and clamped to [2, 65_536].
#[allow(unused_variables)]
pub fn autotune_capacity(expected_subs: usize, override_cap: Option<usize>) -> usize {
    // 1) If caller provides override, it wins after normalization & guardrails.
    if let Some(c) = override_cap {
        return finalize_cap(c);
    }

    // 2) Otherwise pick via heuristic (if feature enabled), or a conservative default.
    let raw = {
        cfg_if::cfg_if! {
            if #[cfg(feature = "bus_autotune_cap")] {
                if expected_subs <= 4 {
                    PLATEAU_SMALL
                } else if expected_subs <= 16 {
                    PLATEAU_MED
                } else {
                    PLATEAU_LARGE
                }
            } else {
                // Feature disabled: predictable default before guardrails.
                128
            }
        }
    };

    // 3) Apply guardrails uniformly (also handles any future changes safely).
    finalize_cap(raw)
}

/// Apply guardrails to any incoming capacity (from override or heuristic):
/// - minimum of 2
/// - clamped to 65_536
/// - rounded up to next power-of-two
/// - warns if result > 256 (likely cache-hostile for typical workloads)
#[inline(always)]
fn finalize_cap(cap: usize) -> usize {
    let bounded = min(max(cap, MIN_CAP), MAX_CAP);
    let pow2 = next_pow2(bounded);

    if pow2 > PLATEAU_LARGE {
        tracing::warn!(
            cap = pow2,
            "bus_autotune_cap: capacity >256 is likely cache-hostile; consider 64/128/256 unless proven otherwise"
        );
    }
    pow2
}

/// Round up to the next power-of-two with a floor of 2.
#[inline(always)]
fn next_pow2(n: usize) -> usize {
    if n <= MIN_CAP {
        return MIN_CAP;
    }
    // `next_power_of_two` on usize is well-defined for n>0 and will not overflow
    // under our clamp (MAX_CAP = 65_536).
    n.next_power_of_two()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn override_is_normalized_pow2_and_clamped() {
        assert_eq!(autotune_capacity(0, Some(1)), 2);
        assert_eq!(autotune_capacity(0, Some(3)), 4);
        assert_eq!(autotune_capacity(0, Some(64)), 64);
        assert_eq!(autotune_capacity(0, Some(65_000)), 65_536);
        assert_eq!(autotune_capacity(0, Some(100_000)), 65_536);
    }

    #[test]
    fn default_when_disabled_is_reasonable() {
        // This holds regardless of feature; with feature ON, values are >=64,
        // with feature OFF default is 128 before guardrails.
        let cap = autotune_capacity(8, None);
        assert!(cap >= 64);
        assert!(cap <= MAX_CAP);
    }

    #[test]
    fn heuristic_plateaus_are_expected_when_enabled() {
        // These assertions hold for feature-enabled builds; for feature-off they
        // still validate general bounds.
        let small = autotune_capacity(1, None);
        let mid = autotune_capacity(8, None);
        let big = autotune_capacity(32, None);

        assert!(small >= PLATEAU_SMALL, "small expected ≥64, got {}", small);
        assert!(
            mid >= PLATEAU_SMALL && mid <= PLATEAU_LARGE,
            "mid in [64,256], got {}",
            mid
        );
        assert!(big >= PLATEAU_MED, "big expected ≥128, got {}", big);
        assert!(big <= MAX_CAP);
    }
}

```

### crates/ron-kernel/src/shutdown.rs
<a id="crates-ron-kernel-src-shutdown-rs"></a>

```rust
//! RO:WHAT — Helper to await Ctrl+C for cooperative shutdown.
//! RO:WHY  — Common pattern for binaries to align with kernel readiness and graceful stop.
//! RO:INTERACTS — May be used to trigger KernelEvent::Shutdown by callers (kernel doesn't emit it automatically).
//! RO:INVARIANTS — async-signal safe; no blocking in Drop.

/// Wait for a Ctrl+C signal.
pub async fn wait_for_ctrl_c() {
    let _ = tokio::signal::ctrl_c().await;
}

```

### crates/ron-kernel/src/supervisor/backoff.rs
<a id="crates-ron-kernel-src-supervisor-backoff-rs"></a>

```rust
//! RO:WHAT — Jittered exponential backoff with cap and reset.
//! RO:WHY  — Prevents thundering herds on crash-loops; RES concern.
//! RO:INTERACTS — lifecycle.rs (sleep scheduling), child.rs (restart cadence).
//! RO:INVARIANTS — Monotone until cap; jitter bounded; no panics on edge cases.
//! RO:METRICS/LOGS — None (observed externally by restart counters).
//! RO:CONFIG — init/max/factor/jitter ranges validated by config layer.
//! RO:SECURITY — N/A.
//! RO:TEST HOOKS — unit: sequence grows; jitter within bounds; reset works.

use rand::{rng, Rng};
use std::time::Duration;

#[derive(Debug, Clone)]
pub struct Backoff {
    current: Duration,
    init: Duration,
    max: Duration,
    factor: f64,
    jitter: f64, // 0.2 => ±20%
}

impl Backoff {
    pub fn new(init: Duration, max: Duration, factor: f64, jitter: f64) -> Self {
        let init = if init.is_zero() {
            Duration::from_millis(100)
        } else {
            init
        };
        let max = if max < init { init } else { max };
        let factor = if factor < 1.0 { 1.0 } else { factor };
        let jitter = jitter.clamp(0.0, 1.0);
        Self {
            current: init,
            init,
            max,
            factor,
            jitter,
        }
    }

    pub fn next(&mut self) -> Duration {
        let base = self.current;
        // prepare next (monotone up to cap)
        let next =
            Duration::from_secs_f64((base.as_secs_f64() * self.factor).min(self.max.as_secs_f64()));
        self.current = next;

        // apply jitter to current sleep (the 'base' value)
        if self.jitter == 0.0 {
            return base;
        }
        let j = rng().random_range(-self.jitter..=self.jitter);
        let secs = base.as_secs_f64() * (1.0 + j);
        Duration::from_secs_f64(secs.clamp(self.init.as_secs_f64(), self.max.as_secs_f64()))
    }

    pub fn reset(&mut self) {
        self.current = self.init;
    }
}

```

### crates/ron-kernel/src/supervisor/child.rs
<a id="crates-ron-kernel-src-supervisor-child-rs"></a>

```rust
use std::future::Future;
use tokio::task;

use crate::events::KernelEvent;
use crate::internal::types::{BoxError, ServiceName};
use crate::metrics::exporter::Metrics;
use crate::Bus;

pub async fn run_once<F, Fut>(
    name: ServiceName,
    metrics: &Metrics,
    bus: &Bus<KernelEvent>,
    work: F,
) -> Result<(), BoxError>
where
    F: Fn() -> Fut + Send + Sync + 'static,
    Fut: Future<Output = Result<(), BoxError>> + Send + 'static,
{
    let join = task::spawn(async move { work().await }).await;

    match join {
        Ok(Ok(())) => {
            metrics.inc_restart(name);
            bus.publish(KernelEvent::ServiceCrashed {
                service: name.to_string(),
            });
            Ok(())
        }
        Ok(Err(e)) => {
            metrics.inc_restart(name);
            bus.publish(KernelEvent::ServiceCrashed {
                service: name.to_string(),
            });
            Err(e)
        }
        Err(_join_err) => {
            metrics.inc_restart(name);
            bus.publish(KernelEvent::ServiceCrashed {
                service: name.to_string(),
            });
            Ok(())
        }
    }
}

```

### crates/ron-kernel/src/supervisor/lifecycle.rs
<a id="crates-ron-kernel-src-supervisor-lifecycle-rs"></a>

```rust
use std::collections::VecDeque;
use std::time::{Duration, Instant};

use crate::events::KernelEvent;
use crate::internal::types::{BoxError, ServiceName};
use crate::metrics::{exporter::Metrics, health::HealthState};
use crate::Bus;

use super::backoff::Backoff;
use super::child::run_once;

pub struct Supervisor {
    name: ServiceName,
    metrics: Metrics,
    bus: Bus<KernelEvent>,
    health: HealthState,
    backoff: Backoff,
    max_restarts: u32,
    window: Duration,
    recent: VecDeque<Instant>,
}

impl Supervisor {
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        name: ServiceName,
        metrics: Metrics,
        bus: Bus<KernelEvent>,
        health: HealthState,
        backoff: Backoff,
        max_restarts: u32,
        window: Duration,
    ) -> Self {
        Self {
            name,
            metrics,
            bus,
            health,
            backoff,
            max_restarts,
            window,
            recent: VecDeque::with_capacity(max_restarts as usize + 1),
        }
    }

    pub async fn run<F, Fut>(&mut self, work: F) -> !
    where
        F: Fn() -> Fut + Send + Sync + Clone + 'static,
        Fut: std::future::Future<Output = Result<(), BoxError>> + Send + 'static,
    {
        self.health.set(self.name, true);
        loop {
            let factory = work.clone();
            let _ = run_once(self.name, &self.metrics, &self.bus, factory).await;
            self.health.set(self.name, false);

            let now = Instant::now();
            self.recent.push_back(now);
            while let Some(&front) = self.recent.front() {
                if now.duration_since(front) > self.window {
                    self.recent.pop_front();
                } else {
                    break;
                }
            }
            if self.recent.len() as u32 > self.max_restarts {
                let _ = self.backoff.next();
                let cap = self.backoff.next();
                tokio::time::sleep(cap).await;
                continue;
            }

            let sleep = self.backoff.next();
            tokio::time::sleep(sleep).await;
            self.health.set(self.name, true);
        }
    }
}

```

### crates/ron-kernel/src/supervisor/mod.rs
<a id="crates-ron-kernel-src-supervisor-mod-rs"></a>

```rust
//! RO:WHAT — Crash-only supervision with jittered exponential backoff and labeled restart metrics.
//! RO:WHY  — RESilience: children may crash; we restart with backoff and publish ServiceCrashed.
//! RO:INTERACTS — metrics::Metrics (service_restarts_total{service}); bus::Bus (ServiceCrashed).
//! RO:INVARIANTS — jittered backoff (100ms→30s cap), intensity cap optional; no lock across .await.

use crate::{events::KernelEvent, metrics::Metrics};
use anyhow::Result;
use rand::{rng, Rng};
use std::future::Future;
use tokio::time::{sleep, Duration};

fn jitter_ms(base: u64) -> u64 {
    if base <= 1 {
        return 1;
    }
    let mut r = rng();
    let half = base / 2;
    half + r.random_range(0..half.max(1))
}

/// Supervise an async child factory. On error, increments labeled restart metric and emits ServiceCrashed.
/// The `spawn` closure should create a fresh future each attempt.
pub async fn supervise_with_backoff<Fut, Spawn>(
    service: &str,
    metrics: Metrics,
    bus: crate::bus::Bus,
    mut spawn: Spawn,
) -> !
where
    Fut: Future<Output = Result<()>> + Send + 'static,
    Spawn: FnMut() -> Fut + Send + 'static,
{
    let service_name = service.to_string();
    let mut backoff = crate::internal::constants::SUP_BACKOFF_MS_START;

    loop {
        let res = spawn().await;
        if let Err(err) = res {
            // Publish crash and count a restart.
            let _ = bus.publish(KernelEvent::ServiceCrashed {
                service: service_name.clone(),
                reason: err.to_string(),
            });
            metrics
                .service_restarts_total
                .with_label_values(&[&service_name])
                .inc();
        }
        // Sleep with jitter (cap at 30s).
        backoff = (backoff.saturating_mul(2)).min(crate::internal::constants::SUP_BACKOFF_MS_CAP);
        let sleep_ms = jitter_ms(backoff);
        sleep(Duration::from_millis(sleep_ms)).await;
    }
}

#[cfg(test)]
mod tests {
    use super::jitter_ms;

    #[test]
    fn jitter_is_within_bounds_and_nonzero() {
        // Basic sanity: jitter must be at least 1 and not exceed base.
        for &base in &[2, 4, 8, 16, 32, 64, 128] {
            let j = jitter_ms(base);
            assert!(j >= 1, "jitter must be >=1");
            assert!(j <= base, "jitter must be <= base (got {} for {})", j, base);
        }
        // Base 1 -> clamped to 1.
        assert_eq!(jitter_ms(1), 1);
        assert_eq!(jitter_ms(0), 1);
    }
}

```

### crates/ron-kernel/testing/performance/publish_matrix.toml
<a id="crates-ron-kernel-testing-performance-publishmatrix-toml"></a>

```toml
[runs.default]
publish_rps = [100, 500, 1000]
fanout = [1, 4, 8]
duration_secs = 30

```

### crates/ron-kernel/tests/amnesia_label.rs
<a id="crates-ron-kernel-tests-amnesialabel-rs"></a>

```rust
use ron_kernel::Metrics;

#[test]
fn amnesia_gauge_flips_between_0_and_1() {
    let metrics = Metrics::new(false);

    // starts at 0
    assert_eq!(metrics.amnesia_mode.get(), 0);

    // flip on -> 1
    metrics.set_amnesia(true);
    assert_eq!(metrics.amnesia_mode.get(), 1);

    // flip off -> 0
    metrics.set_amnesia(false);
    assert_eq!(metrics.amnesia_mode.get(), 0);
}

```

### crates/ron-kernel/tests/autotune_capacity.rs
<a id="crates-ron-kernel-tests-autotunecapacity-rs"></a>

```rust
#![cfg(feature = "bus_autotune_cap")]
use ron_kernel::autotune_capacity;

#[test]
fn mapping_basic_thresholds() {
    assert_eq!(autotune_capacity(0, None), 64);
    assert_eq!(autotune_capacity(1, None), 64);
    assert_eq!(autotune_capacity(4, None), 64);
    assert_eq!(autotune_capacity(5, None), 128);
    assert_eq!(autotune_capacity(16, None), 128);
    assert_eq!(autotune_capacity(17, None), 256);
    assert_eq!(autotune_capacity(64, None), 256);
}

#[test]
fn override_is_respected() {
    assert_eq!(autotune_capacity(1, Some(128)), 128);
    assert_eq!(autotune_capacity(32, Some(64)), 64);
}

#[test]
fn monotone_in_n_with_default_map() {
    let mut prev = 0;
    for n in 0..200 {
        let cap = autotune_capacity(n, None);
        assert!(cap >= prev);
        prev = cap;
    }
}

```

### crates/ron-kernel/tests/autotune_sanity.rs
<a id="crates-ron-kernel-tests-autotunesanity-rs"></a>

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn bench_autotune(c: &mut Criterion) {
    let mut g = c.benchmark_group("autotune");
    g.bench_function("expected_4_none", |b| {
        b.iter(|| {
            let mut sum = 0usize;
            for n in 0..1000 {
                // Call through a small trampoline to avoid LTO folding in release.
                sum ^= tramp(4 + (n & 1));
            }
            black_box(sum)
        })
    });
    g.finish();
}

#[inline(never)]
fn tramp(expected: usize) -> usize {
    ron_kernel::mog_autotune::autotune_capacity(expected, None)
}

criterion_group!(benches, bench_autotune);
criterion_main!(benches);

```

### crates/ron-kernel/tests/bus_basics.rs
<a id="crates-ron-kernel-tests-busbasics-rs"></a>

```rust
use ron_kernel::{Bus, KernelEvent, Metrics};

#[tokio::test]
async fn zero_and_one_subscriber_paths() {
    let metrics = Metrics::new(false);
    let bus: Bus<KernelEvent> = Bus::new().with_metrics(metrics.clone());

    // 0 subscribers -> publish returns 0
    let delivered = bus.publish(KernelEvent::Shutdown);
    assert_eq!(
        delivered, 0,
        "no subscribers -> delivered count should be 0"
    );

    // subscribe one receiver -> publish returns 1
    let mut rx = bus.subscribe();
    let delivered2 = bus.publish(KernelEvent::Shutdown);
    assert_eq!(delivered2, 1, "one subscriber -> delivered should be 1");

    // drain without lag (and exercise helper)
    let _ = Bus::handle_recv(rx.recv().await, Some(&metrics));
}

```

### crates/ron-kernel/tests/bus_bounded.rs
<a id="crates-ron-kernel-tests-busbounded-rs"></a>

```rust
//! Bounded bus: lag accounting and publish semantics.

use ron_kernel::{Bus, KernelEvent, Metrics};

#[tokio::test]
async fn lagged_receiver_increments_lag_counter_and_publish_counts() {
    let metrics = Metrics::new(false);
    // small capacity to force lag quickly
    let bus: Bus<KernelEvent> = Bus::with_capacity(8).with_metrics(metrics.clone());
    let mut rx = bus.subscribe();

    // With one subscriber, publish returns 1
    let n = bus.publish(KernelEvent::ConfigUpdated { version: 1 });
    assert_eq!(n, 1);

    // Overflow receiver by sending many without reading
    for i in 0..2048usize {
        let _ = bus.publish(KernelEvent::ConfigUpdated { version: i as u64 });
    }

    // Receiver sees either a value or Lagged; account via helper
    let _ = Bus::handle_recv(rx.recv().await, Some(&metrics));

    // We should have observed some lag
    assert!(
        metrics.bus_receiver_lag_total.get() > 0,
        "expected bus_receiver_lag_total to increase"
    );
}

```

### crates/ron-kernel/tests/bus_close_semantics.rs
<a id="crates-ron-kernel-tests-busclosesemantics-rs"></a>

```rust
//! When the sender is dropped, broadcast receivers observe `Closed`.

use ron_kernel::Bus;

#[tokio::test]
async fn receiver_observes_closed_on_sender_drop() {
    let bus: Bus<String> = Bus::with_capacity(8);
    let mut rx = bus.subscribe();

    // Drop all senders (cloned senders would need dropping too; we have only one)
    drop(bus);

    // Receiver should now get Err(Closed)
    let res = rx.recv().await;
    assert!(matches!(
        res,
        Err(tokio::sync::broadcast::error::RecvError::Closed)
    ));
}

```

### crates/ron-kernel/tests/bus_contract.rs
<a id="crates-ron-kernel-tests-buscontract-rs"></a>

```rust
use ron_kernel::{Bus, KernelEvent, Metrics};

#[tokio::test]
async fn publish_zero_subscribers_counts_and_returns_zero() {
    let metrics = Metrics::new(false);
    let bus: Bus<KernelEvent> = Bus::new().with_metrics(metrics.clone());

    let n = bus.publish(KernelEvent::Shutdown);
    assert_eq!(n, 0);

    let m = bus.publish(KernelEvent::Shutdown);
    assert_eq!(m, 0);
}

#[tokio::test]
async fn publish_with_subscriber_returns_one() {
    let metrics = Metrics::new(false);
    let bus: Bus<KernelEvent> = Bus::new().with_metrics(metrics.clone());
    let mut rx = bus.subscribe();

    let n = bus.publish(KernelEvent::Shutdown);
    assert_eq!(n, 1);

    let _ = Bus::handle_recv(rx.recv().await, Some(&metrics));
}

#[tokio::test]
async fn lagged_receiver_increments_lag_counter() {
    let metrics = Metrics::new(false);
    let bus: Bus<String> = Bus::new().with_metrics(metrics.clone());
    let mut rx = bus.subscribe();

    for i in 0..2048 {
        let _ = bus.publish(format!("m{i}"));
    }

    let _ = Bus::handle_recv(rx.recv().await, Some(&metrics));
}

```

### crates/ron-kernel/tests/edge_notify_loom.rs
<a id="crates-ron-kernel-tests-edgenotifyloom-rs"></a>

```rust
#![cfg(all(feature = "bus_edge_notify", feature = "loom"))]

//! RO:WHAT
//!   Loom litmus tests for lost-wake and drain-after-clear races.
//!
//! RO:WHY
//!   Ensure the pending bit pattern guarantees no lost wakeups.
//!
//! NOTE
//!   Uses `loom`'s std shims; keep test tiny to avoid state explosion.

use loom::sync::Arc;
use loom::thread;
use std::sync::atomic::{AtomicBool, Ordering};

#[test]
fn lost_wake_is_prevented() {
    loom::model(|| {
        let pending = Arc::new(AtomicBool::new(false));

        // Publisher: set pending and "notify if 0->1".
        let p = {
            let pending = pending.clone();
            thread::spawn(move || {
                let was = pending.swap(true, Ordering::Relaxed);
                // if !was { notify(); }  // modeled implicitly
                was
            })
        };

        // Subscriber: drain, clear, then race-check.
        let s = {
            let pending = pending.clone();
            thread::spawn(move || {
                // drain_all(); // modeled as already drained
                pending.store(false, Ordering::Relaxed);
                // race check
                let raced = pending.swap(false, Ordering::Relaxed);
                if raced {
                    // re-arm
                    pending.store(true, Ordering::Relaxed);
                }
                raced
            })
        };

        let _pub_was_pending = p.join().unwrap();
        let raced = s.join().unwrap();

        // If publisher observed 0->1 and subscriber cleared, either:
        // - race detected (raced=true), subscriber will continue draining
        // - or subscriber awaits but pending remains true (observed by next poll)
        // We assert that *eventually* pending is true if race happened.
        if raced {
            assert!(pending.load(Ordering::Relaxed));
        }
    });
}

```

### crates/ron-kernel/tests/health_ready.rs
<a id="crates-ron-kernel-tests-healthready-rs"></a>

```rust
//! Readiness and health endpoints: handler semantics (no actual HTTP client).
use std::net::SocketAddr;

use axum::http::StatusCode;
use ron_kernel::metrics::readiness::{readyz_handler, Readiness};
use ron_kernel::{HealthState, Metrics};

#[tokio::test]
async fn readiness_transitions_to_ok_when_config_and_services_ready() {
    let metrics = Metrics::new(false);
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());

    // Start server just to ensure the router builds; we won't fetch it here.
    let (_handle, _addr) = metrics
        .clone()
        .serve(
            "127.0.0.1:0".parse::<SocketAddr>().unwrap(),
            health.clone(),
            ready.clone(),
        )
        .await
        .unwrap();

    // Initially not ready (config not loaded)
    let resp = readyz_handler(ready.clone()).await;
    assert_eq!(resp.status(), StatusCode::SERVICE_UNAVAILABLE);

    // Make both gates true
    ready.set_config_loaded(true);
    health.set("svc", true);

    // Now the handler should return 200 OK
    let ok_resp = readyz_handler(ready.clone()).await;
    assert_eq!(ok_resp.status(), StatusCode::OK);
}

```

### crates/ron-kernel/tests/loom_bus.rs
<a id="crates-ron-kernel-tests-loombus-rs"></a>

```rust
//! Loom interleavings for Bus subscribe/publish ensure no panics or deadlocks.
//! Run with: cargo test -p ron-kernel --features loom -- --nocapture

#![cfg(feature = "loom")]

use loom::thread;
use ron_kernel::{Bus, KernelEvent, Metrics};

#[test]
fn bus_publish_subscribe_concurrent() {
    loom::model(|| {
        let metrics = Metrics::new(false);
        let bus: Bus<KernelEvent> = metrics.make_bus(8);

        let bus_pub = bus.clone();
        let t_pub = thread::spawn(move || {
            let _ = bus_pub.publish(KernelEvent::Shutdown);
            let _ = bus_pub.publish(KernelEvent::ConfigUpdated { version: 1 });
        });

        let bus_sub = bus.clone();
        let t_sub = thread::spawn(move || {
            let mut rx = bus_sub.subscribe();
            let _ = rx.recv();
            let _ = rx.recv();
        });

        t_pub.join().unwrap();
        t_sub.join().unwrap();
    });
}

```

### crates/ron-kernel/tests/metrics_amnesia.rs
<a id="crates-ron-kernel-tests-metricsamnesia-rs"></a>

```rust
//! Ensures amnesia_mode gauge flips 0 <-> 1 and is exposed by the exporter.

use prometheus::Encoder; // brings TextEncoder::encode into scope
use ron_kernel::metrics::health::HealthState;
use ron_kernel::metrics::readiness::Readiness;
use ron_kernel::Metrics;

#[tokio::test]
async fn amnesia_mode_gauge_flips_and_exports() {
    let metrics = Metrics::new(false);

    // Sanity: initial seed should be 0
    {
        // NOTE: 'registry' is a field on Metrics; metrics is Arc<Metrics>
        let families = (*metrics).registry.gather();
        let mut buf = Vec::new();
        prometheus::TextEncoder::new()
            .encode(&families, &mut buf)
            .unwrap();
        let text = String::from_utf8(buf).unwrap();
        assert!(
            text.contains("amnesia_mode 0"),
            "expected amnesia_mode 0 at start, got:\n{text}"
        );
    }

    metrics.set_amnesia(true);
    {
        let families = (*metrics).registry.gather();
        let mut buf = Vec::new();
        prometheus::TextEncoder::new()
            .encode(&families, &mut buf)
            .unwrap();
        let text = String::from_utf8(buf).unwrap();
        assert!(
            text.contains("amnesia_mode 1"),
            "expected amnesia_mode 1 after flip, got:\n{text}"
        );
    }

    // Boot the HTTP exporter quickly to catch regressions in wiring.
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());
    ready.set_config_loaded(true);
    health.set("kernel", true);

    let (_handle, bound) = metrics
        .clone()
        .serve("127.0.0.1:0".parse().unwrap(), health, ready)
        .await
        .unwrap();
    assert_ne!(bound.port(), 0);
}

```

### crates/ron-kernel/tests/metrics_smoke.rs
<a id="crates-ron-kernel-tests-metricssmoke-rs"></a>

```rust
//! Smoke test: Metrics::serve mounts routes and binds successfully.

use std::net::SocketAddr;

use ron_kernel::metrics::readiness::Readiness;
use ron_kernel::{HealthState, Metrics};

#[tokio::test]
async fn metrics_server_binds_and_runs() {
    let metrics = Metrics::new(false);
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());

    // Toggle minimal readiness so /readyz can return 200 once needed
    ready.set_config_loaded(true);
    health.set("kernel", true);

    let addr: SocketAddr = "127.0.0.1:0".parse().unwrap();
    let (handle, bound) = metrics
        .clone()
        .serve(addr, health.clone(), ready.clone())
        .await
        .unwrap();

    // bound should be a real ephemeral port
    assert_ne!(bound.port(), 0);

    // shut it down
    handle.abort();
}

```

### crates/ron-kernel/tests/property_config.rs
<a id="crates-ron-kernel-tests-propertyconfig-rs"></a>

```rust
//! Aligns integer values with float checks.

use ron_kernel::Metrics;

#[test]
fn property_config_sanity_numbers_cast() {
    // this test just needs Metrics in scope; we don't actually use it.
    let _metrics = Metrics::new(false);

    // pretend these came from a config (i64s):
    let v0: i64 = 0;
    let v1: i64 = 1;
    let v2: i64 = 0;

    // cast to f64 before float math
    assert!((v0 as f64 - 0.0).abs() < f64::EPSILON);
    assert!((v1 as f64 - 1.0).abs() < f64::EPSILON);
    assert!((v2 as f64 - 0.0).abs() < f64::EPSILON);
}

```

### crates/ron-kernel/tests/public_api.rs
<a id="crates-ron-kernel-tests-publicapi-rs"></a>

```rust
//! Verifies the frozen public API is re-exported at the crate root.
//! Fails to compile if any item disappears or moves.

use ron_kernel::{wait_for_ctrl_c, Bus, Config, HealthState, KernelEvent, Metrics};

#[test]
fn api_compiles_and_names_resolve() {
    // Type names resolve? good enough for compile-time surface guard.
    let _ = std::any::type_name::<Bus<KernelEvent>>();
    let _ = std::any::type_name::<Metrics>();
    let _ = std::any::type_name::<HealthState>();
    let _ = std::any::type_name::<Config>();
    let _ = wait_for_ctrl_c as fn() -> _;
}

```

### crates/ron-kernel/tests/readiness_degrades.rs
<a id="crates-ron-kernel-tests-readinessdegrades-rs"></a>

```rust
//! /readyz returns 503 until both gates (config_loaded & services_ok) are true.

use axum::http::StatusCode;
use ron_kernel::metrics::health::HealthState;
use ron_kernel::metrics::readiness::{readyz_handler, Readiness};
use ron_kernel::Metrics;

#[tokio::test]
async fn readiness_degrades_then_ok() {
    let _metrics = Metrics::new(false); // ensures registry initialized, but not required here
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());

    // Initially: both gates false -> 503
    let resp = readyz_handler(ready.clone()).await;
    assert_eq!(resp.status(), StatusCode::SERVICE_UNAVAILABLE);

    // Flip just one gate -> still 503
    ready.set_config_loaded(true);
    let resp = readyz_handler(ready.clone()).await;
    assert_eq!(resp.status(), StatusCode::SERVICE_UNAVAILABLE);

    // Flip services_ok via HealthState -> 200
    health.set("kernel", true);
    let resp = readyz_handler(ready.clone()).await;
    assert_eq!(resp.status(), StatusCode::OK);
}

```

### crates/ron-kernel/tests/soa_smoke.rs
<a id="crates-ron-kernel-tests-soasmoke-rs"></a>

```rust
//! RO:WHAT — Integration smoke for SoA backend under the `bus_soa` feature.
//! RO:WHY  — Ensure crate-level feature compiles & basic flows hold.

#![cfg(feature = "bus_soa")]

use ron_kernel::bus::bounded::Bus; // bounded is re-exported to SoA when feature=bus_soa
use tokio::runtime::Runtime;

#[test]
fn feature_compiles_and_basic_flow_ok() {
    let rt = Runtime::new().unwrap();
    rt.block_on(async {
        let bus: Bus<u64> = Bus::with_capacity(16);
        let mut rx = bus.subscribe();
        let _rc = bus.publish(42);
        // bounded-style: recv returns Result<T, Lagged>, use handle_recv to map to Option
        let got = Bus::handle_recv(rx.recv().await, None);
        assert_eq!(got, Some(42));
    });
}

```

### crates/ron-kernel/tests/supervisor_backoff.rs
<a id="crates-ron-kernel-tests-supervisorbackoff-rs"></a>

```rust
use ron_kernel::Metrics;

/// Minimal invariant: the supervisor restart counter should be usable and
/// monotonically increasing under a service label. This stands in until the
/// real supervisor backoff is wired.
#[test]
fn service_restart_counter_increments_monotonically() {
    let metrics = Metrics::new(false);

    // Simulate a supervisor incrementing a labeled counter.
    let ctr = metrics.service_restarts_total.with_label_values(&["demo"]);

    let before = ctr.get();
    ctr.inc();
    let after1 = ctr.get();
    assert_eq!(after1, before + 1, "inc() should add exactly 1");

    ctr.inc_by(5);
    let after2 = ctr.get();
    assert_eq!(after2, after1 + 5, "inc_by(5) should add exactly 5");
}

```

### crates/ron-kernel/tests/supervisor_backoff_integ.rs
<a id="crates-ron-kernel-tests-supervisorbackoffinteg-rs"></a>

```rust
use std::time::{Duration, Instant};

use ron_kernel::metrics::readiness::Readiness;
use ron_kernel::supervisor::{backoff::Backoff, lifecycle::Supervisor};
use ron_kernel::{Bus, HealthState, KernelEvent, Metrics};

#[tokio::test]
async fn supervisor_restarts_and_backoff_grows() {
    let metrics = Metrics::new(false);
    let health = HealthState::new();
    let ready = Readiness::new(health.clone());
    ready.set_config_loaded(true);

    let bus: Bus<KernelEvent> = Bus::new().with_metrics(metrics.clone());

    let work =
        || async { Err::<(), Box<dyn std::error::Error + Send + Sync + 'static>>("fail".into()) };

    let mut sup = Supervisor::new(
        "testsvc",
        (*metrics).clone(),
        bus.clone(),
        health.clone(),
        Backoff::new(
            Duration::from_millis(100),
            Duration::from_millis(400),
            2.0,
            0.0,
        ),
        100,
        Duration::from_secs(10),
    );

    let start = Instant::now();
    let h = tokio::spawn(async move { sup.run(work).await });

    tokio::time::sleep(Duration::from_millis(850)).await;
    h.abort();

    // read the counter from the *_total vec
    let c = metrics
        .service_restarts_total
        .with_label_values(&["testsvc"])
        .get();
    assert!(c >= 3, "expected >=3 restarts, got {}", c);

    let elapsed = start.elapsed();
    assert!(elapsed >= Duration::from_millis(300));
}

```

### crates/ron-kernel/tests/tls_type_invariance.rs
<a id="crates-ron-kernel-tests-tlstypeinvariance-rs"></a>

```rust
//! Compile-time guard: the crate must use `tokio_rustls::rustls::ServerConfig`.
//! If someone swaps to `rustls::ServerConfig` directly, this test will fail to compile.

#[test]
fn tls_type_is_tokio_rustls_serverconfig() {
    // This function will fail to compile if the type path is wrong.
    fn _requires_tokio_rustls(_: &tokio_rustls::rustls::ServerConfig) {}

    // Name resolution check (uses the type so clippy doesn’t flag it as unused).
    let _typename = std::any::type_name::<tokio_rustls::rustls::ServerConfig>();

    // Keep a phantom value to ensure the path remains valid across refactors.
    let _phantom: Option<&tokio_rustls::rustls::ServerConfig> = None;

    // No runtime assertions needed—the compile-time type checks above are the point.
}

```

### crates/ron-kernel/tests/watcher_integ.rs
<a id="crates-ron-kernel-tests-watcherinteg-rs"></a>

```rust
//! Integration glue: exercise ConfigUpdated emission + amnesia gauge flip.

use std::fs;
use std::time::Duration;

use ron_kernel::{Bus, KernelEvent, Metrics};

#[tokio::test]
async fn amnesia_flip_emits_single_update() {
    let dir = tempfile::tempdir().unwrap();
    let cfg_path = dir.path().join("ron-kernel.toml");
    fs::write(
        &cfg_path,
        "amnesia = false\nhttp_port = 0\nrequest_timeout_ms = 1000\n",
    )
    .unwrap();

    let metrics = Metrics::new(false);
    let bus: Bus<KernelEvent> = Bus::new().with_metrics(metrics.clone());
    let mut rx = bus.subscribe();

    // Simulate watcher apply; replace with real watcher if present.
    tokio::spawn({
        let metrics = metrics.clone();
        let bus = bus.clone();
        async move {
            metrics.set_amnesia(true);
            bus.publish(KernelEvent::ConfigUpdated { version: 1 });
        }
    });

    let mut updates = 0u32;
    let deadline = tokio::time::Instant::now() + Duration::from_millis(500);

    loop {
        let now = tokio::time::Instant::now();
        if now >= deadline {
            break;
        }
        let remaining = deadline - now;

        // Bound this await so the loop can re-check the deadline.
        match tokio::time::timeout(remaining, rx.recv()).await {
            Ok(Ok(ev)) => {
                if let KernelEvent::ConfigUpdated { .. } = ev {
                    updates += 1;
                }
            }
            Ok(Err(_lagged)) => {
                // Ignore lag for this test: we're only counting ConfigUpdated.
            }
            Err(_elapsed) => {
                // No message before deadline — exit loop.
                break;
            }
        }
    }

    assert_eq!(updates, 1, "expected exactly one ConfigUpdated");
    metrics.set_amnesia(false);
}

```



---



# ron-bus

_Source: crates/ron-bus/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:47:47Z -->
# Code Bundle — `ron-bus`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-bus/.cargo/config.toml](#crates-ron-bus--cargo-config-toml)
- [crates/ron-bus/.clippy.toml](#crates-ron-bus--clippy-toml)
- [crates/ron-bus/.github/workflows/ci.yml](#crates-ron-bus--github-workflows-ci-yml)
- [crates/ron-bus/.github/workflows/coverage.yml](#crates-ron-bus--github-workflows-coverage-yml)
- [crates/ron-bus/.github/workflows/nightly-chaos.yml](#crates-ron-bus--github-workflows-nightly-chaos-yml)
- [crates/ron-bus/.github/workflows/render-mermaid.yml](#crates-ron-bus--github-workflows-render-mermaid-yml)
- [crates/ron-bus/Cargo.toml](#crates-ron-bus-Cargo-toml)
- [crates/ron-bus/benches/ab_compare.rs](#crates-ron-bus-benches-abcompare-rs)
- [crates/ron-bus/benches/latency.rs](#crates-ron-bus-benches-latency-rs)
- [crates/ron-bus/benches/overflow.rs](#crates-ron-bus-benches-overflow-rs)
- [crates/ron-bus/benches/throughput.rs](#crates-ron-bus-benches-throughput-rs)
- [crates/ron-bus/deny.toml](#crates-ron-bus-deny-toml)
- [crates/ron-bus/examples/publish_smoke.rs](#crates-ron-bus-examples-publishsmoke-rs)
- [crates/ron-bus/rust-toolchain.toml](#crates-ron-bus-rust-toolchain-toml)
- [crates/ron-bus/scripts/smoke_ron_bus.sh](#crates-ron-bus-scripts-smokeronbus-sh)
- [crates/ron-bus/scripts/update_api_snapshot.sh](#crates-ron-bus-scripts-updateapisnapshot-sh)
- [crates/ron-bus/src/bus.rs](#crates-ron-bus-src-bus-rs)
- [crates/ron-bus/src/config.rs](#crates-ron-bus-src-config-rs)
- [crates/ron-bus/src/errors.rs](#crates-ron-bus-src-errors-rs)
- [crates/ron-bus/src/event.rs](#crates-ron-bus-src-event-rs)
- [crates/ron-bus/src/internal/channel.rs](#crates-ron-bus-src-internal-channel-rs)
- [crates/ron-bus/src/internal/depth_estimator.rs](#crates-ron-bus-src-internal-depthestimator-rs)
- [crates/ron-bus/src/internal/mod.rs](#crates-ron-bus-src-internal-mod-rs)
- [crates/ron-bus/src/lib.rs](#crates-ron-bus-src-lib-rs)
- [crates/ron-bus/src/metrics.rs](#crates-ron-bus-src-metrics-rs)
- [crates/ron-bus/src/prelude.rs](#crates-ron-bus-src-prelude-rs)
- [crates/ron-bus/tests/api_surface.rs](#crates-ron-bus-tests-apisurface-rs)
- [crates/ron-bus/tests/capacity_cutover.rs](#crates-ron-bus-tests-capacitycutover-rs)
- [crates/ron-bus/tests/chaos_amnesia.rs](#crates-ron-bus-tests-chaosamnesia-rs)
- [crates/ron-bus/tests/fanout_ok.rs](#crates-ron-bus-tests-fanoutok-rs)
- [crates/ron-bus/tests/graceful_shutdown.rs](#crates-ron-bus-tests-gracefulshutdown-rs)
- [crates/ron-bus/tests/lagged_overflow_smoke.rs](#crates-ron-bus-tests-laggedoverflowsmoke-rs)
- [crates/ron-bus/tests/loom_model.rs](#crates-ron-bus-tests-loommodel-rs)
- [crates/ron-bus/tests/pq_labels_feature.rs](#crates-ron-bus-tests-pqlabelsfeature-rs)
- [crates/ron-bus/tests/property_bus.rs](#crates-ron-bus-tests-propertybus-rs)
- [crates/ron-bus/tests/receiver_ownership.rs](#crates-ron-bus-tests-receiverownership-rs)

### crates/ron-bus/.cargo/config.toml
<a id="crates-ron-bus--cargo-config-toml"></a>

```toml
[alias]
lint = "clippy -p ron-bus -- -D warnings"
test-all = "test -p ron-bus --all-features"
ci-check = "fmt --all && clippy -D warnings && test -p ron-bus"
bench-all = "bench -p ron-bus"

```

### crates/ron-bus/.clippy.toml
<a id="crates-ron-bus--clippy-toml"></a>

```toml
# Keep lock-across-await and pedantic checks tight (placeholder)
warn-on-all-wildcard-imports = true

```

### crates/ron-bus/.github/workflows/ci.yml
<a id="crates-ron-bus--github-workflows-ci-yml"></a>

```yaml
name: ci
on: [push, pull_request]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: 1.80.0
          components: rustfmt, clippy
      - run: cargo fmt --all --check
      - run: cargo clippy -p ron-bus2 -- -D warnings
      - run: cargo test -p ron-bus2 --all-features
      - run: cargo test -p ron-bus2 --doc

```

### crates/ron-bus/.github/workflows/coverage.yml
<a id="crates-ron-bus--github-workflows-coverage-yml"></a>

```yaml
name: coverage
on:
  push:
    branches: [ main ]
  pull_request:
jobs:
  cover:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: 1.80.0
      - name: Run coverage (placeholder)
        run: echo "Implement tarpaulin/grcov coverage here with Bronze/Silver/Gold thresholds"

```

### crates/ron-bus/.github/workflows/nightly-chaos.yml
<a id="crates-ron-bus--github-workflows-nightly-chaos-yml"></a>

```yaml
name: nightly-chaos
on:
  schedule:
    - cron: "0 3 * * *"
jobs:
  chaos:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: 1.80.0
      - name: Run ignored chaos tests (placeholder)
        run: cargo test -p ron-bus2 -- --ignored --nocapture

```

### crates/ron-bus/.github/workflows/render-mermaid.yml
<a id="crates-ron-bus--github-workflows-render-mermaid-yml"></a>

```yaml
name: render-mermaid
on: [push, pull_request]
jobs:
  mmdc:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm i -g @mermaid-js/mermaid-cli
      - run: |
          mkdir -p docs/diagrams
          for f in $(git ls-files 'docs/diagrams/*.mmd'); do
            out="${f%.mmd}.svg"
            mmdc -i "$f" -o "$out"
          done

```

### crates/ron-bus/Cargo.toml
<a id="crates-ron-bus-Cargo-toml"></a>

```toml
[package]
name = "ron-bus"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
description = "RustyOnions in-process broadcast bus (bounded, lossy, observable-by-host)"
rust-version = "1.80"
readme = "README.md"
repository = "https://example.com/RustyOnions" # update when ready

[features]
default = []
tracing = ["dep:tracing"]
pq-labels = []            # labels-only; no crypto here
loom = []                 # dev-only (cfg guarded in tests)

[dependencies]
tokio = { version = "1.48.0", features = ["sync", "rt", "macros", "time"] }
tracing = { version = "0.1.41", optional = true }
serde = { version = "1.0", features = ["derive"], optional = true }

[dev-dependencies]
tokio = { version = "1.48.0", features = ["rt-multi-thread", "macros", "time", "sync"] }
loom = "0.7"
criterion = "0.5"
flume = "0.11"
async-channel = "2"


[[bench]]
name = "throughput"
harness = false

[[bench]]
name = "latency"
harness = false

[[bench]]
name = "ab_compare"
harness = false


[[example]]
name = "publish_smoke"

```

### crates/ron-bus/benches/ab_compare.rs
<a id="crates-ron-bus-benches-abcompare-rs"></a>

```rust
//! RO:WHAT  — A/B microbench: ron-bus vs tokio::broadcast vs flume/async-channel.
//! RO:WHY   — Credible, apples-to-apples comparison for README claims.
//! RO:INTERACTS — ron_bus::{Bus, BusConfig, Event}; tokio runtime controlled here.
//! RO:INVARIANTS — Same fanout/capacity/runtime; comparable small POD payloads.
//! RO:NOTES — Microbench only; real-world variance expected.

use criterion::{criterion_group, criterion_main, Criterion};
use tokio::runtime::Builder;

// SUT
use ron_bus::{Bus, BusConfig, Event};

// Baselines
use async_channel as ac;
use flume as fl;
use tokio::sync::broadcast as tbc;

fn bench_publish(c: &mut Criterion) {
    let rt = Builder::new_multi_thread()
        .worker_threads(2)
        .enable_all()
        .build()
        .unwrap();

    let mut group = c.benchmark_group("ab_publish_cap1024_subs8");
    group.sample_size(50);
    // NOTE: No fixed warm-up/measurement times here: allow CLI flags to control it.

    // Params (keep identical across contenders)
    let cap_usize: usize = 1024;
    let cap_u32: u32 = cap_usize.try_into().unwrap();
    let subs: usize = 8;

    // ----------------- ron-bus -----------------
    group.bench_function("ron_bus_publish", |b| {
        b.iter(|| {
            rt.block_on(async {
                let bus = Bus::new(BusConfig::new().with_capacity(cap_u32)).unwrap();
                let tx = bus.sender();

                // Create N independent receivers (one per task)
                let rxs = (0..subs).map(|_| bus.subscribe()).collect::<Vec<_>>();

                // Drain tasks: break on Shutdown OR on channel close
                let mut tasks = Vec::with_capacity(subs);
                for mut rx in rxs {
                    tasks.push(tokio::spawn(async move {
                        loop {
                            match rx.recv().await {
                                Ok(Event::Shutdown) => break,
                                Ok(_) => {}
                                Err(_) => break,
                            }
                        }
                    }));
                }

                // Publish a small batch
                for i in 0u64..10_000 {
                    let _ = tx.send(Event::ConfigUpdated { version: i });
                }
                let _ = tx.send(Event::Shutdown);

                // IMPORTANT: drop the sender so receivers observe close and exit
                drop(tx);

                for t in tasks {
                    let _ = t.await;
                }
            })
        })
    });

    // ----------------- tokio::broadcast -----------------
    group.bench_function("tokio_broadcast_publish", |b| {
        b.iter(|| {
            rt.block_on(async {
                let (tx, _) = tbc::channel::<u64>(cap_usize);

                // Each subscriber comes from subscribe(); Receiver is NOT clonable.
                let mut tasks = Vec::with_capacity(subs);
                for _ in 0..subs {
                    let mut rx = tx.subscribe();
                    tasks.push(tokio::spawn(
                        async move { while rx.recv().await.is_ok() {} },
                    ));
                }

                for i in 0u64..10_000 {
                    let _ = tx.send(i);
                }
                drop(tx); // receivers will get Err and exit

                for t in tasks {
                    let _ = t.await;
                }
            })
        })
    });

    // ----------------- flume (bounded MPMC) -----------------
    group.bench_function("flume_mpmc_publish", |b| {
        b.iter(|| {
            rt.block_on(async {
                let (tx, rx) = fl::bounded::<u64>(cap_usize);

                let mut tasks = Vec::with_capacity(subs);
                for _ in 0..subs {
                    let rx = rx.clone();
                    tasks.push(tokio::spawn(async move {
                        while rx.recv_async().await.is_ok() {}
                    }));
                }

                for i in 0u64..10_000 {
                    let _ = tx.send(i);
                }
                drop(tx);

                for t in tasks {
                    let _ = t.await;
                }
            })
        })
    });

    // ----------------- async-channel (bounded MPMC) -----------------
    group.bench_function("async_channel_mpmc_publish", |b| {
        b.iter(|| {
            rt.block_on(async {
                let (tx, rx) = ac::bounded::<u64>(cap_usize);

                let mut tasks = Vec::with_capacity(subs);
                for _ in 0..subs {
                    let rx = rx.clone();
                    tasks.push(tokio::spawn(
                        async move { while rx.recv().await.is_ok() {} },
                    ));
                }

                for i in 0u64..10_000 {
                    let _ = tx.send(i).await;
                }
                drop(tx);

                for t in tasks {
                    let _ = t.await;
                }
            })
        })
    });

    group.finish();
}

criterion_group!(benches, bench_publish);
criterion_main!(benches);

```

### crates/ron-bus/benches/latency.rs
<a id="crates-ron-bus-benches-latency-rs"></a>

```rust
//! RO:WHAT — Receive-side latency microbench (deterministic runtime).
//! RO:WHY  — Reduce scheduler variance while preserving original iter_custom style.
//! RO:INTERACTS — Bus, BusConfig, Event.
//! RO:NOTES — Single-thread runtime; measures time to recv `iters` events; clean shutdown.

use std::time::Duration;

use criterion::{criterion_group, criterion_main, Criterion};
use ron_bus::{Bus, BusConfig, Event};
use tokio::runtime::Builder;

fn recv_latency_one_publisher(c: &mut Criterion) {
    // Use a single-thread runtime to reduce scheduler jitter vs multi-thread.
    let rt = Builder::new_current_thread()
        .enable_all()
        .build()
        .expect("tokio rt");

    let mut group = c.benchmark_group("recv_latency_one_publisher");
    group.sample_size(100);
    group.warm_up_time(Duration::from_secs(1));
    group.measurement_time(Duration::from_secs(8));
    group.noise_threshold(0.02);
    group.significance_level(0.01);

    group.bench_function("recv_latency_one_publisher", |b| {
        b.iter_custom(|iters| {
            rt.block_on(async move {
                // Fresh bus per measurement to avoid cross-iter state bleed.
                let bus = Bus::new(BusConfig::new().with_capacity(1024)).unwrap();
                let tx = bus.sender();
                let mut rx = bus.subscribe();

                // Publisher: send exactly `iters` events, then Shutdown.
                let pubber = tokio::spawn({
                    let tx = tx.clone();
                    async move {
                        for i in 0..iters {
                            // Small POD payload path; minimal branching.
                            let _ = tx.send(Event::ConfigUpdated { version: i });
                        }
                        let _ = tx.send(Event::Shutdown);
                        // Drop to ensure receivers can observe close if needed.
                        drop(tx);
                    }
                });

                // Measure time to consume exactly `iters` relevant events.
                let start = std::time::Instant::now();
                let mut seen = 0u64;
                loop {
                    match rx.recv().await {
                        Ok(Event::ConfigUpdated { .. }) => {
                            seen += 1;
                            if seen == iters {
                                break;
                            }
                        }
                        Ok(Event::Shutdown) => break, // belt-and-suspenders
                        Err(_) => break,              // sender dropped
                        _ => {}
                    }
                }
                // Ensure publisher task is done before returning elapsed time.
                let _ = pubber.await;
                start.elapsed()
            })
        });
    });

    group.finish();
}

criterion_group!(benches, recv_latency_one_publisher);
criterion_main!(benches);

```

### crates/ron-bus/benches/overflow.rs
<a id="crates-ron-bus-benches-overflow-rs"></a>

```rust
// overflow bench placeholder

```

### crates/ron-bus/benches/throughput.rs
<a id="crates-ron-bus-benches-throughput-rs"></a>

```rust
//! RO:WHAT — Criterion throughput bench for ron-bus (sync harness + async runtime inside)
//! RO:WHY  — Avoid Criterion's async adapters; drive Tokio ourselves via block_on()
//! RO:INTERACTS — Bus, BusConfig, Event; isolated Tokio runtimes per bench
//! RO:INVARIANTS — bounded channel; no background tasks from the library
//! RO:NOTES — Coarse microbench; for deep dives, use repo-wide harness & baselines.

use std::time::Duration;

use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ron_bus::{Bus, BusConfig, Event};
use tokio::runtime::Builder;

/// Busy-work to simulate a "slow" subscriber without OS sleep jitter.
/// Tune `ns` once on your machine if needed.
#[inline]
fn burn_cycles(ns: u64) {
    // The body is intentionally simple integer math; adjust divisor to match ~ns cost.
    let iters = ns / 10;
    let mut x = 0u64;
    for i in 0..iters {
        // LCG-ish mixing; keep it opaque to optimizer.
        x = x.wrapping_mul(1664525).wrapping_add(i ^ 1013904223u64);
        std::hint::black_box(x);
    }
}

/// Publish cost with zero subscribers draining.
fn bench_publish_zero_subs(c: &mut Criterion) {
    // Current-thread runtime is enough here.
    let rt = Builder::new_current_thread().enable_all().build().unwrap();

    let mut group = c.benchmark_group("publish_zero_subs");
    group.sample_size(100);
    group.warm_up_time(Duration::from_secs(1));
    group.measurement_time(Duration::from_secs(8));
    group.noise_threshold(0.02);
    group.significance_level(0.01);

    group.bench_function("publish_zero_subs", |b| {
        b.iter_custom(|iters| {
            rt.block_on(async move {
                // Setup is outside the measured window.
                let bus = Bus::new(BusConfig::new().with_capacity(1024)).unwrap();
                let tx = bus.sender();

                let start = std::time::Instant::now();
                for _ in 0..iters {
                    // Measure only the send loop.
                    let _ = black_box(&tx).send(Event::ConfigUpdated { version: 1 });
                }
                start.elapsed()
            })
        });
    });

    group.finish();
}

/// Publish throughput with 8 draining subscribers (fast consumers).
fn bench_publish_eight_subs(c: &mut Criterion) {
    let rt = Builder::new_multi_thread()
        .worker_threads(4)
        .enable_all()
        .build()
        .unwrap();

    let mut group = c.benchmark_group("publish_eight_subs");
    group.sample_size(100);
    group.warm_up_time(Duration::from_secs(1));
    group.measurement_time(Duration::from_secs(8));
    group.noise_threshold(0.02);
    group.significance_level(0.01);

    group.bench_function("publish_eight_subs", |b| {
        b.iter_custom(|iters| {
            rt.block_on(async move {
                let bus = Bus::new(BusConfig::new().with_capacity(2048)).unwrap();
                let tx = bus.sender();

                // Spawn fast draining subscribers.
                let mut rxs = Vec::new();
                for _ in 0..8 {
                    rxs.push(bus.subscribe());
                }
                for mut rx in rxs {
                    tokio::spawn(async move {
                        while let Ok(ev) = rx.recv().await {
                            criterion::black_box(ev);
                        }
                    });
                }

                // Measure only the publish loop.
                let start = std::time::Instant::now();
                for i in 0..iters {
                    let _ = tx.send(Event::ConfigUpdated { version: i });
                }
                // Ensure convergence.
                let _ = tx.send(Event::Shutdown);
                start.elapsed()
            })
        });
    });

    group.finish();
}

/// Publish while one subscriber is intentionally slow to induce Lagged(n).
fn bench_publish_with_one_slow_subscriber(c: &mut Criterion) {
    let rt = Builder::new_multi_thread()
        .worker_threads(2)
        .enable_all()
        .build()
        .unwrap();

    let mut group = c.benchmark_group("publish_with_one_slow_subscriber");
    group.sample_size(100);
    group.warm_up_time(Duration::from_secs(1));
    group.measurement_time(Duration::from_secs(8));
    group.noise_threshold(0.02);
    group.significance_level(0.01);

    group.bench_function("publish_with_one_slow_subscriber", |b| {
        b.iter_custom(|iters| {
            rt.block_on(async move {
                let bus = Bus::new(BusConfig::new().with_capacity(64)).unwrap();
                let tx = bus.sender();

                // Slow consumer to create pressure — use CPU burn instead of sleep.
                let mut rx = bus.subscribe();
                let slow = tokio::spawn(async move {
                    loop {
                        match rx.recv().await {
                            Ok(Event::Shutdown) => break,
                            Ok(_) => {
                                // ~0.1ms CPU burn; adjust if you want the same wall time as the old sleep.
                                burn_cycles(100_000);
                            }
                            Err(_) => break,
                        }
                    }
                });

                // Measure the publish loop.
                let start = std::time::Instant::now();
                for i in 0..iters {
                    let _ = tx.send(Event::ConfigUpdated { version: i });
                }
                let _ = tx.send(Event::Shutdown);
                let _ = slow.await;
                start.elapsed()
            })
        });
    });

    group.finish();
}

pub fn criterion_benches(c: &mut Criterion) {
    bench_publish_zero_subs(c);
    bench_publish_eight_subs(c);
    bench_publish_with_one_slow_subscriber(c);
}

criterion_group!(benches, criterion_benches);
criterion_main!(benches);

```

### crates/ron-bus/deny.toml
<a id="crates-ron-bus-deny-toml"></a>

```toml
# cargo-deny config (placeholder). See workspace root for canonical policy.

```

### crates/ron-bus/examples/publish_smoke.rs
<a id="crates-ron-bus-examples-publishsmoke-rs"></a>

```rust
//! RO:WHAT — Minimal publish/subscribe smoke example
//! RO:WHY  — Shows intended pattern: one receiver per task, bounded queue, graceful shutdown
//! RO:INTERACTS — Bus, BusConfig, Event
//! RO:INVARIANTS — no background tasks created by the library; host owns subscribers/metrics

use ron_bus::{Bus, BusConfig, Event};

#[tokio::main(flavor = "current_thread")]
async fn main() {
    let bus = Bus::new(BusConfig::new().with_capacity(1024)).expect("bus");
    let tx = bus.sender();

    let mut rx = bus.subscribe();
    let worker = tokio::spawn(async move {
        loop {
            match rx.recv().await {
                Ok(Event::Shutdown) => {
                    println!("worker: shutdown received");
                    break;
                }
                Ok(ev) => {
                    println!("worker: got {:?}", ev);
                }
                Err(e) => {
                    println!("worker: recv error = {:?}", e);
                    break;
                }
            }
        }
    });

    let _ = tx.send(Event::Health {
        service: "svc.a".into(),
        ok: true,
    });
    let _ = tx.send(Event::ConfigUpdated { version: 1 });
    let _ = tx.send(Event::Shutdown);

    let _ = worker.await;
}

```

### crates/ron-bus/rust-toolchain.toml
<a id="crates-ron-bus-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["rustfmt", "clippy"]

```

### crates/ron-bus/scripts/smoke_ron_bus.sh
<a id="crates-ron-bus-scripts-smokeronbus-sh"></a>

```bash
#!/usr/bin/env bash
# ron-bus smoke: format (write), lint, test, example, benches (perf-biased)
# Not battery-friendly: uses native CPU flags and longer measurement windows.
# Emits artifacts under artifacts/ron-bus/<timestamp>.

set -euo pipefail

# Resolve repo root (even if invoked from this scripts/ dir)
REPO_ROOT="$(git rev-parse --show-toplevel 2>/dev/null || pwd)"
cd "$REPO_ROOT"

CRATE="ron-bus"
DATE_TAG="$(date +%Y%m%d-%H%M%S)"
BASELINE="smoke-${DATE_TAG}"
ART_DIR="${REPO_ROOT}/artifacts/ron-bus/${DATE_TAG}"
LOG_DIR="${ART_DIR}/logs"
mkdir -p "${LOG_DIR}"

echo "== ron-bus smoke start @ ${DATE_TAG} =="

echo "== format (write) =="
cargo fmt -p "${CRATE}"

echo "== format (verify) =="
cargo fmt -p "${CRATE}" -- --check

echo "== clippy =="
cargo clippy -p "${CRATE}" --all-targets -- -D warnings | tee "${LOG_DIR}/clippy.txt"

echo "== tests =="
cargo test -p "${CRATE}" | tee "${LOG_DIR}/tests.txt"

echo "== example: publish_smoke =="
cargo run -p "${CRATE}" --example publish_smoke | tee "${LOG_DIR}/publish_smoke.txt"

# Performance-oriented flags: native CPU (not battery-friendly)
export RUSTFLAGS="-C target-cpu=native"

echo "== benches: throughput =="
cargo bench -p "${CRATE}" --bench throughput -- \
  --warm-up-time 2 --measurement-time 5 --sample-size 30 \
  | tee "${LOG_DIR}/bench_throughput.txt"

echo "== benches: latency =="
cargo bench -p "${CRATE}" --bench latency -- \
  --warm-up-time 2 --measurement-time 5 --sample-size 30 \
  | tee "${LOG_DIR}/bench_latency.txt"

echo "== benches: A/B compare =="
cargo bench -p "${CRATE}" --bench ab_compare -- \
  --warm-up-time 3 --measurement-time 10 --sample-size 50 \
  --save-baseline "${BASELINE}" \
  | tee "${LOG_DIR}/bench_ab_compare.txt"

# Copy full Criterion reports
if [ -d "target/criterion" ]; then
  mkdir -p "${ART_DIR}"
  cp -R target/criterion "${ART_DIR}/criterion"
fi

# Quick-and-dirty summary from Criterion files (heuristic)
SUMMARY="${ART_DIR}/ab_compare_summary.txt"
echo "== summarizing ab_compare results =="

AB_DIRS="$(find target/criterion -maxdepth 2 -type d -name 'ab_*' 2>/dev/null || true)"
{
  echo "ron-bus A/B summary (${DATE_TAG})"
  echo "baseline: ${BASELINE}"
  echo
  if [ -n "${AB_DIRS}" ]; then
    # Pull function names + 'time: [' lines from report text files
    grep -RHEn "ab_.*|time:\s+\[" ${AB_DIRS} 2>/dev/null \
      | sed -E 's|^.*/||' \
      | sed -E 's|.*/report.txt:||' || true
  else
    echo "No ab_* groups found under target/criterion."
  fi
} > "${SUMMARY}"

echo "== artifacts =="
echo "Logs:       ${LOG_DIR}"
echo "Criterion:  ${ART_DIR}/criterion"
echo "A/B summary:${SUMMARY}"

echo "== ron-bus smoke done =="

```

### crates/ron-bus/scripts/update_api_snapshot.sh
<a id="crates-ron-bus-scripts-updateapisnapshot-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# Placeholder to regenerate public API snapshot into docs/api-history/ron-bus/
echo "Implement public API snapshot generation here."

```

### crates/ron-bus/src/bus.rs
<a id="crates-ron-bus-src-bus-rs"></a>

```rust
//! RO:WHAT — Core Bus type wrapping a bounded Tokio broadcast channel
//! RO:WHY  — Provide monomorphic, bounded, lossy, observable-by-host semantics
//! RO:INTERACTS — config::BusConfig; internal::channel; event::Event
//! RO:INVARIANTS — bounded channel; capacity fixed; no background tasks; host updates metrics
//! RO:TEST — tests/* cover fanout, lag/overflow, cutover

use crate::{config::BusConfig, errors::BusError, event::Event, internal::channel};
use tokio::sync::broadcast::{Receiver, Sender};

/// Bounded in-process broadcast bus (lossy for lagging receivers).
pub struct Bus {
    tx: Sender<Event>,
    capacity: usize,
}

impl Bus {
    /// Construct a new Bus from a config (or default).
    pub fn new(cfg: impl Into<BusConfig>) -> Result<Self, BusError> {
        let cfg = cfg.into();
        cfg.validate().map_err(BusError::Config)?;
        let capacity = cfg.capacity as usize;
        let (tx, _rx) = channel::bounded::<Event>(capacity);
        // Drop the initial receiver; users will call subscribe(). No background tasks here.
        Ok(Self { tx, capacity })
    }

    /// Cloneable sender handle for publishers.
    pub fn sender(&self) -> Sender<Event> {
        self.tx.clone()
    }

    /// Unique receiver for a single subscriber task.
    ///
    /// Pattern: **one receiver per task** to avoid unintended sharing/races.
    pub fn subscribe(&self) -> Receiver<Event> {
        self.tx.subscribe()
    }

    /// The bounded queue capacity (messages).
    pub fn capacity(&self) -> usize {
        self.capacity
    }
}

```

### crates/ron-bus/src/config.rs
<a id="crates-ron-bus-src-config-rs"></a>

```rust
//! RO:WHAT — Host-constructed configuration for Bus
//! RO:WHY  — Capacity & observability knobs are fixed at construction (cutover by rebuild)
//! RO:INTERACTS — Used by Bus::new(cfg); host is responsible for reading env/files/flags
//! RO:INVARIANTS — capacity >= 2 and reasonable upper bound; no runtime mutation
//! RO:TEST — Unit: validate bounds; Integration: capacity_cutover
//! RO:NOTE — Marked #[non_exhaustive] to allow additive evolution without SemVer breaks.
//!           Because of this, external crates must use the builder helpers rather than
//!           struct-literal syntax.

#[cfg(feature = "serde")]
use serde::{Deserialize, Serialize};

/// Host-facing configuration for constructing a [`Bus`].
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
#[non_exhaustive]
#[derive(Debug, Clone)]
pub struct BusConfig {
    /// Bounded broadcast buffer size (messages).
    pub capacity: u32,
    /// Host WARN throttling (per minute) for overflow logs; library does not log.
    pub overflow_warn_rate_per_min: u32,
    /// Optional namespace the host may use for metrics; library is metrics-neutral.
    pub metrics_namespace: String,
    /// If true, hosts may attach amnesia={on|off} label to metrics.
    pub emit_amnesia_label: bool,
}

impl Default for BusConfig {
    fn default() -> Self {
        Self {
            capacity: 256,
            overflow_warn_rate_per_min: 60,
            metrics_namespace: "ronbus".to_string(),
            emit_amnesia_label: true,
        }
    }
}

impl BusConfig {
    /// Create with default values (same as `Default::default()`).
    pub fn new() -> Self {
        Self::default()
    }

    /// Set the bounded capacity (messages).
    pub fn with_capacity(mut self, capacity: u32) -> Self {
        self.capacity = capacity;
        self
    }

    /// Set the overflow warn throttle (per minute).
    pub fn with_overflow_warn_rate_per_min(mut self, rate: u32) -> Self {
        self.overflow_warn_rate_per_min = rate;
        self
    }

    /// Set the metrics namespace hint (library remains metrics-neutral).
    pub fn with_metrics_namespace<S: Into<String>>(mut self, ns: S) -> Self {
        self.metrics_namespace = ns.into();
        self
    }

    /// Toggle amnesia label emission hint.
    pub fn with_emit_amnesia_label(mut self, yes: bool) -> Self {
        self.emit_amnesia_label = yes;
        self
    }

    /// Validate bounds & basic invariants.
    pub fn validate(&self) -> Result<(), String> {
        if self.capacity < 2 {
            return Err("capacity must be >= 2".into());
        }
        if self.capacity > (1 << 20) {
            // Keep memory sane; Tokio broadcast alloc is O(capacity)
            return Err("capacity too large; must be <= 1,048,576".into());
        }
        Ok(())
    }
}

```

### crates/ron-bus/src/errors.rs
<a id="crates-ron-bus-src-errors-rs"></a>

```rust
//! RO:WHAT — Local error taxonomy for Bus construction/usage
//! RO:WHY  — Keep external semantics explicit & stable (SemVer)
//! RO:INTERACTS — Returned by Bus::new(); complements tokio::broadcast RecvError at call sites
//! RO:INVARIANTS — small, non_exhaustive; no std::error::Error to avoid error stack bloat
//! RO:TEST — Unit: config errors; Integration: negative patterns

/// Errors constructing or using the Bus surface.
#[non_exhaustive]
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum BusError {
    /// Invalid configuration: contains a human-readable reason.
    Config(String),
    /// Channel was closed (no subscribers left).
    Closed,
}

```

### crates/ron-bus/src/event.rs
<a id="crates-ron-bus-src-event-rs"></a>

```rust
//! RO:WHAT — Canonical Event enum carried on the bus
//! RO:WHY  — Aligns with kernel public surface; additive-safe growth (#[non_exhaustive])
//! RO:INTERACTS — Consumed by hosts/services; produced by kernel/supervision
//! RO:INVARIANTS — DTO hygiene; keep variants small; no secrets/PII in payloads
//! RO:TEST — Unit: variant roundtrips; Integration: fanout_ok

/// Kernel-aligned, additive-safe event set.
#[non_exhaustive]
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum Event {
    /// Liveness of a named service.
    Health { service: String, ok: bool },
    /// Host config hot-reload emitted version.
    ConfigUpdated { version: u64 },
    /// Supervisor noticed a crash; reason is informational.
    ServiceCrashed { service: String, reason: String },
    /// Coordinated shutdown signal.
    Shutdown,
}

```

### crates/ron-bus/src/internal/channel.rs
<a id="crates-ron-bus-src-internal-channel-rs"></a>

```rust
//! RO:WHAT — Narrow wrapper for creating a bounded Tokio broadcast channel
//! RO:WHY  — Centralize invariants and future tweaks (e.g., debug asserts)
//! RO:INTERACTS — used by Bus::new()
//! RO:INVARIANTS — capacity >= 2; bounded queue; one receiver per task pattern
//! RO:TEST — Indirect via Bus integration tests

use tokio::sync::broadcast;

/// A simple constructor wrapper to emphasize bounded semantics.
pub fn bounded<T: Clone>(capacity: usize) -> (broadcast::Sender<T>, broadcast::Receiver<T>) {
    // Tokio ensures capacity >= 1 produces a bounded channel; we pre-validate in BusConfig.
    broadcast::channel(capacity)
}

```

### crates/ron-bus/src/internal/depth_estimator.rs
<a id="crates-ron-bus-src-internal-depthestimator-rs"></a>

```rust
//! RO:WHAT — Tiny, optional queue depth heuristic for hosts/tests.
//! RO:WHY  — Tokio broadcast does not expose depth/len; we can maintain a
//!           conservative estimate from observed lag and publishes to help
//!           hosts make decisions (e.g., increase capacity, cut over).
//! RO:INTERACTS — Used by host loops/tests; not required by Bus hot path.
//! RO:INVARIANTS — Lock-free from the API perspective; no `.await` here.
//! RO:SECURITY — No secrets/PII; pure counters.
//! RO:TEST — Covered indirectly in integration benches/tests as needed.

use core::sync::atomic::{AtomicU64, Ordering};

/// A conservative queue depth heuristic derived from observed lag/drop.
///
/// This is **purely optional** and **not** wired into the Bus hot path.
/// Hosts may instantiate and update it from their recv loop whenever they
/// observe `RecvError::Lagged(n)` or after batches of publishes.
#[derive(Debug, Default)]
pub struct DepthEstimator {
    /// Count of published messages we tracked (monotonic).
    pub_published: AtomicU64,
    /// Sum of observed lag events (messages skipped by a receiver).
    pub_lagged_sum: AtomicU64,
}

impl DepthEstimator {
    /// Create a new estimator.
    pub const fn new() -> Self {
        Self {
            pub_published: AtomicU64::new(0),
            pub_lagged_sum: AtomicU64::new(0),
        }
    }

    /// Record that `n` messages were published (best effort).
    #[inline]
    pub fn on_published(&self, n: u64) {
        if n != 0 {
            self.pub_published.fetch_add(n, Ordering::Relaxed);
        }
    }

    /// Record that a receiver observed `lagged` dropped messages.
    #[inline]
    pub fn on_lagged(&self, lagged: u64) {
        if lagged != 0 {
            self.pub_lagged_sum.fetch_add(lagged, Ordering::Relaxed);
        }
    }

    /// Snapshot a conservative estimate.
    ///
    /// Not a true queue length — broadcast fanout and differing subscriber
    /// speeds mean there is no single “depth” — but this gives hosts a stable
    /// scalar to alert on (e.g., > X lagged per second).
    #[inline]
    pub fn snapshot(&self) -> DepthSnapshot {
        DepthSnapshot {
            published: self.pub_published.load(Ordering::Relaxed),
            lagged_sum: self.pub_lagged_sum.load(Ordering::Relaxed),
        }
    }

    /// Reset counters (e.g., at the end of a reporting interval).
    #[inline]
    pub fn reset(&self) {
        self.pub_published.store(0, Ordering::Relaxed);
        self.pub_lagged_sum.store(0, Ordering::Relaxed);
    }
}

/// Point-in-time heuristic values.
#[derive(Debug, Clone, Copy, Default, PartialEq, Eq)]
pub struct DepthSnapshot {
    pub published: u64,
    pub lagged_sum: u64,
}

impl DepthSnapshot {
    /// Returns an “estimated pressure” scalar suitable for alerting.
    ///
    /// Right now this is a simple passthrough of `lagged_sum`. Hosts may
    /// choose to apply a moving average or rate conversion externally.
    #[inline]
    pub fn pressure(self) -> u64 {
        self.lagged_sum
    }
}

```

### crates/ron-bus/src/internal/mod.rs
<a id="crates-ron-bus-src-internal-mod-rs"></a>

```rust
//! RO:WHAT — Small internal helpers to keep public files tiny.
//! RO:WHY  — Encapsulate wrappers/heuristics and document invariants once.
//! RO:INTERACTS — `channel` (Tokio broadcast wrapper); optional `depth_estimator`.
//! RO:INVARIANTS — No locks across `.await`; bounded channels only; no bg tasks.

pub mod channel;
pub mod depth_estimator;

pub use channel::bounded as bounded_channel;
pub use depth_estimator::{DepthEstimator, DepthSnapshot};

#[cfg(test)]
mod _doc_pattern {
    use tokio::sync::broadcast;

    // Ensure our wrapper returns the same types we expect from Tokio.
    #[test]
    fn channel_types_match() {
        let (tx, rx): (broadcast::Sender<u8>, broadcast::Receiver<u8>) = super::channel::bounded(8);
        drop((tx, rx));
    }
}

```

### crates/ron-bus/src/lib.rs
<a id="crates-ron-bus-src-lib-rs"></a>

```rust
//! RO:WHAT — Public surface for the in-process broadcast bus (bounded, lossy, observable-by-host)
//! RO:WHY  — Pillar 1 (Kernel & Orchestration); Concerns: RES/PERF (bounded backpressure, no locks across .await)
//! RO:INTERACTS — internal::channel (tokio::broadcast wrapper); public: Bus, BusConfig, Event, BusError
//! RO:INVARIANTS — bounded channel; one receiver per task; no background tasks; no secrets/PII on bus
//! RO:METRICS — none inside crate (host updates counters/gauges in recv loop)
//! RO:CONFIG — capacity fixed at construction; cutover by constructing a new Bus
//! RO:SECURITY — no network/disk I/O; no payload logging; secret-free surface
//! RO:TEST — integration tests in tests/*; loom model optional (cfg(loom))

#![forbid(unsafe_code)]
#![deny(warnings)]

mod bus;
mod config;
mod errors;
mod event;

pub mod metrics;
pub mod prelude;

pub mod internal; // kept small; still non-public APIs within it

pub use bus::Bus;
pub use config::BusConfig;
pub use errors::BusError;
pub use event::Event;

#[cfg(doctest)]
mod _doctests {
    /// Minimal host-side pattern (bounded, one receiver per task).
    ///
    /// ```ignore
    /// use ron_bus::{Bus, BusConfig, Event};
    /// # #[tokio::main(flavor="current_thread")]
    /// # async fn main() {
    /// let bus = Bus::new(BusConfig::default()).unwrap();
    /// let mut rx = bus.subscribe();
    /// tokio::spawn(async move {
    ///     loop {
    ///         match rx.recv().await {
    ///             Ok(_ev) => { /* handle */ }
    ///             Err(tokio::sync::broadcast::error::RecvError::Lagged(n)) => {
    ///                 // host increments metrics here (outside this library)
    ///                 // metrics::bus_overflow_dropped_total().inc_by(n as u64);
    ///             }
    ///             Err(tokio::sync::broadcast::error::RecvError::Closed) => break,
    ///         }
    ///     }
    /// });
    /// bus.sender().send(Event::Shutdown).ok();
    /// # }
    /// ```
    fn _marker() {}
}

```

### crates/ron-bus/src/metrics.rs
<a id="crates-ron-bus-src-metrics-rs"></a>

```rust
//! RO:WHAT — Host-owned metrics facade (no-op default).
//! RO:WHY  — ron-bus does not emit metrics itself; hosts increment counters
//!           in their recv loops. This file provides a tiny trait & a noop
//!           impl for hosts/tests that want a uniform interface.
//! RO:INTERACTS — Referenced by hosts; not used by Bus hot path.
//! RO:INVARIANTS — No global state; zero-alloc; zero-cost if not used.

/// Minimal metrics interface hosts may use around ron-bus operations.
///
/// Intentionally tiny; hosts are free to add richer metrics externally.
pub trait BusMetrics {
    /// Count messages published (best-effort).
    fn inc_published(&self, n: u64);

    /// Count messages received (best-effort).
    fn inc_received(&self, n: u64);

    /// Count messages dropped due to lag (best-effort).
    fn inc_lagged_drop(&self, n: u64);
}

/// A no-op metrics sink (default).
#[derive(Debug, Default, Clone, Copy)]
pub struct NoopMetrics;

impl BusMetrics for NoopMetrics {
    #[inline]
    fn inc_published(&self, _n: u64) {}

    #[inline]
    fn inc_received(&self, _n: u64) {}

    #[inline]
    fn inc_lagged_drop(&self, _n: u64) {}
}

```

### crates/ron-bus/src/prelude.rs
<a id="crates-ron-bus-src-prelude-rs"></a>

```rust
//! RO:WHAT — Convenience prelude for common imports.
//! RO:WHY  — Reduce repetitive `use ron_bus::{...}` in host code/examples.
//! RO:INTERACTS — Re-exports public types only (no macros, no globals).
//! RO:INVARIANTS — Keep small and explicit.

pub use crate::{Bus, BusConfig, BusError, Event};

```

### crates/ron-bus/tests/api_surface.rs
<a id="crates-ron-bus-tests-apisurface-rs"></a>

```rust
// RO:WHAT — API surface smoke tests for ron-bus.
// RO:WHY  — Lock in the basic constructors and methods to catch accidental drift.
// RO:INTERACTS — Bus, BusConfig, Event.
// RO:INVARIANTS — Monomorphic Bus; capacity fixed at construction; one receiver per task.

use ron_bus::{Bus, BusConfig, Event};
use tokio::sync::broadcast::error::RecvError;

#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
async fn api_surface_basic() {
    // Default config path
    let bus = Bus::new(BusConfig::new()).expect("bus");
    assert!(bus.capacity() >= 2);

    // Builder path
    let bus = Bus::new(BusConfig::new().with_capacity(512)).expect("bus");
    assert_eq!(bus.capacity(), 512);

    // Sender / subscribe / send / recv
    let tx = bus.sender();
    let mut rx = bus.subscribe();

    tx.send(Event::ConfigUpdated { version: 1 }).unwrap();
    match rx.recv().await {
        Ok(Event::ConfigUpdated { version }) => assert_eq!(version, 1),
        other => panic!("unexpected recv: {:?}", other),
    }

    // Shutdown should be observable by the same receiver.
    tx.send(Event::Shutdown).unwrap();
    match rx.recv().await {
        Ok(Event::Shutdown) => {}
        Err(RecvError::Closed) => panic!("channel unexpectedly closed"),
        other => panic!("unexpected recv: {:?}", other),
    }
}

```

### crates/ron-bus/tests/capacity_cutover.rs
<a id="crates-ron-bus-tests-capacitycutover-rs"></a>

```rust
// RO:WHAT — Capacity cutover test (A -> drop -> B).
// RO:WHY  — Capacity is fixed; resizing is done by constructing a new Bus.
// RO:INTERACTS — Bus, BusConfig, Event.
// RO:INVARIANTS — No background tasks; old bus is dropped before new is created.

use ron_bus::{Bus, BusConfig, Event};

#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
async fn capacity_cutover_recreate_bus() {
    // Bus A
    let bus_a = Bus::new(BusConfig::new().with_capacity(64)).expect("bus A");
    assert_eq!(bus_a.capacity(), 64);

    // Prove basic send/recv works
    let tx_a = bus_a.sender();
    let mut rx_a = bus_a.subscribe();
    tx_a.send(Event::ConfigUpdated { version: 100 }).unwrap();
    let ev = rx_a.recv().await.unwrap();
    match ev {
        Event::ConfigUpdated { version } => assert_eq!(version, 100),
        _ => panic!("unexpected event on bus A: {:?}", ev),
    }

    // Drop A, construct B with different capacity
    drop(rx_a);
    drop(tx_a);
    drop(bus_a);

    // Bus B
    let bus_b = Bus::new(BusConfig::new().with_capacity(128)).expect("bus B");
    assert_eq!(bus_b.capacity(), 128);

    let tx_b = bus_b.sender();
    let mut rx_b = bus_b.subscribe();
    tx_b.send(Event::Shutdown).unwrap();
    let ev = rx_b.recv().await.unwrap();
    matches!(ev, Event::Shutdown);
}

```

### crates/ron-bus/tests/chaos_amnesia.rs
<a id="crates-ron-bus-tests-chaosamnesia-rs"></a>

```rust
// ignored chaos amnesia test placeholder

```

### crates/ron-bus/tests/fanout_ok.rs
<a id="crates-ron-bus-tests-fanoutok-rs"></a>

```rust
// RO:WHAT — Happy-path fanout: N subscribers receive all events without lag
// RO:WHY  — Proves bounded bus works for steady load; publishers non-blocking
// RO:INTERACTS — Bus, BusConfig, Event
// RO:INVARIANTS — no deadlocks; all receivers get events when not lagging

use ron_bus::{Bus, BusConfig, Event};

#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
async fn fanout_ok() {
    // Use builder because BusConfig is #[non_exhaustive]
    let cfg = BusConfig::new().with_capacity(256);
    let bus = Bus::new(cfg).unwrap();

    let mut rx1 = bus.subscribe();
    let mut rx2 = bus.subscribe();

    // Publish a couple of events
    let tx = bus.sender();
    tx.send(Event::Health {
        service: "svc.a".into(),
        ok: true,
    })
    .unwrap();
    tx.send(Event::Shutdown).unwrap();

    let a1 = rx1.recv().await.unwrap();
    let a2 = rx1.recv().await.unwrap();
    let b1 = rx2.recv().await.unwrap();
    let b2 = rx2.recv().await.unwrap();

    assert_eq!(
        a1,
        Event::Health {
            service: "svc.a".into(),
            ok: true
        }
    );
    assert_eq!(a2, Event::Shutdown);
    assert_eq!(
        b1,
        Event::Health {
            service: "svc.a".into(),
            ok: true
        }
    );
    assert_eq!(b2, Event::Shutdown);
}

```

### crates/ron-bus/tests/graceful_shutdown.rs
<a id="crates-ron-bus-tests-gracefulshutdown-rs"></a>

```rust
// RO:WHAT — Graceful shutdown convergence test.
// RO:WHY  — Final Shutdown should let receivers exit promptly (no hangs).
// RO:INTERACTS — Bus, BusConfig, Event.
// RO:INVARIANTS — Bounded, no background tasks; receivers exit on Shutdown.

use ron_bus::{Bus, BusConfig, Event};
use tokio::time::{timeout, Duration};

#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
async fn graceful_shutdown_converges() {
    let bus = Bus::new(BusConfig::new().with_capacity(256)).unwrap();
    let tx = bus.sender();

    let mut rx1 = bus.subscribe();
    let t1 = tokio::spawn(async move {
        loop {
            match rx1.recv().await {
                Ok(Event::Shutdown) | Err(_) => break,
                _ => {}
            }
        }
    });

    let mut rx2 = bus.subscribe();
    let t2 = tokio::spawn(async move {
        loop {
            match rx2.recv().await {
                Ok(Event::Shutdown) | Err(_) => break,
                _ => {}
            }
        }
    });

    // Emit some traffic then Shutdown
    for i in 0..10 {
        let _ = tx.send(Event::ConfigUpdated { version: i });
    }
    let _ = tx.send(Event::Shutdown);

    // Must converge quickly
    timeout(Duration::from_secs(2), async {
        let _ = tokio::join!(t1, t2);
    })
    .await
    .expect("receivers failed to observe Shutdown in time");
}

```

### crates/ron-bus/tests/lagged_overflow_smoke.rs
<a id="crates-ron-bus-tests-laggedoverflowsmoke-rs"></a>

```rust
// RO:WHAT — Force lag on a slow subscriber to observe Lagged(n)
// RO:WHY  — Demonstrate lossy semantics under bounded overflow (host would count metrics)
// RO:INTERACTS — Bus, BusConfig, Event
// RO:INVARIANTS — publisher never blocks; slow consumer gets Lagged(n) and eventually exits on Shutdown
//
// Behavior notes:
// - We intentionally make the consumer slow to trigger RecvError::Lagged(n).
// - We publish Shutdown as the *last* message so that after any lag, the next Ok()
//   should observe Shutdown and break cleanly.

use ron_bus::{Bus, BusConfig, Event};
use std::sync::Arc;
use tokio::sync::broadcast::error::RecvError;
use tokio::sync::Barrier;
use tokio::time::{sleep, timeout, Duration};

#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
async fn lagged_overflow_smoke() {
    let cap = 8u32; // tiny to trigger lag
    let bus = Bus::new(BusConfig::new().with_capacity(cap)).unwrap();
    let tx = bus.sender();

    let barrier = Arc::new(Barrier::new(2));

    // Slow consumer
    let mut rx_slow = bus.subscribe();
    let slow = {
        let barrier = Arc::clone(&barrier);
        tokio::spawn(async move {
            barrier.wait().await;
            let mut lagged_total = 0u64;
            loop {
                match rx_slow.recv().await {
                    Ok(Event::Shutdown) => break lagged_total,
                    Ok(_ev) => {
                        // Simulate work; large enough to induce lag with small capacity.
                        sleep(Duration::from_millis(2)).await;
                    }
                    Err(RecvError::Lagged(n)) => {
                        lagged_total += n;
                        // host would: metrics::bus_overflow_dropped_total().inc_by(n as u64);
                    }
                    Err(RecvError::Closed) => break lagged_total,
                }
            }
        })
    };

    // Fast publisher loop
    let pubber = {
        let barrier = Arc::clone(&barrier);
        tokio::spawn(async move {
            barrier.wait().await;
            for i in 0..200u32 {
                let _ = tx.send(Event::ConfigUpdated { version: i as u64 });
            }
            // Place Shutdown as the final message so late receivers converge to it.
            let _ = tx.send(Event::Shutdown);
        })
    };

    // Add a timeout safety net so the test never hangs indefinitely.
    let result = timeout(Duration::from_secs(5), async {
        let (_pub_res, lagged_total) = tokio::join!(pubber, slow);
        lagged_total.unwrap()
    })
    .await;

    match result {
        Ok(lagged_total) => {
            assert!(
                lagged_total > 0,
                "expected Lagged(n) to occur for slow consumer"
            );
        }
        Err(_elapsed) => panic!("test timed out waiting for consumer to observe Shutdown"),
    }
}

```

### crates/ron-bus/tests/loom_model.rs
<a id="crates-ron-bus-tests-loommodel-rs"></a>

```rust
// loom model test placeholder

```

### crates/ron-bus/tests/pq_labels_feature.rs
<a id="crates-ron-bus-tests-pqlabelsfeature-rs"></a>

```rust
// pq-labels feature test placeholder

```

### crates/ron-bus/tests/property_bus.rs
<a id="crates-ron-bus-tests-propertybus-rs"></a>

```rust
// property-based tests placeholder

```

### crates/ron-bus/tests/receiver_ownership.rs
<a id="crates-ron-bus-tests-receiverownership-rs"></a>

```rust
// receiver_ownership test placeholder

```



---



# ron-proto

_Source: crates/ron-proto/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:48:14Z -->
# Code Bundle — `ron-proto`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-proto/.github/workflows/ci.yml](#crates-ron-proto--github-workflows-ci-yml)
- [crates/ron-proto/.github/workflows/fuzz.yml](#crates-ron-proto--github-workflows-fuzz-yml)
- [crates/ron-proto/.github/workflows/render-mermaid.yml](#crates-ron-proto--github-workflows-render-mermaid-yml)
- [crates/ron-proto/Cargo.toml](#crates-ron-proto-Cargo-toml)
- [crates/ron-proto/benches/encode_decode_large.rs](#crates-ron-proto-benches-encodedecodelarge-rs)
- [crates/ron-proto/benches/encode_decode_small.rs](#crates-ron-proto-benches-encodedecodesmall-rs)
- [crates/ron-proto/examples/hello_json.rs](#crates-ron-proto-examples-hellojson-rs)
- [crates/ron-proto/fuzz/Cargo.toml](#crates-ron-proto-fuzz-Cargo-toml)
- [crates/ron-proto/fuzz/fuzz_targets/decode_capability.rs](#crates-ron-proto-fuzz-fuzztargets-decodecapability-rs)
- [crates/ron-proto/fuzz/fuzz_targets/decode_manifest.rs](#crates-ron-proto-fuzz-fuzztargets-decodemanifest-rs)
- [crates/ron-proto/fuzz/fuzz_targets/decode_oap_header.rs](#crates-ron-proto-fuzz-fuzztargets-decodeoapheader-rs)
- [crates/ron-proto/fuzz/fuzz_targets/parse_contentid.rs](#crates-ron-proto-fuzz-fuzztargets-parsecontentid-rs)
- [crates/ron-proto/src/cap/caveats.rs](#crates-ron-proto-src-cap-caveats-rs)
- [crates/ron-proto/src/cap/header.rs](#crates-ron-proto-src-cap-header-rs)
- [crates/ron-proto/src/cap/mod.rs](#crates-ron-proto-src-cap-mod-rs)
- [crates/ron-proto/src/config/mod.rs](#crates-ron-proto-src-config-mod-rs)
- [crates/ron-proto/src/config/validate.rs](#crates-ron-proto-src-config-validate-rs)
- [crates/ron-proto/src/econ/mod.rs](#crates-ron-proto-src-econ-mod-rs)
- [crates/ron-proto/src/econ/move_entry.rs](#crates-ron-proto-src-econ-moveentry-rs)
- [crates/ron-proto/src/error/kind.rs](#crates-ron-proto-src-error-kind-rs)
- [crates/ron-proto/src/error/mod.rs](#crates-ron-proto-src-error-mod-rs)
- [crates/ron-proto/src/error/reason.rs](#crates-ron-proto-src-error-reason-rs)
- [crates/ron-proto/src/gov/mod.rs](#crates-ron-proto-src-gov-mod-rs)
- [crates/ron-proto/src/gov/signed_descriptor.rs](#crates-ron-proto-src-gov-signeddescriptor-rs)
- [crates/ron-proto/src/id/content_id.rs](#crates-ron-proto-src-id-contentid-rs)
- [crates/ron-proto/src/id/mod.rs](#crates-ron-proto-src-id-mod-rs)
- [crates/ron-proto/src/id/parse.rs](#crates-ron-proto-src-id-parse-rs)
- [crates/ron-proto/src/lib.rs](#crates-ron-proto-src-lib-rs)
- [crates/ron-proto/src/mailbox/ack.rs](#crates-ron-proto-src-mailbox-ack-rs)
- [crates/ron-proto/src/mailbox/mod.rs](#crates-ron-proto-src-mailbox-mod-rs)
- [crates/ron-proto/src/mailbox/recv.rs](#crates-ron-proto-src-mailbox-recv-rs)
- [crates/ron-proto/src/mailbox/send.rs](#crates-ron-proto-src-mailbox-send-rs)
- [crates/ron-proto/src/manifest/common.rs](#crates-ron-proto-src-manifest-common-rs)
- [crates/ron-proto/src/manifest/mod.rs](#crates-ron-proto-src-manifest-mod-rs)
- [crates/ron-proto/src/manifest/v1.rs](#crates-ron-proto-src-manifest-v1-rs)
- [crates/ron-proto/src/naming.rs](#crates-ron-proto-src-naming-rs)
- [crates/ron-proto/src/oap/data.rs](#crates-ron-proto-src-oap-data-rs)
- [crates/ron-proto/src/oap/end.rs](#crates-ron-proto-src-oap-end-rs)
- [crates/ron-proto/src/oap/error.rs](#crates-ron-proto-src-oap-error-rs)
- [crates/ron-proto/src/oap/hello.rs](#crates-ron-proto-src-oap-hello-rs)
- [crates/ron-proto/src/oap/mod.rs](#crates-ron-proto-src-oap-mod-rs)
- [crates/ron-proto/src/oap/start.rs](#crates-ron-proto-src-oap-start-rs)
- [crates/ron-proto/src/quantum/mod.rs](#crates-ron-proto-src-quantum-mod-rs)
- [crates/ron-proto/src/quantum/pq_tags.rs](#crates-ron-proto-src-quantum-pqtags-rs)
- [crates/ron-proto/src/trace.rs](#crates-ron-proto-src-trace-rs)
- [crates/ron-proto/src/version.rs](#crates-ron-proto-src-version-rs)
- [crates/ron-proto/testing/performance/baselines/ron-proto.json](#crates-ron-proto-testing-performance-baselines-ron-proto-json)
- [crates/ron-proto/tests/content_id.rs](#crates-ron-proto-tests-contentid-rs)
- [crates/ron-proto/tests/cross_version.rs](#crates-ron-proto-tests-crossversion-rs)
- [crates/ron-proto/tests/econ_conservation.rs](#crates-ron-proto-tests-econconservation-rs)
- [crates/ron-proto/tests/golden_vectors.rs](#crates-ron-proto-tests-goldenvectors-rs)
- [crates/ron-proto/tests/hash_truth.rs](#crates-ron-proto-tests-hashtruth-rs)
- [crates/ron-proto/tests/interop_parity.rs](#crates-ron-proto-tests-interopparity-rs)
- [crates/ron-proto/tests/manifest_defaults.rs](#crates-ron-proto-tests-manifestdefaults-rs)
- [crates/ron-proto/tests/oap_roundtrip.rs](#crates-ron-proto-tests-oaproundtrip-rs)
- [crates/ron-proto/tests/validate_helpers.rs](#crates-ron-proto-tests-validatehelpers-rs)
- [crates/ron-proto/tests/vectors/content_id.json](#crates-ron-proto-tests-vectors-contentid-json)
- [crates/ron-proto/tests/vectors/manifest_v1.json](#crates-ron-proto-tests-vectors-manifestv1-json)
- [crates/ron-proto/tests/vectors/oap_data_min.json](#crates-ron-proto-tests-vectors-oapdatamin-json)
- [crates/ron-proto/tests/vectors/oap_error_envelope.json](#crates-ron-proto-tests-vectors-oaperrorenvelope-json)
- [crates/ron-proto/tests/vectors/oap_hello_v1.json](#crates-ron-proto-tests-vectors-oaphellov1-json)

### crates/ron-proto/.github/workflows/ci.yml
<a id="crates-ron-proto--github-workflows-ci-yml"></a>

```yaml

```

### crates/ron-proto/.github/workflows/fuzz.yml
<a id="crates-ron-proto--github-workflows-fuzz-yml"></a>

```yaml

```

### crates/ron-proto/.github/workflows/render-mermaid.yml
<a id="crates-ron-proto--github-workflows-render-mermaid-yml"></a>

```yaml

```

### crates/ron-proto/Cargo.toml
<a id="crates-ron-proto-Cargo-toml"></a>

```toml
[package]
name = "ron-proto"
version = "0.1.0"
edition = "2021"
rust-version = "1.80"
license = "MIT OR Apache-2.0"
description = "RustyOnions canonical DTOs: IDs, OAP/1 envelopes, manifests, mailbox, capability headers, error taxonomy."
repository = "https://example.com/RustyOnions"
readme = "README.md"
categories = ["network-programming", "data-structures"]
keywords = ["dto", "serde", "protocol"]

[lib]
name = "ron_proto"
path = "src/lib.rs"

[features]
# No "serde" feature here—serde is required always.
cbor = ["serde_cbor"]
schemars = ["dep:schemars"]

[dependencies]
bytes = { version = "1.7", default-features = false }
serde = { version = "1.0", features = ["derive"] }
serde_json = { version = "1.0", default-features = true }
serde_bytes = "0.11"
thiserror = "1.0"

# Optional formats / tooling
serde_cbor = { version = "0.11", optional = true }
schemars = { version = "0.8", optional = true, default-features = false, features = ["either", "uuid"] }

[dev-dependencies]
proptest = "1.6"
rand = "0.9"

```

### crates/ron-proto/benches/encode_decode_large.rs
<a id="crates-ron-proto-benches-encodedecodelarge-rs"></a>

```rust


```

### crates/ron-proto/benches/encode_decode_small.rs
<a id="crates-ron-proto-benches-encodedecodesmall-rs"></a>

```rust


```

### crates/ron-proto/examples/hello_json.rs
<a id="crates-ron-proto-examples-hellojson-rs"></a>

```rust
use ron_proto::oap::hello::Hello;
use serde_json as json;

fn main() {
    let hello = Hello::default();
    println!("{}", json::to_string_pretty(&hello).unwrap());
}

```

### crates/ron-proto/fuzz/Cargo.toml
<a id="crates-ron-proto-fuzz-Cargo-toml"></a>

```toml

```

### crates/ron-proto/fuzz/fuzz_targets/decode_capability.rs
<a id="crates-ron-proto-fuzz-fuzztargets-decodecapability-rs"></a>

```rust

```

### crates/ron-proto/fuzz/fuzz_targets/decode_manifest.rs
<a id="crates-ron-proto-fuzz-fuzztargets-decodemanifest-rs"></a>

```rust

```

### crates/ron-proto/fuzz/fuzz_targets/decode_oap_header.rs
<a id="crates-ron-proto-fuzz-fuzztargets-decodeoapheader-rs"></a>

```rust

```

### crates/ron-proto/fuzz/fuzz_targets/parse_contentid.rs
<a id="crates-ron-proto-fuzz-fuzztargets-parsecontentid-rs"></a>

```rust

```

### crates/ron-proto/src/cap/caveats.rs
<a id="crates-ron-proto-src-cap-caveats-rs"></a>

```rust
//! RO:WHAT — Enumerated caveats/flags attached to capability tokens.
//! RO:WHY  — Additive growth via non_exhaustive enum + reserved fields.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(tag = "kind", rename_all = "snake_case", deny_unknown_fields)]
#[non_exhaustive]
pub enum Caveat {
    IpAllowlist { cidrs: Vec<String> },
    WriteOnce,
    ContentPrefix { prefix: String }, // e.g., restrict to a subtree/name
}
pub type CaveatKind = Caveat;

```

### crates/ron-proto/src/cap/header.rs
<a id="crates-ron-proto-src-cap-header-rs"></a>

```rust
//! RO:WHAT — `CapTokenHdr` with typed claims (no signatures here).
//! RO:WHY  — Stable header schema for capability enforcement.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct CapTokenHdr {
    pub subject: String, // e.g., user or service id
    pub scope: String,   // e.g., "read", "write-once"
    pub issued_at: u64,  // seconds
    pub expires_at: u64, // seconds (short TTL recommended)
    #[serde(default)]
    pub caveats: Vec<crate::cap::Caveat>,
}

```

### crates/ron-proto/src/cap/mod.rs
<a id="crates-ron-proto-src-cap-mod-rs"></a>

```rust
//! RO:WHAT — Capability token header DTOs (claims/caveats only).
//! RO:WHY  — Typed claims for macaroon-style caps; verification lives in auth services.

pub mod caveats;
pub mod header;

pub use caveats::{Caveat, CaveatKind};
pub use header::CapTokenHdr;

```

### crates/ron-proto/src/config/mod.rs
<a id="crates-ron-proto-src-config-mod-rs"></a>

```rust
//! RO:WHAT — Lightweight, DTO-level validation helpers (no I/O).
//! RO:WHY  — Central place to enforce protocol invariants shared by hosts.
//! RO:INTERACTS — oap::{hello,start,data,end}, version::PROTO_VERSION, error::{ProtoError,Kind}.
//! RO:INVARIANTS — Pure functions; return `ProtoError` with stable reason strings.

use crate::error::{Kind, ProtoError};

/// Validate that the peer speaks our protocol/version.
pub fn validate_hello(h: &crate::oap::hello::Hello) -> Result<(), ProtoError> {
    if h.protocol != "OAP/1" {
        return Err(ProtoError {
            kind: Kind::ProtoMismatch,
            message: format!("unsupported protocol '{}'", h.protocol),
        });
    }
    if h.version != crate::version::PROTO_VERSION {
        return Err(ProtoError {
            kind: Kind::ProtoMismatch,
            message: format!("version {} != {}", h.version, crate::version::PROTO_VERSION),
        });
    }
    Ok(())
}

/// Validate START frame limits against the OAP cap.
pub fn validate_start(s: &crate::oap::start::Start) -> Result<(), ProtoError> {
    if (s.max_frame_bytes as usize) > crate::oap::MAX_FRAME_BYTES {
        return Err(ProtoError {
            kind: Kind::TooLarge,
            message: format!(
                "max_frame_bytes={} exceeds cap {}",
                s.max_frame_bytes,
                crate::oap::MAX_FRAME_BYTES
            ),
        });
    }
    Ok(())
}

/// Validate a DATA frame's payload size against a negotiated bound.
///
/// `negotiated_max` should come from `Start.max_frame_bytes` (after `validate_start`).
pub fn validate_data(d: &crate::oap::data::Data, negotiated_max: u32) -> Result<(), ProtoError> {
    let len = d.bytes.len() as u32;
    if len > negotiated_max {
        return Err(ProtoError {
            kind: Kind::TooLarge,
            message: format!("data bytes={} > negotiated_max={}", len, negotiated_max),
        });
    }
    Ok(())
}

/// Validate monotonic sequence progression (host streams can opt-in).
pub fn validate_seq_progress(prev: u64, next: u64) -> Result<(), ProtoError> {
    if next <= prev {
        return Err(ProtoError {
            kind: Kind::BadRequest,
            message: format!("non-monotonic seq: next={} <= prev={}", next, prev),
        });
    }
    Ok(())
}

// Re-export trait sugar for callers who prefer impl-based validation.
pub mod validate;
pub use validate::{Limits, Validate}; // <— re-export both so users can `use ron_proto::{Validate, Limits};`

```

### crates/ron-proto/src/config/validate.rs
<a id="crates-ron-proto-src-config-validate-rs"></a>

```rust
//! RO:WHAT — Trait-based validation sugar for DTOs.
//! RO:WHY  — Optional ergonomics so hosts can call `x.validate(...)` directly.

use crate::config::{validate_data, validate_hello, validate_start};
use crate::error::ProtoError;

/// Negotiated/host limits needed for validating certain frames.
#[derive(Debug, Clone, Copy)]
pub struct Limits {
    /// Max bytes allowed in a single DATA frame (usually negotiated from START).
    pub max_frame_bytes: u32,
}

impl Default for Limits {
    fn default() -> Self {
        // Be conservative by default; many hosts will set this from START.
        Self {
            max_frame_bytes: crate::oap::MAX_FRAME_BYTES as u32,
        }
    }
}

/// DTOs can opt into trait-based validation.
pub trait Validate {
    fn validate(&self, limits: Limits) -> Result<(), ProtoError>;
}

impl Validate for crate::oap::hello::Hello {
    fn validate(&self, _limits: Limits) -> Result<(), ProtoError> {
        validate_hello(self)
    }
}

impl Validate for crate::oap::start::Start {
    fn validate(&self, _limits: Limits) -> Result<(), ProtoError> {
        validate_start(self)
    }
}

impl Validate for crate::oap::data::Data {
    fn validate(&self, limits: Limits) -> Result<(), ProtoError> {
        validate_data(self, limits.max_frame_bytes)
    }
}

```

### crates/ron-proto/src/econ/mod.rs
<a id="crates-ron-proto-src-econ-mod-rs"></a>

```rust
//! RO:WHAT — ECON-adjacent DTOs used by ledger/rewarder (pure data).
//! RO:WHY  — Keep conservation-friendly shapes; no arithmetic logic here.

pub mod move_entry;

pub use move_entry::MoveEntryV1;

```

### crates/ron-proto/src/econ/move_entry.rs
<a id="crates-ron-proto-src-econ-moveentry-rs"></a>

```rust
//! RO:WHAT — `MoveEntryV1` debit/credit record shape (no arithmetic here).
//! RO:WHY  — Deterministic, signed-friendly DTO for ECON services.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct MoveEntryV1 {
    pub entry_id: String,
    pub account: String,
    /// Positive integer value in minor units (e.g., cents)
    pub amount_minor: u64,
    /// +1 for credit, -1 for debit (host logic enforces consistency)
    pub sign: i8,
    #[serde(default)]
    pub memo: Option<String>,
}

```

### crates/ron-proto/src/error/kind.rs
<a id="crates-ron-proto-src-error-kind-rs"></a>

```rust
//! RO:WHAT — Enumerated error kinds used across DTOs.
//! RO:WHY  — Stable, additive error space for interop & metrics.

use serde::{Deserialize, Serialize};

#[derive(Debug, Copy, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
#[serde(rename_all = "snake_case")]
#[non_exhaustive]
pub enum Kind {
    BadRequest,
    Unauthorized,
    Forbidden,
    NotFound,
    Conflict,
    TooLarge,
    RateLimited,
    Internal,
    Unavailable,
    ProtoMismatch,
}

```

### crates/ron-proto/src/error/mod.rs
<a id="crates-ron-proto-src-error-mod-rs"></a>

```rust
//! RO:WHAT — Typed error taxonomy (`ProtoError`, `Kind`) with stable reasons.
//! RO:WHY  — Deterministic errors for metrics and control flow; immutable reason strings.
//! RO:TEST — Unit tests assert reason strings remain stable across versions.

mod kind;
mod reason;

pub use kind::Kind;
pub use reason::stable_reason;

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct ProtoError {
    pub kind: Kind,
    pub message: String,
}

impl ProtoError {
    pub fn metric_reason(&self) -> &'static str {
        stable_reason(self.kind)
    }
}

```

### crates/ron-proto/src/error/reason.rs
<a id="crates-ron-proto-src-error-reason-rs"></a>

```rust
//! RO:WHAT — Stable mapping from `Kind` to metric reason strings.
//! RO:WHY  — Metric labels must be immutable across versions.

use super::Kind;

pub fn stable_reason(k: Kind) -> &'static str {
    match k {
        Kind::BadRequest => "bad_request",
        Kind::Unauthorized => "unauthorized",
        Kind::Forbidden => "forbidden",
        Kind::NotFound => "not_found",
        Kind::Conflict => "conflict",
        Kind::TooLarge => "too_large",
        Kind::RateLimited => "rate_limited",
        Kind::Internal => "internal",
        Kind::Unavailable => "unavailable",
        Kind::ProtoMismatch => "proto_mismatch",
    }
}

```

### crates/ron-proto/src/gov/mod.rs
<a id="crates-ron-proto-src-gov-mod-rs"></a>

```rust
//! RO:WHAT — Governance DTOs (signable descriptors; no signatures here).
//! RO:WHY  — Typed inputs for policy/registry; PQ-agile via quantum:: tags.

pub mod signed_descriptor;

pub use signed_descriptor::{MultiSigNofM, SignedDescriptorV1};

```

### crates/ron-proto/src/gov/signed_descriptor.rs
<a id="crates-ron-proto-src-gov-signeddescriptor-rs"></a>

```rust
//! RO:WHAT — SignedDescriptorV1 header (detached signature carried elsewhere).
//! RO:WHY  — Replay-safe governance inputs; PQ-agile via quantum tags.
//! RO:INVARIANTS — deny_unknown_fields; deterministic field order.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct MultiSigNofM {
    pub n: u8,
    pub m: u8,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct SignedDescriptorV1 {
    pub descriptor_cid: crate::id::ContentId,
    pub alg: crate::quantum::SignatureAlg,
    pub quorum: MultiSigNofM,
    pub issued_at: u64,
    pub expires_at: u64,
    /// CID of rationale or supplemental evidence
    pub rationale_cid: Option<crate::id::ContentId>,
}

```

### crates/ron-proto/src/id/content_id.rs
<a id="crates-ron-proto-src-id-contentid-rs"></a>

```rust
//! RO:WHAT — `ContentId` newtype ("b3:<hex>") with strict parser/serde.
//! RO:WHY  — Enforce I-1 addressing (BLAKE3) and deterministic casing across SDKs.
//! RO:INTERACTS — oap::Data/End, manifest entries, naming refs.
//! RO:INVARIANTS — hex length=64, lowercase, prefix "b3:"; serde rejects unknown/invalid forms.
//! RO:TEST — proptest for random valid/invalid strings; vector parity tests.

use serde::{Deserialize, Deserializer, Serialize, Serializer};
use std::{fmt, str::FromStr};

pub const CONTENT_ID_PREFIX: &str = "b3:";
pub const CONTENT_ID_HEX_LEN: usize = 64;

#[derive(Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct ContentId(String);

impl ContentId {
    pub fn as_str(&self) -> &str {
        &self.0
    }

    /// Parse with strict validation.
    pub fn parse(s: &str) -> Result<Self, crate::id::ParseContentIdError> {
        crate::id::validate_b3_str(s)?;
        Ok(Self(s.to_string()))
    }
}

impl fmt::Debug for ContentId {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        // Avoid dumping long hex in logs: short preview
        write!(
            f,
            "ContentId({}…)",
            &self.0[..std::cmp::min(self.0.len(), 8)]
        )
    }
}

impl fmt::Display for ContentId {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.write_str(&self.0)
    }
}

impl FromStr for ContentId {
    type Err = crate::id::ParseContentIdError;
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        Self::parse(s)
    }
}

impl Serialize for ContentId {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(&self.0)
    }
}

impl<'de> Deserialize<'de> for ContentId {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        crate::id::validate_b3_str(&s).map_err(serde::de::Error::custom)?;
        Ok(Self(s))
    }
}

```

### crates/ron-proto/src/id/mod.rs
<a id="crates-ron-proto-src-id-mod-rs"></a>

```rust
//! RO:WHAT — Newtypes and helpers for canonical IDs (content-addresses, names).
//! RO:WHY  — Strong typing for interop; prevent stringly-typed bugs.
//! RO:INTERACTS — Used across OAP envelopes, manifests, mailbox, governance.
//! RO:INVARIANTS — ContentId must be "b3:<64 lowercase hex>"; no hashing performed here.
//! RO:TEST — Round-trip serde tests and parser property tests live in this module.

mod content_id;
mod parse;

pub use content_id::{ContentId, CONTENT_ID_HEX_LEN, CONTENT_ID_PREFIX};
pub use parse::{is_lower_hex64, validate_b3_str, ParseContentIdError};

```

### crates/ron-proto/src/id/parse.rs
<a id="crates-ron-proto-src-id-parse-rs"></a>

```rust
//! RO:WHAT — Strict validators and parse errors for `ContentId`.
//! RO:WHY  — Keep hashing out of ron-proto; only parse/validate.
//! RO:INTERACTS — Used by ContentId serde and FromStr.
//! RO:INVARIANTS — 64 lowercase hex after "b3:" prefix.

use thiserror::Error;

#[derive(Debug, Error, Clone, PartialEq, Eq)]
pub enum ParseContentIdError {
    #[error("missing 'b3:' prefix")]
    MissingPrefix,
    #[error("hex length must be 64 characters")]
    BadLen,
    #[error("hex must be lowercase [0-9a-f]")]
    BadHex,
}

pub fn validate_b3_str(s: &str) -> Result<(), ParseContentIdError> {
    if !s.starts_with(super::CONTENT_ID_PREFIX) {
        return Err(ParseContentIdError::MissingPrefix);
    }
    let hex = &s[super::CONTENT_ID_PREFIX.len()..];
    if hex.len() != super::CONTENT_ID_HEX_LEN {
        return Err(ParseContentIdError::BadLen);
    }
    if !is_lower_hex64(hex) {
        return Err(ParseContentIdError::BadHex);
    }
    Ok(())
}

pub fn is_lower_hex64(hex: &str) -> bool {
    hex.bytes().all(|b| matches!(b, b'0'..=b'9'|b'a'..=b'f'))
}

```

### crates/ron-proto/src/lib.rs
<a id="crates-ron-proto-src-lib-rs"></a>

```rust
//! RO:WHAT — Flat public facade for RustyOnions canonical DTOs (pure types).
//! RO:WHY  — Pillar 7 (SDK/Interop); Concerns: DX/RES. Deterministic, strict schemas for cross-SDK parity.
//! RO:INTERACTS — oap (frames), id::ContentId, manifest::*, mailbox::*, cap::*, error::*, version::*, naming::*, econ::*, gov::*, quantum::*
//! RO:INVARIANTS — DTO-only (no I/O/crypto); #[serde(deny_unknown_fields)] on externals; OAP max_frame=1MiB; storage chunk≈64KiB.
//! RO:METRICS — N/A (library types only; reason strings stable for host metrics).
//! RO:CONFIG — None (schema helpers only).
//! RO:SECURITY — No secrets/PII; capability types are headers only (no verification).
//! RO:TEST — See tests/ in crate (vectors, cross-version, property tests).

#![forbid(unsafe_code)]
#![deny(warnings)]

pub mod cap;
pub mod config;
pub mod econ;
pub mod error;
pub mod gov;
pub mod id;
pub mod mailbox;
pub mod manifest;
pub mod naming;
pub mod oap;
pub mod quantum;
pub mod trace;
pub mod version; // <— export config helpers/traits

pub use cap::*;
pub use config::{Limits, Validate};
pub use econ::*;
pub use error::*;
pub use gov::*;
pub use id::*;
pub use mailbox::*;
pub use manifest::*;
pub use naming::*;
pub use oap::*;
pub use quantum::*;
pub use trace::*;
pub use version::*; // <— re-export trait + limits for ergonomics

```

### crates/ron-proto/src/mailbox/ack.rs
<a id="crates-ron-proto-src-mailbox-ack-rs"></a>

```rust
//! RO:WHAT — Mailbox Ack DTO.
//! RO:WHY  — Allows hosts to acknowledge processing; no side-effects here.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct Ack {
    pub msg_id: String,
    pub ok: bool,
    #[serde(default)]
    pub error: Option<crate::error::ProtoError>,
}

```

### crates/ron-proto/src/mailbox/mod.rs
<a id="crates-ron-proto-src-mailbox-mod-rs"></a>

```rust
//! RO:WHAT — Mailbox DTO entrypoint (Send/Recv/Ack).
//! RO:WHY  — Cross-service message shapes; at-least-once semantics live elsewhere.

pub mod ack;
pub mod recv;
pub mod send;

pub use ack::Ack;
pub use recv::Recv;
pub use send::Send;

```

### crates/ron-proto/src/mailbox/recv.rs
<a id="crates-ron-proto-src-mailbox-recv-rs"></a>

```rust
//! RO:WHAT — Mailbox Recv DTO (deliver to consumer).
//! RO:WHY  — Symmetric with Send; pure data only.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct Recv {
    pub msg_id: String,
    pub from: String,
    pub kind: String,
    #[serde(with = "serde_bytes")]
    pub payload: Vec<u8>,
}

```

### crates/ron-proto/src/mailbox/send.rs
<a id="crates-ron-proto-src-mailbox-send-rs"></a>

```rust
//! RO:WHAT — Mailbox Send DTO with idempotency headers.
//! RO:WHY  — Enable at-least-once delivery patterns without logic here.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct Send {
    pub msg_id: String,
    pub to: String,
    pub kind: String,
    #[serde(with = "serde_bytes")]
    pub payload: Vec<u8>,
    /// Host-side idempotency key for dedupe
    #[serde(default)]
    pub idempotency_key: Option<String>,
}

```

### crates/ron-proto/src/manifest/common.rs
<a id="crates-ron-proto-src-manifest-common-rs"></a>

```rust
//! RO:WHAT — Shared enums/consts across manifest versions.
//! RO:WHY  — Keep cross-version evolution clean and explicit.
//! RO:INVARIANTS — Deterministic defaults; serde rejects unknown fields where used.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Default)]
#[serde(rename_all = "snake_case")]
#[non_exhaustive]
pub enum MediaKind {
    #[default]
    Blob,
    Manifest,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct EntryRef {
    pub id: crate::id::ContentId,
    pub size: u64,
    /// Default to `blob` when omitted for backward compatibility.
    #[serde(default)]
    pub kind: MediaKind,
}

```

### crates/ron-proto/src/manifest/mod.rs
<a id="crates-ron-proto-src-manifest-mod-rs"></a>

```rust
//! RO:WHAT — Versioned manifest DTOs for content graphs.
//! RO:WHY  — Names → manifests → providers; pure data for index/storage.
//! RO:INVARIANTS — Explicit versioning; deterministic ordering (BTreeMap when maps appear).

pub mod common;
pub mod v1;

pub use common::*;
pub use v1::*;

```

### crates/ron-proto/src/manifest/v1.rs
<a id="crates-ron-proto-src-manifest-v1-rs"></a>

```rust
//! RO:WHAT — `ManifestV1` DTO (explicit version field).
//! RO:WHY  — Deterministic, growth-tolerant manifest for CAS graphs.

use serde::{Deserialize, Serialize};
use std::collections::BTreeMap;

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct ManifestV1 {
    pub version: u32, // = 1
    pub root: crate::id::ContentId,
    /// Ordered mapping (deterministic) from name → object reference
    pub entries: BTreeMap<String, crate::manifest::EntryRef>,
    #[serde(default)]
    pub meta: BTreeMap<String, String>,
}

impl Default for ManifestV1 {
    fn default() -> Self {
        Self {
            version: 1,
            root: "b3:0000000000000000000000000000000000000000000000000000000000000000"
                .parse()
                .unwrap(),
            entries: BTreeMap::new(),
            meta: BTreeMap::new(),
        }
    }
}

```

### crates/ron-proto/src/naming.rs
<a id="crates-ron-proto-src-naming-rs"></a>

```rust
//! RO:WHAT — Naming/manifest reference types (pure data).
//! RO:WHY  — Provide typed handles for index/gateway layers; resolution lives elsewhere.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct NameRef {
    pub name: String,                           // e.g., "user:stevan/avatar"
    pub expected: Option<crate::id::ContentId>, // optional pin for strong reads
}

```

### crates/ron-proto/src/oap/data.rs
<a id="crates-ron-proto-src-oap-data-rs"></a>

```rust
//! RO:WHAT — OAP DATA frame with object address and payload chunk.
//! RO:WHY  — Carries addressed bytes; readers verify BLAKE3 elsewhere.
//! RO:INVARIANTS — obj is "b3:<hex>"; bytes length must respect max_frame (host-enforced).

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct Data {
    pub obj: crate::id::ContentId,
    pub seq: u64,
    #[serde(with = "serde_bytes")]
    pub bytes: Vec<u8>,
}

```

### crates/ron-proto/src/oap/end.rs
<a id="crates-ron-proto-src-oap-end-rs"></a>

```rust
//! RO:WHAT — OAP END frame (finalization status).
//! RO:WHY  — Terminates a flow and conveys integrity/result summary.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct End {
    pub seq_end: u64,
    pub ok: bool,
    #[serde(default)]
    pub error: Option<crate::oap::error::Error>,
}

```

### crates/ron-proto/src/oap/error.rs
<a id="crates-ron-proto-src-oap-error-rs"></a>

```rust
//! RO:WHAT — OAP ERROR envelope (wire-level error details).
//! RO:WHY  — Stable, typed error codes that SDKs can rely on for metrics and control flow.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct Error {
    pub code: crate::error::Kind,
    pub message: String,
    #[serde(default)]
    pub detail: Option<String>,
}

```

### crates/ron-proto/src/oap/hello.rs
<a id="crates-ron-proto-src-oap-hello-rs"></a>

```rust
//! RO:WHAT — OAP HELLO frame (protocol/version negotiation).
//! RO:WHY  — Establishes version/features; first contact envelope.
//! RO:INVARIANTS — Strict fields; unknown fields rejected. Use owned `String`
//!                 so JSON deserialization doesn't require a `'static` lifetime.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct Hello {
    pub protocol: String, // was &'static str; use String for serde-compat
    pub version: u32,     // mirrors PROTO_VERSION
    #[serde(default)]
    pub features: Vec<String>, // future growth; strings must be stable tokens
}

impl Default for Hello {
    fn default() -> Self {
        Self {
            protocol: "OAP/1".to_string(),
            version: crate::version::PROTO_VERSION,
            features: Vec::new(),
        }
    }
}

```

### crates/ron-proto/src/oap/mod.rs
<a id="crates-ron-proto-src-oap-mod-rs"></a>

```rust
//! RO:WHAT — OAP/1 envelope DTOs (HELLO/START/DATA/END/ERROR).
//! RO:WHY  — Interop contract: frames carry DTOs between services/SDKs.
//! RO:INTERACTS — id::ContentId; version::PROTO_VERSION; error::ProtoError.
//! RO:INVARIANTS — OAP/1 max_frame=1MiB; chunk≈64KiB is a storage guideline (not enforced here). Strict serde.
//! RO:TEST — vectors under tests/vectors; fuzz targets for headers.

use serde::{Deserialize, Serialize};

pub const MAX_FRAME_BYTES: usize = 1024 * 1024; // 1 MiB

#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "UPPERCASE")]
#[non_exhaustive]
pub enum OapKind {
    Hello,
    Start,
    Data,
    End,
    Error,
}

pub mod data;
pub mod end;
pub mod error;
pub mod hello;
pub mod start;

```

### crates/ron-proto/src/oap/start.rs
<a id="crates-ron-proto-src-oap-start-rs"></a>

```rust
//! RO:WHAT — OAP START frame (session/stream parameters).
//! RO:WHY  — Sets negotiated limits before DATA frames flow.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(deny_unknown_fields)]
pub struct Start {
    pub seq_start: u64,
    pub max_frame_bytes: u32, // must be <= 1MiB; validated by hosts
    #[serde(default)]
    pub meta: Option<String>, // reserved for growth (e.g., codec hints)
}

```

### crates/ron-proto/src/quantum/mod.rs
<a id="crates-ron-proto-src-quantum-mod-rs"></a>

```rust
//! RO:WHAT — PQ-hybrid algorithm tags (enums only; no crypto).
//! RO:WHY  — Keep protocol PQ-agile without dragging crypto deps here.

pub mod pq_tags;

pub use pq_tags::{KemAlg, SignatureAlg};

```

### crates/ron-proto/src/quantum/pq_tags.rs
<a id="crates-ron-proto-src-quantum-pqtags-rs"></a>

```rust
//! RO:WHAT — Enumerations for PQ-capable algorithms referenced by DTOs.
//! RO:WHY  — Wire-stable tokens for hybrid/transition periods (no crypto here).

use serde::{Deserialize, Serialize};

#[derive(Debug, Copy, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
#[serde(rename_all = "snake_case")]
#[non_exhaustive]
pub enum SignatureAlg {
    Ed25519,
    Dilithium3,
    HybridEd25519Dilithium3,
}

#[derive(Debug, Copy, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
#[serde(rename_all = "snake_case")]
#[non_exhaustive]
pub enum KemAlg {
    X25519,
    Kyber768,
    HybridX25519Kyber768,
}

```

### crates/ron-proto/src/trace.rs
<a id="crates-ron-proto-src-trace-rs"></a>

```rust
//! RO:WHAT — Tiny helpers for correlation/trace fields in DTOs.
//! RO:WHY  — Allow hosts to carry correlation IDs without depending on tracing crates.

use serde::{Deserialize, Serialize};

#[derive(Debug, Copy, Clone, Serialize, Deserialize, PartialEq, Eq, Hash, Default)]
#[serde(deny_unknown_fields)]
pub struct CorrId {
    pub id: u64,
}

```

### crates/ron-proto/src/version.rs
<a id="crates-ron-proto-src-version-rs"></a>

```rust
//! RO:WHAT — Protocol version & ABI fingerprint constants.
//! RO:WHY  — Gate breaking changes; SDKs/tests assert these during upgrades.

pub const PROTO_VERSION: u32 = 1;

// NOTE: In CI you can replace this with include_str!("../docs/schema/fingerprint.txt")
// to enforce schema-diff gates. Using a placeholder here to keep the crate self-contained.
pub const PROTO_ABI_FINGERPRINT: &str = "dev-fingerprint";

```

### crates/ron-proto/testing/performance/baselines/ron-proto.json
<a id="crates-ron-proto-testing-performance-baselines-ron-proto-json"></a>

```json

```

### crates/ron-proto/tests/content_id.rs
<a id="crates-ron-proto-tests-contentid-rs"></a>

```rust
use ron_proto::ContentId;

#[test]
fn content_id_parses_and_displays() {
    let s = "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef";
    let cid: ContentId = s.parse().unwrap();
    assert_eq!(cid.to_string(), s);
    assert_eq!(cid.as_str(), s);
}

#[test]
fn content_id_rejects_bad_prefix() {
    let s = "b2:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef";
    assert!(s.parse::<ContentId>().is_err());
}

#[test]
fn content_id_rejects_bad_len() {
    let s = "b3:0123456789abcdef"; // too short
    assert!(s.parse::<ContentId>().is_err());
}

#[test]
fn content_id_rejects_uppercase() {
    let s = "b3:0123456789ABCDEF0123456789abcdef0123456789abcdef0123456789abcdef";
    assert!(s.parse::<ContentId>().is_err());
}

```

### crates/ron-proto/tests/cross_version.rs
<a id="crates-ron-proto-tests-crossversion-rs"></a>

```rust


```

### crates/ron-proto/tests/econ_conservation.rs
<a id="crates-ron-proto-tests-econconservation-rs"></a>

```rust


```

### crates/ron-proto/tests/golden_vectors.rs
<a id="crates-ron-proto-tests-goldenvectors-rs"></a>

```rust
use serde_json as json;

#[test]
fn golden_oap_hello_v1_loads() {
    // Embedded golden vector
    const HELLO_JSON: &str = r#"
    {
      "protocol": "OAP/1",
      "version": 1,
      "features": []
    }
    "#;

    let hello: ron_proto::oap::hello::Hello = json::from_str(HELLO_JSON).unwrap();
    assert_eq!(hello.protocol, "OAP/1");
    assert_eq!(hello.version, ron_proto::version::PROTO_VERSION);
}

#[test]
fn golden_oap_data_min_loads() {
    // IMPORTANT: serde_json + serde_bytes represent Vec<u8> as an array of integers
    // (not base64) by default. Use numeric bytes here for portable goldens.
    const DATA_JSON: &str = r#"
    {
      "obj": "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef",
      "seq": 1,
      "bytes": [104,101,108,108,111]
    }
    "#;

    let data: ron_proto::oap::data::Data = json::from_str(DATA_JSON).unwrap();
    assert_eq!(data.seq, 1);
    assert_eq!(data.bytes, b"hello");
}

```

### crates/ron-proto/tests/hash_truth.rs
<a id="crates-ron-proto-tests-hashtruth-rs"></a>

```rust


```

### crates/ron-proto/tests/interop_parity.rs
<a id="crates-ron-proto-tests-interopparity-rs"></a>

```rust


```

### crates/ron-proto/tests/manifest_defaults.rs
<a id="crates-ron-proto-tests-manifestdefaults-rs"></a>

```rust
use ron_proto::{manifest::EntryRef, ContentId};
use serde_json as json;

#[test]
fn entryref_kind_defaults_to_blob() {
    let cid: ContentId = "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"
        .parse()
        .unwrap();

    // kind omitted on purpose (should default to "blob")
    let value = json::json!({
        "id": cid.to_string(),
        "size": 1234
    });

    let parsed: EntryRef = json::from_value(value).unwrap();

    // Serialize back and ensure "blob" is present
    let round = json::to_value(&parsed).unwrap();
    assert_eq!(round.get("kind").unwrap().as_str().unwrap(), "blob");
}

```

### crates/ron-proto/tests/oap_roundtrip.rs
<a id="crates-ron-proto-tests-oaproundtrip-rs"></a>

```rust
use ron_proto::ContentId;
use serde_json as json;

#[test]
fn hello_default_roundtrip() {
    let h = ron_proto::oap::hello::Hello::default();
    let s = json::to_string(&h).unwrap();
    let back: ron_proto::oap::hello::Hello = json::from_str(&s).unwrap();
    assert_eq!(h.protocol, back.protocol);
    assert_eq!(h.version, back.version);
}

#[test]
fn data_frame_roundtrip() {
    let cid: ContentId = "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"
        .parse()
        .unwrap();
    let d = ron_proto::oap::data::Data {
        obj: cid,
        seq: 42,
        bytes: b"hello world".to_vec(),
    };
    let s = json::to_string(&d).unwrap();
    let back: ron_proto::oap::data::Data = json::from_str(&s).unwrap();
    assert_eq!(back.seq, 42);
    assert_eq!(back.bytes, b"hello world");
}

#[test]
fn end_with_error_roundtrip() {
    let e = ron_proto::oap::error::Error {
        code: ron_proto::error::Kind::TooLarge,
        message: "frame exceeds limit".into(),
        detail: Some("max 1MiB".into()),
    };
    let end = ron_proto::oap::end::End {
        seq_end: 99,
        ok: false,
        error: Some(e),
    };
    let s = json::to_string(&end).unwrap();
    let back: ron_proto::oap::end::End = json::from_str(&s).unwrap();
    assert!(!back.ok);
    assert!(matches!(
        back.error.as_ref().unwrap().code,
        ron_proto::error::Kind::TooLarge
    ));
}

#[test]
fn kind_enum_ser_names_match() {
    use ron_proto::oap::OapKind;
    let kinds = [
        OapKind::Hello,
        OapKind::Start,
        OapKind::Data,
        OapKind::End,
        OapKind::Error,
    ];
    let names: Vec<String> = kinds.iter().map(|k| json::to_string(k).unwrap()).collect();
    assert_eq!(
        names,
        vec![
            r#""HELLO""#,
            r#""START""#,
            r#""DATA""#,
            r#""END""#,
            r#""ERROR""#
        ]
    );
}

```

### crates/ron-proto/tests/validate_helpers.rs
<a id="crates-ron-proto-tests-validatehelpers-rs"></a>

```rust
use ron_proto::{oap, ContentId, Limits, Validate};

#[test]
fn hello_and_start_validate() {
    let hello = oap::hello::Hello::default();
    hello.validate(Limits::default()).unwrap();

    let start = oap::start::Start {
        seq_start: 0,
        max_frame_bytes: 1_048_576,
        meta: None,
    };
    start.validate(Limits::default()).unwrap();
}

#[test]
fn data_respects_negotiated_max() {
    let limits = Limits { max_frame_bytes: 8 };

    // Make the type explicit so .parse() knows the target type:
    let cid: ContentId = "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"
        .parse()
        .unwrap();

    let ok = oap::data::Data {
        obj: cid.clone(),
        seq: 1,
        bytes: b"12345678".to_vec(),
    };
    ok.validate(limits).unwrap();

    let too_big = oap::data::Data {
        obj: cid,
        seq: 2,
        bytes: b"abcdefghi".to_vec(),
    };
    assert!(too_big.validate(limits).is_err());
}

```

### crates/ron-proto/tests/vectors/content_id.json
<a id="crates-ron-proto-tests-vectors-contentid-json"></a>

```json

```

### crates/ron-proto/tests/vectors/manifest_v1.json
<a id="crates-ron-proto-tests-vectors-manifestv1-json"></a>

```json

```

### crates/ron-proto/tests/vectors/oap_data_min.json
<a id="crates-ron-proto-tests-vectors-oapdatamin-json"></a>

```json
{
  "obj": "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef",
  "seq": 1,
  "bytes": "aGVsbG8="
}

```

### crates/ron-proto/tests/vectors/oap_error_envelope.json
<a id="crates-ron-proto-tests-vectors-oaperrorenvelope-json"></a>

```json

```

### crates/ron-proto/tests/vectors/oap_hello_v1.json
<a id="crates-ron-proto-tests-vectors-oaphellov1-json"></a>

```json
{
  "protocol": "OAP/1",
  "version": 1,
  "features": []
}

```



---



# ron-metrics

_Source: crates/ron-metrics/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:47:02Z -->
# Code Bundle — `ron-metrics`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-metrics/.cargo/config.toml](#crates-ron-metrics--cargo-config-toml)
- [crates/ron-metrics/.github/workflows/ci.yml](#crates-ron-metrics--github-workflows-ci-yml)
- [crates/ron-metrics/.github/workflows/coverage.yml](#crates-ron-metrics--github-workflows-coverage-yml)
- [crates/ron-metrics/.github/workflows/mermaid.yml](#crates-ron-metrics--github-workflows-mermaid-yml)
- [crates/ron-metrics/.github/workflows/perf-smoke.yml](#crates-ron-metrics--github-workflows-perf-smoke-yml)
- [crates/ron-metrics/.github/workflows/public-api.yml](#crates-ron-metrics--github-workflows-public-api-yml)
- [crates/ron-metrics/.github/workflows/sanitizer.yml](#crates-ron-metrics--github-workflows-sanitizer-yml)
- [crates/ron-metrics/Cargo.toml](#crates-ron-metrics-Cargo-toml)
- [crates/ron-metrics/benches/exposer_bench.rs](#crates-ron-metrics-benches-exposerbench-rs)
- [crates/ron-metrics/benches/hotpath_bench.rs](#crates-ron-metrics-benches-hotpathbench-rs)
- [crates/ron-metrics/deny.toml](#crates-ron-metrics-deny-toml)
- [crates/ron-metrics/examples/axum_api.rs](#crates-ron-metrics-examples-axumapi-rs)
- [crates/ron-metrics/examples/exposer.rs](#crates-ron-metrics-examples-exposer-rs)
- [crates/ron-metrics/examples/pump.rs](#crates-ron-metrics-examples-pump-rs)
- [crates/ron-metrics/examples/watch_bus.rs](#crates-ron-metrics-examples-watchbus-rs)
- [crates/ron-metrics/rust-toolchain.toml](#crates-ron-metrics-rust-toolchain-toml)
- [crates/ron-metrics/scripts/check-taxonomy.sh](#crates-ron-metrics-scripts-check-taxonomy-sh)
- [crates/ron-metrics/scripts/render-mermaid.sh](#crates-ron-metrics-scripts-render-mermaid-sh)
- [crates/ron-metrics/src/axum_latency.rs](#crates-ron-metrics-src-axumlatency-rs)
- [crates/ron-metrics/src/axum_status.rs](#crates-ron-metrics-src-axumstatus-rs)
- [crates/ron-metrics/src/build_info.rs](#crates-ron-metrics-src-buildinfo-rs)
- [crates/ron-metrics/src/bus_watcher.rs](#crates-ron-metrics-src-buswatcher-rs)
- [crates/ron-metrics/src/config.rs](#crates-ron-metrics-src-config-rs)
- [crates/ron-metrics/src/errors.rs](#crates-ron-metrics-src-errors-rs)
- [crates/ron-metrics/src/exporters/mod.rs](#crates-ron-metrics-src-exporters-mod-rs)
- [crates/ron-metrics/src/exporters/otel.rs](#crates-ron-metrics-src-exporters-otel-rs)
- [crates/ron-metrics/src/exposer/http.rs](#crates-ron-metrics-src-exposer-http-rs)
- [crates/ron-metrics/src/exposer/middleware.rs](#crates-ron-metrics-src-exposer-middleware-rs)
- [crates/ron-metrics/src/exposer/mod.rs](#crates-ron-metrics-src-exposer-mod-rs)
- [crates/ron-metrics/src/exposer/tls.rs](#crates-ron-metrics-src-exposer-tls-rs)
- [crates/ron-metrics/src/exposer/uds.rs](#crates-ron-metrics-src-exposer-uds-rs)
- [crates/ron-metrics/src/health.rs](#crates-ron-metrics-src-health-rs)
- [crates/ron-metrics/src/labels.rs](#crates-ron-metrics-src-labels-rs)
- [crates/ron-metrics/src/lib.rs](#crates-ron-metrics-src-lib-rs)
- [crates/ron-metrics/src/metrics.rs](#crates-ron-metrics-src-metrics-rs)
- [crates/ron-metrics/src/pq.rs](#crates-ron-metrics-src-pq-rs)
- [crates/ron-metrics/src/readiness.rs](#crates-ron-metrics-src-readiness-rs)
- [crates/ron-metrics/src/registry.rs](#crates-ron-metrics-src-registry-rs)
- [crates/ron-metrics/src/zk.rs](#crates-ron-metrics-src-zk-rs)
- [crates/ron-metrics/tests/bus_watcher.rs](#crates-ron-metrics-tests-buswatcher-rs)
- [crates/ron-metrics/tests/health_ready.rs](#crates-ron-metrics-tests-healthready-rs)
- [crates/ron-metrics/tests/http_endpoints.rs](#crates-ron-metrics-tests-httpendpoints-rs)
- [crates/ron-metrics/tests/http_status_counter.rs](#crates-ron-metrics-tests-httpstatuscounter-rs)
- [crates/ron-metrics/tests/integration_http_endpoints.rs](#crates-ron-metrics-tests-integrationhttpendpoints-rs)
- [crates/ron-metrics/tests/loom_shutdown.rs](#crates-ron-metrics-tests-loomshutdown-rs)
- [crates/ron-metrics/tests/metrics_encode_ok.rs](#crates-ron-metrics-tests-metricsencodeok-rs)
- [crates/ron-metrics/tests/public_api.rs](#crates-ron-metrics-tests-publicapi-rs)
- [crates/ron-metrics/tests/readiness_semantics.rs](#crates-ron-metrics-tests-readinesssemantics-rs)
- [crates/ron-metrics/tests/taxonomy_labels.rs](#crates-ron-metrics-tests-taxonomylabels-rs)
- [crates/ron-metrics/tests/vectors/interop/ron-metrics/readyz-degraded.json](#crates-ron-metrics-tests-vectors-interop-ron-metrics-readyz-degraded-json)
- [crates/ron-metrics/tests/vectors/interop/ron-metrics/readyz-ready.json](#crates-ron-metrics-tests-vectors-interop-ron-metrics-readyz-ready-json)

### crates/ron-metrics/.cargo/config.toml
<a id="crates-ron-metrics--cargo-config-toml"></a>

```toml
# Minimal, portable Cargo config for CI parity
[build]
rustflags = []

[env]
RUSTFLAGS = "-Dwarnings"

```

### crates/ron-metrics/.github/workflows/ci.yml
<a id="crates-ron-metrics--github-workflows-ci-yml"></a>

```yaml
name: ci
on: [push, pull_request]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: rustup toolchain install 1.80.0 --profile minimal --component rustfmt clippy
      - run: cargo fmt --all -- --check
      - run: cargo clippy -p ron-metrics2 -- -D warnings
      - run: cargo test -p ron-metrics2
      - run: cargo deny check

```

### crates/ron-metrics/.github/workflows/coverage.yml
<a id="crates-ron-metrics--github-workflows-coverage-yml"></a>

```yaml
name: coverage
on: [push, pull_request]
jobs:
  cov:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: taiki-e/install-action@cargo-llvm-cov
      - run: cargo llvm-cov --workspace --lcov --output-path lcov.info
      - run: cargo llvm-cov report --json | jq -e '.data[0].totals.branches.percent >= 80'

```

### crates/ron-metrics/.github/workflows/mermaid.yml
<a id="crates-ron-metrics--github-workflows-mermaid-yml"></a>

```yaml
name: render-mermaid
on: [push, pull_request]
jobs:
  mmdc:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm i -g @mermaid-js/mermaid-cli
      - run: |
          mkdir -p docs
          for f in $(git ls-files 'docs/mmd/*.mmd'); do
            out="${f%.mmd}.svg"
            mmdc -i "$f" -o "$out"
          done

```

### crates/ron-metrics/.github/workflows/perf-smoke.yml
<a id="crates-ron-metrics--github-workflows-perf-smoke-yml"></a>

```yaml
name: perf-smoke
on:
  workflow_dispatch:
jobs:
  bombardier:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "perf smoke placeholder (would hammer /metrics and record p95)"

```

### crates/ron-metrics/.github/workflows/public-api.yml
<a id="crates-ron-metrics--github-workflows-public-api-yml"></a>

```yaml
name: public-api
on: [push, pull_request]
jobs:
  api:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: cargo install cargo-public-api
      # Allow first run to pass before snapshots exist; tighten later.
      - run: cargo public-api --crate ron-metrics2 --deny changed || true

```

### crates/ron-metrics/.github/workflows/sanitizer.yml
<a id="crates-ron-metrics--github-workflows-sanitizer-yml"></a>

```yaml
name: sanitizer
on:
  schedule:
    - cron: "0 4 * * *"
jobs:
  tsan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: rustup toolchain install nightly --profile minimal
      - run: rustup default nightly
      - run: RUSTFLAGS="-Z sanitizer=thread" RUSTDOCFLAGS="-Z sanitizer=thread" cargo test -p ron-metrics2 --target x86_64-unknown-linux-gnu || true

```

### crates/ron-metrics/Cargo.toml
<a id="crates-ron-metrics-Cargo-toml"></a>

```toml
[package]
name = "ron-metrics"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
rust-version = "1.80.0"
description = "RustyOnions observability library (+ tiny HTTP exposer)"

[features]
default = []
bus = ["dep:ron-bus"]                      # bridge ron-bus events -> metrics/health (optional)
otel = ["dep:opentelemetry", "dep:opentelemetry-otlp"]
tls = ["dep:tokio-rustls"]
uds = []

[dependencies]
axum = { version = "0.7.9", default-features = false, features = ["tokio", "http1", "http2", "json"] }
prometheus = "0.14"
tokio = { version = "1.47.1", features = ["rt-multi-thread","macros","net","signal","time","io-util"] }
parking_lot = "0.12"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
thiserror = "1.0"
once_cell = "1.19"
tracing = "0.1"
http = "1.1"
tower = "0.4"


# optional
tokio-rustls = { version = "0.26.2", optional = true }
opentelemetry = { version = "0.23", optional = true }
opentelemetry-otlp = { version = "0.16", optional = true }
ron-bus = { path = "../ron-bus", optional = true }   # adjust path if your workspace differs

[dev-dependencies]
anyhow = "1.0"
# Hyper core + client
hyper = { version = "1.4", features = ["client", "http1", "http2"] }
hyper-util = { version = "0.1", features = ["client", "http1", "http2", "tokio", "client-legacy"] }
http-body-util = "0.1"
tracing-subscriber = "0.3"
rand = "0.9"
reqwest = { version = "0.12", default-features = false, features = ["rustls-tls"] }

```

### crates/ron-metrics/benches/exposer_bench.rs
<a id="crates-ron-metrics-benches-exposerbench-rs"></a>

```rust
// Criterion bench placeholder for exposition latency across registry sizes.
fn main() {}

```

### crates/ron-metrics/benches/hotpath_bench.rs
<a id="crates-ron-metrics-benches-hotpathbench-rs"></a>

```rust
// Measures counter/histogram hot path (scaffold placeholder).
fn main() {}

```

### crates/ron-metrics/deny.toml
<a id="crates-ron-metrics-deny-toml"></a>

```toml
# cargo-deny baseline (licenses, advisories, bans)
[advisories]
vulnerability = "deny"
yanked = "deny"

[licenses]
confidence-threshold = 0.8
allow = [
  "MIT", "Apache-2.0", "Unicode-DFS-2016", "BSD-3-Clause",
  "ISC", "CC0-1.0", "OpenSSL"
]

```

### crates/ron-metrics/examples/axum_api.rs
<a id="crates-ron-metrics-examples-axumapi-rs"></a>

```rust
//! RO:WHAT — Example Axum API instrumented with ron-metrics middleware (latency + status-class).
//! RO:WHY  — Zero-touch HTTP visibility: /metrics + automatic histograms/counters.
//! Run: RON_METRICS_METRICS_ADDR=127.0.0.1:0 cargo run -p ron-metrics --example axum_api

use axum::{routing::get, Router};
use std::{env, net::SocketAddr, time::Duration};
use tokio::time::sleep;

use ron_metrics::{
    axum_latency, // latency histogram middleware (request_latency_seconds)
    axum_status,  // status-class counter middleware (request_status_total)
    build_info::build_version,
    exposer::http::make_router as make_metrics_router,
    BaseLabels,
    HealthState,
    Metrics,
};

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    tracing_subscriber::fmt::init();

    // Base labels
    let base = BaseLabels {
        service: env::var("RON_SERVICE").unwrap_or_else(|_| "demo-api".into()),
        instance: env::var("RON_INSTANCE").unwrap_or_else(|_| "local-1".into()),
        build_version: build_version(),
        amnesia: env::var("RON_AMNESIA").unwrap_or_else(|_| "off".into()),
    };

    // Health state
    let health = HealthState::new();
    health.set("config_loaded".into(), true);
    health.set("db".into(), true);

    // Metrics
    let metrics = Metrics::new(base, health)?;

    // App routes (business endpoints)
    let app = Router::new()
        .route("/ping", get(|| async { "pong" }))
        .route(
            "/sleep",
            get(|| async {
                // Simulate work
                sleep(Duration::from_millis(12)).await;
                "ok"
            }),
        );

    // Expose /metrics, /healthz, /readyz on same server
    let app = app.merge(make_metrics_router(metrics.clone()));

    // Attach middlewares (order is fine either way; both apply to all routes)
    let app = axum_latency::attach(app, metrics.clone());
    let app = axum_status::attach(app, metrics.clone());

    // Bind & serve
    let bind: SocketAddr = env::var("RON_METRICS_METRICS_ADDR")
        .unwrap_or_else(|_| "127.0.0.1:0".into())
        .parse()?;
    let listener = tokio::net::TcpListener::bind(bind).await?;
    let addr = listener.local_addr()?;
    println!("api     :  http://{}/ping", addr);
    println!("sleep   :  http://{}/sleep", addr);
    println!("metrics :  http://{}/metrics", addr);
    println!("healthz :  http://{}/healthz", addr);
    println!("readyz  :  http://{}/readyz", addr);

    axum::serve(listener, app).await?;
    Ok(())
}

```

### crates/ron-metrics/examples/exposer.rs
<a id="crates-ron-metrics-examples-exposer-rs"></a>

```rust
//! RO:WHAT — Tiny demo: start the exposer and print bound addr.

use ron_metrics::build_info::build_version;
use ron_metrics::{BaseLabels, HealthState, Metrics};
use std::env;
use std::net::SocketAddr;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    tracing_subscriber::fmt::init();

    let service = env::var("RON_SERVICE").unwrap_or_else(|_| "demo".into());
    let instance = env::var("RON_INSTANCE").unwrap_or_else(|_| "local-1".into());
    let amnesia = match env::var("RON_AMNESIA").ok().as_deref() {
        Some("on") | Some("1") | Some("true") => "on".to_string(),
        _ => "off".to_string(),
    };

    let base = BaseLabels {
        service,
        instance,
        build_version: build_version(),
        amnesia,
    };

    let health = HealthState::new();
    // Declare one dependency and mark ready
    health.set("config_loaded".to_string(), true);

    let metrics = Metrics::new(base, health)?;
    let bind: SocketAddr = env::var("RON_METRICS_METRICS_ADDR")
        .unwrap_or_else(|_| "127.0.0.1:9100".into())
        .parse()?;

    let (_jh, addr) = metrics.serve(bind).await?;
    println!("metrics:  http://{addr}/metrics");
    println!("healthz:  http://{addr}/healthz");
    println!("readyz :  http://{addr}/readyz");
    tokio::signal::ctrl_c().await?;
    Ok(())
}

```

### crates/ron-metrics/examples/pump.rs
<a id="crates-ron-metrics-examples-pump-rs"></a>

```rust
//! RO:WHAT — Simulate activity against Metrics so /metrics moves live.
//! Run: RON_METRICS_METRICS_ADDR=127.0.0.1:0 cargo run -p ron-metrics --example pump

use rand::{rng, Rng}; // rand 0.9 API
use ron_metrics::{build_info::build_version, BaseLabels, HealthState, Metrics};
use std::{env, net::SocketAddr, time::Duration};
use tokio::time::sleep;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    tracing_subscriber::fmt::init();

    let service = env::var("RON_SERVICE").unwrap_or_else(|_| "demo".into());
    let instance = env::var("RON_INSTANCE").unwrap_or_else(|_| "local-1".into());
    let amnesia = match env::var("RON_AMNESIA").ok().as_deref() {
        Some("on") | Some("1") | Some("true") => "on".to_string(),
        _ => "off".to_string(),
    };

    let base = BaseLabels {
        service,
        instance,
        build_version: build_version(),
        amnesia,
    };

    let health = HealthState::new();
    health.set("config_loaded".to_string(), true);
    health.set("db".to_string(), false);
    health.set("cache".to_string(), false);

    let metrics = Metrics::new(base, health)?;
    let bind: SocketAddr = env::var("RON_METRICS_METRICS_ADDR")
        .unwrap_or_else(|_| "127.0.0.1:0".into())
        .parse()?;

    let (_jh, addr) = metrics.clone().serve(bind).await?;
    println!("metrics:  http://{addr}/metrics");
    println!("healthz:  http://{addr}/healthz");
    println!("readyz :  http://{addr}/readyz");

    // Simulate activity forever
    let mut tick: u64 = 0;
    loop {
        let mut r = rng();

        // Simulate a request with 0.3–20 ms latency
        let lat_ms: f64 = r.random_range(0.3..20.0);
        metrics.observe_request(lat_ms / 1000.0);

        // Pretend a service restarted every ~15s
        if tick % 15 == 0 {
            metrics.inc_service_restart("worker-A");
        }

        // Pretend the bus overwrote some lagged messages sporadically
        if tick % 7 == 0 {
            let overwrites: u64 = r.random_range(1..5);
            metrics.add_bus_lag("kernel", overwrites);
        }

        // Flip readiness of db/cache occasionally to show /readyz truth
        if tick % 9 == 0 {
            let ok = r.random::<bool>();
            metrics.set_ready("db", ok);
        }
        if tick % 11 == 0 {
            let ok = r.random::<bool>();
            metrics.set_ready("cache", ok);
        }

        tick += 1;
        sleep(Duration::from_millis(1000)).await;
    }
}

```

### crates/ron-metrics/examples/watch_bus.rs
<a id="crates-ron-metrics-examples-watchbus-rs"></a>

```rust
//! RO:WHAT — Demo: bridge ron-bus events into ron-metrics endpoints.
//! Run: cargo run -p ron-metrics --features bus --example watch_bus

use ron_metrics::{build_info::build_version, BaseLabels, HealthState, Metrics};
use std::{env, net::SocketAddr, time::Duration};

#[cfg(feature = "bus")]
use {
    ron_bus::{Bus, BusConfig, Event},
    ron_metrics::bus_watcher::start_bus_watcher,
    tokio::time::sleep,
};

/// When `bus` feature is OFF, provide a tiny placeholder main so examples still build under `cargo test`.
#[cfg(not(feature = "bus"))]
fn main() {
    eprintln!("watch_bus example requires `--features bus`");
}

/// Real example when `bus` feature is ON.
#[cfg(feature = "bus")]
#[tokio::main]
async fn main() -> anyhow::Result<()> {
    tracing_subscriber::fmt::init();

    let base = BaseLabels {
        service: env::var("RON_SERVICE").unwrap_or_else(|_| "demo".into()),
        instance: env::var("RON_INSTANCE").unwrap_or_else(|_| "local-1".into()),
        build_version: build_version(),
        amnesia: env::var("RON_AMNESIA").unwrap_or_else(|_| "off".into()),
    };

    let cfg = BusConfig::default().with_capacity(256);
    let bus = Bus::new(cfg).expect("bus");

    let health = HealthState::new();
    health.set("config_loaded".into(), false);

    let metrics = Metrics::new(base, health)?;
    let bind: SocketAddr = env::var("RON_METRICS_METRICS_ADDR")
        .unwrap_or_else(|_| "127.0.0.1:0".into())
        .parse()?;

    let (_jh, addr) = metrics.clone().serve(bind).await?;
    println!("metrics:  http://{addr}/metrics");
    println!("healthz:  http://{addr}/healthz");
    println!("readyz :  http://{addr}/readyz");

    let _watcher = start_bus_watcher(metrics.clone(), &bus, "demo-watcher");

    let tx = bus.sender();
    tx.send(Event::Health {
        service: "config_loaded".into(),
        ok: false,
    })
    .expect("send");
    sleep(Duration::from_millis(250)).await;
    tx.send(Event::Health {
        service: "config_loaded".into(),
        ok: true,
    })
    .expect("send");

    println!("curl the endpoints now. shutting down in ~3s…");
    sleep(Duration::from_secs(3)).await;
    tx.send(Event::Shutdown).expect("send");

    Ok(())
}

```

### crates/ron-metrics/rust-toolchain.toml
<a id="crates-ron-metrics-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["rustfmt", "clippy"]

```

### crates/ron-metrics/scripts/check-taxonomy.sh
<a id="crates-ron-metrics-scripts-check-taxonomy-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# Placeholder: fetch /metrics and assert suffix and base labels (scaffold).
echo "check-taxonomy: placeholder"

```

### crates/ron-metrics/scripts/render-mermaid.sh
<a id="crates-ron-metrics-scripts-render-mermaid-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# Renders all docs/mmd/*.mmd to .svg (requires mmdc).
echo "render-mermaid: placeholder"

```

### crates/ron-metrics/src/axum_latency.rs
<a id="crates-ron-metrics-src-axumlatency-rs"></a>

```rust
//! RO:WHAT — Axum middleware to observe request latency into ron-metrics.
//! RO:WHY  — Zero-touch per-request timing for Axum apps.
//! RO:INVARIANTS — no locks across .await; low overhead.
//! RO:USAGE — let app = axum_latency::attach(router, metrics.clone());

use std::time::Instant;

use crate::Metrics;
use axum::{
    body::Body,
    extract::State,
    http::Request,
    middleware::{self, Next},
    response::Response,
    Router,
};

/// Attach a latency middleware to the given Router that records per-request
/// latency into `request_latency_seconds`.
///
/// ```ignore
/// let router = Router::new()
///     .route("/ping", get(|| async { "pong" }));
/// let router = ron_metrics::axum_latency::attach(router, metrics.clone());
/// ```
pub fn attach(router: Router, metrics: Metrics) -> Router {
    router.layer(middleware::from_fn_with_state(metrics, track_latency))
}

async fn track_latency(State(metrics): State<Metrics>, req: Request<Body>, next: Next) -> Response {
    let started = Instant::now();
    let resp = next.run(req).await;
    metrics.observe_request(started.elapsed().as_secs_f64());
    resp
}

```

### crates/ron-metrics/src/axum_status.rs
<a id="crates-ron-metrics-src-axumstatus-rs"></a>

```rust
//! RO:WHAT — Axum middleware to count responses by status class (1xx..5xx).
//! RO:WHY  — Low-cardinality error-rate signal for SRE/alerts.
//! RO:USAGE — let app = axum_status::attach(router, metrics.clone());

use crate::Metrics;
use axum::{
    body::Body,
    http::Request,
    middleware::{self, Next},
    response::Response,
    Router,
};

pub fn attach(router: Router, metrics: Metrics) -> Router {
    router.layer(middleware::from_fn_with_state(metrics, count_status))
}

async fn count_status(
    axum::extract::State(metrics): axum::extract::State<Metrics>,
    req: Request<Body>,
    next: Next,
) -> Response {
    let resp = next.run(req).await;
    let code = resp.status().as_u16();
    let class = match code {
        100..=199 => "1xx",
        200..=299 => "2xx",
        300..=399 => "3xx",
        400..=499 => "4xx",
        500..=599 => "5xx",
        _ => "other",
    };
    metrics.observe_status_class(class);
    resp
}

```

### crates/ron-metrics/src/build_info.rs
<a id="crates-ron-metrics-src-buildinfo-rs"></a>

```rust
//! RO:WHAT — Build/version helpers for base labels.

pub fn build_version() -> String {
    // Package version + short git if provided by outer build
    let ver = env!("CARGO_PKG_VERSION");
    match option_env!("GIT_SHA_SHORT") {
        Some(sha) if !sha.is_empty() => format!("{ver}+{sha}"),
        _ => ver.to_string(),
    }
}

```

### crates/ron-metrics/src/bus_watcher.rs
<a id="crates-ron-metrics-src-buswatcher-rs"></a>

```rust
//! RO:WHAT — Translate ron-bus events into metrics + health updates.
//! RO:WHY  — Unified observability; keep ron-bus lean, exporter lives here.
//! RO:INTERACTS — ron_bus::{Bus, Event}; Metrics; HealthState.
//! RO:INVARIANTS — single subscriber; bounded; no lock across .await.
//! RO:TODO — If ron-bus later emits lag/overwrite events, extend the match arms here behind the same feature.

#![allow(dead_code)]

#[cfg(feature = "bus")]
mod impls {
    use crate::Metrics;
    use ron_bus::{Bus, Event};
    use tokio::task::JoinHandle;
    use tokio::time::{sleep, Duration};
    use tracing::{info, warn};

    /// Start a watcher that consumes events from the shared bus and updates metrics/health.
    /// We only borrow the `Bus` to create a subscriber; the subscriber is moved into the task.
    pub fn start_bus_watcher(
        metrics: Metrics,
        bus: &Bus,
        watcher_name: &'static str,
    ) -> JoinHandle<()> {
        // Each subscriber has its own cursor by design.
        let mut sub = bus.subscribe();

        tokio::spawn(async move {
            info!(watcher=%watcher_name, "ron-metrics: bus watcher started");
            loop {
                match sub.recv().await {
                    Ok(ev) => match ev {
                        Event::Health { service, ok } => {
                            metrics.set_ready(&service, ok);
                        }
                        Event::Shutdown => {
                            info!(watcher=%watcher_name, "ron-metrics: bus watcher received Shutdown; exiting");
                            break;
                        }
                        // Extend here when new events are added (e.g., ConfigUpdated, BusLag, etc.)
                        _ => {}
                    },
                    Err(e) => {
                        // Channel closed or transient error — back off a hair to avoid hot loop.
                        warn!(watcher=%watcher_name, error=?e, "bus watcher recv error; backing off");
                        sleep(Duration::from_millis(5)).await;
                    }
                }
            }
        })
    }
}

#[cfg(feature = "bus")]
pub use impls::start_bus_watcher;

// If the feature is off, expose a stub so callsites can compile behind cfg.
#[cfg(not(feature = "bus"))]
pub fn start_bus_watcher(_: crate::Metrics, _: (), _: &'static str) -> () {
    ()
}

```

### crates/ron-metrics/src/config.rs
<a id="crates-ron-metrics-src-config-rs"></a>

```rust
// Typed configuration placeholder for ron-metrics2.
// Defines TCP addr vs UDS, timeouts, TLS paths, OTLP endpoint (env-first).
// Implementation intentionally omitted in scaffold.

```

### crates/ron-metrics/src/errors.rs
<a id="crates-ron-metrics-src-errors-rs"></a>

```rust
use thiserror::Error;

#[derive(Debug, Error)]
pub enum MetricsError {
    #[error("prometheus error: {0}")]
    Prometheus(#[from] prometheus::Error),

    #[error("io error: {0}")]
    Io(#[from] std::io::Error),

    #[error("other: {0}")]
    Other(String),
}

```

### crates/ron-metrics/src/exporters/mod.rs
<a id="crates-ron-metrics-src-exporters-mod-rs"></a>

```rust
//! RO:WHAT — Optional exporters (OTLP), feature-gated.

#[cfg(feature = "otel")]
pub mod otel;

```

### crates/ron-metrics/src/exporters/otel.rs
<a id="crates-ron-metrics-src-exporters-otel-rs"></a>

```rust
//! RO:WHAT — Minimal OTLP exporter wiring (feature gated).

#[allow(dead_code)]
pub fn init_otel() -> Result<(), Box<dyn std::error::Error>> {
    // Stub for future: map families to OTLP if desired.
    Ok(())
}

```

### crates/ron-metrics/src/exposer/http.rs
<a id="crates-ron-metrics-src-exposer-http-rs"></a>

```rust
//! RO:WHAT — Axum router + handlers for /metrics, /healthz, /readyz.

use crate::{
    metrics::Metrics,
    readiness::{make_ready_json, ReadyJson, ReadyPolicy},
};
use axum::{
    extract::State,
    http::{header, StatusCode},
    response::{IntoResponse, Response},
    routing::get,
    Json, Router,
};
use prometheus::{Encoder, TextEncoder}; // <-- Encoder trait needed
use std::time::{Instant, SystemTime};

#[derive(Clone)]
pub struct AppState {
    pub metrics: Metrics,
    pub ready_since: SystemTime,
}

pub fn make_router(metrics: Metrics) -> Router {
    let state = AppState {
        metrics,
        ready_since: SystemTime::now(),
    };

    Router::new()
        .route("/metrics", get(get_metrics))
        .route("/healthz", get(get_healthz))
        .route("/readyz", get(get_readyz))
        .with_state(state)
}

async fn get_metrics(State(st): State<AppState>) -> impl IntoResponse {
    let t0 = Instant::now();
    let mf = st.metrics.registry().gather();

    let mut buf = Vec::with_capacity(64 * 1024);
    let enc = TextEncoder::new();

    if let Err(e) = enc.encode(&mf, &mut buf) {
        return (
            StatusCode::INTERNAL_SERVER_ERROR,
            format!("encode failed: {e}"),
        )
            .into_response();
    }

    let secs = t0.elapsed().as_secs_f64();
    st.metrics.observe_exposition(secs, "/metrics");

    Response::builder()
        .status(StatusCode::OK)
        .header(header::CONTENT_TYPE, enc.format_type())
        .body(axum::body::Body::from(buf))
        .unwrap()
}

async fn get_healthz() -> impl IntoResponse {
    (StatusCode::OK, "ok")
}

async fn get_readyz(State(st): State<AppState>) -> impl IntoResponse {
    let health = st.metrics.health();
    let snap = health.snapshot();
    let all_ready = snap.values().all(|v| *v);
    let missing: Vec<String> = snap
        .into_iter()
        .filter_map(|(svc, ok)| if ok { None } else { Some(svc) })
        .collect();

    let policy: ReadyPolicy = st.metrics.ready_policy();
    let body: ReadyJson = make_ready_json(all_ready, missing, policy, st.ready_since);

    if all_ready {
        (StatusCode::OK, Json(body)).into_response()
    } else {
        let mut resp = (StatusCode::SERVICE_UNAVAILABLE, Json(body)).into_response();
        let retry_after = policy.retry_after_secs.to_string();
        resp.headers_mut()
            .insert(header::RETRY_AFTER, retry_after.parse().unwrap());
        resp
    }
}

```

### crates/ron-metrics/src/exposer/middleware.rs
<a id="crates-ron-metrics-src-exposer-middleware-rs"></a>

```rust
// Middleware placeholder: timeouts, concurrency caps, inflight gauge hooks.

```

### crates/ron-metrics/src/exposer/mod.rs
<a id="crates-ron-metrics-src-exposer-mod-rs"></a>

```rust
//! RO:WHAT — HTTP exposer surface (router + helpers).

pub mod http;
// Future: pub mod tls; pub mod uds;

```

### crates/ron-metrics/src/exposer/tls.rs
<a id="crates-ron-metrics-src-exposer-tls-rs"></a>

```rust
// TLS wiring placeholder (tokio_rustls::rustls::ServerConfig only).

```

### crates/ron-metrics/src/exposer/uds.rs
<a id="crates-ron-metrics-src-exposer-uds-rs"></a>

```rust
// UDS bind placeholder with secure modes (0700 dir / 0600 socket), no symlinks.

```

### crates/ron-metrics/src/health.rs
<a id="crates-ron-metrics-src-health-rs"></a>

```rust
//! RO:WHAT — In-memory readiness map with snapshot semantics.

use parking_lot::RwLock;
use std::{collections::BTreeMap, sync::Arc};

pub type ServiceName = String;

#[derive(Clone)]
pub struct HealthState {
    inner: Arc<RwLock<BTreeMap<ServiceName, bool>>>,
}

impl HealthState {
    pub fn new() -> Self {
        Self {
            inner: Arc::new(RwLock::new(BTreeMap::new())),
        }
    }
    pub fn set(&self, service: ServiceName, ok: bool) {
        let mut w = self.inner.write();
        w.insert(service, ok);
    }
    pub fn snapshot(&self) -> BTreeMap<ServiceName, bool> {
        self.inner.read().clone()
    }
    pub fn all_ready(&self) -> bool {
        self.inner.read().values().all(|v| *v)
    }
}

```

### crates/ron-metrics/src/labels.rs
<a id="crates-ron-metrics-src-labels-rs"></a>

```rust
//! RO:WHAT — Base label helpers (service, instance, build_version, amnesia).

use std::collections::HashMap;

#[derive(Clone, Debug)]
pub struct BaseLabels {
    pub service: String,
    pub instance: String,
    pub build_version: String,
    pub amnesia: String,
}

impl BaseLabels {
    pub fn to_const_labels(&self) -> HashMap<String, String> {
        let mut m = HashMap::with_capacity(4);
        m.insert("service".into(), self.service.clone());
        m.insert("instance".into(), self.instance.clone());
        m.insert("build_version".into(), self.build_version.clone());
        m.insert("amnesia".into(), self.amnesia.clone());
        m
    }
}

```

### crates/ron-metrics/src/lib.rs
<a id="crates-ron-metrics-src-lib-rs"></a>

```rust
//! RO:WHAT — Public façade for ron-metrics: golden families, health/readiness, HTTP exposer.
//! RO:WHY  — Pillar 5 Observability; Concerns: PERF/RES/GOV.
//! RO:INTERACTS — crate::{metrics,registry,labels,health,readiness}, axum; prometheus Registry.
//! RO:INVARIANTS — single registration per process; GET-only; no lock across .await; TLS type=tokio_rustls::rustls::ServerConfig.
//! RO:METRICS — service_restarts_total, bus_lagged_total, request_latency_seconds, exposition_latency_seconds, health_ready{service}.
//! RO:CONFIG — base labels include {service,instance,build_version,amnesia}; amnesia truthful.

#![forbid(unsafe_code)]

pub mod axum_latency;
pub mod axum_status;
pub mod build_info;
pub mod bus_watcher;
mod errors;
pub mod exporters;
pub mod exposer;
mod health;
mod labels;
mod metrics;
mod readiness;
mod registry;

pub use crate::errors::MetricsError;
pub use crate::health::HealthState;
pub use crate::labels::BaseLabels;
pub use crate::metrics::Metrics;
pub use crate::readiness::{ReadyJson, ReadyPolicy};
pub use crate::registry::SafeRegistry;

```

### crates/ron-metrics/src/metrics.rs
<a id="crates-ron-metrics-src-metrics-rs"></a>

```rust
//! RO:WHAT — Metrics facade and registry wiring for ron-metrics.
//! RO:WHY  — Single place to define/own metric families and expose helpers.
//! RO:INVARIANTS — no locks across .await; single registry instance; stable names.

use std::sync::Arc;

use crate::exposer::http::make_router;
use crate::health::HealthState;
use crate::readiness::ReadyPolicy; // <- import ReadyPolicy from the public module
use crate::registry::SafeRegistry;

use prometheus::{Histogram, HistogramOpts, IntCounterVec, IntGaugeVec, Opts};
use tokio::net::TcpListener;
use tokio::task::JoinHandle;

use crate::errors::MetricsError;
use crate::BaseLabels;

#[derive(Clone)]
pub struct Metrics {
    inner: Arc<Inner>,
}

struct Inner {
    registry: SafeRegistry,
    // Golden families
    pub service_restarts_total: IntCounterVec,
    pub bus_lagged_total: IntCounterVec,
    pub request_latency_seconds: Histogram,
    pub exposition_latency_seconds: Histogram,
    pub health_ready: IntGaugeVec,
    pub request_status_total: IntCounterVec,
    // Health state used by /healthz,/readyz
    pub health: HealthState,
}

impl Metrics {
    pub fn new(_base: BaseLabels, health: HealthState) -> Result<Self, MetricsError> {
        // Current SafeRegistry only exposes `new()`
        let registry = SafeRegistry::new();

        // ---- metric families ----
        let service_restarts_total = IntCounterVec::new(
            Opts::new("service_restarts_total", "Total restarts per component"),
            &["component"],
        )?;

        let bus_lagged_total = IntCounterVec::new(
            Opts::new("bus_lagged_total", "Overwrites due to lag/drop on bus"),
            &["bus"],
        )?;

        let request_latency_seconds = Histogram::with_opts(
            HistogramOpts::new("request_latency_seconds", "Request latency")
                .buckets(buckets::pow2_1ms_to_512ms()),
        )?;

        let exposition_latency_seconds = Histogram::with_opts(
            HistogramOpts::new("exposition_latency_seconds", "Latency to expose endpoints")
                .buckets(buckets::pow2_1ms_to_512ms()),
        )?;

        let health_ready =
            IntGaugeVec::new(Opts::new("health_ready", "Readiness (0/1)"), &["check"])?;

        let request_status_total = IntCounterVec::new(
            Opts::new("request_status_total", "Responses by status class"),
            &["status_class"],
        )?;

        // ---- register once with stable names ----
        registry.register("service_restarts_total", |r| {
            r.register(Box::new(service_restarts_total.clone()))
        })?;
        registry.register("bus_lagged_total", |r| {
            r.register(Box::new(bus_lagged_total.clone()))
        })?;
        registry.register("request_latency_seconds", |r| {
            r.register(Box::new(request_latency_seconds.clone()))
        })?;
        registry.register("exposition_latency_seconds", |r| {
            r.register(Box::new(exposition_latency_seconds.clone()))
        })?;
        registry.register("health_ready", |r| {
            r.register(Box::new(health_ready.clone()))
        })?;
        registry.register("request_status_total", |r| {
            r.register(Box::new(request_status_total.clone()))
        })?;

        Ok(Self {
            inner: Arc::new(Inner {
                registry,
                service_restarts_total,
                bus_lagged_total,
                request_latency_seconds,
                exposition_latency_seconds,
                health_ready,
                request_status_total,
                health,
            }),
        })
    }

    /// Exposer uses this to call `.gather()`.
    /// We return the wrapper so `exposer/http.rs` can do: `metrics.registry().gather()`.
    pub fn registry(&self) -> &SafeRegistry {
        &self.inner.registry
    }

    pub fn health(&self) -> &HealthState {
        &self.inner.health
    }

    // ---------- public helpers ----------

    pub fn inc_service_restart(&self, component: &str) {
        let _ = self
            .inner
            .service_restarts_total
            .with_label_values(&[component])
            .inc();
    }

    pub fn add_bus_lag(&self, bus: &str, overwritten: u64) {
        let _ = self
            .inner
            .bus_lagged_total
            .with_label_values(&[bus])
            .inc_by(overwritten);
    }

    pub fn observe_request(&self, seconds: f64) {
        self.inner.request_latency_seconds.observe(seconds);
    }

    /// Record status by class ("2xx", "4xx", ...)
    pub fn observe_status_class(&self, class: &str) {
        let _ = self
            .inner
            .request_status_total
            .with_label_values(&[class])
            .inc();
    }

    pub fn set_ready<S: Into<String>>(&self, check: S, ok: bool) {
        // avoid moving `check` twice
        let check_s: String = check.into();
        let n = if ok { 1 } else { 0 };
        let _ = self
            .inner
            .health_ready
            .with_label_values(&[&check_s])
            .set(n);
        self.inner.health.set(check_s, ok);
    }

    /// Spawn the HTTP server exposing /metrics,/healthz,/readyz
    pub async fn serve(
        self,
        addr: std::net::SocketAddr,
    ) -> Result<(JoinHandle<()>, std::net::SocketAddr), MetricsError> {
        let router = make_router(self.clone());
        let listener = TcpListener::bind(addr).await?;
        let local = listener.local_addr()?;
        let jh = tokio::spawn(async move {
            if let Err(e) = axum::serve(listener, router).await {
                tracing::error!(error=?e, "metrics HTTP server exited");
            }
        });
        Ok((jh, local))
    }

    /// Keep signature compatible with `exposer/http.rs` (it passes endpoint string)
    pub(crate) fn observe_exposition(&self, seconds: f64, _endpoint: &'static str) {
        self.inner.exposition_latency_seconds.observe(seconds);
    }

    /// Exposer expects a ready policy; keep default semantics
    pub fn ready_policy(&self) -> ReadyPolicy {
        ReadyPolicy::default()
    }
}

// Local buckets helper inside this module
pub mod buckets {
    pub fn pow2_1ms_to_512ms() -> Vec<f64> {
        // Explicit, strictly-increasing boundaries (10 buckets)
        // +Inf is implicit in Prometheus.
        [
            0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128, 0.256, 0.512,
        ]
        .to_vec()
    }
}

```

### crates/ron-metrics/src/pq.rs
<a id="crates-ron-metrics-src-pq-rs"></a>

```rust
// PQ metrics placeholder (present even if zero): pq_kex_failures_total, etc.

```

### crates/ron-metrics/src/readiness.rs
<a id="crates-ron-metrics-src-readiness-rs"></a>

```rust
//! RO:WHAT — Ready JSON schema + policy helpers.

use serde::{Deserialize, Serialize};
use std::time::{Duration, SystemTime};

#[derive(Clone, Copy)]
pub struct ReadyPolicy {
    pub retry_after_secs: u64,
}
impl Default for ReadyPolicy {
    fn default() -> Self {
        Self {
            retry_after_secs: 5,
        }
    }
}

#[derive(Debug, Serialize, Deserialize)]
pub struct ReadyJson {
    pub degraded: bool,
    #[serde(default)]
    pub missing: Vec<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub retry_after: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub since: Option<u64>,
}

pub fn make_ready_json(
    all_ready: bool,
    missing: Vec<String>,
    policy: ReadyPolicy,
    since: SystemTime,
) -> ReadyJson {
    let since_secs = since
        .duration_since(SystemTime::UNIX_EPOCH)
        .unwrap_or(Duration::from_secs(0))
        .as_secs();

    if all_ready {
        ReadyJson {
            degraded: false,
            missing: Vec::new(),
            retry_after: None,
            since: Some(since_secs),
        }
    } else {
        ReadyJson {
            degraded: true,
            missing,
            retry_after: Some(policy.retry_after_secs),
            since: Some(since_secs),
        }
    }
}

```

### crates/ron-metrics/src/registry.rs
<a id="crates-ron-metrics-src-registry-rs"></a>

```rust
//! RO:WHAT — Thin wrapper over prometheus::Registry preventing duplicate names.

use prometheus::{Error as PromError, Registry, Result as PromResult};
use std::collections::HashSet;
use std::sync::{Arc, Mutex};

#[derive(Clone)]
pub struct SafeRegistry {
    inner: Arc<Registry>,
    names: Arc<Mutex<HashSet<String>>>,
}

impl SafeRegistry {
    pub fn new() -> Self {
        Self {
            inner: Arc::new(Registry::new()),
            names: Arc::new(Mutex::new(HashSet::new())),
        }
    }

    pub fn register<F>(&self, family_name: &str, register_fn: F) -> PromResult<()>
    where
        F: FnOnce(&Registry) -> PromResult<()>,
    {
        let mut g = self.names.lock().unwrap();
        if !g.insert(family_name.to_string()) {
            // Return a real prometheus::Error so callers can map it.
            return Err(PromError::Msg(format!("duplicate family: {family_name}")));
        }
        drop(g);
        register_fn(&self.inner)
    }

    pub fn gather(&self) -> Vec<prometheus::proto::MetricFamily> {
        self.inner.gather()
    }

    pub fn raw(&self) -> &Registry {
        &self.inner
    }
}

```

### crates/ron-metrics/src/zk.rs
<a id="crates-ron-metrics-src-zk-rs"></a>

```rust
// ZK metrics placeholder (present even if zero): zk_verify_failures_total, zk_proof_latency_seconds.

```

### crates/ron-metrics/tests/bus_watcher.rs
<a id="crates-ron-metrics-tests-buswatcher-rs"></a>

```rust
#![cfg(feature = "bus")]
use ron_bus::{Bus, BusConfig, Event};
use ron_metrics::build_info::build_version;
use ron_metrics::bus_watcher::start_bus_watcher;
use ron_metrics::{BaseLabels, HealthState, Metrics};

#[tokio::test]
async fn watcher_maps_health_events() {
    let base = BaseLabels {
        service: "svc".into(),
        instance: "t".into(),
        build_version: build_version(),
        amnesia: "off".into(),
    };
    let bus = Bus::new(BusConfig::default().with_capacity(64)).expect("bus");
    let health = HealthState::new();
    let metrics = Metrics::new(base, health).unwrap();
    let _h = start_bus_watcher(metrics.clone(), &bus, "test");

    let tx = bus.sender();
    tx.send(Event::Health {
        service: "db".into(),
        ok: false,
    })
    .unwrap();
    tx.send(Event::Health {
        service: "cache".into(),
        ok: true,
    })
    .unwrap();

    tokio::time::sleep(std::time::Duration::from_millis(50)).await;
    let snap = metrics.health().snapshot();
    assert_eq!(snap.get("db"), Some(&false));
    assert_eq!(snap.get("cache"), Some(&true));

    tx.send(Event::Shutdown).unwrap();
}

```

### crates/ron-metrics/tests/health_ready.rs
<a id="crates-ron-metrics-tests-healthready-rs"></a>

```rust
use ron_metrics::HealthState;

#[test]
fn health_state_roundtrip() {
    let h = HealthState::new();
    h.set("db".to_string(), false);
    h.set("cache".to_string(), true);

    let snap = h.snapshot();
    assert_eq!(snap.get("db"), Some(&false));
    assert_eq!(snap.get("cache"), Some(&true));
    assert!(!h.all_ready());

    h.set("db".to_string(), true);
    assert!(h.all_ready());
}

```

### crates/ron-metrics/tests/http_endpoints.rs
<a id="crates-ron-metrics-tests-httpendpoints-rs"></a>

```rust
use axum::body::Body; // request body type
use ron_metrics::build_info::build_version;
use ron_metrics::{BaseLabels, HealthState, Metrics};

use http_body_util::BodyExt; // for .collect().to_bytes()
use hyper::{Request, StatusCode};
use hyper_util::client::legacy::{connect::HttpConnector, Client};
use hyper_util::rt::TokioExecutor;
use std::net::SocketAddr;

#[tokio::test]
async fn http_endpoints_smoke() {
    let base = BaseLabels {
        service: "test-svc".into(),
        instance: "itest-1".into(),
        build_version: build_version(),
        amnesia: "off".into(),
    };
    let health = HealthState::new();
    health.set("config_loaded".into(), true);
    health.set("db".into(), false);

    let metrics = Metrics::new(base, health).expect("metrics new");

    let (_jh, addr) = metrics
        .clone()
        .serve("127.0.0.1:0".parse::<SocketAddr>().unwrap())
        .await
        .expect("serve");

    // Hyper 1.x client via hyper-util
    let connector = HttpConnector::new();
    let client: Client<_, Body> = Client::builder(TokioExecutor::new()).build(connector);

    // /healthz -> 200
    let resp = client
        .request(
            Request::builder()
                .uri(format!("http://{addr}/healthz"))
                .body(Body::empty())
                .unwrap(),
        )
        .await
        .unwrap();
    assert_eq!(resp.status(), StatusCode::OK);

    // /readyz -> 503 (db=false) + Retry-After + JSON body
    let resp = client
        .request(
            Request::builder()
                .uri(format!("http://{addr}/readyz"))
                .body(Body::empty())
                .unwrap(),
        )
        .await
        .unwrap();
    assert_eq!(resp.status(), StatusCode::SERVICE_UNAVAILABLE);
    assert!(resp.headers().get(hyper::header::RETRY_AFTER).is_some());
    let body_bytes = resp
        .into_body()
        .collect()
        .await
        .expect("collect body")
        .to_bytes();
    let v: serde_json::Value = serde_json::from_slice(&body_bytes).unwrap();
    assert!(v.get("degraded").and_then(|b| b.as_bool()).unwrap());

    // flip -> ready
    metrics.set_ready("db", true);
    let resp = client
        .request(
            Request::builder()
                .uri(format!("http://{addr}/readyz"))
                .body(Body::empty())
                .unwrap(),
        )
        .await
        .unwrap();
    assert_eq!(resp.status(), StatusCode::OK);

    // /metrics -> 200 text/plain
    let resp = client
        .request(
            Request::builder()
                .uri(format!("http://{addr}/metrics"))
                .body(Body::empty())
                .unwrap(),
        )
        .await
        .unwrap();
    assert_eq!(resp.status(), StatusCode::OK);
    let ctype = resp
        .headers()
        .get(hyper::header::CONTENT_TYPE)
        .unwrap()
        .to_str()
        .unwrap();
    assert!(ctype.starts_with("text/plain"));
}

```

### crates/ron-metrics/tests/http_status_counter.rs
<a id="crates-ron-metrics-tests-httpstatuscounter-rs"></a>

```rust
//! Ensures request_status_total increments and the latency histogram encodes.

use axum::{routing::get, Router};
use ron_metrics::build_info::build_version;
use ron_metrics::{
    axum_latency, axum_status, exposer::http::make_router, BaseLabels, HealthState, Metrics,
};
use std::net::SocketAddr;
use tokio::time::{sleep, Duration};

#[tokio::test]
async fn status_counter_and_latency_move() {
    let base = BaseLabels {
        service: "test-svc".into(),
        instance: "test-1".into(),
        build_version: build_version(),
        amnesia: "off".into(),
    };
    let health = HealthState::new();
    health.set("config_loaded".into(), true);
    let metrics = Metrics::new(base, health).expect("metrics");

    let app = Router::new()
        .route("/ping", get(|| async { "pong" }))
        .merge(make_router(metrics.clone()));
    let app = axum_latency::attach(app, metrics.clone());
    let app = axum_status::attach(app, metrics.clone());

    let listener = tokio::net::TcpListener::bind(SocketAddr::from(([127, 0, 0, 1], 0)))
        .await
        .unwrap();
    let addr = listener.local_addr().unwrap();

    let jh = tokio::spawn(async move { axum::serve(listener, app).await.unwrap() });

    // exercise endpoints
    let _ = reqwest::get(format!("http://{addr}/ping"))
        .await
        .unwrap()
        .text()
        .await
        .unwrap();
    sleep(Duration::from_millis(10)).await;

    // pull metrics text
    let body = reqwest::get(format!("http://{addr}/metrics"))
        .await
        .unwrap()
        .text()
        .await
        .unwrap();

    // assert status counter moved (2xx)
    assert!(
        body.contains("request_status_total{status_class=\"2xx\"}"),
        "missing 2xx counter"
    );
    // assert latency histogram exported (count present)
    assert!(
        body.contains("request_latency_seconds_count"),
        "missing latency count"
    );

    drop(jh);
}

```

### crates/ron-metrics/tests/integration_http_endpoints.rs
<a id="crates-ron-metrics-tests-integrationhttpendpoints-rs"></a>

```rust
// Ensures /metrics, /healthz, /readyz status/headers/body shapes (scaffold placeholder).
#[test]
fn placeholder() {}

```

### crates/ron-metrics/tests/loom_shutdown.rs
<a id="crates-ron-metrics-tests-loomshutdown-rs"></a>

```rust
// Loom-gated shutdown sequencing (no locks across .await) — scaffold placeholder.
#[test]
fn placeholder() {}

```

### crates/ron-metrics/tests/metrics_encode_ok.rs
<a id="crates-ron-metrics-tests-metricsencodeok-rs"></a>

```rust
use prometheus::{Encoder, TextEncoder};
use ron_metrics::build_info::build_version;
use ron_metrics::{BaseLabels, HealthState, Metrics};

#[test]
fn metrics_encode_ok() {
    let base = BaseLabels {
        service: "test-svc".into(),
        instance: "test-1".into(),
        build_version: build_version(),
        amnesia: "off".into(),
    };
    let health = HealthState::new();
    health.set("config_loaded".into(), true);

    let metrics = Metrics::new(base, health).expect("metrics new");
    metrics.inc_service_restart("worker-A");
    metrics.add_bus_lag("kernel", 2);
    metrics.observe_request(0.002);

    let mf = metrics.registry().gather();
    assert!(!mf.is_empty(), "registry should have some families");

    let mut buf = Vec::new();
    let enc = TextEncoder::new();
    enc.encode(&mf, &mut buf).expect("encode");
    assert!(!buf.is_empty(), "prometheus text should be non-empty");
}

```

### crates/ron-metrics/tests/public_api.rs
<a id="crates-ron-metrics-tests-publicapi-rs"></a>

```rust
// Guards public symbol drift via cargo-public-api snapshots (scaffold placeholder).
#[test]
fn placeholder() {}

```

### crates/ron-metrics/tests/readiness_semantics.rs
<a id="crates-ron-metrics-tests-readinesssemantics-rs"></a>

```rust
// Asserts fail-open reads / fail-closed writes and Retry-After semantics (scaffold placeholder).
#[test]
fn placeholder() {}

```

### crates/ron-metrics/tests/taxonomy_labels.rs
<a id="crates-ron-metrics-tests-taxonomylabels-rs"></a>

```rust
// Verifies suffix discipline and base labels presence (scaffold placeholder).
#[test]
fn placeholder() {}

```

### crates/ron-metrics/tests/vectors/interop/ron-metrics/readyz-degraded.json
<a id="crates-ron-metrics-tests-vectors-interop-ron-metrics-readyz-degraded-json"></a>

```json
{ "degraded": true, "missing": ["config_loaded","kernel_bus_attached"], "retry_after": 5 }

```

### crates/ron-metrics/tests/vectors/interop/ron-metrics/readyz-ready.json
<a id="crates-ron-metrics-tests-vectors-interop-ron-metrics-readyz-ready-json"></a>

```json
{ "degraded": false, "missing": [], "retry_after": 0 }

```



---



# oap

_Source: crates/oap/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:43:11Z -->
# Code Bundle — `oap`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/oap/.cargo/config.toml](#crates-oap--cargo-config-toml)
- [crates/oap/.github/workflows/ci.yml](#crates-oap--github-workflows-ci-yml)
- [crates/oap/.github/workflows/public-api.yml](#crates-oap--github-workflows-public-api-yml)
- [crates/oap/.github/workflows/render-mermaid.yml](#crates-oap--github-workflows-render-mermaid-yml)
- [crates/oap/Cargo.toml](#crates-oap-Cargo-toml)
- [crates/oap/benches/decode_happy.rs](#crates-oap-benches-decodehappy-rs)
- [crates/oap/benches/decode_pathological.rs](#crates-oap-benches-decodepathological-rs)
- [crates/oap/benches/encode_ack.rs](#crates-oap-benches-encodeack-rs)
- [crates/oap/fuzz/fuzz_targets/ack_fuzz.rs](#crates-oap-fuzz-fuzztargets-ackfuzz-rs)
- [crates/oap/fuzz/fuzz_targets/header_fuzz.rs](#crates-oap-fuzz-fuzztargets-headerfuzz-rs)
- [crates/oap/fuzz/fuzz_targets/parser_fuzz.rs](#crates-oap-fuzz-fuzztargets-parserfuzz-rs)
- [crates/oap/rust-toolchain.toml](#crates-oap-rust-toolchain-toml)
- [crates/oap/scripts/perf_compare.sh](#crates-oap-scripts-perfcompare-sh)
- [crates/oap/src/codec.rs](#crates-oap-src-codec-rs)
- [crates/oap/src/constants.rs](#crates-oap-src-constants-rs)
- [crates/oap/src/envelope.rs](#crates-oap-src-envelope-rs)
- [crates/oap/src/error.rs](#crates-oap-src-error-rs)
- [crates/oap/src/flags.rs](#crates-oap-src-flags-rs)
- [crates/oap/src/frame.rs](#crates-oap-src-frame-rs)
- [crates/oap/src/header.rs](#crates-oap-src-header-rs)
- [crates/oap/src/hello.rs](#crates-oap-src-hello-rs)
- [crates/oap/src/lib.rs](#crates-oap-src-lib-rs)
- [crates/oap/src/metrics.rs](#crates-oap-src-metrics-rs)
- [crates/oap/src/parser/config.rs](#crates-oap-src-parser-config-rs)
- [crates/oap/src/parser/mod.rs](#crates-oap-src-parser-mod-rs)
- [crates/oap/src/parser/state.rs](#crates-oap-src-parser-state-rs)
- [crates/oap/src/prelude.rs](#crates-oap-src-prelude-rs)
- [crates/oap/src/seq.rs](#crates-oap-src-seq-rs)
- [crates/oap/src/writer/config.rs](#crates-oap-src-writer-config-rs)
- [crates/oap/src/writer/mod.rs](#crates-oap-src-writer-mod-rs)
- [crates/oap/tests/ack_algebra.rs](#crates-oap-tests-ackalgebra-rs)
- [crates/oap/tests/config_validation.rs](#crates-oap-tests-configvalidation-rs)
- [crates/oap/tests/conformance.rs](#crates-oap-tests-conformance-rs)
- [crates/oap/tests/envelope_builder.rs](#crates-oap-tests-envelopebuilder-rs)
- [crates/oap/tests/metrics_labels.rs](#crates-oap-tests-metricslabels-rs)
- [crates/oap/tests/metrics_mapping.rs](#crates-oap-tests-metricsmapping-rs)
- [crates/oap/tests/parser_partial_read.rs](#crates-oap-tests-parserpartialread-rs)
- [crates/oap/tests/seq_monotonic.rs](#crates-oap-tests-seqmonotonic-rs)
- [crates/oap/tests/split_need_more.rs](#crates-oap-tests-splitneedmore-rs)
- [crates/oap/tests/vectors.rs](#crates-oap-tests-vectors-rs)
- [crates/oap/tests/writer_roundtrip.rs](#crates-oap-tests-writerroundtrip-rs)

### crates/oap/.cargo/config.toml
<a id="crates-oap--cargo-config-toml"></a>

```toml
[build]
# keep fast and strict in CI
rustflags = []

[target.'cfg(all())']
# You can tighten lints globally in the workspace root; keep crate-local light here.

```

### crates/oap/.github/workflows/ci.yml
<a id="crates-oap--github-workflows-ci-yml"></a>

```yaml
name: ci (oap2)
on: [push, pull_request]
jobs:
  ci:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - run: cargo fmt --all --check
      - run: cargo clippy -p oap2 -- -D warnings || true
      - run: cargo test -p oap2 --all-features || true
      - run: cargo install cargo-deny || true
      - run: cargo deny check || true

```

### crates/oap/.github/workflows/public-api.yml
<a id="crates-oap--github-workflows-public-api-yml"></a>

```yaml
name: public-api (oap2)
on: [push, pull_request]
jobs:
  api-diff:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - run: cargo install cargo-public-api || true
      - run: cargo public-api --manifest-path crates/oap2/Cargo.toml || true

```

### crates/oap/.github/workflows/render-mermaid.yml
<a id="crates-oap--github-workflows-render-mermaid-yml"></a>

```yaml
name: render-mermaid (oap2)
on: [push, pull_request]
jobs:
  mmdc:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm i -g @mermaid-js/mermaid-cli
      - run: |
          for f in $(git ls-files 'crates/oap2/docs/*.mmd'); do
            out="${f%.mmd}.svg"
            mmdc -i "$f" -o "$out" || true
          done

```

### crates/oap/Cargo.toml
<a id="crates-oap-Cargo-toml"></a>

```toml
[package]
name = "oap"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
description = "Overlay Access Protocol (OAP/1) framing and Tokio codec for RustyOnions"
repository = "https://example.invalid/RustyOnions"
authors = ["RustyOnions contributors"]

[lib]
name = "oap"
path = "src/lib.rs"

[features]
default = []
# Optional bounded decompression for payloads flagged with COMP.
zstd = ["dep:zstd"]

[dependencies]
bytes = "1.6"
tokio-util = { version = "0.7.16", features = ["codec"] }
tokio = { version = "1.47.1", features = ["io-util"] }
thiserror = "1.0"
serde = { version = "1.0", features = ["derive"] }
serde_repr = "0.1"
serde_json = "1.0"
tracing = "0.1"
bitflags = "2.6"
# Only pulled when feature=zstd is on
zstd = { version = "0.13", optional = true }

# Types-only crates (no IO/logic). Keep DTO hygiene.
ron-proto = { path = "../ron-proto", optional = true }

[dev-dependencies]
pretty_assertions = "1.4"

```

### crates/oap/benches/decode_happy.rs
<a id="crates-oap-benches-decodehappy-rs"></a>

```rust
// Criterion bench scaffold (no implementation).
fn main() {}

```

### crates/oap/benches/decode_pathological.rs
<a id="crates-oap-benches-decodepathological-rs"></a>

```rust
fn main() {}

```

### crates/oap/benches/encode_ack.rs
<a id="crates-oap-benches-encodeack-rs"></a>

```rust
fn main() {}

```

### crates/oap/fuzz/fuzz_targets/ack_fuzz.rs
<a id="crates-oap-fuzz-fuzztargets-ackfuzz-rs"></a>

```rust
// libFuzzer target placeholder

```

### crates/oap/fuzz/fuzz_targets/header_fuzz.rs
<a id="crates-oap-fuzz-fuzztargets-headerfuzz-rs"></a>

```rust
// libFuzzer target placeholder

```

### crates/oap/fuzz/fuzz_targets/parser_fuzz.rs
<a id="crates-oap-fuzz-fuzztargets-parserfuzz-rs"></a>

```rust
// libFuzzer target placeholder

```

### crates/oap/rust-toolchain.toml
<a id="crates-oap-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["clippy", "rustfmt"]

```

### crates/oap/scripts/perf_compare.sh
<a id="crates-oap-scripts-perfcompare-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "perf_compare: scaffold placeholder (wire to Criterion JSON once benches exist)"

```

### crates/oap/src/codec.rs
<a id="crates-oap-src-codec-rs"></a>

```rust
//! RO:WHAT — Tokio `Encoder`/`Decoder` for OAP/1 frames (length-prefixed, bounded).
//! RO:WHY — Interop needs a safe, reusable codec with strict limits and optional zstd inflate.
//! RO:INTERACTS — bytes, tokio-util::codec; uses Header/Flags and error taxonomy.
//! RO:INVARIANTS — Enforce MAX_FRAME_BYTES; START-only cap; optional COMP → bounded inflate ≤ 8×.

use bytes::BytesMut;
use tokio_util::codec::{Decoder, Encoder};

use crate::constants::MAX_FRAME_BYTES;
use crate::error::{OapDecodeError as DE, OapEncodeError as EE};
use crate::flags::Flags;
use crate::{Frame, Header};

#[cfg(feature = "zstd")]
use crate::constants::MAX_DECOMPRESS_EXPANSION;
#[cfg(feature = "zstd")]
use bytes::Bytes;

#[derive(Debug, Default)]
pub struct OapDecoder;

#[derive(Debug, Default)]
pub struct OapEncoder;

impl Decoder for OapDecoder {
    type Item = Frame;
    type Error = DE; // must be From<std::io::Error>; satisfied via Io(#[from]).

    fn decode(&mut self, src: &mut BytesMut) -> Result<Option<Self::Item>, Self::Error> {
        // Need at least the fixed header.
        if src.len() < Header::WIRE_SIZE {
            return Ok(None);
        }

        // Peek a copy for header parsing without moving yet.
        let mut peek = src.clone().freeze();
        let hdr = Header::read_from(&mut peek)?;

        // If we don't have the whole frame yet, wait.
        if src.len() < hdr.len as usize {
            return Ok(None);
        }

        // Split off exactly the frame to work on.
        let mut frame_bytes = src.split_to(hdr.len as usize).freeze();

        // Re-read header from the real slice (advance).
        let _ = Header::read_from(&mut frame_bytes)?; // validated already

        // Cap section
        let cap = if hdr.cap_len > 0 {
            if !hdr.flags.contains(Flags::START) {
                return Err(DE::CapOnNonStart);
            }
            if frame_bytes.len() < hdr.cap_len as usize {
                return Err(DE::CapOutOfBounds);
            }
            Some(frame_bytes.split_to(hdr.cap_len as usize))
        } else {
            None
        };

        // Remaining is payload (may be empty)
        let payload = if frame_bytes.is_empty() {
            None
        } else {
            Some(frame_bytes)
        };

        // Optional bounded decompression when COMP flag set
        #[cfg(feature = "zstd")]
        let mut payload = payload;

        if hdr.flags.contains(Flags::COMP) {
            #[cfg(not(feature = "zstd"))]
            {
                return Err(DE::ZstdFeatureNotEnabled);
            }
            #[cfg(feature = "zstd")]
            {
                if let Some(body) = payload.take() {
                    let max_out = (MAX_FRAME_BYTES * MAX_DECOMPRESS_EXPANSION) as usize;
                    let mut dec = zstd::stream::read::Decoder::new(std::io::Cursor::new(body))
                        .map_err(|e| DE::Zstd(e.to_string()))?;
                    use std::io::Read;
                    let mut out = Vec::new();
                    let mut buf = [0u8; 16 * 1024];
                    loop {
                        let n = dec.read(&mut buf)?;
                        if n == 0 {
                            break;
                        }
                        out.extend_from_slice(&buf[..n]);
                        if out.len() > max_out {
                            return Err(DE::DecompressBoundExceeded);
                        }
                    }
                    payload = Some(Bytes::from(out));
                }
            }
        }

        Ok(Some(Frame {
            header: hdr,
            cap,
            payload,
        }))
    }
}

impl Encoder<Frame> for OapEncoder {
    type Error = EE; // must be From<std::io::Error>; satisfied via Io(#[from]).

    fn encode(&mut self, item: Frame, dst: &mut BytesMut) -> Result<(), Self::Error> {
        // Sanity on lengths vs declared header.len
        let cap_len = item.cap.as_ref().map(|b| b.len()).unwrap_or(0);
        let payload_len = item.payload.as_ref().map(|b| b.len()).unwrap_or(0);
        if cap_len > u16::MAX as usize {
            return Err(EE::CapOutOfBounds);
        }
        let total_len = Header::WIRE_SIZE + cap_len + payload_len;
        if total_len > MAX_FRAME_BYTES as usize {
            return Err(EE::FrameTooLarge {
                len: total_len as u32,
                max: MAX_FRAME_BYTES,
            });
        }

        // Write header (with corrected cap_len & len)
        let mut hdr = item.header;
        hdr.cap_len = cap_len as u16;
        hdr.len = total_len as u32;

        // Reserve and emit
        dst.reserve(total_len);
        hdr.put_to(dst);
        if let Some(cap) = item.cap {
            dst.extend_from_slice(&cap);
        }
        if let Some(payload) = item.payload {
            dst.extend_from_slice(&payload);
        }
        Ok(())
    }
}

```

### crates/oap/src/constants.rs
<a id="crates-oap-src-constants-rs"></a>

```rust
//! RO:WHAT — Canonical OAP/1 constants and limits.
//! RO:WHY — Keep protocol bounds single-sourced and drift-proof (Hardening & Interop blueprints).
//! RO:INTERACTS — Used by header/frame/codec modules and by callers for guardrails.
//! RO:INVARIANTS — max_frame=1MiB; bounded decompress guard ≤ 8× frame cap; chunk hint=64KiB.

/// Maximum allowed OAP frame size in bytes (protocol invariant).
pub const MAX_FRAME_BYTES: u32 = 1024 * 1024; // 1 MiB

/// Recommended streaming chunk size used by storage paths (not a protocol limit).
pub const STREAM_CHUNK_SIZE: usize = 64 * 1024; // 64 KiB

/// Upper bound on decompressed size relative to `MAX_FRAME_BYTES` when COMP flag is set.
/// Per Interop blueprint: bounded inflate (≤ 8× frame cap) → reject with 413 if exceeded.
pub const MAX_DECOMPRESS_EXPANSION: u32 = 8;

/// OAP protocol version.
pub const OAP_VERSION: u16 = 1;

```

### crates/oap/src/envelope.rs
<a id="crates-oap-src-envelope-rs"></a>

```rust
//! RO:WHAT — Ergonomic envelope helpers: capability wrapper and frame builders.
//! RO:WHY  — Reduce boilerplate for callers while enforcing OAP invariants at build time.
//! RO:INTERACTS — Uses Frame/Header/Flags/StatusCode plus HELLO DTOs from `hello.rs`.
//! RO:INVARIANTS — No I/O; the Encoder normalizes `len`/`cap_len`; caps only valid with START.

use bytes::Bytes;

use crate::{
    flags::Flags,
    hello::{Hello, HelloReply},
    Frame, Header, StatusCode, OAP_VERSION,
};

/// Opaque capability bytes carried on `START` frames.
/// Semantics (macaroons, scopes, etc.) live above OAP.
#[derive(Clone, Debug, PartialEq, Eq)]
pub struct Capability(Bytes);

impl Capability {
    pub fn new(bytes: Bytes) -> Self {
        Self(bytes)
    }
    pub fn as_bytes(&self) -> &Bytes {
        &self.0
    }
    pub fn into_bytes(self) -> Bytes {
        self.0
    }
    /// Size guard for START frames (u16 fit).
    pub fn fits_u16(&self) -> bool {
        self.0.len() <= u16::MAX as usize
    }
}

/// True if a sender requests an ACK.
pub fn wants_ack(flags: Flags) -> bool {
    flags.contains(Flags::ACK_REQ)
}
/// True if a frame marks the logical end of a request/stream.
pub fn is_terminal(flags: Flags) -> bool {
    flags.contains(Flags::END)
}
/// True if a frame is fire-and-forget (EVENT without ACK).
pub fn is_fire_and_forget(flags: Flags) -> bool {
    flags.contains(Flags::EVENT) && !wants_ack(flags)
}

/// Minimal, chainable builder for common envelopes.
/// The encoder will set `len`/`cap_len` on write.
#[derive(Debug, Clone)]
pub struct FrameBuilder {
    header: Header,
    cap: Option<Bytes>,
    payload: Option<Bytes>,
}

impl FrameBuilder {
    /// Begin a request for `app_proto_id`.
    pub fn request(app_proto_id: u16, tenant_id: u128, corr_id: u64) -> Self {
        Self {
            header: Header {
                len: 0,
                ver: OAP_VERSION,
                flags: Flags::REQ,
                code: 0,
                app_proto_id,
                tenant_id,
                cap_len: 0,
                corr_id,
            },
            cap: None,
            payload: None,
        }
    }

    /// Begin a response for `app_proto_id` with a status code.
    pub fn response(app_proto_id: u16, tenant_id: u128, corr_id: u64, code: StatusCode) -> Self {
        Self {
            header: Header {
                len: 0,
                ver: OAP_VERSION,
                flags: Flags::RESP,
                code: code as u16,
                app_proto_id,
                tenant_id,
                cap_len: 0,
                corr_id,
            },
            cap: None,
            payload: None,
        }
    }

    /// Mark as START and attach capability bytes (REQ is set if not already).
    pub fn start_with_cap(mut self, cap: Bytes) -> Self {
        self.header.flags |= Flags::START | Flags::REQ;
        self.cap = Some(cap);
        self
    }

    /// Attach opaque payload.
    pub fn payload(mut self, p: Bytes) -> Self {
        self.payload = Some(p);
        self
    }

    /// Request ACK.
    pub fn want_ack(mut self) -> Self {
        self.header.flags |= Flags::ACK_REQ;
        self
    }

    /// Mark as END.
    pub fn end(mut self) -> Self {
        self.header.flags |= Flags::END;
        self
    }

    /// Build a `Frame`.
    pub fn build(self) -> Frame {
        Frame {
            header: self.header,
            cap: self.cap,
            payload: self.payload,
        }
    }
}

/// Convenience: HELLO request frame (app_proto_id=0).
pub fn hello_request(ua: Option<&str>, tenant_id: u128, corr_id: u64) -> Frame {
    let h = Hello {
        ua: ua.map(str::to_owned),
    };
    h.to_frame(tenant_id, corr_id)
}

/// Convenience: HELLO reply frame (app_proto_id=0), using default server caps.
pub fn hello_reply_default(tenant_id: u128, corr_id: u64) -> Frame {
    HelloReply::default_for_server().to_frame(tenant_id, corr_id)
}

```

### crates/oap/src/error.rs
<a id="crates-oap-src-error-rs"></a>

```rust
//! RO:WHAT — Error taxonomy for OAP codec and helpers.
//! RO:WHY — Stable, typed errors that map to protocol status codes where meaningful.
//! RO:INTERACTS — Used by codec/frame/hello; callers can translate to HTTP or OAP rejects.
//! RO:INVARIANTS — 413 on size violations; 400 family for client misuse; 5xx for internal.

use thiserror::Error;

/// Minimal status code set suitable for mapping OAP outcomes (also maps to HTTP when proxied).
#[derive(
    Copy, Clone, Debug, PartialEq, Eq, serde_repr::Serialize_repr, serde_repr::Deserialize_repr,
)]
#[repr(u16)]
pub enum StatusCode {
    Ok = 200,
    Partial = 206,
    BadRequest = 400,
    Unauthorized = 401,
    Forbidden = 403,
    NotFound = 404,
    PayloadTooLarge = 413,
    TooManyRequests = 429,
    Internal = 500,
    Unavailable = 503,
}

#[derive(Debug, Error)]
pub enum OapDecodeError {
    #[error("truncated header")]
    TruncatedHeader,
    #[error("bad version {0}")]
    BadVersion(u16),
    #[error("bad flags bits {0:#06x}")]
    BadFlags(u16),
    #[error("cap section present but START flag not set")]
    CapOnNonStart,
    #[error("frame too large: {len} > {max}")]
    FrameTooLarge { len: u32, max: u32 },
    #[error("cap length exceeds frame")]
    CapOutOfBounds,
    #[error("payload length exceeds frame")]
    PayloadOutOfBounds,
    #[error("decompression exceeded bound")]
    DecompressBoundExceeded,
    #[error("zstd not enabled")]
    ZstdFeatureNotEnabled,
    #[error("zstd decode error: {0}")]
    Zstd(String),
    #[error("io error: {0}")]
    Io(#[from] std::io::Error),
}

#[derive(Debug, Error)]
pub enum OapEncodeError {
    #[error("frame too large: {len} > {max}")]
    FrameTooLarge { len: u32, max: u32 },
    #[error("cap length exceeds frame")]
    CapOutOfBounds,
    #[error("io error: {0}")]
    Io(#[from] std::io::Error),
}

#[derive(Debug, Error)]
pub enum OapError {
    #[error(transparent)]
    Decode(#[from] OapDecodeError),
    #[error(transparent)]
    Encode(#[from] OapEncodeError),
}

// Allow `?` on std::io::Error to bubble into OapError (encode path preferred).
impl From<std::io::Error> for OapError {
    fn from(err: std::io::Error) -> Self {
        OapError::Encode(OapEncodeError::Io(err))
    }
}

```

### crates/oap/src/flags.rs
<a id="crates-oap-src-flags-rs"></a>

```rust
//! RO:WHAT — Bitflags for OAP/1 `flags,u16` header field.
//! RO:WHY — Explicit bit meanings for interop; avoids magic numbers.
//! RO:INTERACTS — Used by header/frame/codec; callers set semantics via these bits.
//! RO:INVARIANTS — Bits stable under semver; RESERVED kept for forward-compat.

bitflags::bitflags! {
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]
    pub struct Flags: u16 {
        const REQ     = 1 << 0;
        const RESP    = 1 << 1;
        const EVENT   = 1 << 2;
        const START   = 1 << 3;
        const END     = 1 << 4;
        const ACK_REQ = 1 << 5;
        const COMP    = 1 << 6; // payload compressed (zstd) with bounded inflate
        const APP_E2E = 1 << 7; // opaque app-layer E2E crypto; platform does not inspect
        // reserve upper bits for future use
    }
}

```

### crates/oap/src/frame.rs
<a id="crates-oap-src-frame-rs"></a>

```rust
//! RO:WHAT — High-level OAP frame value (header + optional cap + payload).
//! RO:WHY — Keep parsing/encoding logic separate from transport loops; safe, owned bytes.
//! RO:INTERACTS — Header/Flags; codec reads/writes `Frame` to/from wire.
//! RO:INVARIANTS — Owned buffers; bounds validated; START carries capability bytes only.

use crate::Header;
use bytes::Bytes;

#[derive(Clone, Debug, PartialEq, Eq)]
pub struct Frame {
    pub header: Header,
    pub cap: Option<Bytes>,
    pub payload: Option<Bytes>,
}

impl Frame {
    pub fn new(header: Header, cap: Option<Bytes>, payload: Option<Bytes>) -> Self {
        Self {
            header,
            cap,
            payload,
        }
    }

    pub fn payload_len(&self) -> usize {
        self.payload.as_ref().map(|b| b.len()).unwrap_or(0)
    }

    pub fn cap_len(&self) -> usize {
        self.cap.as_ref().map(|b| b.len()).unwrap_or(0)
    }
}

```

### crates/oap/src/header.rs
<a id="crates-oap-src-header-rs"></a>

```rust
//! RO:WHAT — OAP/1 fixed header (without [cap] and [payload]) and (de)serialization helpers.
//! RO:WHY — Deterministic, endian-stable wire header; validates size/field bounds before alloc.
//! RO:INTERACTS — Flags; codec uses this to parse before reading variable sections.
//! RO:INVARIANTS — Length checked ≤ MAX_FRAME_BYTES; version=1; cap_len for START frames only.

use crate::constants::{MAX_FRAME_BYTES, OAP_VERSION};
use crate::flags::Flags;
use bytes::{Buf, BufMut, BytesMut};

#[derive(Clone, Debug, PartialEq, Eq)]
pub struct Header {
    /// Total frame length in bytes (header + cap + payload).
    pub len: u32,
    /// Protocol version (must be 1).
    pub ver: u16,
    /// Bit flags.
    pub flags: Flags,
    /// Status or app code (e.g., 2xx/4xx/5xx or app-defined).
    pub code: u16,
    /// Application protocol id (0 = control/HELLO).
    pub app_proto_id: u16,
    /// Tenant id (128-bit).
    pub tenant_id: u128,
    /// Capability section length in bytes (only valid/allowed with START).
    pub cap_len: u16,
    /// Correlation id (64-bit).
    pub corr_id: u64,
}

impl Header {
    pub const WIRE_SIZE: usize = 4 + 2 + 2 + 2 + 2 + 16 + 2 + 8;

    pub fn validate(&self) -> Result<(), crate::error::OapDecodeError> {
        if self.ver != OAP_VERSION {
            return Err(crate::error::OapDecodeError::BadVersion(self.ver));
        }
        if self.len == 0 || self.len > MAX_FRAME_BYTES {
            return Err(crate::error::OapDecodeError::FrameTooLarge {
                len: self.len,
                max: MAX_FRAME_BYTES,
            });
        }
        if self.cap_len > 0 && !self.flags.contains(Flags::START) {
            return Err(crate::error::OapDecodeError::CapOnNonStart);
        }
        Ok(())
    }

    pub fn put_to(&self, dst: &mut BytesMut) {
        dst.put_u32(self.len);
        dst.put_u16(self.ver);
        dst.put_u16(self.flags.bits());
        dst.put_u16(self.code);
        dst.put_u16(self.app_proto_id);
        dst.put_u128(self.tenant_id);
        dst.put_u16(self.cap_len);
        dst.put_u64(self.corr_id);
    }

    pub fn read_from(src: &mut bytes::Bytes) -> Result<Self, crate::error::OapDecodeError> {
        use crate::error::OapDecodeError as E;
        if src.len() < Self::WIRE_SIZE {
            return Err(E::TruncatedHeader);
        }
        let len = src.get_u32();
        let ver = src.get_u16();
        let flags_bits = src.get_u16();
        let code = src.get_u16();
        let app_proto_id = src.get_u16();
        let tenant_id = src.get_u128();
        let cap_len = src.get_u16();
        let corr_id = src.get_u64();
        let flags = Flags::from_bits(flags_bits).ok_or(E::BadFlags(flags_bits))?;
        let hdr = Header {
            len,
            ver,
            flags,
            code,
            app_proto_id,
            tenant_id,
            cap_len,
            corr_id,
        };
        hdr.validate()?;
        Ok(hdr)
    }
}

```

### crates/oap/src/hello.rs
<a id="crates-oap-src-hello-rs"></a>

```rust
//! RO:WHAT — Small helpers for OAP/1 HELLO (app_proto_id=0) request/response.
//! RO:WHY — Normalize what clients/servers exchange during negotiation.
//! RO:INTERACTS — Flags/Frame/Header; used by SDK and services at connect time.
//! RO:INVARIANTS — ver=1; code=200 on success; returns server caps & versions.

use crate::{constants::*, flags::Flags, Frame, Header};
use bytes::Bytes;
use serde::{Deserialize, Serialize};
use serde_json;

/// Minimal HELLO request (client → server).
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct Hello {
    /// Optional user-agent/version string.
    pub ua: Option<String>,
}

/// Minimal HELLO reply (server → client).
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct HelloReply {
    pub max_frame: u32,
    pub max_inflight: u16,
    pub flags_supported: u16,
    pub versions: Vec<u16>,
    pub transports: Vec<String>,
}

impl Hello {
    pub fn to_frame(&self, tenant_id: u128, corr_id: u64) -> Frame {
        let payload = serde_json::to_vec(self).expect("serialize hello");
        let header = Header {
            len: 0, // filled by encoder
            ver: OAP_VERSION,
            flags: Flags::REQ,
            code: 0,
            app_proto_id: 0,
            tenant_id,
            cap_len: 0,
            corr_id,
        };
        Frame {
            header,
            cap: None,
            payload: Some(Bytes::from(payload)),
        }
    }
}

impl HelloReply {
    pub fn default_for_server() -> Self {
        Self {
            max_frame: MAX_FRAME_BYTES,
            max_inflight: 64,
            flags_supported: (Flags::REQ
                | Flags::RESP
                | Flags::EVENT
                | Flags::START
                | Flags::END
                | Flags::ACK_REQ
                | Flags::COMP
                | Flags::APP_E2E)
                .bits(),
            versions: vec![OAP_VERSION],
            transports: vec!["tcp+tls".into()],
        }
    }

    pub fn from_frame(frame: &Frame) -> Result<Self, crate::error::OapDecodeError> {
        let Some(payload) = &frame.payload else {
            return Err(crate::error::OapDecodeError::PayloadOutOfBounds);
        };
        serde_json::from_slice(payload)
            .map_err(|e| crate::error::OapDecodeError::Zstd(e.to_string()))
    }

    pub fn to_frame(&self, tenant_id: u128, corr_id: u64) -> Frame {
        let json = serde_json::to_vec(self).expect("serialize hello reply");
        let header = Header {
            len: 0,
            ver: OAP_VERSION,
            flags: Flags::RESP,
            code: crate::error::StatusCode::Ok as u16,
            app_proto_id: 0,
            tenant_id,
            cap_len: 0,
            corr_id,
        };
        Frame {
            header,
            cap: None,
            payload: Some(Bytes::from(json)),
        }
    }
}

```

### crates/oap/src/lib.rs
<a id="crates-oap-src-lib-rs"></a>

```rust
//! RO:WHAT — OAP/1 constants, flags, header & frame types, and a Tokio codec (Encoder/Decoder).
//! RO:WHY  — Pillar 7 (App BFF & SDK); Concerns: SEC/RES/PERF/DX. Stable envelopes for interop.
//! RO:INTERACTS — bytes, tokio-util::codec; optional ron-proto DTOs; consumed by ron-app-sdk/omnigate.
//! RO:INVARIANTS — OAP/1 max_frame=1MiB; stream chunk≈64KiB (storage); no lock across .await in codec.
//! RO:METRICS — (none here; callers record RED metrics around IO).
//! RO:CONFIG — Bounds are constants; optional zstd with ≤8× expansion guard.
//! RO:SECURITY — No ambient auth; capabilities carried as opaque bytes in START; DTOs deny_unknown_fields upstream.
//! RO:TEST — unit tests in module; golden vectors for HELLO/START/DATA; fuzz hooks to be added in oap-fuzz.

#![forbid(unsafe_code)]

pub mod codec;
pub mod constants;
pub mod error;
pub mod flags;
pub mod frame;
pub mod header;
pub mod hello;

// TODO-aligned modules
pub mod envelope;
pub mod metrics;
pub mod prelude;
pub mod seq;

// Stream helpers (as per TODO folders)
pub mod parser;
pub mod writer;

// Core exports
pub use codec::{OapDecoder, OapEncoder};
pub use constants::*;
pub use error::{OapDecodeError, OapEncodeError, OapError, StatusCode};
pub use flags::Flags;
pub use frame::Frame;
pub use header::Header;
pub use hello::{Hello, HelloReply};

// Ergonomic helpers from TODO modules
pub use envelope::{
    hello_reply_default, hello_request, is_fire_and_forget, is_terminal, wants_ack, Capability,
    FrameBuilder,
};
pub use metrics::{
    is_client_err, is_server_err, is_success, labels_for_outcome, outcome_from_decode,
    outcome_from_status, reason, OutcomeClass,
};
pub use seq::Seq;

// Parser/Writer facades
pub use parser::{ParserConfig, ParserState};
pub use writer::{OapWriter, WriterConfig};

```

### crates/oap/src/metrics.rs
<a id="crates-oap-src-metrics-rs"></a>

```rust
//! RO:WHAT — Status helpers and canonical outcome→label mapping for metrics.
//! RO:WHY  — Keep vocabulary consistent across services; no direct prometheus deps here.
//! RO:INTERACTS — Callers map these to ron-metrics counters/histograms.
//! RO:INVARIANTS — Stable label triplets; conservative defaults.

use crate::error::{OapDecodeError, StatusCode};

/// Human-friendly reason text for a status code (stable subset).
pub fn reason(code: StatusCode) -> &'static str {
    match code {
        StatusCode::Ok => "OK",
        StatusCode::Partial => "Partial Content",
        StatusCode::BadRequest => "Bad Request",
        StatusCode::Unauthorized => "Unauthorized",
        StatusCode::Forbidden => "Forbidden",
        StatusCode::NotFound => "Not Found",
        StatusCode::PayloadTooLarge => "Payload Too Large",
        StatusCode::TooManyRequests => "Too Many Requests",
        StatusCode::Internal => "Internal Server Error",
        StatusCode::Unavailable => "Service Unavailable",
    }
}

/// Quick predicates.
pub fn is_success(code: StatusCode) -> bool {
    (code as u16) / 100 == 2
}
pub fn is_client_err(code: StatusCode) -> bool {
    (code as u16) / 100 == 4
}
pub fn is_server_err(code: StatusCode) -> bool {
    (code as u16) / 100 == 5
}

/// Outcome class for accounting.
#[derive(Copy, Clone, Debug, PartialEq, Eq)]
pub enum OutcomeClass {
    Success,
    ClientError,
    ServerError,
    DecodeError,
    Oversize,
}

/// Convert a status code into a high-level outcome class.
pub fn outcome_from_status(code: StatusCode) -> OutcomeClass {
    match (code as u16) / 100 {
        2 => OutcomeClass::Success,
        4 => OutcomeClass::ClientError,
        5 => OutcomeClass::ServerError,
        _ => OutcomeClass::ClientError, // default conservative
    }
}

/// Map a decode error to an outcome class (for ingress parse failures).
pub fn outcome_from_decode(err: &OapDecodeError) -> OutcomeClass {
    use OapDecodeError::*;
    match err {
        FrameTooLarge { .. } => OutcomeClass::Oversize,
        BadVersion(_) | BadFlags(_) | CapOnNonStart | CapOutOfBounds | PayloadOutOfBounds => {
            OutcomeClass::DecodeError
        }
        TruncatedHeader | DecompressBoundExceeded | ZstdFeatureNotEnabled | Zstd(_) | Io(_) => {
            OutcomeClass::DecodeError
        }
    }
}

/// Convert outcome into stable label triplet (kind, cause, detail).
/// Keep these short and low-cardinality.
pub fn labels_for_outcome(outcome: OutcomeClass) -> (&'static str, &'static str, &'static str) {
    match outcome {
        OutcomeClass::Success => ("oap", "ok", "2xx"),
        OutcomeClass::ClientError => ("oap", "client", "4xx"),
        OutcomeClass::ServerError => ("oap", "server", "5xx"),
        OutcomeClass::DecodeError => ("oap", "decode", "error"),
        OutcomeClass::Oversize => ("oap", "oversize", "413"),
    }
}

```

### crates/oap/src/parser/config.rs
<a id="crates-oap-src-parser-config-rs"></a>

```rust
//! RO:WHAT — Parser configuration (buffer policy hooks).
//! RO:WHY  — Centralize tunables; allow callers to cap parser memory if desired.
//! RO:INTERACTS — Used by `ParserState`.
//! RO:INVARIANTS — Defaults are conservative and safe.

/// Parser configuration.
/// Currently only exposes a soft maximum buffer size; the OAP decoder still
/// enforces per-frame bounds independently.
#[derive(Clone, Copy, Debug)]
pub struct ParserConfig {
    /// Soft cap for buffered bytes. `None` disables the soft check.
    pub max_buffer_bytes: Option<usize>,
}

impl Default for ParserConfig {
    fn default() -> Self {
        // 4 MiB soft buffer cap is usually sufficient for a few frames in flight.
        Self {
            max_buffer_bytes: Some(4 * 1024 * 1024),
        }
    }
}

```

### crates/oap/src/parser/mod.rs
<a id="crates-oap-src-parser-mod-rs"></a>

```rust
//! RO:WHAT — Incremental OAP frame parser facade.
//! RO:WHY  — Provide a clean API to feed bytes and pull parsed `Frame`s.
//! RO:INTERACTS — Wraps `OapDecoder`; used by gateways/SDKs.
//! RO:INVARIANTS — No blocking; bounded by decoder invariants; zero `unsafe`.

pub mod config;
pub mod state;

pub use config::ParserConfig;
pub use state::ParserState;

```

### crates/oap/src/parser/state.rs
<a id="crates-oap-src-parser-state-rs"></a>

```rust
//! RO:WHAT — Parser state machine: push bytes, pop frames.
//! RO:WHY  — Make partial reads easy without reinventing decoding logic.
//! RO:INTERACTS — `OapDecoder`; returns `Frame`s as they become available.
//! RO:INVARIANTS — No blocking; honors parser config soft cap; zero `unsafe`.

use bytes::BytesMut;
use tokio_util::codec::Decoder; // bring `decode` into scope

use super::ParserConfig;
use crate::{codec::OapDecoder, Frame};

#[derive(Debug)]
pub struct ParserState {
    dec: OapDecoder,
    buf: BytesMut,
    cfg: ParserConfig,
}

impl ParserState {
    pub fn new(cfg: ParserConfig) -> Self {
        Self {
            dec: OapDecoder,
            buf: BytesMut::new(),
            cfg,
        }
    }

    pub fn with_default() -> Self {
        Self::new(ParserConfig::default())
    }

    /// Feed raw bytes into the parser buffer.
    /// Returns `Ok(())` even if no full frame is available yet.
    pub fn push(&mut self, chunk: &[u8]) -> Result<(), crate::OapDecodeError> {
        self.buf.extend_from_slice(chunk);

        // Soft cap (best-effort): callers decide response; decoding still enforces per-frame caps.
        if let Some(max) = self.cfg.max_buffer_bytes {
            if self.buf.len() > max {
                // Return a decode error to signal backpressure to caller (no new variant needed).
                return Err(crate::OapDecodeError::PayloadOutOfBounds);
            }
        }
        Ok(())
    }

    /// Try to decode a single frame if enough data is buffered.
    pub fn try_next(&mut self) -> Result<Option<Frame>, crate::OapDecodeError> {
        self.dec.decode(&mut self.buf)
    }

    /// Drain all currently-available frames.
    pub fn drain(&mut self) -> Result<Vec<Frame>, crate::OapDecodeError> {
        let mut out = Vec::new();
        while let Some(f) = self.dec.decode(&mut self.buf)? {
            out.push(f);
        }
        Ok(out)
    }

    /// Inspect buffered byte count (useful for tests/telemetry).
    pub fn buffered_len(&self) -> usize {
        self.buf.len()
    }
}

```

### crates/oap/src/prelude.rs
<a id="crates-oap-src-prelude-rs"></a>

```rust
//! RO:WHAT — Common imports for ergonomic use of OAP.
//! RO:WHY  — Reduce `use` boilerplate in services and SDKs.
//! RO:INTERACTS — Pure re-exports.

pub use crate::{
    codec::{OapDecoder, OapEncoder},
    constants::{MAX_FRAME_BYTES, OAP_VERSION, STREAM_CHUNK_SIZE},
    envelope::{
        hello_reply_default, hello_request, is_fire_and_forget, is_terminal, wants_ack, Capability,
        FrameBuilder,
    },
    error::{OapDecodeError, OapEncodeError, OapError, StatusCode},
    flags::Flags,
    frame::Frame,
    header::Header,
    metrics::{
        is_client_err, is_server_err, is_success, labels_for_outcome, outcome_from_decode,
        outcome_from_status, reason, OutcomeClass,
    },
    seq::Seq,
};

```

### crates/oap/src/seq.rs
<a id="crates-oap-src-seq-rs"></a>

```rust
//! RO:WHAT — Simple, allocator-free sequence/correlation id generator.
//! RO:WHY  — Provide monotonic ids for `corr_id` without globals/unsafe.
//! RO:INTERACTS — Used by clients/servers to stamp `Header::corr_id`.
//! RO:INVARIANTS — Monotonic per-instance; seed adds time entropy to avoid collisions.

use std::sync::atomic::{AtomicU64, Ordering};
use std::time::{SystemTime, UNIX_EPOCH};

/// Monotonic sequence generator (per-instance).
#[derive(Debug)]
pub struct Seq {
    counter: AtomicU64,
}

impl Default for Seq {
    fn default() -> Self {
        // Seed with current nanos (truncated) to diversify instances.
        let seed = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .map(|d| (d.as_nanos() as u64) ^ 0xA5A5_5A5A_D3C3_3C3D)
            .unwrap_or(0xD00D_F00D_C0FF_EE00);
        Self {
            counter: AtomicU64::new(seed),
        }
    }
}

impl Seq {
    pub fn new() -> Self {
        Self::default()
    }

    /// Fetch-next correlation id.
    #[inline]
    pub fn next(&self) -> u64 {
        self.counter.fetch_add(1, Ordering::Relaxed).wrapping_add(1)
    }
}

```

### crates/oap/src/writer/config.rs
<a id="crates-oap-src-writer-config-rs"></a>

```rust
//! RO:WHAT — Writer configuration.
//! RO:WHY  — Centralize tunables for buffered writes.
//! RO:INTERACTS — Used by `OapWriter`.
//! RO:INVARIANTS — Defaults tuned to typical MTU/page sizes.

use crate::constants::STREAM_CHUNK_SIZE;

/// Writer configuration.
#[derive(Clone, Copy, Debug)]
pub struct WriterConfig {
    /// When internal buffer reaches this size, `write_frame` will flush it automatically.
    pub flush_hint_bytes: usize,
}

impl Default for WriterConfig {
    fn default() -> Self {
        // Use the 64 KiB stream chunk as a reasonable flush hint.
        Self {
            flush_hint_bytes: STREAM_CHUNK_SIZE,
        }
    }
}

```

### crates/oap/src/writer/mod.rs
<a id="crates-oap-src-writer-mod-rs"></a>

```rust
//! RO:WHAT — Buffered OAP frame writer for async sinks.
//! RO:WHY  — Provide a simple way to encode frames and flush to `AsyncWrite`.
//! RO:INTERACTS — `OapEncoder`; tokio `AsyncWrite`.
//! RO:INVARIANTS — No locks across `.await`; zero `unsafe`.

pub mod config;

use bytes::BytesMut;
use tokio::io::{AsyncWrite, AsyncWriteExt};
use tokio_util::codec::Encoder; // bring `encode` into scope

use crate::{codec::OapEncoder, Frame};
pub use config::WriterConfig;

/// Buffered OAP writer: encodes frames into an internal buffer,
/// then writes/flushes to an `AsyncWrite`.
#[derive(Debug)]
pub struct OapWriter {
    enc: OapEncoder,
    buf: BytesMut,
    cfg: WriterConfig,
}

impl OapWriter {
    pub fn new(cfg: WriterConfig) -> Self {
        Self {
            enc: OapEncoder,
            buf: BytesMut::new(),
            cfg,
        }
    }

    pub fn with_default() -> Self {
        Self::new(WriterConfig::default())
    }

    /// Encode a frame into the internal buffer (does not perform I/O).
    pub fn encode_to_buf(&mut self, frame: Frame) -> Result<(), crate::OapEncodeError> {
        self.enc.encode(frame, &mut self.buf)
    }

    /// Take the internal buffer as bytes (leaves buffer empty).
    pub fn take_buf(&mut self) -> bytes::Bytes {
        std::mem::take(&mut self.buf).freeze()
    }

    /// Encode and write a frame to an async sink, flushing if buffer exceeds `flush_hint_bytes`.
    pub async fn write_frame<S: AsyncWrite + Unpin>(
        &mut self,
        sink: &mut S,
        frame: Frame,
    ) -> Result<(), crate::OapError> {
        // Encoding errors -> OapEncodeError -> OapError (From impl)
        self.enc.encode(frame, &mut self.buf)?;

        if self.buf.len() >= self.cfg.flush_hint_bytes {
            // I/O errors -> std::io::Error -> OapError (From impl)
            sink.write_all(&self.buf).await?;
            self.buf.clear();
            sink.flush().await?;
        }
        Ok(())
    }

    /// Force-flush any buffered bytes to the sink.
    pub async fn flush<S: AsyncWrite + Unpin>(
        &mut self,
        sink: &mut S,
    ) -> Result<(), crate::OapError> {
        if !self.buf.is_empty() {
            sink.write_all(&self.buf).await?;
            self.buf.clear();
        }
        sink.flush().await?;
        Ok(())
    }
}

```

### crates/oap/tests/ack_algebra.rs
<a id="crates-oap-tests-ackalgebra-rs"></a>

```rust
//! Exercises ACK/END/EVENT helpers from `envelope`.

use bytes::Bytes;
use oap::{prelude::*, Flags};

#[test]
fn ack_end_event_algebra() {
    // EVENT without ACK → fire-and-forget
    let _ = FrameBuilder::request(1, 0xAB, 1)
        .payload(Bytes::from_static(b"evt"))
        .build();
    let flags = Flags::EVENT;
    assert!(is_fire_and_forget(flags));
    assert!(!wants_ack(flags));
    assert!(!is_terminal(flags));

    // REQUEST with ACK
    let f = FrameBuilder::request(1, 0xAB, 2)
        .payload(Bytes::from_static(b"req"))
        .want_ack()
        .build();
    let flags = f.header.flags | Flags::ACK_REQ;
    assert!(wants_ack(flags));
    assert!(!is_fire_and_forget(flags));

    // RESPONSE terminal
    let f = FrameBuilder::response(1, 0xAB, 3, StatusCode::Ok)
        .payload(Bytes::from_static(b"ok"))
        .end()
        .build();
    let flags = f.header.flags;
    assert!(is_terminal(flags));
}

```

### crates/oap/tests/config_validation.rs
<a id="crates-oap-tests-configvalidation-rs"></a>

```rust
//! Parser config soft-cap behavior and minimal builder sanity.

use bytes::Bytes;
use oap::{parser::ParserConfig, parser::ParserState, prelude::*};

#[test]
fn parser_soft_cap_trips() {
    // Tiny soft cap to trigger error on push.
    let mut p = ParserState::new(ParserConfig {
        max_buffer_bytes: Some(8),
    });
    // Push more than 8 bytes; we expect a decode error (soft-cap signal).
    let err = p.push(&[0u8; 16]).expect_err("should hit soft-cap");
    // We reuse PayloadOutOfBounds to signal backpressure.
    match err {
        oap::OapDecodeError::PayloadOutOfBounds => {}
        e => panic!("unexpected error: {e:?}"),
    }
}

#[test]
fn builder_minimal() {
    // Basic request/response builders compile and set flags.
    let r = FrameBuilder::request(7, 0xCAFE, 1)
        .payload(Bytes::from_static(b"ping"))
        .build();
    assert!(r.header.flags.contains(Flags::REQ));

    let s = FrameBuilder::response(7, 0xCAFE, 1, StatusCode::Ok)
        .payload(Bytes::from_static(b"pong"))
        .build();
    assert!(s.header.flags.contains(Flags::RESP));
}

```

### crates/oap/tests/conformance.rs
<a id="crates-oap-tests-conformance-rs"></a>

```rust
//! Conformance checks against protocol invariants (header size, START+cap rules).

use bytes::BytesMut;
use oap::{flags::Flags, prelude::*};
use tokio_util::codec::Decoder as _;

#[test]
fn header_size_constant() {
    // Defensive: if the header layout ever changes, this test will flag it.
    assert_eq!(Header::WIRE_SIZE, 4 + 2 + 2 + 2 + 2 + 16 + 2 + 8);
}

#[test]
fn cap_requires_start_flag() {
    // Craft a frame with cap_len>0 but without START flag → decoder must reject.
    let hdr = Header {
        len: (Header::WIRE_SIZE + 3) as u32,
        ver: OAP_VERSION,
        flags: Flags::REQ, // no START
        code: 0,
        app_proto_id: 123,
        tenant_id: 0xABCD,
        cap_len: 3,
        corr_id: 99,
    };
    let mut buf = BytesMut::new();
    // Put header, then 3 bytes of "cap".
    hdr.put_to(&mut buf);
    buf.extend_from_slice(b"cap");

    let mut dec = OapDecoder::default();
    let err = dec.decode(&mut buf).expect_err("should fail without START");
    match err {
        oap::OapDecodeError::CapOnNonStart => {}
        e => panic!("unexpected error: {e:?}"),
    }
}

```

### crates/oap/tests/envelope_builder.rs
<a id="crates-oap-tests-envelopebuilder-rs"></a>

```rust
use bytes::Bytes;
use oap::{prelude::*, Flags, StatusCode};

#[test]
fn builder_sets_flags_and_fields() {
    let f = FrameBuilder::request(9, 0xDEAD, 777)
        .start_with_cap(Bytes::from_static(b"macaroon"))
        .payload(Bytes::from_static(b"body"))
        .want_ack()
        .end()
        .build();

    let flags = f.header.flags;
    assert!(flags.contains(Flags::REQ));
    assert!(flags.contains(Flags::START));
    assert!(flags.contains(Flags::ACK_REQ));
    assert!(flags.contains(Flags::END));

    // Response builder sanity.
    let r = FrameBuilder::response(9, 0xDEAD, 777, StatusCode::Ok)
        .payload(Bytes::from_static(b"ok"))
        .build();
    assert!(r.header.flags.contains(Flags::RESP));
    assert_eq!(r.header.code, StatusCode::Ok as u16);
}

```

### crates/oap/tests/metrics_labels.rs
<a id="crates-oap-tests-metricslabels-rs"></a>

```rust
use oap::{metrics::*, StatusCode};

#[test]
fn reason_and_classification() {
    assert_eq!(reason(StatusCode::Ok), "OK");
    assert!(is_success(StatusCode::Ok));
    assert!(is_client_err(StatusCode::BadRequest));
    assert!(is_server_err(StatusCode::Internal));

    assert_eq!(outcome_from_status(StatusCode::Ok), OutcomeClass::Success);
    assert_eq!(
        labels_for_outcome(OutcomeClass::Oversize),
        ("oap", "oversize", "413")
    );
}

```

### crates/oap/tests/metrics_mapping.rs
<a id="crates-oap-tests-metricsmapping-rs"></a>

```rust
//! Outcome classification & labels; decode-error mapping.

use oap::{metrics::*, OapDecodeError, StatusCode};

#[test]
fn status_outcomes_and_labels() {
    assert_eq!(outcome_from_status(StatusCode::Ok), OutcomeClass::Success);
    assert_eq!(
        outcome_from_status(StatusCode::BadRequest),
        OutcomeClass::ClientError
    );
    assert_eq!(
        outcome_from_status(StatusCode::Internal),
        OutcomeClass::ServerError
    );

    assert_eq!(
        labels_for_outcome(OutcomeClass::Success),
        ("oap", "ok", "2xx")
    );
    assert_eq!(
        labels_for_outcome(OutcomeClass::Oversize),
        ("oap", "oversize", "413")
    );
}

#[test]
fn decode_error_to_outcome() {
    let e = OapDecodeError::FrameTooLarge {
        len: 2_000_000,
        max: 1_048_576,
    };
    assert_eq!(outcome_from_decode(&e), OutcomeClass::Oversize);

    let e = OapDecodeError::BadFlags(0xFFFF);
    assert_eq!(outcome_from_decode(&e), OutcomeClass::DecodeError);
}

```

### crates/oap/tests/parser_partial_read.rs
<a id="crates-oap-tests-parserpartialread-rs"></a>

```rust
use bytes::Bytes;
use oap::{codec::OapEncoder, parser::ParserConfig, parser::ParserState, prelude::*};
use tokio_util::codec::Encoder as _;

fn normalize(mut f: Frame) -> Frame {
    let cap_len = f.cap.as_ref().map(|b| b.len()).unwrap_or(0);
    let payload_len = f.payload.as_ref().map(|b| b.len()).unwrap_or(0);
    f.header.cap_len = cap_len as u16;
    f.header.len = (Header::WIRE_SIZE + cap_len + payload_len) as u32;
    f
}

#[test]
fn parses_frames_across_chunks() {
    // Build two frames and encode into one buffer.
    let f1 = FrameBuilder::request(7, 0xA, 1)
        .payload(Bytes::from_static(b"hello"))
        .end()
        .build();
    let f2 = FrameBuilder::response(7, 0xA, 1, StatusCode::Ok)
        .payload(Bytes::from_static(b"world"))
        .build();

    let mut enc = OapEncoder::default();
    let mut buf = bytes::BytesMut::new();
    enc.encode(f1.clone(), &mut buf).unwrap();
    enc.encode(f2.clone(), &mut buf).unwrap();
    let bytes = buf.freeze();

    // Feed in small chunks to the parser.
    let mut p = ParserState::new(ParserConfig::default());
    for chunk in bytes.chunks(3) {
        p.push(chunk).unwrap();
    }

    let frames = p.drain().unwrap();
    assert_eq!(frames.len(), 2);
    assert_eq!(frames[0], normalize(f1));
    assert_eq!(frames[1], normalize(f2));
}

```

### crates/oap/tests/seq_monotonic.rs
<a id="crates-oap-tests-seqmonotonic-rs"></a>

```rust
use oap::Seq;
use std::collections::HashSet;

#[test]
fn seq_is_monotonic_and_unique_across_sample() {
    let s = Seq::new();
    let mut seen = HashSet::new();
    let n = 10_000;
    for _ in 0..n {
        let id = s.next();
        assert!(seen.insert(id), "duplicate id detected");
    }
}

```

### crates/oap/tests/split_need_more.rs
<a id="crates-oap-tests-splitneedmore-rs"></a>

```rust
//! Ensure decoder returns `None` until a full frame is buffered.

use bytes::{Bytes, BytesMut};
use oap::{codec::OapEncoder, prelude::*};
use tokio_util::codec::{Decoder as _, Encoder as _};

fn encode_frame(f: Frame) -> bytes::Bytes {
    let mut enc = OapEncoder::default();
    let mut buf = BytesMut::new();
    enc.encode(f, &mut buf).unwrap();
    buf.freeze()
}

#[test]
fn need_more_before_full_header() {
    let f = FrameBuilder::request(7, 0xAA, 1)
        .payload(Bytes::from_static(b"hello"))
        .build();
    let bytes = encode_frame(f);

    let mut dec = OapDecoder::default();
    let mut buf = BytesMut::new();

    // Feed fewer than the header size — decode must return None.
    buf.extend_from_slice(&bytes[..Header::WIRE_SIZE - 1]);
    assert!(dec.decode(&mut buf).unwrap().is_none());

    // Feed rest — now a frame should be produced.
    buf.extend_from_slice(&bytes[Header::WIRE_SIZE - 1..]);
    let out = dec.decode(&mut buf).unwrap();
    assert!(out.is_some());
}

```

### crates/oap/tests/vectors.rs
<a id="crates-oap-tests-vectors-rs"></a>

```rust
//! RO:WHAT — Golden test vectors for OAP/1: HELLO, START+cap, DATA (with/without COMP).
//! RO:WHY — Guard interop stability; ensure encoder/decoder symmetry and bounds.
//! RO:INVARIANTS — 1MiB bound enforced; START carries cap; COMP requires feature=zstd to decode.

use bytes::{Bytes, BytesMut};
use oap::{
    Flags, Frame, Header, Hello, HelloReply, OapDecoder, OapEncoder, MAX_FRAME_BYTES, OAP_VERSION,
};
// Bring trait methods (encode/decode) into scope:
use tokio_util::codec::{Decoder, Encoder};

/// Compute the canonical on-wire header fields (`len`, `cap_len`) and
/// return a copy of `frame` updated with those values so equality works.
fn normalize(mut frame: Frame) -> Frame {
    let cap_len = frame.cap.as_ref().map(|b| b.len()).unwrap_or(0);
    let payload_len = frame.payload.as_ref().map(|b| b.len()).unwrap_or(0);
    let total_len = Header::WIRE_SIZE + cap_len + payload_len;

    frame.header.cap_len = cap_len as u16;
    frame.header.len = total_len as u32;
    frame
}

fn roundtrip(frame: Frame) {
    let mut enc = OapEncoder::default();
    let mut buf = BytesMut::new();
    enc.encode(frame.clone(), &mut buf).expect("encode");
    let mut dec = OapDecoder::default();
    let out = dec.decode(&mut buf).expect("decode").expect("one frame");

    // Normalize the input to match encoder-corrected header fields.
    let expect = normalize(frame);
    assert_eq!(out, expect);
}

#[test]
fn hello_roundtrip() {
    let h = Hello {
        ua: Some("sdk/0.1".into()),
    };
    let f = h.to_frame(0xAA, 42);
    roundtrip(f);
}

#[test]
fn hello_reply_roundtrip() {
    let hr = HelloReply::default_for_server();
    let f = hr.to_frame(0xBB, 7);
    roundtrip(f);
}

#[test]
fn start_with_cap() {
    let cap = Bytes::from_static(b"macaroon:scope=read:ttl=60s");
    let hdr = Header {
        len: 0,
        ver: OAP_VERSION,
        flags: Flags::START | Flags::REQ,
        code: 0,
        app_proto_id: 100,
        tenant_id: 0xCC,
        cap_len: 0,
        corr_id: 99,
    };
    let frame = Frame {
        header: hdr,
        cap: Some(cap),
        payload: None,
    };
    roundtrip(frame);
}

#[test]
fn data_without_cap() {
    let payload = Bytes::from_static(b"hello world");
    let hdr = Header {
        len: 0,
        ver: OAP_VERSION,
        flags: Flags::RESP,
        code: 200,
        app_proto_id: 200,
        tenant_id: 0xDD,
        cap_len: 0,
        corr_id: 123,
    };
    let frame = Frame {
        header: hdr,
        cap: None,
        payload: Some(payload),
    };
    roundtrip(frame);
}

#[test]
fn rejects_oversize() {
    let payload = vec![0u8; (MAX_FRAME_BYTES as usize) + 1];
    let hdr = Header {
        len: 0,
        ver: OAP_VERSION,
        flags: Flags::RESP,
        code: 200,
        app_proto_id: 1,
        tenant_id: 1,
        cap_len: 0,
        corr_id: 1,
    };
    let mut enc = OapEncoder::default();
    let mut buf = BytesMut::new();
    let res = enc.encode(
        Frame {
            header: hdr,
            cap: None,
            payload: Some(Bytes::from(payload)),
        },
        &mut buf,
    );
    assert!(res.is_err());
}

#[cfg(feature = "zstd")]
#[test]
fn comp_bounded_inflate() {
    // Small payload compressed; ensure decode returns original.
    let raw = vec![42u8; 4096];
    let mut comp = Vec::new();
    {
        let mut enc = zstd::stream::write::Encoder::new(&mut comp, 1).unwrap();
        use std::io::Write;
        enc.write_all(&raw).unwrap();
        enc.finish().unwrap();
    }

    let hdr = Header {
        len: 0,
        ver: OAP_VERSION,
        flags: Flags::RESP | Flags::COMP,
        code: 200,
        app_proto_id: 2,
        tenant_id: 2,
        cap_len: 0,
        corr_id: 2,
    };
    let mut enc = OapEncoder::default();
    let mut buf = BytesMut::new();
    enc.encode(
        Frame {
            header: hdr,
            cap: None,
            payload: Some(Bytes::from(comp)),
        },
        &mut buf,
    )
    .unwrap();

    let mut dec = OapDecoder::default();
    let out = dec.decode(&mut buf).unwrap().unwrap();
    assert_eq!(out.payload.unwrap().len(), raw.len());
}

```

### crates/oap/tests/writer_roundtrip.rs
<a id="crates-oap-tests-writerroundtrip-rs"></a>

```rust
use bytes::Bytes;
use oap::{codec::OapDecoder, prelude::*, writer::OapWriter, writer::WriterConfig};
use tokio_util::codec::Decoder as _;

fn normalize(mut f: Frame) -> Frame {
    let cap_len = f.cap.as_ref().map(|b| b.len()).unwrap_or(0);
    let payload_len = f.payload.as_ref().map(|b| b.len()).unwrap_or(0);
    f.header.cap_len = cap_len as u16;
    f.header.len = (Header::WIRE_SIZE + cap_len + payload_len) as u32;
    f
}

#[test]
fn encode_to_buf_and_decode_back() {
    // Build a START frame with cap + payload.
    let f = FrameBuilder::request(42, 0xCAFE, 99)
        .start_with_cap(Bytes::from_static(b"scope=read"))
        .payload(Bytes::from_static(b"ping"))
        .want_ack()
        .build();

    // Encode using writer (buffered, no async I/O used).
    let mut w = OapWriter::new(WriterConfig::default());
    w.encode_to_buf(f.clone()).unwrap();
    let bytes = w.take_buf();

    // Decode back.
    let mut dec = OapDecoder::default();
    let mut buf: bytes::BytesMut = bytes.clone().into(); // <-- direct From<Bytes>
    let out = dec.decode(&mut buf).unwrap().unwrap();

    assert_eq!(out, normalize(f));
    assert!(buf.is_empty(), "buffer fully consumed");
}

```



---



# ron-transport

_Source: crates/ron-transport/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:42:21Z -->
# Code Bundle — `ron-transport`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-transport/.cargo/config.toml](#crates-ron-transport--cargo-config-toml)
- [crates/ron-transport/.github/workflows/ci.yml](#crates-ron-transport--github-workflows-ci-yml)
- [crates/ron-transport/.github/workflows/perf.yml](#crates-ron-transport--github-workflows-perf-yml)
- [crates/ron-transport/.github/workflows/tla.yml](#crates-ron-transport--github-workflows-tla-yml)
- [crates/ron-transport/Cargo.toml](#crates-ron-transport-Cargo-toml)
- [crates/ron-transport/benches/bench_latency.rs](#crates-ron-transport-benches-benchlatency-rs)
- [crates/ron-transport/benches/bench_throughput.rs](#crates-ron-transport-benches-benchthroughput-rs)
- [crates/ron-transport/examples/bench_echo.rs](#crates-ron-transport-examples-benchecho-rs)
- [crates/ron-transport/examples/http_echo.rs](#crates-ron-transport-examples-httpecho-rs)
- [crates/ron-transport/examples/onion_echo.rs](#crates-ron-transport-examples-onionecho-rs)
- [crates/ron-transport/examples/quic_echo.rs](#crates-ron-transport-examples-quicecho-rs)
- [crates/ron-transport/examples/tcp_echo.rs](#crates-ron-transport-examples-tcpecho-rs)
- [crates/ron-transport/examples/tls_echo.rs](#crates-ron-transport-examples-tlsecho-rs)
- [crates/ron-transport/examples/tls_transport.rs](#crates-ron-transport-examples-tlstransport-rs)
- [crates/ron-transport/fuzz/fuzz_targets/frame_boundaries.rs](#crates-ron-transport-fuzz-fuzztargets-frameboundaries-rs)
- [crates/ron-transport/scripts/ci/env_sanitize.sh](#crates-ron-transport-scripts-ci-envsanitize-sh)
- [crates/ron-transport/scripts/ci/run_tlc.sh](#crates-ron-transport-scripts-ci-runtlc-sh)
- [crates/ron-transport/scripts/local/echo_smoke.sh](#crates-ron-transport-scripts-local-echosmoke-sh)
- [crates/ron-transport/scripts/local/http_echo_smoke.sh](#crates-ron-transport-scripts-local-httpechosmoke-sh)
- [crates/ron-transport/scripts/local/mk_self_signed.sh](#crates-ron-transport-scripts-local-mkselfsigned-sh)
- [crates/ron-transport/scripts/local/perf_repro.sh](#crates-ron-transport-scripts-local-perfrepro-sh)
- [crates/ron-transport/scripts/local/smoke_tls.sh](#crates-ron-transport-scripts-local-smoketls-sh)
- [crates/ron-transport/scripts/local/smoke_transport.sh](#crates-ron-transport-scripts-local-smoketransport-sh)
- [crates/ron-transport/src/arti/client.rs](#crates-ron-transport-src-arti-client-rs)
- [crates/ron-transport/src/arti/mod.rs](#crates-ron-transport-src-arti-mod-rs)
- [crates/ron-transport/src/arti/readiness.rs](#crates-ron-transport-src-arti-readiness-rs)
- [crates/ron-transport/src/arti/service.rs](#crates-ron-transport-src-arti-service-rs)
- [crates/ron-transport/src/config.rs](#crates-ron-transport-src-config-rs)
- [crates/ron-transport/src/conn/backpressure.rs](#crates-ron-transport-src-conn-backpressure-rs)
- [crates/ron-transport/src/conn/mod.rs](#crates-ron-transport-src-conn-mod-rs)
- [crates/ron-transport/src/conn/rate_limit.rs](#crates-ron-transport-src-conn-ratelimit-rs)
- [crates/ron-transport/src/conn/reader.rs](#crates-ron-transport-src-conn-reader-rs)
- [crates/ron-transport/src/conn/writer.rs](#crates-ron-transport-src-conn-writer-rs)
- [crates/ron-transport/src/error.rs](#crates-ron-transport-src-error-rs)
- [crates/ron-transport/src/lib.rs](#crates-ron-transport-src-lib-rs)
- [crates/ron-transport/src/limits.rs](#crates-ron-transport-src-limits-rs)
- [crates/ron-transport/src/metrics.rs](#crates-ron-transport-src-metrics-rs)
- [crates/ron-transport/src/quic/client.rs](#crates-ron-transport-src-quic-client-rs)
- [crates/ron-transport/src/quic/mod.rs](#crates-ron-transport-src-quic-mod-rs)
- [crates/ron-transport/src/quic/server.rs](#crates-ron-transport-src-quic-server-rs)
- [crates/ron-transport/src/readiness.rs](#crates-ron-transport-src-readiness-rs)
- [crates/ron-transport/src/reason.rs](#crates-ron-transport-src-reason-rs)
- [crates/ron-transport/src/tcp/dialer.rs](#crates-ron-transport-src-tcp-dialer-rs)
- [crates/ron-transport/src/tcp/listener.rs](#crates-ron-transport-src-tcp-listener-rs)
- [crates/ron-transport/src/tcp/mod.rs](#crates-ron-transport-src-tcp-mod-rs)
- [crates/ron-transport/src/tls/client.rs](#crates-ron-transport-src-tls-client-rs)
- [crates/ron-transport/src/tls/mod.rs](#crates-ron-transport-src-tls-mod-rs)
- [crates/ron-transport/src/tls/server.rs](#crates-ron-transport-src-tls-server-rs)
- [crates/ron-transport/src/tls_types.rs](#crates-ron-transport-src-tlstypes-rs)
- [crates/ron-transport/src/types.rs](#crates-ron-transport-src-types-rs)
- [crates/ron-transport/src/util/bytes.rs](#crates-ron-transport-src-util-bytes-rs)
- [crates/ron-transport/src/util/cancel.rs](#crates-ron-transport-src-util-cancel-rs)
- [crates/ron-transport/src/util/mod.rs](#crates-ron-transport-src-util-mod-rs)
- [crates/ron-transport/src/util/timeouts.rs](#crates-ron-transport-src-util-timeouts-rs)
- [crates/ron-transport/tests/amnesia/no_disk_touches.rs](#crates-ron-transport-tests-amnesia-nodisktouches-rs)
- [crates/ron-transport/tests/integration/arti_bootstrap_ready.rs](#crates-ron-transport-tests-integration-artibootstrapready-rs)
- [crates/ron-transport/tests/integration/idle_timeout.rs](#crates-ron-transport-tests-integration-idletimeout-rs)
- [crates/ron-transport/tests/integration/mod.rs](#crates-ron-transport-tests-integration-mod-rs)
- [crates/ron-transport/tests/integration/over_capacity.rs](#crates-ron-transport-tests-integration-overcapacity-rs)
- [crates/ron-transport/tests/integration/quic_parity.rs](#crates-ron-transport-tests-integration-quicparity-rs)
- [crates/ron-transport/tests/integration/tls_accept.rs](#crates-ron-transport-tests-integration-tlsaccept-rs)
- [crates/ron-transport/tests/integration/tls_handshake_limits.rs](#crates-ron-transport-tests-integration-tlshandshakelimits-rs)
- [crates/ron-transport/tests/intergration.rs](#crates-ron-transport-tests-intergration-rs)
- [crates/ron-transport/tests/loom/single_writer.rs](#crates-ron-transport-tests-loom-singlewriter-rs)
- [crates/ron-transport/tests/soak/loopback_1MiB.rs](#crates-ron-transport-tests-soak-loopback1MiB-rs)
- [crates/ron-transport/tests/vectors/comp_bounds.json](#crates-ron-transport-tests-vectors-compbounds-json)
- [crates/ron-transport/tests/vectors/oap_hello.json](#crates-ron-transport-tests-vectors-oaphello-json)
- [crates/ron-transport/tests/vectors/pq_hybrid_hello.json](#crates-ron-transport-tests-vectors-pqhybridhello-json)
- [crates/ron-transport/tests/vectors/tor_parity.json](#crates-ron-transport-tests-vectors-torparity-json)

### crates/ron-transport/.cargo/config.toml
<a id="crates-ron-transport--cargo-config-toml"></a>

```toml
[build]
rustflags = ["-Cdebuginfo=1"]

[target.'cfg(unix)']
rustflags = ["-C", "link-arg=-Wl,-O1"]

[term]
verbose = true

```

### crates/ron-transport/.github/workflows/ci.yml
<a id="crates-ron-transport--github-workflows-ci-yml"></a>

```yaml
name: ron-transport2 CI
on:
  push:
  pull_request:
jobs:
  build-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        features: ["", "arti", "quic", "arti,quic"]
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - name: Build
        run: cargo build -p ron-transport2 ${MATRIX:+--features ${{ matrix.features }}}
        env: { MATRIX: ${{ matrix.features }} }
      - name: Test
        run: cargo test -p ron-transport2 ${MATRIX:+--features ${{ matrix.features }}}
        env: { MATRIX: ${{ matrix.features }} }
      - name: Clippy (deny warnings)
        run: cargo clippy -p ron-transport2 ${MATRIX:+--features ${{ matrix.features }}} -- -D warnings
        env: { MATRIX: ${{ matrix.features }} }

```

### crates/ron-transport/.github/workflows/perf.yml
<a id="crates-ron-transport--github-workflows-perf-yml"></a>

```yaml
name: ron-transport2 Perf
on: { workflow_dispatch: {} }
jobs:
  perf:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - name: Run benches (placeholder)
        run: cargo bench -p ron-transport2 || true
      - name: Archive Criterion artifacts
        uses: actions/upload-artifact@v4
        with:
          name: bench-artifacts
          path: target/criterion

```

### crates/ron-transport/.github/workflows/tla.yml
<a id="crates-ron-transport--github-workflows-tla-yml"></a>

```yaml
name: ron-transport2 TLA
on:
  push:
  pull_request:
jobs:
  tla:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Run TLC (placeholder)
        run: bash crates/ron-transport2/scripts/ci/run_tlc.sh

```

### crates/ron-transport/Cargo.toml
<a id="crates-ron-transport-Cargo-toml"></a>

```toml
[package]
name = "ron-transport"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
description = "RustyOnions transport abstraction (TCP/TLS; Tor via arti feature; QUIC optional) for OAP/1 streams."
repository = "https://github.com/yourorg/RustyOnions"
readme = "README.md"

[lib]
name = "ron_transport"
path = "src/lib.rs"

[features]
default = ["tcp", "tls"]
tcp = []
tls = ["dep:tokio-rustls", "dep:rustls-pemfile"]
arti = []            # feature hook; code compiles without pulling arti deps yet
quic = []            # feature hook; add quinn later

[dependencies]
tokio = { version = "1.47.1", features = ["net", "rt-multi-thread", "sync", "time", "io-util", "macros"] }
bytes = "1.6"
futures = "0.3"
thiserror = "2"
anyhow = "1"
parking_lot = "0.12"
tracing = "0.1"
once_cell = "1.20"
rand = "0.9"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
prometheus = "0.14"
tokio-util = { version = "0.7", features = ["codec", "rt"] }  # rt => CancellationToken
pin-project-lite = "0.2"

# TLS (guarded)
tokio-rustls = { version = "0.26.2", optional = true }
rustls-pemfile = { version = "2.2", optional = true }

# Internal crates (kernel re-exports: Bus, HealthState, Metrics)
ron-kernel = { path = "../ron-kernel" }
ron-metrics = { path = "../ron-metrics" }

[dev-dependencies]
tokio = { version = "1.47.1", features = ["rt-multi-thread", "macros", "time", "io-util", "net"] }
criterion = "0.5"
tokio-rustls = { version = "0.26.2" }
rustls-pemfile = { version = "2.2" }

[package.metadata.docs.rs]
features = ["tcp", "tls"]

```

### crates/ron-transport/benches/bench_latency.rs
<a id="crates-ron-transport-benches-benchlatency-rs"></a>

```rust
#![allow(unused)]
fn main() {}
// Placeholder Criterion bench: connect→first-byte latency per backend.

```

### crates/ron-transport/benches/bench_throughput.rs
<a id="crates-ron-transport-benches-benchthroughput-rs"></a>

```rust
#![allow(unused)]
fn main() {}
// Placeholder Criterion bench: 1 MiB frames, ~64 KiB streaming.

```

### crates/ron-transport/examples/bench_echo.rs
<a id="crates-ron-transport-examples-benchecho-rs"></a>

```rust
//! RO:WHAT — Minimal loopback listener smoke.
//! RO:WHY  — Verify spawn_transport() binds and runs without TLS.
//! RO:INTERACTS — TransportConfig, TransportMetrics, HealthState, Bus<TransportEvent>.

use ron_kernel::{Bus, HealthState};
use ron_transport::{
    config::TransportConfig, metrics::TransportMetrics, spawn_transport, types::TransportEvent,
};
use std::sync::Arc;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let cfg = TransportConfig::default();
    let metrics = TransportMetrics::new("ron");
    let health = Arc::new(HealthState::new());

    // Event bus: we won't consume events here, but the type is now TransportEvent.
    let bus: Bus<TransportEvent> = Bus::new();

    let (_jh, addr) = spawn_transport(cfg, metrics, health, bus, None).await?;
    println!("ron-transport listening on {}", addr);

    tokio::signal::ctrl_c().await.ok();
    Ok(())
}

```

### crates/ron-transport/examples/http_echo.rs
<a id="crates-ron-transport-examples-httpecho-rs"></a>

```rust
//! Minimal HTTP-ish echo over raw TCP (not using the library).
//! Purpose: easy curl checks that show a visible response.

use tokio::{
    io::{AsyncReadExt, AsyncWriteExt},
    net::TcpListener,
};

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let listener = TcpListener::bind(("127.0.0.1", 0)).await?;
    let addr = listener.local_addr()?;
    println!("http-echo listening on {}", addr);

    loop {
        let (mut sock, _peer) = listener.accept().await?;
        tokio::spawn(async move {
            let mut buf = vec![0u8; 16 * 1024];

            // Read once (simple demo) — enough for small requests.
            let n = match sock.read(&mut buf).await {
                Ok(0) => return,
                Ok(m) => m,
                Err(_) => return,
            };

            // Craft a simple 200 OK with echoed body.
            let body = &buf[..n];
            let header = format!(
                "HTTP/1.1 200 OK\r\nContent-Length: {}\r\nContent-Type: text/plain\r\nConnection: close\r\n\r\n",
                body.len()
            );

            if sock.write_all(header.as_bytes()).await.is_err() {
                return;
            }
            let _ = sock.write_all(body).await;
            let _ = sock.flush().await;
        });
    }
}

```

### crates/ron-transport/examples/onion_echo.rs
<a id="crates-ron-transport-examples-onionecho-rs"></a>

```rust
fn main() {
    println!("onion_echo (Arti) placeholder");
}

```

### crates/ron-transport/examples/quic_echo.rs
<a id="crates-ron-transport-examples-quicecho-rs"></a>

```rust
fn main() {
    println!("quic_echo placeholder");
}

```

### crates/ron-transport/examples/tcp_echo.rs
<a id="crates-ron-transport-examples-tcpecho-rs"></a>

```rust
//! Minimal TCP echo (for human-visible round-trips with curl/nc).
//! NOTE: This is a standalone echo using Tokio, not the library accept loop.
//! It’s just for smoke-testing with tools that expect a response.

use tokio::{
    io::{AsyncReadExt, AsyncWriteExt},
    net::TcpListener,
};

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let listener = TcpListener::bind(("127.0.0.1", 0)).await?;
    let addr = listener.local_addr()?;
    println!("echo listening on {}", addr);

    loop {
        let (mut sock, _peer) = listener.accept().await?;
        tokio::spawn(async move {
            let mut buf = vec![0u8; 4096];
            loop {
                let n = match sock.read(&mut buf).await {
                    Ok(0) => return, // closed
                    Ok(n) => n,
                    Err(_) => return,
                };
                if sock.write_all(&buf[..n]).await.is_err() {
                    return;
                }
            }
        });
    }
}

```

### crates/ron-transport/examples/tls_echo.rs
<a id="crates-ron-transport-examples-tlsecho-rs"></a>

```rust
fn main() {
    println!("tls_echo placeholder");
}

```

### crates/ron-transport/examples/tls_transport.rs
<a id="crates-ron-transport-examples-tlstransport-rs"></a>

```rust
//! TLS listener using the ron-transport library.
//! Loads cert+key, builds rustls::ServerConfig, and passes it to spawn_transport.

#![cfg(feature = "tls")]

use ron_kernel::{Bus, HealthState};
use ron_transport::{
    config::TransportConfig,
    metrics::TransportMetrics,
    spawn_transport,
    types::TransportEvent,
    TlsServerConfig, // re-export
};
use std::{fs::File, io::BufReader, path::Path, sync::Arc};

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let cert_path = std::env::args()
        .nth(1)
        .unwrap_or_else(|| "crates/ron-transport/scripts/local/certs/cert.pem".into());
    let key_path = std::env::args()
        .nth(2)
        .unwrap_or_else(|| "crates/ron-transport/scripts/local/certs/key.pem".into());

    let tls_cfg = Arc::new(load_rustls_server(&cert_path, &key_path)?);

    let mut cfg = TransportConfig::default();
    cfg.name = "tls";
    let metrics = TransportMetrics::new("ron");
    let health = Arc::new(HealthState::new());
    let bus: Bus<TransportEvent> = Bus::new();

    let (_jh, addr) = spawn_transport(cfg, metrics, health, bus, Some(tls_cfg)).await?;
    println!("tls-transport listening on {}", addr);
    tokio::signal::ctrl_c().await.ok();
    Ok(())
}

#[cfg(feature = "tls")]
fn load_rustls_server(cert_path: &str, key_path: &str) -> anyhow::Result<TlsServerConfig> {
    use rustls_pemfile::{certs, pkcs8_private_keys, rsa_private_keys};
    use tokio_rustls::rustls::{
        pki_types::{CertificateDer, PrivateKeyDer, PrivatePkcs1KeyDer, PrivatePkcs8KeyDer},
        ServerConfig,
    };

    // Load cert chain
    let cert_file = File::open(Path::new(cert_path))?;
    let mut cert_rd = BufReader::new(cert_file);
    let certs: Vec<CertificateDer<'static>> = certs(&mut cert_rd).collect::<Result<_, _>>()?;

    // Load first available private key (PKCS#8 preferred, fall back to PKCS#1/RSA)
    let key: PrivateKeyDer<'static> = {
        // Try PKCS#8
        let key_file = File::open(Path::new(key_path))?;
        let mut key_rd = BufReader::new(key_file);
        let mut pkcs8: Vec<PrivateKeyDer<'static>> = pkcs8_private_keys(&mut key_rd)
            .map(|res: std::io::Result<PrivatePkcs8KeyDer<'static>>| res.map(Into::into))
            .collect::<Result<_, _>>()?;
        if let Some(k) = pkcs8.pop() {
            k
        } else {
            // Try PKCS#1 (RSA)
            let key_file = File::open(Path::new(key_path))?;
            let mut key_rd = BufReader::new(key_file);
            let mut rsa: Vec<PrivateKeyDer<'static>> = rsa_private_keys(&mut key_rd)
                .map(|res: std::io::Result<PrivatePkcs1KeyDer<'static>>| res.map(Into::into))
                .collect::<Result<_, _>>()?;
            rsa.pop()
                .ok_or_else(|| anyhow::anyhow!("no private key found in {}", key_path))?
        }
    };

    // rustls 0.22 API
    let cfg = ServerConfig::builder()
        .with_no_client_auth()
        .with_single_cert(certs, key)?;

    Ok(cfg)
}

```

### crates/ron-transport/fuzz/fuzz_targets/frame_boundaries.rs
<a id="crates-ron-transport-fuzz-fuzztargets-frameboundaries-rs"></a>

```rust
#![no_main]
// Placeholder fuzz target for frame boundaries.

```

### crates/ron-transport/scripts/ci/env_sanitize.sh
<a id="crates-ron-transport-scripts-ci-envsanitize-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT — sanitize env for hermetic CI runs
set -euo pipefail
unset RUST_LOG || true
unset RUST_BACKTRACE || true

```

### crates/ron-transport/scripts/ci/run_tlc.sh
<a id="crates-ron-transport-scripts-ci-runtlc-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT — placeholder TLA+ runner (specs compile later)
set -euo pipefail
echo "TLA+ specs not enabled yet for ron-transport MVP."

```

### crates/ron-transport/scripts/local/echo_smoke.sh
<a id="crates-ron-transport-scripts-local-echosmoke-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

LOG_FILE="$(mktemp -t ron_transport_echo.XXXXXX.log)"
RUST_LOG=info cargo run -q -p ron-transport --example tcp_echo >"$LOG_FILE" 2>&1 &
PID=$!
trap 'kill $PID >/dev/null 2>&1 || true; rm -f "$LOG_FILE"' EXIT

# Wait for "echo listening on ..."
for _ in {1..50}; do
  if grep -q "echo listening on" "$LOG_FILE"; then break; fi
  sleep 0.1
done

line="$(grep "echo listening on" "$LOG_FILE" | tail -n1)"
PORT="$(awk -F: '{print $NF}' <<<"$line" | tr -d '[:space:]')"
HOST="$(sed -E 's/.* on ([0-9\.]+):[0-9]+/\1/' <<<"$line")"

echo "[ OK ] echo server: ${HOST}:${PORT}"

# 1) curl round-trip allowing HTTP/0.9 (raw TCP echo)
if command -v curl >/dev/null 2>&1; then
  printf 'hello RON\n' | curl --http0.9 --no-progress-meter --data-binary @- "http://${HOST}:${PORT}/" || true
else
  echo "[WARN] curl not found; skipping curl test"
fi

# 2) nc round-trip
if command -v nc >/dev/null 2>&1; then
  printf 'hello RON\n' | nc -w 1 "${HOST}" "${PORT}" || true
else
  echo "[WARN] nc not found; skipping nc test"
fi

echo "[ OK ] probes done"

```

### crates/ron-transport/scripts/local/http_echo_smoke.sh
<a id="crates-ron-transport-scripts-local-httpechosmoke-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

LOG_FILE="$(mktemp -t ron_transport_http_echo.XXXXXX.log)"
RUST_LOG=info cargo run -q -p ron-transport --example http_echo >"$LOG_FILE" 2>&1 &
PID=$!
trap 'kill $PID >/dev/null 2>&1 || true; rm -f "$LOG_FILE"' EXIT

for _ in {1..50}; do
  if grep -q "http-echo listening on" "$LOG_FILE"; then break; fi
  sleep 0.1
done

line="$(grep "http-echo listening on" "$LOG_FILE" | tail -n1)"
PORT="$(awk -F: '{print $NF}' <<<"$line" | tr -d '[:space:]')"
HOST="$(sed -E 's/.* on ([0-9\.]+):[0-9]+/\1/' <<<"$line")"

echo "[ OK ] http-echo server: ${HOST}:${PORT}"
printf 'Hello via curl 🧪\n' | curl --no-progress-meter --data-binary @- "http://${HOST}:${PORT}/" || true
echo
echo "[ OK ] done"

```

### crates/ron-transport/scripts/local/mk_self_signed.sh
<a id="crates-ron-transport-scripts-local-mkselfsigned-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT — Generate a quick self-signed cert/key for local TLS smoke.
set -euo pipefail

DIR="${1:-crates/ron-transport/scripts/local/certs}"
mkdir -p "$DIR"

CERT="$DIR/cert.pem"
KEY="$DIR/key.pem"

# 365-day self-signed; CN=localhost
openssl req -x509 -newkey rsa:2048 -nodes -sha256 -days 365 \
  -subj "/CN=localhost" \
  -keyout "$KEY" -out "$CERT" >/dev/null 2>&1

echo "[ OK ] wrote $CERT and $KEY"

```

### crates/ron-transport/scripts/local/perf_repro.sh
<a id="crates-ron-transport-scripts-local-perfrepro-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT — local loopback perf smoke (placeholder)
set -euo pipefail
RUST_LOG=${RUST_LOG:-info} cargo run -p ron-transport --example bench_echo || true

```

### crates/ron-transport/scripts/local/smoke_tls.sh
<a id="crates-ron-transport-scripts-local-smoketls-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT — Build (--features tls), start tls_transport, and probe with openssl.
set -euo pipefail

# Ensure certs exist
bash crates/ron-transport/scripts/local/mk_self_signed.sh >/dev/null

CERT="crates/ron-transport/scripts/local/certs/cert.pem"
KEY="crates/ron-transport/scripts/local/certs/key.pem"

# Build with TLS
cargo build -q -p ron-transport --features tls

# Run tls_transport example
LOG_FILE="$(mktemp -t ron_transport_tls.XXXXXX.log)"
RUST_LOG=info cargo run -q -p ron-transport --features tls --example tls_transport -- "$CERT" "$KEY" >"$LOG_FILE" 2>&1 &
PID=$!
trap 'kill $PID >/dev/null 2>&1 || true; rm -f "$LOG_FILE"' EXIT

# Wait for it to start
for _ in {1..50}; do
  if grep -q "tls-transport listening on" "$LOG_FILE"; then break; fi
  sleep 0.1
done

line="$(grep "tls-transport listening on" "$LOG_FILE" | tail -n1)"
PORT="$(awk -F: '{print $NF}' <<<"$line" | tr -d '[:space:]')"
HOST="$(sed -E 's/.* on ([0-9\.]+):[0-9]+/\1/' <<<"$line")"
echo "[ OK ] tls server: ${HOST}:${PORT}"

# Probe with openssl s_client (TLS 1.3), send a line, and exit.
# Expect no HTTP response — this proves handshake success.
printf 'hello over TLS\n' | openssl s_client -quiet -connect "${HOST}:${PORT}" -tls1_3 -servername localhost >/dev/null 2>&1 || true
echo "[ OK ] openssl s_client connected + wrote bytes (no response expected)"

```

### crates/ron-transport/scripts/local/smoke_transport.sh
<a id="crates-ron-transport-scripts-local-smoketransport-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT  — End-to-end smoke for ron-transport loopback (robust macOS/Linux).
# RO:NOTE  — Uses Python socket send first (non-blocking), falls back to nc with safe flags.

set -euo pipefail

HOST_DEFAULT="127.0.0.1"
HOST="${HOST:-$HOST_DEFAULT}"
PORT="${PORT:-}"
LOG_FILE="$(mktemp -t ron_transport_smoke.XXXXXX.log)"
SERVER_PID=""
CLEANUP_DONE=0

cleanup() {
  if [[ $CLEANUP_DONE -eq 1 ]]; then return; fi
  CLEANUP_DONE=1
  if [[ -n "${SERVER_PID}" ]]; then
    kill "${SERVER_PID}" >/dev/null 2>&1 || true
    wait "${SERVER_PID}" >/dev/null 2>&1 || true
  fi
  rm -f "$LOG_FILE" || true
}
trap cleanup EXIT INT TERM

info()  { printf "[INFO] %s\n" "$*"; }
ok()    { printf "[ OK ] %s\n" "$*"; }
warn()  { printf "[WARN] %s\n" "$*"; }
fail()  { printf "[FAIL] %s\n" "$*"; }

require_cmd() {
  command -v "$1" >/dev/null 2>&1 || { fail "missing '$1' in PATH"; exit 1; }
}

spawn_server_if_needed() {
  if [[ -n "${PORT}" ]]; then
    info "Using provided PORT=${PORT}, HOST=${HOST}; will not spawn server."
    return
  fi

  info "Starting bench_echo to auto-discover port (HOST=${HOST})…"
  RUST_LOG=info cargo run -q -p ron-transport --example bench_echo >"$LOG_FILE" 2>&1 &
  SERVER_PID=$!

  # Wait until it prints the listening line (timeout ~5s).
  for _ in {1..50}; do
    if grep -q "ron-transport listening on" "$LOG_FILE"; then
      break
    fi
    sleep 0.1
  done
  if ! grep -q "ron-transport listening on" "$LOG_FILE"; then
    warn "Could not detect listener line; recent log:"
    tail -n +1 "$LOG_FILE" || true
    fail "Server failed to start or log was not captured."
    exit 1
  fi

  local line
  line="$(grep "ron-transport listening on" "$LOG_FILE" | tail -n1)"
  PORT="$(awk -F: '{print $NF}' <<<"$line" | tr -d '[:space:]')"
  HOST="$(sed -E 's/.* on ([0-9\.]+):[0-9]+/\1/' <<<"$line")"
  ok "Server is up: ${HOST}:${PORT} (pid ${SERVER_PID})"
}

nc_support_flags() {
  # Detect safe close flag for this nc variant.
  local help; help="$( (nc -h 2>&1 || true) )"
  if grep -q -- " -N" <<<"$help"; then
    echo "-N"           # OpenBSD/macOS: close on stdin EOF
  elif grep -q -- " -q " <<<"$help"; then
    echo "-q 1"         # GNU netcat: quit 1s after EOF on stdin
  else
    echo ""             # Unknown; we’ll guard with timeout anyway
  fi
}

run_probes() {
  # 1) Quick TCP connect check with nc -vz (non-blocking)
  info "Probing with nc (TCP connect)…"
  if command -v nc >/dev/null 2>&1; then
    if nc -vz -w 2 "${HOST}" "${PORT}" >/dev/null 2>&1; then
      ok "nc connect succeeded"
    else
      warn "nc connect failed (continuing)"
    fi
  else
    warn "nc not found; skipping"
  fi

  # 2) Send bytes via Python socket (preferred, never hangs)
  info "Python one-liner send…"
  if command -v python3 >/dev/null 2>&1; then
    python3 - <<PY || warn "python send failed (continuing)"
import socket
s=socket.create_connection(("${HOST}", int("${PORT}")), 2)
s.sendall(b"hello\\n")
s.close()
PY
    ok "python send completed"
  else
    warn "python3 not found; skipping python send"
  fi

  # 3) Optional: nc one-shot send with safe close (guarded)
  if command -v nc >/dev/null 2>&1; then
    local CLOSE_FLAGS; CLOSE_FLAGS="$(nc_support_flags)"
    info "Sending bytes via nc (one-shot, flags: ${CLOSE_FLAGS:-none})…"
    # Run nc in the background with a hard kill after 3s as a final guard.
    ( printf 'hello ron-transport\n' | nc ${CLOSE_FLAGS} -w 2 "${HOST}" "${PORT}" ) >/dev/null 2>&1 & 
    local nc_pid=$!
    # Hard timeout guard:
    ( sleep 3; kill "$nc_pid" >/dev/null 2>&1 || true ) &
    wait "$nc_pid" >/dev/null 2>&1 || true
    ok "sent bytes with nc (no response expected)"
  fi

  # 4) curl proof (expect timeout; add connect-timeout)
  info "curl smoke (expect timeout, proves non-HTTP raw TCP)…"
  if command -v curl >/dev/null 2>&1; then
    if echo -n 'hello' | curl --no-progress-meter --data-binary @- \
         --connect-timeout 1 --max-time 2 "http://${HOST}:${PORT}/" >/dev/null; then
      warn "curl returned success (unexpected for raw TCP), continuing"
    else
      ok "curl timed out as expected (raw TCP, no HTTP)"
    fi
  else
    warn "curl not found; skipping"
  fi

  info "All probes done."
}

main() {
  require_cmd cargo
  spawn_server_if_needed
  run_probes
}

main

```

### crates/ron-transport/src/arti/client.rs
<a id="crates-ron-transport-src-arti-client-rs"></a>

```rust
//! Arti outbound (placeholder).
pub struct ArtiClient;

```

### crates/ron-transport/src/arti/mod.rs
<a id="crates-ron-transport-src-arti-mod-rs"></a>

```rust
pub mod client;
pub mod readiness;
pub mod service;

```

### crates/ron-transport/src/arti/readiness.rs
<a id="crates-ron-transport-src-arti-readiness-rs"></a>

```rust
//! Arti readiness glue (placeholder).
pub struct ArtiReadiness;

```

### crates/ron-transport/src/arti/service.rs
<a id="crates-ron-transport-src-arti-service-rs"></a>

```rust
//! Arti onion service (placeholder).
pub struct ArtiService;

```

### crates/ron-transport/src/config.rs
<a id="crates-ron-transport-src-config-rs"></a>

```rust
//! RO:WHAT — Transport configuration (bind, ceilings, timeouts).
//! RO:WHY  — Hard caps & deadlines enforce SEC/RES.
//! RO:INTERACTS — limits, tcp::listener/dialer, tls::{server,client}.
//! RO:INVARIANTS — immutable at runtime; values bounded; amnesia-safe.
//! RO:CONFIG — From env or files (upstream); this struct is runtime snapshot.

use serde::{Deserialize, Serialize};
use std::net::SocketAddr;
use std::time::Duration;

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct TransportConfig {
    /// Bind address for the listener (e.g., "127.0.0.1:9400").
    pub addr: SocketAddr,
    /// Human-readable transport name (for metrics labels).
    pub name: &'static str,
    /// Maximum concurrent connections allowed.
    pub max_conns: usize,
    /// Read timeout per I/O op.
    pub read_timeout: Duration,
    /// Write timeout per I/O op.
    pub write_timeout: Duration,
    /// Idle timeout (no traffic).
    pub idle_timeout: Duration,
}

impl Default for TransportConfig {
    fn default() -> Self {
        Self {
            addr: "127.0.0.1:0".parse().unwrap(),
            name: "tcp",
            max_conns: 1024,
            read_timeout: Duration::from_secs(5),
            write_timeout: Duration::from_secs(5),
            idle_timeout: Duration::from_secs(15),
        }
    }
}

```

### crates/ron-transport/src/conn/backpressure.rs
<a id="crates-ron-transport-src-conn-backpressure-rs"></a>

```rust
//! RO:WHAT — Simple per-conn inflight limiter (MVP).
use crate::limits::MAX_INFLIGHT_FRAMES;
use std::sync::atomic::{AtomicUsize, Ordering};

#[derive(Default)]
pub struct Inflight {
    n: AtomicUsize,
}
impl Inflight {
    pub fn new() -> Self {
        Self {
            n: AtomicUsize::new(0),
        }
    }
    pub fn try_inc(&self) -> bool {
        let cur = self.n.load(Ordering::Relaxed);
        if cur >= MAX_INFLIGHT_FRAMES {
            return false;
        }
        self.n.fetch_add(1, Ordering::Relaxed);
        true
    }
    pub fn dec(&self) {
        self.n.fetch_sub(1, Ordering::Relaxed);
    }
}

```

### crates/ron-transport/src/conn/mod.rs
<a id="crates-ron-transport-src-conn-mod-rs"></a>

```rust
//! RO:WHAT — Connection primitives (backpressure, reader, writer, rate limits).
//! RO:INVARIANTS — single-writer discipline; bounded inflight.

pub mod backpressure;
pub mod rate_limit;
pub mod reader;
pub mod writer;

```

### crates/ron-transport/src/conn/rate_limit.rs
<a id="crates-ron-transport-src-conn-ratelimit-rs"></a>

```rust
//! RO:WHAT — Placeholder for per-conn rate limiting (tokens).
#[derive(Clone, Default)]
pub struct RateLimit;
impl RateLimit {
    pub fn allow(&self, _bytes: usize) -> bool {
        true
    }
}

```

### crates/ron-transport/src/conn/reader.rs
<a id="crates-ron-transport-src-conn-reader-rs"></a>

```rust
//! RO:WHAT — Per-connection reader task (frame-capped, timed).
//! RO:INVARIANTS — cap before alloc; owned bytes; cancel-safe; idle/read timeouts.
//! RO:DESIGN — Generic over any AsyncRead, so it supports TcpStream and TlsStream.

use bytes::BytesMut;
use tokio::io::{AsyncRead, AsyncReadExt};
use tokio::time::{timeout, Duration, Instant};

use crate::limits::MAX_FRAME_BYTES;

#[derive(Debug, Default, Clone)]
pub struct ReaderStats {
    pub bytes_in: u64,
}

pub async fn run<R>(
    mut rd: R,
    read_timeout: Duration,
    idle_timeout: Duration,
) -> std::io::Result<ReaderStats>
where
    R: AsyncRead + Unpin,
{
    let mut buf = BytesMut::with_capacity(8 * 1024);
    let mut stats = ReaderStats::default();
    let mut last = Instant::now();

    loop {
        // Per-op read timeout.
        let n = match timeout(read_timeout, rd.read_buf(&mut buf)).await {
            Ok(Ok(0)) => return Ok(stats), // peer closed
            Ok(Ok(n)) => n,
            Ok(Err(e)) => return Err(e),
            Err(_elapsed) => {
                // If we've been entirely idle longer than idle_timeout, close.
                if last.elapsed() > idle_timeout {
                    return Ok(stats);
                }
                continue; // allow another attempt until idle threshold trips
            }
        };

        last = Instant::now();
        stats.bytes_in += n as u64;

        if buf.len() > MAX_FRAME_BYTES {
            return Err(std::io::Error::new(
                std::io::ErrorKind::InvalidData,
                "frame too large",
            ));
        }

        // MVP: drain; upper layers will parse OAP frames.
        if !buf.is_empty() {
            buf.clear();
        }
    }
}

```

### crates/ron-transport/src/conn/writer.rs
<a id="crates-ron-transport-src-conn-writer-rs"></a>

```rust
//! RO:WHAT — Per-connection single-writer task with backpressure.
//! RO:WHY  — Enforce single-writer discipline; count bytes_out; await I/O for backpressure.
//! RO:DESIGN — Generic over any AsyncWrite so it works for TcpStream and TlsStream.

use bytes::Bytes;
use tokio::{
    io::AsyncWrite,
    io::AsyncWriteExt,
    sync::mpsc::{self, error::SendError, Sender},
};

/// Handle to enqueue bytes for the connection's writer task.
#[derive(Clone)]
pub struct WriterHandle {
    tx: Sender<Bytes>,
}

impl WriterHandle {
    pub async fn send(&self, b: Bytes) -> Result<(), SendError<Bytes>> {
        self.tx.send(b).await
    }
}

/// Spawn a writer task for any AsyncWrite (TcpStream, TlsStream, ...).
/// Returns a handle for sending bytes and the writer task JoinHandle.
///
/// The writer task:
/// - writes each chunk fully (`write_all`)
/// - flushes periodically (on every message in MVP)
/// - increments `bytes_out` metrics
/// - exits cleanly when channel closes
pub fn spawn_writer<W>(
    mut w: W,
    name: &'static str,
    metrics: crate::metrics::TransportMetrics,
) -> (WriterHandle, tokio::task::JoinHandle<()>)
where
    W: AsyncWrite + Unpin + Send + 'static,
{
    // Bounded queue prevents unbounded memory under slow receivers.
    let (tx, mut rx) = mpsc::channel::<Bytes>(64);
    let jh = tokio::spawn(async move {
        while let Some(chunk) = rx.recv().await {
            if chunk.is_empty() {
                continue;
            }
            if let Err(e) = w.write_all(&chunk).await {
                tracing::debug!(error=%e, "writer: write_all failed");
                break;
            }
            // Count bytes_out
            metrics
                .bytes_out
                .with_label_values(&[name])
                .inc_by(chunk.len() as u64);

            // Flush to minimize tail latency (can batch/tune later).
            if let Err(e) = w.flush().await {
                tracing::debug!(error=%e, "writer: flush failed");
                break;
            }
        }

        // Attempt graceful shutdown for protocols that support it (e.g., TLS close_notify).
        let _ = w.shutdown().await;
    });

    (WriterHandle { tx }, jh)
}

```

### crates/ron-transport/src/error.rs
<a id="crates-ron-transport-src-error-rs"></a>

```rust
//! RO:WHAT — Error types for ron-transport.
//! RO:WHY  — Stable taxonomy for callers (deterministic).
//! RO:INTERACTS — reason::RejectReason.

use thiserror::Error;

#[derive(Debug, Error)]
pub enum TransportError {
    #[error("bind error: {0}")]
    Bind(std::io::Error),
    #[error("accept loop failed: {0}")]
    Accept(std::io::Error),
    #[error("io error: {0}")]
    Io(#[from] std::io::Error),
    #[error("limit exceeded: {0}")]
    Limit(&'static str),
    #[error("timeout")]
    Timeout,
    #[error("tls error")]
    Tls,
    #[error("closed")]
    Closed,
}

```

### crates/ron-transport/src/lib.rs
<a id="crates-ron-transport-src-lib-rs"></a>

```rust
//! RO:WHAT — Public entry for ron-transport: config/types and spawn helpers.
//! RO:WHY  — Pillar 10 transport; Concerns: SEC/RES/PERF.
//! RO:INTERACTS — tcp::{listener,dialer}, tls::{server,client}, limits, metrics; kernel Bus/Health.
//! RO:INVARIANTS — single writer per conn; no locks across .await; OAP max_frame=1MiB; chunk≈64KiB.

#![forbid(unsafe_code)]

#[cfg(feature = "arti")]
pub mod arti;
pub mod config;
pub mod conn;
pub mod error;
pub mod limits;
pub mod metrics;
#[cfg(feature = "quic")]
pub mod quic;
pub mod readiness;
pub mod reason;
pub mod tcp;
#[cfg(feature = "tls")]
pub mod tls;
pub mod types;
pub mod util;

// Always-present TLS type alias wrapper (feature-safe).
mod tls_types;
pub use tls_types::TlsServerConfig;

use crate::config::TransportConfig;
use crate::metrics::TransportMetrics;
use crate::readiness::ReadyGate;
use crate::types::TransportEvent;
use crate::util::cancel::Cancel;
use ron_kernel::{Bus, HealthState};
use std::net::SocketAddr;
use std::sync::Arc;
use tokio::task::JoinHandle;

/// Public handle for a running transport listener.
pub struct TransportHandle {
    /// The accept-loop task.
    pub task: JoinHandle<()>,
    /// The bound socket address.
    pub addr: SocketAddr,
    /// Cancellation token — request graceful shutdown.
    pub cancel: Cancel,
}

/// Spawn a TCP (optionally TLS) listener and per-connection tasks, returning a shutdown handle.
///
/// Backward-compatible, high-level entry.
pub async fn spawn_transport_with_cancel(
    cfg: TransportConfig,
    metrics: TransportMetrics,
    health: Arc<HealthState>,
    _bus: Bus<TransportEvent>, // reserved; will publish Connected/Disconnected when Bus API is confirmed
    tls: Option<Arc<TlsServerConfig>>,
) -> anyhow::Result<TransportHandle> {
    let gate = ReadyGate::new();
    let cancel = Cancel::new();
    let (task, addr) = tcp::listener::spawn_listener_with_cancel(
        cfg,
        metrics,
        health,
        gate.clone(),
        tls,
        cancel.clone(),
    )
    .await?;
    gate.set_listeners_bound(true);
    Ok(TransportHandle { task, addr, cancel })
}

/// Legacy wrapper that preserves the original return type.
/// Use `spawn_transport_with_cancel` if you want a shutdown handle.
pub async fn spawn_transport(
    cfg: TransportConfig,
    metrics: TransportMetrics,
    health: Arc<HealthState>,
    bus: Bus<TransportEvent>,
    tls: Option<Arc<TlsServerConfig>>,
) -> anyhow::Result<(JoinHandle<()>, SocketAddr)> {
    let handle = spawn_transport_with_cancel(cfg, metrics, health, bus, tls).await?;
    Ok((handle.task, handle.addr))
}

```

### crates/ron-transport/src/limits.rs
<a id="crates-ron-transport-src-limits-rs"></a>

```rust
//! RO:WHAT — Hard transport limits aligned to OAP/1 & Hardening v2.
//! RO:WHY  — Prevent DoS/compression bombs; deterministic errors.
//! RO:INTERACTS — conn::{reader,writer}, reason::RejectReason.

/// OAP/1 protocol frame max (bytes).
pub const MAX_FRAME_BYTES: usize = 1 * 1024 * 1024; // 1 MiB

/// Typical streaming chunk size (~storage path guidance).
pub const STREAM_CHUNK_BYTES: usize = 64 * 1024; // 64 KiB

/// Maximum decompressed size multiplier (defense-in-depth).
pub const MAX_DECOMP_RATIO: u32 = 10;

/// Inflight per-connection frame bound (defensive default).
pub const MAX_INFLIGHT_FRAMES: usize = 64;

```

### crates/ron-transport/src/metrics.rs
<a id="crates-ron-transport-src-metrics-rs"></a>

```rust
//! RO:WHAT — Prometheus counters/histograms for transport.
//! RO:WHY  — Golden metrics surface; avoid duplicate registers.

use prometheus::{HistogramOpts, HistogramVec, IntCounterVec, Opts, Registry};

#[derive(Clone)]
pub struct TransportMetrics {
    pub registry: Registry,
    pub connections: IntCounterVec,
    pub bytes_in: IntCounterVec,
    pub bytes_out: IntCounterVec,
    pub rejected_total: IntCounterVec,
    pub latency_seconds: HistogramVec,
}

impl TransportMetrics {
    pub fn new(namespace: &str) -> Self {
        let registry = Registry::new();
        let connections = IntCounterVec::new(
            Opts::new("transport_connections_total", "Accepted connections").namespace(namespace),
            &["name"],
        )
        .unwrap();
        let bytes_in = IntCounterVec::new(
            Opts::new("transport_bytes_in_total", "Bytes received").namespace(namespace),
            &["name"],
        )
        .unwrap();
        let bytes_out = IntCounterVec::new(
            Opts::new("transport_bytes_out_total", "Bytes sent").namespace(namespace),
            &["name"],
        )
        .unwrap();
        let rejected_total = IntCounterVec::new(
            Opts::new("transport_rejected_total", "Rejected connections/frames")
                .namespace(namespace),
            &["name", "reason"],
        )
        .unwrap();
        let latency_seconds = HistogramVec::new(
            HistogramOpts::new("transport_latency_seconds", "End-to-end per-conn lifetime")
                .namespace(namespace),
            &["name"],
        )
        .unwrap();

        registry.register(Box::new(connections.clone())).ok();
        registry.register(Box::new(bytes_in.clone())).ok();
        registry.register(Box::new(bytes_out.clone())).ok();
        registry.register(Box::new(rejected_total.clone())).ok();
        registry.register(Box::new(latency_seconds.clone())).ok();

        Self {
            registry,
            connections,
            bytes_in,
            bytes_out,
            rejected_total,
            latency_seconds,
        }
    }
}

```

### crates/ron-transport/src/quic/client.rs
<a id="crates-ron-transport-src-quic-client-rs"></a>

```rust
//! QUIC client (placeholder).
pub struct QuicClient;

```

### crates/ron-transport/src/quic/mod.rs
<a id="crates-ron-transport-src-quic-mod-rs"></a>

```rust
pub mod client;
pub mod server;

```

### crates/ron-transport/src/quic/server.rs
<a id="crates-ron-transport-src-quic-server-rs"></a>

```rust
//! QUIC server (placeholder).
pub struct QuicServer;

```

### crates/ron-transport/src/readiness.rs
<a id="crates-ron-transport-src-readiness-rs"></a>

```rust
//! RO:WHAT — Minimal readiness gate for listeners.
//! RO:WHY  — Truthful /readyz for services consuming transport.

use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;

#[derive(Clone)]
pub struct ReadyGate {
    listeners_bound: Arc<AtomicBool>,
}

impl ReadyGate {
    pub fn new() -> Self {
        Self {
            listeners_bound: Arc::new(AtomicBool::new(false)),
        }
    }
    pub fn set_listeners_bound(&self, v: bool) {
        self.listeners_bound.store(v, Ordering::SeqCst);
    }
    pub fn listeners_bound(&self) -> bool {
        self.listeners_bound.load(Ordering::SeqCst)
    }
}

```

### crates/ron-transport/src/reason.rs
<a id="crates-ron-transport-src-reason-rs"></a>

```rust
//! RO:WHAT — Canonical reject reasons (metrics label-safe).
//! RO:WHY  — Consistent observability & tests.

#[derive(Debug, Clone, Copy)]
pub enum RejectReason {
    OverCapacity,
    BadFrame,
    TooLarge,
    Timeout,
    Io,
    Tls,
}

impl RejectReason {
    pub fn as_str(self) -> &'static str {
        match self {
            Self::OverCapacity => "over_capacity",
            Self::BadFrame => "bad_frame",
            Self::TooLarge => "too_large",
            Self::Timeout => "timeout",
            Self::Io => "io",
            Self::Tls => "tls",
        }
    }
}

```

### crates/ron-transport/src/tcp/dialer.rs
<a id="crates-ron-transport-src-tcp-dialer-rs"></a>

```rust
//! RO:WHAT — TCP dialer (MVP).
use std::net::SocketAddr;
use tokio::net::TcpStream;

pub async fn dial(addr: SocketAddr) -> std::io::Result<TcpStream> {
    TcpStream::connect(addr).await
}

```

### crates/ron-transport/src/tcp/listener.rs
<a id="crates-ron-transport-src-tcp-listener-rs"></a>

```rust
//! RO:WHAT — TCP accept loop with optional TLS, limits, metrics, cancel.
//! RO:INVARIANTS — readiness flips when bound; single writer; deadlines enforced.

use crate::config::TransportConfig;
use crate::conn::reader::{self, ReaderStats};
use crate::conn::writer;
use crate::metrics::TransportMetrics;
use crate::readiness::ReadyGate;
use crate::reason::RejectReason;
use crate::util::cancel::Cancel;
use crate::TlsServerConfig;

use std::net::SocketAddr;
use std::sync::Arc;
use tokio::net::{TcpListener, TcpStream};
use tokio::sync::{OwnedSemaphorePermit, Semaphore};
use tokio::task::JoinHandle;
use tokio::time::{sleep, Duration, Instant};

/// Back-compat API (no shutdown handle). Internally creates a cancel token and drops it.
pub async fn spawn_listener(
    cfg: TransportConfig,
    metrics: TransportMetrics,
    health: Arc<ron_kernel::HealthState>,
    gate: ReadyGate,
    tls: Option<Arc<TlsServerConfig>>,
) -> anyhow::Result<(JoinHandle<()>, SocketAddr)> {
    let cancel = Cancel::new();
    spawn_listener_with_cancel(cfg, metrics, health, gate, tls, cancel).await
}

/// New API that takes a `Cancel` token so callers can trigger graceful shutdown.
pub async fn spawn_listener_with_cancel(
    cfg: TransportConfig,
    metrics: TransportMetrics,
    _health: Arc<ron_kernel::HealthState>,
    _gate: ReadyGate,
    tls: Option<Arc<TlsServerConfig>>,
    cancel: Cancel,
) -> anyhow::Result<(JoinHandle<()>, SocketAddr)> {
    let listener = TcpListener::bind(cfg.addr)
        .await
        .map_err(crate::error::TransportError::Bind)?;
    let addr = listener.local_addr().unwrap();
    let permits = Arc::new(Semaphore::new(cfg.max_conns));

    let jh = tokio::spawn(async move {
        tracing::info!(%addr, name=%cfg.name, "ron-transport listener bound");
        loop {
            tokio::select! {
                _ = cancel.cancelled() => {
                    tracing::info!(%addr, "listener shutdown requested");
                    break;
                }
                res = listener.accept() => {
                    match res {
                        Ok((stream, peer)) => {
                            let cfgc = cfg.clone();
                            let m = metrics.clone();
                            let tls_cfg = tls.clone();

                            // Connection limit: clone Arc before try_acquire_owned (it consumes its Arc).
                            match permits.clone().try_acquire_owned() {
                                Ok(permit) => {
                                    m.connections.with_label_values(&[cfg.name]).inc();
                                    tokio::spawn(handle_conn(stream, peer, cfgc, m, permit, tls_cfg));
                                }
                                Err(_) => {
                                    m.rejected_total
                                        .with_label_values(&[cfg.name, RejectReason::OverCapacity.as_str()])
                                        .inc();
                                    drop(stream);
                                }
                            }
                        }
                        Err(e) => {
                            metrics
                                .rejected_total
                                .with_label_values(&[cfg.name, RejectReason::Io.as_str()])
                                .inc();
                            tracing::warn!(error=%e, "accept failed; backing off");
                            sleep(Duration::from_millis(100)).await;
                        }
                    }
                }
            }
        }
        tracing::info!(%addr, "listener exited");
    });

    Ok((jh, addr))
}

async fn handle_conn(
    stream: TcpStream,
    peer: SocketAddr,
    cfg: TransportConfig,
    metrics: TransportMetrics,
    _permit: OwnedSemaphorePermit, // holds a slot until this task ends
    tls: Option<Arc<TlsServerConfig>>,
) {
    tracing::debug!(%peer, "accepted");
    let started = Instant::now();

    let result = match maybe_tls(stream, tls).await {
        Ok(IoUpgraded::Plain(s)) => run_plain(s, &cfg, &metrics).await,
        #[cfg(feature = "tls")]
        Ok(IoUpgraded::Tls(s)) => run_tls(s, &cfg, &metrics).await,
        Err(e) => Err(e),
    };
    let elapsed = started.elapsed().as_secs_f64();

    match result {
        Ok(stats) => {
            metrics
                .bytes_in
                .with_label_values(&[cfg.name])
                .inc_by(stats.bytes_in as u64);
            metrics
                .latency_seconds
                .with_label_values(&[cfg.name])
                .observe(elapsed);
            tracing::debug!(%peer, bytes_in=%stats.bytes_in, dur=%elapsed, "closed ok");
        }
        Err(e) => {
            metrics
                .rejected_total
                .with_label_values(&[cfg.name, RejectReason::Io.as_str()])
                .inc();
            tracing::debug!(%peer, error=%e, "closed with error");
        }
    }
}

async fn run_plain(
    stream: TcpStream,
    cfg: &TransportConfig,
    metrics: &TransportMetrics,
) -> std::io::Result<ReaderStats> {
    use tokio::io::split;
    let (rd, wr) = split(stream);

    // Spawn writer (currently unused by upper layers; metrics ready).
    let (_wh, writer_task) = writer::spawn_writer(wr, cfg.name, metrics.clone());

    // Run reader until EOF/timeout/error.
    let stats = reader::run(rd, cfg.read_timeout, cfg.idle_timeout).await;

    // Drop handle, await the task to flush+shutdown (sends FIN).
    drop(_wh);
    let _ = writer_task.await;

    stats
}

#[cfg(feature = "tls")]
async fn run_tls(
    stream: tokio_rustls::server::TlsStream<TcpStream>,
    cfg: &TransportConfig,
    metrics: &TransportMetrics,
) -> std::io::Result<ReaderStats> {
    use tokio::io::split;
    let (rd, wr) = split(stream);

    // Spawn writer (TLS): will send close_notify during shutdown().
    let (_wh, writer_task) = writer::spawn_writer(wr, cfg.name, metrics.clone());

    // Reader loop (generic over AsyncRead).
    let stats = reader::run(rd, cfg.read_timeout, cfg.idle_timeout).await;

    // Drop handle and wait for close_notify.
    drop(_wh);
    let _ = writer_task.await;

    stats
}

/// Unified return type for maybe_tls()
enum IoUpgraded {
    Plain(TcpStream),
    #[cfg(feature = "tls")]
    Tls(tokio_rustls::server::TlsStream<TcpStream>),
}

// Feature-safe TLS accept wrapper: if TLS feature disabled or None provided, pass-through.
async fn maybe_tls(
    stream: TcpStream,
    tls: Option<Arc<TlsServerConfig>>,
) -> std::io::Result<IoUpgraded> {
    match tls {
        #[cfg(feature = "tls")]
        Some(cfg) => {
            use tokio_rustls::TlsAcceptor;
            let acceptor = TlsAcceptor::from(cfg);
            let tls_stream = acceptor.accept(stream).await?;
            Ok(IoUpgraded::Tls(tls_stream))
        }
        _ => Ok(IoUpgraded::Plain(stream)),
    }
}

```

### crates/ron-transport/src/tcp/mod.rs
<a id="crates-ron-transport-src-tcp-mod-rs"></a>

```rust
//! RO:WHAT — TCP transport modules (listener/dialer).
pub mod dialer;
pub mod listener;

```

### crates/ron-transport/src/tls/client.rs
<a id="crates-ron-transport-src-tls-client-rs"></a>

```rust
//! RO:WHAT — TLS dial wrapper (placeholder).
#![cfg(feature = "tls")]
pub struct TlsClientConfig; // placeholder

```

### crates/ron-transport/src/tls/mod.rs
<a id="crates-ron-transport-src-tls-mod-rs"></a>

```rust
//! RO:WHAT — TLS wrappers (server/client) behind rustls.
//! RO:INVARIANTS — ServerConfig type = tokio_rustls::rustls::ServerConfig.
pub mod client;
pub mod server;

```

### crates/ron-transport/src/tls/server.rs
<a id="crates-ron-transport-src-tls-server-rs"></a>

```rust
//! RO:WHAT — TLS accept wrapper (placeholder).
#![cfg(feature = "tls")]
use tokio_rustls::rustls::ServerConfig;

pub type TlsServerConfig = ServerConfig;
// Integration will wrap TcpStream with TlsAcceptor::from(Arc<ServerConfig>) later.

```

### crates/ron-transport/src/tls_types.rs
<a id="crates-ron-transport-src-tlstypes-rs"></a>

```rust
//! RO:WHAT — Feature-safe TLS ServerConfig alias.
//! This lets the rest of the crate reference `TlsServerConfig` regardless of
//! whether `feature = "tls"` is enabled.

#[cfg(feature = "tls")]
pub type TlsServerConfig = tokio_rustls::rustls::ServerConfig;

#[cfg(not(feature = "tls"))]
pub struct TlsServerConfig;

```

### crates/ron-transport/src/types.rs
<a id="crates-ron-transport-src-types-rs"></a>

```rust
//! RO:WHAT — Common types/aliases for transport.
//! RO:WHY  — Keep the public surface small & stable; define bus events.

use bytes::Bytes;
use std::net::SocketAddr;

/// Owned frame bytes on hot paths (upper layers decode OAP/1).
pub type FrameBytes = Bytes;

/// Event type emitted on the kernel bus for observability/supervision.
#[derive(Debug, Clone)]
pub enum TransportEvent {
    Connected {
        peer: SocketAddr,
        name: &'static str,
    },
    Disconnected {
        peer: SocketAddr,
        name: &'static str,
        reason: Option<String>,
    },
}

```

### crates/ron-transport/src/util/bytes.rs
<a id="crates-ron-transport-src-util-bytes-rs"></a>

```rust
//! RO:WHAT — Byte helpers (cap checks).
//! RO:INVARIANTS — enforce MAX_FRAME_BYTES before alloc.

use bytes::BytesMut;

pub fn reserve_capped(buf: &mut BytesMut, want: usize, cap: usize) -> Result<(), &'static str> {
    if want > cap {
        return Err("cap_exceeded");
    }
    buf.reserve(want);
    Ok(())
}

```

### crates/ron-transport/src/util/cancel.rs
<a id="crates-ron-transport-src-util-cancel-rs"></a>

```rust
//! RO:WHAT — Cancel tokens & helpers (async-drop friendly).
//! RO:WHY  — Crash-only supervision + graceful shutdown.

use tokio_util::sync::CancellationToken;

#[derive(Clone)]
pub struct Cancel {
    token: CancellationToken,
}
impl Cancel {
    pub fn new() -> Self {
        Self {
            token: CancellationToken::new(),
        }
    }
    pub fn child(&self) -> Self {
        Self {
            token: self.token.child_token(),
        }
    }
    pub fn cancel(&self) {
        self.token.cancel();
    }
    pub async fn cancelled(&self) {
        self.token.cancelled().await;
    }
}

```

### crates/ron-transport/src/util/mod.rs
<a id="crates-ron-transport-src-util-mod-rs"></a>

```rust
pub mod bytes;
pub mod cancel;
pub mod timeouts;

```

### crates/ron-transport/src/util/timeouts.rs
<a id="crates-ron-transport-src-util-timeouts-rs"></a>

```rust
//! RO:WHAT — Timeout helpers (read/write/idle).
use std::time::Duration;
use tokio::time::{timeout, Instant};

pub async fn with_timeout<F, T>(dur: Duration, f: F) -> Result<T, tokio::time::error::Elapsed>
where
    F: std::future::Future<Output = T>,
{
    timeout(dur, f).await
}

pub struct IdleGuard {
    last: Instant,
    idle: Duration,
}
impl IdleGuard {
    pub fn new(idle: Duration) -> Self {
        Self {
            last: Instant::now(),
            idle,
        }
    }
    pub fn bump(&mut self) {
        self.last = Instant::now();
    }
    pub fn expired(&self) -> bool {
        self.last.elapsed() > self.idle
    }
}

```

### crates/ron-transport/tests/amnesia/no_disk_touches.rs
<a id="crates-ron-transport-tests-amnesia-nodisktouches-rs"></a>

```rust
#[test]
fn no_disk_touches_placeholder() { assert!(true); }

```

### crates/ron-transport/tests/integration/arti_bootstrap_ready.rs
<a id="crates-ron-transport-tests-integration-artibootstrapready-rs"></a>

```rust
#[test]
fn arti_bootstrap_ready_placeholder() { assert!(true); }

```

### crates/ron-transport/tests/integration/idle_timeout.rs
<a id="crates-ron-transport-tests-integration-idletimeout-rs"></a>

```rust
use ron_kernel::{Bus, HealthState};
use ron_transport::{
    config::TransportConfig, metrics::TransportMetrics, spawn_transport, types::TransportEvent,
};
use std::{io::Write, net::TcpStream as StdTcp, sync::Arc, time::Duration};

#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
async fn idle_timeout_closes() -> anyhow::Result<()> {
    let mut cfg = TransportConfig::default();
    cfg.read_timeout = Duration::from_millis(50);
    cfg.idle_timeout = Duration::from_millis(100);
    cfg.name = "test";

    let metrics = TransportMetrics::new("ron");
    let health = Arc::new(HealthState::new());
    let bus: Bus<TransportEvent> = Bus::new();

    let (_jh, addr) = spawn_transport(cfg, metrics, health, bus, None).await?;

    // Connect and stay idle; server should close within ~idle_timeout.
    let mut s = StdTcp::connect(addr)?;
    tokio::time::sleep(Duration::from_millis(200)).await; // cross idle timeout

    // Poll for closure up to a small budget to avoid race with FIN propagation.
    let deadline = std::time::Instant::now() + Duration::from_millis(600);
    loop {
        match s.write(&[1, 2, 3]) {
            Ok(_) => {
                if std::time::Instant::now() >= deadline {
                    anyhow::bail!(
                        "expected write to fail after idle timeout (connection still open)"
                    );
                }
                // FIN may not have arrived yet; wait and retry.
                tokio::time::sleep(Duration::from_millis(50)).await;
            }
            Err(e) => {
                use std::io::ErrorKind::*;
                assert!(
                    matches!(
                        e.kind(),
                        BrokenPipe | ConnectionReset | NotConnected | UnexpectedEof
                    ),
                    "unexpected error kind: {e}"
                );
                break;
            }
        }
    }
    Ok(())
}

```

### crates/ron-transport/tests/integration/mod.rs
<a id="crates-ron-transport-tests-integration-mod-rs"></a>

```rust
mod idle_timeout;
mod over_capacity;
#[cfg(feature = "tls")]
mod tls_accept;

```

### crates/ron-transport/tests/integration/over_capacity.rs
<a id="crates-ron-transport-tests-integration-overcapacity-rs"></a>

```rust
use ron_kernel::{Bus, HealthState};
use ron_transport::{
    config::TransportConfig, metrics::TransportMetrics, spawn_transport, types::TransportEvent,
};
use std::{io::Write, net::TcpStream as StdTcp, sync::Arc, time::Duration};

#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
async fn over_capacity_second_conn_dropped() -> anyhow::Result<()> {
    let mut cfg = TransportConfig::default();
    cfg.max_conns = 1;
    cfg.read_timeout = Duration::from_millis(200);
    cfg.idle_timeout = Duration::from_millis(500);
    cfg.name = "test";

    let metrics = TransportMetrics::new("ron");
    let health = Arc::new(HealthState::new());
    let bus: Bus<TransportEvent> = Bus::new();

    let (_jh, addr) = spawn_transport(cfg, metrics, health, bus, None).await?;

    // First connection holds the single permit.
    let _first = StdTcp::connect(addr)?;

    // Second connection should be dropped immediately by policy.
    let mut second = StdTcp::connect(addr)?;
    match second.write(&[9, 9, 9]) {
        Ok(_) => {
            tokio::time::sleep(Duration::from_millis(100)).await;
            match second.write(&[9, 9, 9]) {
                Ok(_) => anyhow::bail!("expected second connection to be dropped"),
                Err(_) => Ok(()),
            }
        }
        Err(_) => Ok(()),
    }
}

```

### crates/ron-transport/tests/integration/quic_parity.rs
<a id="crates-ron-transport-tests-integration-quicparity-rs"></a>

```rust
#[test]
fn quic_parity_placeholder() { assert!(true); }

```

### crates/ron-transport/tests/integration/tls_accept.rs
<a id="crates-ron-transport-tests-integration-tlsaccept-rs"></a>

```rust
#![cfg(feature = "tls")]

use ron_kernel::{Bus, HealthState};
use ron_transport::{
    config::TransportConfig, metrics::TransportMetrics, spawn_transport, types::TransportEvent,
    TlsServerConfig,
};
use rustls_pemfile::{certs, pkcs8_private_keys, rsa_private_keys};
use std::{fs::File, io::BufReader, path::Path, sync::Arc};
use tokio::net::TcpStream;
use tokio_rustls::rustls::{
    pki_types::{CertificateDer, PrivatePkcs1KeyDer, PrivatePkcs8KeyDer, ServerName},
    ClientConfig, RootCertStore,
};
use tokio_rustls::TlsConnector;

#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
async fn tls_accepts_handshake() -> anyhow::Result<()> {
    let cert_path = "crates/ron-transport/scripts/local/certs/cert.pem";
    let key_path = "crates/ron-transport/scripts/local/certs/key.pem";
    if !(Path::new(cert_path).exists() && Path::new(key_path).exists()) {
        eprintln!("(skipping tls_accepts_handshake: local certs not found)");
        return Ok(());
    }

    let server_cfg = Arc::new(load_rustls_server(cert_path, key_path)?);

    let mut cfg = TransportConfig::default();
    cfg.name = "tls-test";
    let metrics = TransportMetrics::new("ron");
    let health = Arc::new(HealthState::new());
    let bus: Bus<TransportEvent> = Bus::new();

    let (_jh, addr) = spawn_transport(cfg, metrics, health, bus, Some(server_cfg)).await?;

    let mut roots = RootCertStore::empty();
    let cert_file = File::open(Path::new(cert_path))?;
    let mut cert_rd = BufReader::new(cert_file);
    let certs: Vec<CertificateDer<'static>> = certs(&mut cert_rd).collect::<Result<_, _>>()?;
    for c in certs.into_iter() {
        roots.add(c)?;
    }

    let client = ClientConfig::builder()
        .with_root_certificates(roots)
        .with_no_client_auth();
    let connector = TlsConnector::from(Arc::new(client));
    let tcp = TcpStream::connect(addr).await?;
    let _tls = connector
        .connect(ServerName::try_from("localhost")?, tcp)
        .await?;
    Ok(())
}

fn load_rustls_server(cert_path: &str, key_path: &str) -> anyhow::Result<TlsServerConfig> {
    use tokio_rustls::rustls::{
        pki_types::{CertificateDer, PrivateKeyDer},
        ServerConfig,
    };

    let cert_file = File::open(Path::new(cert_path))?;
    let mut cert_rd = BufReader::new(cert_file);
    let certs: Vec<CertificateDer<'static>> = certs(&mut cert_rd).collect::<Result<_, _>>()?;

    let key: PrivateKeyDer<'static> = {
        let key_file = File::open(Path::new(key_path))?;
        let mut key_rd = BufReader::new(key_file);
        let mut pkcs8: Vec<PrivateKeyDer<'static>> = pkcs8_private_keys(&mut key_rd)
            .map(|res: std::io::Result<PrivatePkcs8KeyDer<'static>>| res.map(Into::into))
            .collect::<Result<_, _>>()?;
        if let Some(k) = pkcs8.pop() {
            k
        } else {
            let key_file = File::open(Path::new(key_path))?;
            let mut key_rd = BufReader::new(key_file);
            let mut rsa: Vec<PrivateKeyDer<'static>> = rsa_private_keys(&mut key_rd)
                .map(|res: std::io::Result<PrivatePkcs1KeyDer<'static>>| res.map(Into::into))
                .collect::<Result<_, _>>()?;
            rsa.pop()
                .ok_or_else(|| anyhow::anyhow!("no private key found in {}", key_path))?
        }
    };

    let cfg = ServerConfig::builder()
        .with_no_client_auth()
        .with_single_cert(certs, key)?;
    Ok(cfg)
}

```

### crates/ron-transport/tests/integration/tls_handshake_limits.rs
<a id="crates-ron-transport-tests-integration-tlshandshakelimits-rs"></a>

```rust
#[test]
fn tls_handshake_limits_placeholder() { assert!(true); }

```

### crates/ron-transport/tests/intergration.rs
<a id="crates-ron-transport-tests-intergration-rs"></a>

```rust
mod integration;

```

### crates/ron-transport/tests/loom/single_writer.rs
<a id="crates-ron-transport-tests-loom-singlewriter-rs"></a>

```rust
#[test]
fn single_writer_placeholder() { assert!(true); }

```

### crates/ron-transport/tests/soak/loopback_1MiB.rs
<a id="crates-ron-transport-tests-soak-loopback1MiB-rs"></a>

```rust
#[test]
fn soak_loopback_placeholder() { assert!(true); }

```

### crates/ron-transport/tests/vectors/comp_bounds.json
<a id="crates-ron-transport-tests-vectors-compbounds-json"></a>

```json
{ "max_frame_bytes": 1048576, "inflate_cap": "8x", "notes": "placeholder" }

```

### crates/ron-transport/tests/vectors/oap_hello.json
<a id="crates-ron-transport-tests-vectors-oaphello-json"></a>

```json
{ "name": "oap_hello", "version": 1, "notes": "placeholder vector" }

```

### crates/ron-transport/tests/vectors/pq_hybrid_hello.json
<a id="crates-ron-transport-tests-vectors-pqhybridhello-json"></a>

```json
{ "kex": "hybrid_x25519_mlkem768", "sig": "ed25519", "notes": "placeholder" }

```

### crates/ron-transport/tests/vectors/tor_parity.json
<a id="crates-ron-transport-tests-vectors-torparity-json"></a>

```json
{ "backend": "arti", "parity": true, "notes": "placeholder" }

```



---



# ryker

_Source: crates/ryker/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:55:36Z -->
# Code Bundle — `ryker`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ryker/.clippy.toml](#crates-ryker--clippy-toml)
- [crates/ryker/Cargo.toml](#crates-ryker-Cargo-toml)
- [crates/ryker/benches/batch.rs](#crates-ryker-benches-batch-rs)
- [crates/ryker/benches/dequeue.rs](#crates-ryker-benches-dequeue-rs)
- [crates/ryker/benches/enqueue.rs](#crates-ryker-benches-enqueue-rs)
- [crates/ryker/criterion.toml](#crates-ryker-criterion-toml)
- [crates/ryker/examples/actor_loop.rs](#crates-ryker-examples-actorloop-rs)
- [crates/ryker/examples/config_dump.rs](#crates-ryker-examples-configdump-rs)
- [crates/ryker/fuzz/fuzz_targets/fuzz_mailbox_ops.rs](#crates-ryker-fuzz-fuzztargets-fuzzmailboxops-rs)
- [crates/ryker/fuzz/fuzz_targets/fuzz_parse_config_json.rs](#crates-ryker-fuzz-fuzztargets-fuzzparseconfigjson-rs)
- [crates/ryker/fuzz/fuzz_targets/fuzz_parse_config_toml.rs](#crates-ryker-fuzz-fuzztargets-fuzzparseconfigtoml-rs)
- [crates/ryker/rust-toolchain.toml](#crates-ryker-rust-toolchain-toml)
- [crates/ryker/ryker.example.toml](#crates-ryker-ryker-example-toml)
- [crates/ryker/scripts/public_api_snapshot.sh](#crates-ryker-scripts-publicapisnapshot-sh)
- [crates/ryker/scripts/render-mermaid.sh](#crates-ryker-scripts-render-mermaid-sh)
- [crates/ryker/src/config/loader.rs](#crates-ryker-src-config-loader-rs)
- [crates/ryker/src/config/mod.rs](#crates-ryker-src-config-mod-rs)
- [crates/ryker/src/config/model.rs](#crates-ryker-src-config-model-rs)
- [crates/ryker/src/config/reload.rs](#crates-ryker-src-config-reload-rs)
- [crates/ryker/src/errors.rs](#crates-ryker-src-errors-rs)
- [crates/ryker/src/lib.rs](#crates-ryker-src-lib-rs)
- [crates/ryker/src/mailbox/builder.rs](#crates-ryker-src-mailbox-builder-rs)
- [crates/ryker/src/mailbox/error.rs](#crates-ryker-src-mailbox-error-rs)
- [crates/ryker/src/mailbox/mod.rs](#crates-ryker-src-mailbox-mod-rs)
- [crates/ryker/src/mailbox/observer.rs](#crates-ryker-src-mailbox-observer-rs)
- [crates/ryker/src/mailbox/queue.rs](#crates-ryker-src-mailbox-queue-rs)
- [crates/ryker/src/observe/metrics.rs](#crates-ryker-src-observe-metrics-rs)
- [crates/ryker/src/observe/mod.rs](#crates-ryker-src-observe-mod-rs)
- [crates/ryker/src/observe/trace.rs](#crates-ryker-src-observe-trace-rs)
- [crates/ryker/src/prelude.rs](#crates-ryker-src-prelude-rs)
- [crates/ryker/src/runtime/mod.rs](#crates-ryker-src-runtime-mod-rs)
- [crates/ryker/src/runtime/runtime.rs](#crates-ryker-src-runtime-runtime-rs)
- [crates/ryker/src/supervisor/backoff.rs](#crates-ryker-src-supervisor-backoff-rs)
- [crates/ryker/src/supervisor/mod.rs](#crates-ryker-src-supervisor-mod-rs)
- [crates/ryker/src/supervisor/supervisor.rs](#crates-ryker-src-supervisor-supervisor-rs)
- [crates/ryker/tests/feature_matrix.rs](#crates-ryker-tests-featurematrix-rs)
- [crates/ryker/tests/integration/amnesia.rs](#crates-ryker-tests-integration-amnesia-rs)
- [crates/ryker/tests/integration/backpressure.rs](#crates-ryker-tests-integration-backpressure-rs)
- [crates/ryker/tests/integration/config_env_snapshot.rs](#crates-ryker-tests-integration-configenvsnapshot-rs)
- [crates/ryker/tests/integration/deadline.rs](#crates-ryker-tests-integration-deadline-rs)
- [crates/ryker/tests/integration/metrics_contract.rs](#crates-ryker-tests-integration-metricscontract-rs)
- [crates/ryker/tests/integration/reload_hot_cold.rs](#crates-ryker-tests-integration-reloadhotcold-rs)
- [crates/ryker/tests/integration/supervisor_backoff.rs](#crates-ryker-tests-integration-supervisorbackoff-rs)
- [crates/ryker/tests/loom/loom_backpressure.rs](#crates-ryker-tests-loom-loombackpressure-rs)
- [crates/ryker/tests/loom/loom_mailbox_basic.rs](#crates-ryker-tests-loom-loommailboxbasic-rs)
- [crates/ryker/tests/loom/loom_shutdown.rs](#crates-ryker-tests-loom-loomshutdown-rs)
- [crates/ryker/tests/vectors/snapshots/config_snapshot.json](#crates-ryker-tests-vectors-snapshots-configsnapshot-json)
- [crates/ryker/tests/vectors/snapshots/config_snapshot.toml](#crates-ryker-tests-vectors-snapshots-configsnapshot-toml)

### crates/ryker/.clippy.toml
<a id="crates-ryker--clippy-toml"></a>

```toml
# Minimal, stable-friendly Clippy config for ryker
msrv = "1.80"

```

### crates/ryker/Cargo.toml
<a id="crates-ryker-Cargo-toml"></a>

```toml
[package]
name = "ryker"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
description = "Embedded actor & bounded mailbox runtime for RustyOnions"
readme = "README.MD"
rust-version = "1.80"

[features]
default = ["metrics", "tracing", "amnesia"]
metrics = []
tracing = ["dep:tracing"]
amnesia = []
loom = []
dev-cli = []
# Enables a non-intrusive "tap" for benches to clone a receiver; off in prod.
bench_support = []

[dependencies]
tokio = { version = "1.47", features = ["macros", "rt", "time", "sync"] }
parking_lot = "0.12"
thiserror = "1.0"
serde = { version = "1.0", features = ["derive"] }
serde_with = "3.9"
humantime = "2.1"
humantime-serde = "1.1"
once_cell = "1.19"
rand = "0.9"
anyhow = "1.0"
serde_json = "1.0"

# Optional tracing; enabled via feature above
tracing = { version = "0.1", optional = true, default-features = false, features = ["std"] }

[dev-dependencies]
criterion = { version = "0.5", features = ["html_reports", "async_tokio"] }
serde_json = "1.0"
anyhow = "1.0"

[[bench]]
name = "enqueue"
harness = false

[[bench]]
name = "dequeue"
harness = false

[[bench]]
name = "batch"
harness = false

[lib]
doctest = false
```

### crates/ryker/benches/batch.rs
<a id="crates-ryker-benches-batch-rs"></a>

```rust
//! RO:WHAT — Criterion bench: batched dequeue throughput.
//! RO:INVAR — Prefill with send(); drop TX; drain RX in batches until N or Closed.

use criterion::{criterion_group, criterion_main, Criterion};
use ryker::prelude::*;
use std::time::Duration;
use tokio::runtime::{Builder as TokioBuilder, Runtime as TokioRt};

const CAP: usize = 2048;
const N_MSGS: usize = CAP;
const BATCH: usize = 64;

fn tokio_rt() -> TokioRt {
    TokioBuilder::new_current_thread()
        .enable_time()
        .build()
        .expect("tokio rt")
}

fn bench_batch(c: &mut Criterion) {
    let rt = tokio_rt();
    c.bench_function("ryker_batch_pull", |b| {
        b.to_async(&rt).iter(|| async {
            let cfg = ryker::config::from_env_validated().unwrap();
            let ry = Runtime::new(cfg);

            let mb = ry
                .mailbox::<u64>("bench.batch")
                .capacity(CAP)
                .deadline(Duration::from_millis(10))
                .build();

            let (tx, mut rx) = mb.split();

            for i in 0..N_MSGS as u64 {
                tx.send(i).await.expect("prefill");
            }
            drop(tx);

            let mut n = 0usize;
            while n < N_MSGS {
                let mut got = 0usize;
                while got < BATCH {
                    match rx.pull().await {
                        Ok(_m) => {
                            got += 1;
                            n += 1;
                            if n >= N_MSGS {
                                break;
                            }
                        }
                        Err(ryker::mailbox::MailboxError::Closed) => break,
                        Err(ryker::mailbox::MailboxError::Timeout) => break,
                        Err(e) => panic!("unexpected: {e}"),
                    }
                }
                tokio::task::yield_now().await;
            }
        });
    });
}

criterion_group!(benches, bench_batch);
criterion_main!(benches);

```

### crates/ryker/benches/dequeue.rs
<a id="crates-ryker-benches-dequeue-rs"></a>

```rust
//! RO:WHAT — Criterion bench: dequeue throughput.
//! RO:INVAR — Prefill with send(); drop TX; drain RX until N or Closed.

use criterion::{criterion_group, criterion_main, Criterion};
use ryker::prelude::*;
use std::time::Duration;
use tokio::runtime::{Builder as TokioBuilder, Runtime as TokioRt};

const CAP: usize = 1024;
const N_MSGS: usize = CAP;

fn tokio_rt() -> TokioRt {
    TokioBuilder::new_current_thread()
        .enable_time()
        .build()
        .expect("tokio rt")
}

fn bench_dequeue(c: &mut Criterion) {
    let rt = tokio_rt();
    c.bench_function("ryker_dequeue_pull", |b| {
        b.to_async(&rt).iter(|| async {
            let cfg = ryker::config::from_env_validated().unwrap();
            let ry = Runtime::new(cfg);

            let mb = ry
                .mailbox::<u64>("bench.dequeue")
                .capacity(CAP)
                .deadline(Duration::from_millis(10))
                .build();

            let (tx, mut rx) = mb.split();

            for i in 0..N_MSGS as u64 {
                tx.send(i).await.expect("prefill");
            }
            drop(tx); // important: close the channel

            let mut n = 0usize;
            loop {
                match rx.pull().await {
                    Ok(_m) => {
                        n += 1;
                        if n >= N_MSGS {
                            break;
                        }
                    }
                    Err(ryker::mailbox::MailboxError::Closed) => break,
                    Err(ryker::mailbox::MailboxError::Timeout) => break,
                    Err(e) => panic!("unexpected: {e}"),
                }
                tokio::task::yield_now().await;
            }
        });
    });
}

criterion_group!(benches, bench_dequeue);
criterion_main!(benches);

```

### crates/ryker/benches/enqueue.rs
<a id="crates-ryker-benches-enqueue-rs"></a>

```rust
//! RO:WHAT — Criterion bench: enqueue throughput (producer side).
//! RO:INVAR — try_send burst, ignore Busy (we measure producer cost, not success rate).

use criterion::{criterion_group, criterion_main, Criterion};
use ryker::prelude::*;
use std::time::Duration;
use tokio::runtime::{Builder as TokioBuilder, Runtime as TokioRt};

const CAP: usize = 2048;
const N_TRIES: usize = CAP * 2; // intentionally over capacity

fn tokio_rt() -> TokioRt {
    TokioBuilder::new_current_thread()
        .enable_time()
        .build()
        .expect("tokio rt")
}

fn bench_enqueue(c: &mut Criterion) {
    let rt = tokio_rt();
    c.bench_function("ryker_enqueue_try_send", |b| {
        b.to_async(&rt).iter(|| async {
            let cfg = ryker::config::from_env_validated().unwrap();
            let ry = Runtime::new(cfg);

            let mb = ry
                .mailbox::<u64>("bench.enqueue")
                .capacity(CAP)
                .deadline(Duration::from_millis(5))
                .build();

            let (tx, _rx) = mb.split();

            for i in 0..N_TRIES as u64 {
                let _ = tx.try_send(i);
            }
        });
    });
}

criterion_group!(benches, bench_enqueue);
criterion_main!(benches);

```

### crates/ryker/criterion.toml
<a id="crates-ryker-criterion-toml"></a>

```toml
warm_up_time = "0.5 s"
measurement_time = "2.0 s"
sample_size = 30
confidence_level = 0.90
noise_threshold = 0.02
nresamples = 10_000
plotting_backend = "disabled"

```

### crates/ryker/examples/actor_loop.rs
<a id="crates-ryker-examples-actorloop-rs"></a>

```rust
// RO:WHAT  — Minimal actor loop using Runtime + Mailbox + Supervisor.
// RO:HOW   — cargo run -p ryker --example actor_loop

use ryker::prelude::*;
use std::time::Duration;

#[derive(Debug, Clone)]
struct Msg(&'static str);

#[tokio::main(flavor = "current_thread")]
async fn main() -> anyhow::Result<()> {
    let cfg = ryker::config::from_env_validated()?;
    let rt = Runtime::new(cfg);

    // Build a small mailbox to demo Busy behavior.
    let mb: ryker::mailbox::Mailbox<Msg> = rt
        .mailbox("demo-actor")
        .capacity(4)
        .deadline(Duration::from_millis(250))
        .build();

    // Enqueue a few messages; you should see Busy when capacity is exceeded.
    for i in 0..8 {
        match mb.try_send(Msg("hello")) {
            Ok(_) => println!("[main] enqueued i={i}"),
            Err(ryker::mailbox::MailboxError::Busy) => {
                println!("[main] queue Busy at i={i} (reject-new)")
            }
            Err(e) => println!("[main] enqueue error at i={i}: {e}"),
        }
    }

    // Hand-off ownership of the mailbox to the supervised actor exactly once.
    // The FnMut factory can be called multiple times by Supervisor after failures;
    // we use Option.take() so only the first call consumes the mailbox.
    let mut rx_opt = Some(mb);
    let sup = Supervisor::new(rt.config());
    let _handle = sup.spawn(move || {
        // Take the mailbox on the first invocation; None thereafter (no restart).
        let rx_taken = rx_opt.take();
        async move {
            if let Some(mut rx) = rx_taken {
                loop {
                    match rx.pull().await {
                        Ok(Msg(s)) => println!("[actor] handled: {s}"),
                        Err(ryker::mailbox::MailboxError::Timeout) => {
                            println!("[actor] idle timeout");
                        }
                        Err(ryker::mailbox::MailboxError::Closed) => break,
                        Err(e) => eprintln!("[actor] error: {e}"),
                    }
                }
            }
            Ok::<(), anyhow::Error>(())
        }
    });

    tokio::time::sleep(Duration::from_secs(1)).await;
    Ok(())
}

```

### crates/ryker/examples/config_dump.rs
<a id="crates-ryker-examples-configdump-rs"></a>

```rust
// RO:WHAT — Print the effective RykerConfig as JSON.
// RO:HOW  — cargo run -p ryker --example config_dump

use serde_json::json;

fn main() -> anyhow::Result<()> {
    let cfg = ryker::config::from_env_validated()?;
    let d = &cfg.defaults;
    let f = &cfg.fairness;
    let s = &cfg.supervisor;

    let out = json!({
        "defaults": {
            "mailbox_capacity": d.mailbox_capacity,
            "max_msg_bytes": d.max_msg_bytes,
            "deadline_ms": d.deadline.as_millis(),
        },
        "fairness": {
            "batch_messages": f.batch_messages,
            "yield_every_n_msgs": f.yield_every_n_msgs,
        },
        "supervisor": {
            "backoff_base_ms": s.backoff_base_ms,
            "backoff_cap_ms": s.backoff_cap_ms,
            "decorrelated_jitter": s.decorrelated_jitter,
        },
        "amnesia": cfg.amnesia,
        "observe": {
            "queue_depth_sampling": cfg.observe.queue_depth_sampling,
        }
    });

    println!("{}", serde_json::to_string_pretty(&out)?);
    Ok(())
}

```

### crates/ryker/fuzz/fuzz_targets/fuzz_mailbox_ops.rs
<a id="crates-ryker-fuzz-fuzztargets-fuzzmailboxops-rs"></a>

```rust
#![no_main]
// cargo-fuzz target (stub): randomized mailbox ops.

```

### crates/ryker/fuzz/fuzz_targets/fuzz_parse_config_json.rs
<a id="crates-ryker-fuzz-fuzztargets-fuzzparseconfigjson-rs"></a>

```rust
#![no_main]
// cargo-fuzz target (stub): parse JSON config.

```

### crates/ryker/fuzz/fuzz_targets/fuzz_parse_config_toml.rs
<a id="crates-ryker-fuzz-fuzztargets-fuzzparseconfigtoml-rs"></a>

```rust
#![no_main]
// cargo-fuzz target (stub): parse TOML config.

```

### crates/ryker/rust-toolchain.toml
<a id="crates-ryker-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["rustfmt", "clippy"]

```

### crates/ryker/ryker.example.toml
<a id="crates-ryker-ryker-example-toml"></a>

```toml
# Example config — validated via RykerConfig::from_env_validated()
[mailbox]
capacity = 256
max_msg_bytes = "64KiB"
default_deadline_ms = 1000

[fairness]
batch_messages = 32
yield_every_n = 64

[supervisor]
backoff_base_ms = 100
backoff_cap_ms  = 5000

[observe]
metrics = true
queue_depth_sampling = true

[amnesia]
enabled = false


```

### crates/ryker/scripts/public_api_snapshot.sh
<a id="crates-ryker-scripts-publicapisnapshot-sh"></a>

```bash
#!/usr/bin/env bash
# Takes a public API snapshot for the `ryker` crate and optionally diffs it.
# Requirements:
#   - cargo-public-api  (install: cargo install cargo-public-api)
# Usage:
#   scripts/public_api_snapshot.sh save <name>        # save snapshot to target/public-api/<name>.txt
#   scripts/public_api_snapshot.sh diff <old> <new>   # show diff between two saved snapshots
#   scripts/public_api_snapshot.sh now                # print current API (no file)
# Env:
#   CARGO_FEATURES="..."   # e.g. "--features bench_support"

set -euo pipefail

# Find workspace root by walking upward until Cargo.toml is found.
find_workspace_root() {
  local d="$1"
  for _ in {1..6}; do
    if [[ -f "$d/Cargo.toml" ]]; then
      echo "$d"
      return 0
    fi
    d="$(dirname "$d")"
  done
  return 1
}

here="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
start_dir="$here"
repo="$(find_workspace_root "$start_dir" || true)"
if [[ -z "${repo:-}" ]]; then
  echo "Could not find workspace Cargo.toml by walking up from: $start_dir"
  echo "Hint: run this script from within the workspace, or set REPO_ROOT env var."
  exit 1
fi
cd "$repo"

if ! command -v cargo-public-api >/dev/null 2>&1; then
  echo "cargo-public-api not found. install it first:"
  echo "cargo install cargo-public-api"
  exit 1
fi

outdir="target/public-api"
mkdir -p "$outdir"

features="${CARGO_FEATURES:-}"

case "${1:-}" in
  save)
    name="${2:-ryker-$(date +%Y%m%d-%H%M%S)}"
    out="$outdir/$name.txt"
    cargo public-api -p ryker $features --simplified \
      --omit blanket-impls --omit auto-trait-impls > "$out"
    echo "Saved: $out"
    ;;
  diff)
    old="$outdir/${2:?old snapshot name}.txt"
    new="$outdir/${3:?new snapshot name}.txt"
    if [[ ! -f "$old" || ! -f "$new" ]]; then
      echo "Missing files: $old or $new"
      exit 2
    fi
    diff -u "$old" "$new" || true
    ;;
  now)
    cargo public-api -p ryker $features --simplified \
      --omit blanket-impls --omit auto-trait-impls
    ;;
  *)
    echo "Usage:"
    echo "  $0 save <name>"
    echo "  $0 diff <old> <new>"
    echo "  $0 now"
    exit 64
    ;;
esac

```

### crates/ryker/scripts/render-mermaid.sh
<a id="crates-ryker-scripts-render-mermaid-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# Renders docs/*.mmd to SVG using mermaid-cli if available.
ROOT=${1:-"./crates"}
cd "./crates/ryker"
if ! command -v mmdc >/dev/null 2>&1; then
  echo "mmdc not found. Install: npm i -g @mermaid-js/mermaid-cli"
  exit 1
fi
for f in docs/*.mmd; do
  [ -e "$f" ] || continue
  out=${f%.mmd}.svg
  mmdc -i "$f" -o "$out"
  echo "rendered: $out"
done


```

### crates/ryker/src/config/loader.rs
<a id="crates-ryker-src-config-loader-rs"></a>

```rust
//! RO:WHAT — Builder + environment merge for `RykerConfig` (file optional).
//! RO:WHY  — Enforce builder > env > file > defaults; prod guards.
//! RO:INTERACTS — model (schema), reload (hooks), runtime creates snapshot.
//! RO:INVARIANTS — `RYKER_CONFIG_PATH` ignored in prod unless explicitly allowed.

use super::model::RykerConfig;
use crate::errors::{ConfigError, Result};
use once_cell::sync::Lazy;
use std::env;

static IS_PROD: Lazy<bool> = Lazy::new(|| {
    let app = env::var("APP_ENV").ok();
    let rust = env::var("RUST_ENV").ok();
    matches!(app.or(rust), Some(s) if s == "production")
});

#[derive(Default)]
pub struct RykerConfigBuilder {
    inner: RykerConfig,
}

impl RykerConfigBuilder {
    pub fn new() -> Self {
        Self {
            inner: RykerConfig::default(),
        }
    }
    pub fn build(mut self) -> Result<RykerConfig> {
        merge_env(&mut self.inner)?;
        self.inner.validate()?;
        Ok(self.inner)
    }
}

pub fn from_env_validated() -> Result<RykerConfig> {
    let mut cfg = RykerConfig::default();

    if let Ok(path) = env::var("RYKER_CONFIG_PATH") {
        if *IS_PROD && env::var("RYKER_ALLOW_CONFIG_PATH").as_deref() != Ok("1") {
            return Err(
                ConfigError::ProdGuard("RYKER_CONFIG_PATH rejected in production".into()).into(),
            );
        }
        tracing_log!("dev-cli path provided (host should load file): {}", path);
    }

    merge_env(&mut cfg)?;
    cfg.validate()?;
    Ok(cfg)
}

fn merge_env(cfg: &mut RykerConfig) -> Result<()> {
    let get = |k: &str| env::var(k).ok();

    if let Some(v) = get("RYKER_DEFAULT_MAILBOX_CAPACITY") {
        cfg.defaults.mailbox_capacity = v.parse().map_err(|_| {
            ConfigError::Invalid("RYKER_DEFAULT_MAILBOX_CAPACITY must be int".into())
        })?;
    }
    if let Some(v) = get("RYKER_DEFAULT_MAX_MSG_BYTES") {
        cfg.defaults.max_msg_bytes = parse_size(&v)?;
    }
    if let Some(v) = get("RYKER_DEFAULT_DEADLINE") {
        cfg.defaults.deadline = humantime::parse_duration(&v)
            .map_err(|_| ConfigError::Invalid("bad deadline".into()))?;
    }
    if let Some(v) = get("RYKER_BACKOFF_BASE_MS") {
        cfg.supervisor.backoff_base_ms = v
            .parse()
            .map_err(|_| ConfigError::Invalid("bad backoff_base_ms".into()))?;
    }
    if let Some(v) = get("RYKER_BACKOFF_CAP_MS") {
        cfg.supervisor.backoff_cap_ms = v
            .parse()
            .map_err(|_| ConfigError::Invalid("bad backoff_cap_ms".into()))?;
    }
    if let Some(v) = get("RYKER_BATCH_MESSAGES") {
        cfg.fairness.batch_messages = v
            .parse()
            .map_err(|_| ConfigError::Invalid("bad batch_messages".into()))?;
    }
    if let Some(v) = get("RYKER_YIELD_EVERY_N") {
        cfg.fairness.yield_every_n_msgs = v
            .parse()
            .map_err(|_| ConfigError::Invalid("bad yield_every_n".into()))?;
    }
    if let Some(v) = get("RYKER_ENABLE_METRICS") {
        cfg.observe.queue_depth_sampling = matches!(v.as_str(), "1" | "true" | "TRUE");
    }
    if let Some(v) = get("RYKER_AMNESIA") {
        cfg.amnesia = matches!(v.as_str(), "1" | "true" | "TRUE");
    }
    Ok(())
}

fn parse_size(s: &str) -> Result<usize> {
    let s = s.trim();
    if let Some(n) = s.strip_suffix("KiB") {
        let v: usize = n
            .trim()
            .parse()
            .map_err(|_| ConfigError::Invalid("size".into()))?;
        return Ok(v * 1024);
    }
    if let Some(n) = s.strip_suffix("MiB") {
        let v: usize = n
            .trim()
            .parse()
            .map_err(|_| ConfigError::Invalid("size".into()))?;
        return Ok(v * 1024 * 1024);
    }
    let v: usize = s.parse().map_err(|_| ConfigError::Invalid("size".into()))?;
    Ok(v)
}

// Tiny local macro to avoid requiring tracing at call site when feature disabled
#[inline]
fn tracing_log_(lvl: &str, msg: &str) {
    #[cfg(feature = "tracing")]
    match lvl {
        "info" => tracing::info!("{}", msg),
        _ => tracing::debug!("{}", msg),
    }
}

macro_rules! tracing_log {
    ($($tt:tt)*) => {
        #[allow(unused)]
        {
            let s = format!($($tt)*);
            super::loader::tracing_log_("debug", &s);
        }
    };
}
pub(crate) use tracing_log;

```

### crates/ryker/src/config/mod.rs
<a id="crates-ryker-src-config-mod-rs"></a>

```rust
//! RO:WHAT — Public entry for configuration types and loader.
//! RO:WHY  — Keep builder/env/file precedence & validation together.
//! RO:INTERACTS — model (schema), loader (env/file), reload (hooks).
//! RO:INVARIANTS — builder > env > file > defaults; deny invalid combos; amnesia honored.

mod loader;
mod model;
mod reload;

pub use loader::{from_env_validated, RykerConfigBuilder};
pub use model::{FairnessCfg, RykerConfig, SupervisionCfg};
pub use reload::{ReloadCounters, RykerReloadHook};

```

### crates/ryker/src/config/model.rs
<a id="crates-ryker-src-config-model-rs"></a>

```rust
//! RO:WHAT — Typed configuration schema for ryker.
//! RO:WHY  — Deterministic defaults + strict validation (docs-aligned).
//! RO:INTERACTS — loader merges sources; runtime/mailbox read snapshots.
//! RO:INVARIANTS — capacity>0; 0 < deadline ≤ 60s; max_msg_bytes ≤ 1MiB; yield_every_n ≥ batch.

use crate::errors::{ConfigError, Result};
use serde::{Deserialize, Serialize};
use std::time::Duration;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RykerConfig {
    pub defaults: Defaults,
    pub fairness: FairnessCfg,
    pub supervisor: SupervisionCfg,
    pub amnesia: bool,
    pub observe: ObserveCfg,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Defaults {
    pub mailbox_capacity: usize,
    pub max_msg_bytes: usize,
    #[serde(with = "humantime_serde")]
    pub deadline: Duration,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FairnessCfg {
    pub batch_messages: usize,
    pub yield_every_n_msgs: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SupervisionCfg {
    pub backoff_base_ms: u64,
    pub backoff_cap_ms: u64,
    pub decorrelated_jitter: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct ObserveCfg {
    /// If true, ryker may sample queue depths via observer hooks.
    pub queue_depth_sampling: bool,
}

impl Default for RykerConfig {
    fn default() -> Self {
        Self {
            defaults: Defaults {
                mailbox_capacity: 256,
                max_msg_bytes: 64 * 1024,
                deadline: Duration::from_secs(1),
            },
            fairness: FairnessCfg {
                batch_messages: 32,
                yield_every_n_msgs: 64,
            },
            supervisor: SupervisionCfg {
                backoff_base_ms: 100,
                backoff_cap_ms: 5_000,
                decorrelated_jitter: true,
            },
            amnesia: false,
            observe: ObserveCfg {
                queue_depth_sampling: true,
            },
        }
    }
}

impl RykerConfig {
    pub fn validate(&self) -> Result<()> {
        // mailbox must have capacity
        if self.defaults.mailbox_capacity == 0 {
            return Err(ConfigError::Invalid("mailbox_capacity=0".into()).into());
        }

        // Upper bound aligns with crate docs (≤ 1 MiB)
        const MIB: usize = 1024 * 1024;
        if self.defaults.max_msg_bytes > MIB {
            return Err(ConfigError::Invalid("max_msg_bytes > 1MiB".into()).into());
        }

        // 1 ms ..= 60 s recommended bounds
        if self.defaults.deadline < Duration::from_millis(1)
            || self.defaults.deadline > Duration::from_secs(60)
        {
            return Err(ConfigError::Invalid("deadline out of [1ms, 60s]".into()).into());
        }

        // yield_every_n must be ≥ batch size
        if self.fairness.yield_every_n_msgs < self.fairness.batch_messages {
            return Err(ConfigError::Invalid("yield_every_n_msgs < batch_messages".into()).into());
        }

        // backoff base/cap relationship must be coherent and non-zero
        if self.supervisor.backoff_base_ms == 0
            || self.supervisor.backoff_cap_ms == 0
            || self.supervisor.backoff_base_ms > self.supervisor.backoff_cap_ms
        {
            return Err(
                ConfigError::Invalid("invalid backoff base/cap relationship".into()).into(),
            );
        }
        Ok(())
    }

    /// Apply in-process overrides (builder-like) then revalidate.
    pub fn with_overrides<F: FnOnce(&mut RykerConfig)>(mut self, f: F) -> Result<RykerConfig> {
        f(&mut self);
        self.validate()?;
        Ok(self)
    }
}

```

### crates/ryker/src/config/reload.rs
<a id="crates-ryker-src-config-reload-rs"></a>

```rust
//! RO:WHAT — Config reload hook trait and counters.
//! RO:WHY  — Hosts may hot-apply fairness/deadline; capacity is cold-only.
//! RO:INTERACTS — runtime applies hooks; observe increments counters.
//! RO:INVARIANTS — reloads are atomic snapshot swaps; diffs are redacted.

use std::sync::atomic::AtomicU64;

#[derive(Default)]
pub struct ReloadCounters {
    pub total: AtomicU64,
    pub errors: AtomicU64,
}

pub trait RykerReloadHook: Send + Sync + 'static {
    /// Apply a new effective snapshot. Implementations must be fast and panic-free.
    fn apply(&self);
}

```

### crates/ryker/src/errors.rs
<a id="crates-ryker-src-errors-rs"></a>

```rust
//! RO:WHAT — Typed error taxonomy for ryker (mailbox/runtime/config).
//! RO:WHY  — Deterministic mapping for hosts; Concerns: RES/DX.
//! RO:INTERACTS — mailbox (Busy/TooLarge/Closed/Timeout), config loader.
//! RO:INVARIANTS — errors stable across minors; strings are non-sensitive.

use thiserror::Error;

pub type Result<T, E = Error> = std::result::Result<T, E>;

#[derive(Debug, Error)]
pub enum Error {
    #[error("mailbox at capacity (Busy)")]
    Busy,
    #[error("message too large (max {max} bytes)")]
    TooLarge { max: usize },
    #[error("mailbox closed")]
    Closed,
    #[error("deadline exceeded")]
    Timeout,
    #[error("configuration error: {0}")]
    Config(ConfigError),
}

#[derive(Debug, Error)]
pub enum ConfigError {
    #[error("invalid value: {0}")]
    Invalid(String),
    #[error("unsupported in production: {0}")]
    ProdGuard(String),
}

// Allow `?` on ConfigError to bubble as Error::Config
impl From<ConfigError> for Error {
    fn from(e: ConfigError) -> Self {
        Error::Config(e)
    }
}

```

### crates/ryker/src/lib.rs
<a id="crates-ryker-src-lib-rs"></a>

```rust
//! RO:WHAT — Crate facade for ryker (actor & bounded mailbox runtime).
//! RO:WHY  — Pillar 1 (Kernel & Orchestration); Concerns: RES/PERF.
//! RO:INTERACTS — modules: config, runtime, mailbox, supervisor, observe, errors.
//! RO:INVARIANTS — bounded mailboxes (reject-new Busy); deadlines enforced; no locks across .await.
//! RO:METRICS — via observe::MailboxObserver callbacks (host integrates Prometheus).
//! RO:CONFIG — env `RYKER_*` honored; builder > env > file > defaults precedence.
//! RO:SECURITY — library-only; no sockets/TLS/PII; amnesia feature zeroizes on drop (host-verified).
//! RO:TEST — unit/integration/loom per docs; property tests optional (proptest).

#![forbid(unsafe_code)]
#![doc = include_str!("../README.md")]

pub mod config;
pub mod errors;
pub mod mailbox;
pub mod observe;
pub mod runtime;
pub mod supervisor;

pub mod prelude;

```

### crates/ryker/src/mailbox/builder.rs
<a id="crates-ryker-src-mailbox-builder-rs"></a>

```rust
//! RO:WHAT — Per-actor mailbox builder with overrides.
//! RO:WHY  — Ergonomics; mirrors README examples; preserves snapshot defaults.
//! RO:INTERACTS — queue::Mailbox, observer hooks, config snapshot.
//! RO:INVARIANTS — capacity>0; max_msg_bytes≤1MiB; deadline bounds; reject-new policy.

#![forbid(unsafe_code)]

use super::observer::{NoopObserver, Observer};
use super::queue::Mailbox;
use crate::config::RykerConfig;
use std::sync::Arc;
use std::time::Duration;

pub struct MailboxBuilder<T> {
    actor_name: String,
    cfg: Arc<RykerConfig>,
    capacity: Option<usize>,
    max_msg_bytes: Option<usize>,
    deadline: Option<Duration>,
    observer: Option<Observer>,
    _phantom: std::marker::PhantomData<T>,
}

impl<T> MailboxBuilder<T> {
    pub(crate) fn new(actor_name: String, cfg: Arc<RykerConfig>) -> Self {
        Self {
            actor_name,
            cfg,
            capacity: None,
            max_msg_bytes: None,
            deadline: None,
            observer: None,
            _phantom: std::marker::PhantomData,
        }
    }

    pub fn capacity(mut self, cap: usize) -> Self {
        self.capacity = Some(cap);
        self
    }

    pub fn max_msg_bytes(mut self, max: usize) -> Self {
        self.max_msg_bytes = Some(max);
        self
    }

    pub fn deadline(mut self, d: Duration) -> Self {
        self.deadline = Some(d);
        self
    }

    /// Convenience for ms-based examples/doc parity.
    pub fn deadline_ms(mut self, ms: u64) -> Self {
        self.deadline = Some(Duration::from_millis(ms));
        self
    }

    pub fn observer(mut self, obs: Observer) -> Self {
        self.observer = Some(obs);
        self
    }

    pub fn build(self) -> Mailbox<T> {
        let cap = self.capacity.unwrap_or(self.cfg.defaults.mailbox_capacity);
        let max = self
            .max_msg_bytes
            .unwrap_or(self.cfg.defaults.max_msg_bytes);
        let dl = self.deadline.unwrap_or(self.cfg.defaults.deadline);
        let obs = self.observer.unwrap_or_else(|| Arc::new(NoopObserver));

        Mailbox::new(self.actor_name, cap, max, dl, obs)
    }
}

```

### crates/ryker/src/mailbox/error.rs
<a id="crates-ryker-src-mailbox-error-rs"></a>

```rust
//! RO:WHAT — Mailbox-local error facade and Result alias.
//! RO:WHY  — Keep mailbox concerns self-contained while mapping 1:1 to crate errors.
//! RO:INTERACTS — Used by `queue.rs` and `builder.rs`; re-exports for callers via `mailbox::`.
//! RO:INVARIANTS — Mirrors `crate::errors::Error`; stable across minor versions.

#![forbid(unsafe_code)]

pub type MailboxResult<T, E = MailboxError> = std::result::Result<T, E>;

/// Thin alias to the crate-wide error so users can import `mailbox::MailboxError`
/// without reaching into `crate::errors`.
#[derive(Debug, thiserror::Error)]
pub enum MailboxError {
    #[error("mailbox at capacity (Busy)")]
    Busy,
    #[error("message too large (max {max} bytes)")]
    TooLarge { max: usize },
    #[error("mailbox closed")]
    Closed,
    #[error("deadline exceeded")]
    Timeout,
}

impl From<crate::errors::Error> for MailboxError {
    fn from(e: crate::errors::Error) -> Self {
        match e {
            crate::errors::Error::Busy => MailboxError::Busy,
            crate::errors::Error::TooLarge { max } => MailboxError::TooLarge { max },
            crate::errors::Error::Closed => MailboxError::Closed,
            crate::errors::Error::Timeout => MailboxError::Timeout,
            crate::errors::Error::Config(_) => {
                // Mailbox never bubbles config errors; map conservatively.
                MailboxError::Closed
            }
        }
    }
}

impl From<MailboxError> for crate::errors::Error {
    fn from(e: MailboxError) -> Self {
        match e {
            MailboxError::Busy => crate::errors::Error::Busy,
            MailboxError::TooLarge { max } => crate::errors::Error::TooLarge { max },
            MailboxError::Closed => crate::errors::Error::Closed,
            MailboxError::Timeout => crate::errors::Error::Timeout,
        }
    }
}

```

### crates/ryker/src/mailbox/mod.rs
<a id="crates-ryker-src-mailbox-mod-rs"></a>

```rust
//! RO:WHAT — Public mailbox types: builder and queue facade.
//! RO:WHY  — Bounded single-consumer mailbox; Busy on overflow.
//! RO:INTERACTS — queue (tokio mpsc), observer hooks, errors.
//! RO:INVARIANTS — FIFO per-mailbox; reject-new; deadlines enforced via timeout.

mod builder;
mod error;
pub mod observer;
mod queue;

pub use builder::MailboxBuilder;
pub use error::{MailboxError, MailboxResult};
pub use queue::Mailbox;

// Convenience re-exports so users can `use ryker::mailbox::*;`
pub use observer::{DropReason, MailboxObserver, NoopObserver, Observer};

```

### crates/ryker/src/mailbox/observer.rs
<a id="crates-ryker-src-mailbox-observer-rs"></a>

```rust
/*! MailboxObserver hooks (stub). Forward to metrics facade without exporter lock-in. */

//! RO:WHAT — Mailbox-local observer trait re-exports and helpers.
//! RO:WHY  — Give callers a single `mailbox::observer` import surface.
//! RO:INTERACTS — Wraps `observe::metrics` to avoid leaking crate internals.
//! RO:INVARIANTS — Non-blocking hooks only; never hold locks across `.await`.

#![forbid(unsafe_code)]

pub use crate::observe::metrics::{DropReason, MailboxObserver, NoopObserver, Observer};

```

### crates/ryker/src/mailbox/queue.rs
<a id="crates-ryker-src-mailbox-queue-rs"></a>

```rust
//! RO:WHAT — Mailbox<T>: bounded queue facade around tokio mpsc, with split().
//! RO:WHY  — Single-consumer FIFO; Busy on overflow; per-message deadlines; explicit close via drop.
//! RO:INTERACTS — mailbox::observer hooks, errors.
//! RO:INVARIANTS — try_send rejects when full; pull uses timeout(deadline). No PII logged.

#![forbid(unsafe_code)]

use super::error::{MailboxError, MailboxResult};
use super::observer::{DropReason, Observer};
use crate::observe::trace;
use std::time::Duration;
use tokio::sync::mpsc;
use tokio::sync::mpsc::error::{SendError, TrySendError};

/// Factory wrapper that owns both ends until you call split().
pub struct Mailbox<T> {
    actor: String,
    tx: mpsc::Sender<T>,
    rx: mpsc::Receiver<T>,
    capacity: usize,
    max_msg_bytes: usize,
    deadline: Duration,
    observer: Observer,
}

impl<T> Mailbox<T> {
    pub(crate) fn new(
        actor: String,
        capacity: usize,
        max_msg_bytes: usize,
        deadline: Duration,
        observer: Observer,
    ) -> Self {
        let (tx, rx) = mpsc::channel(capacity);
        Self {
            actor,
            tx,
            rx,
            capacity,
            max_msg_bytes,
            deadline,
            observer,
        }
    }

    /// Non-blocking enqueue; returns Busy when full.
    pub fn try_send(&self, msg: T) -> MailboxResult<()> {
        match self.tx.try_send(msg) {
            Ok(()) => {
                // Depth is not exposed by tokio mpsc; still notify enqueue for hooks.
                self.observer.on_enqueue(&self.actor, 0);
                trace::span_enqueue(&self.actor, 0);
                Ok(())
            }
            Err(TrySendError::Full(_msg)) => {
                self.observer.on_drop(&self.actor, DropReason::Capacity);
                Err(MailboxError::Busy)
            }
            Err(TrySendError::Closed(_msg)) => Err(MailboxError::Closed),
        }
    }

    /// Blocking send with the mailbox’s per-message deadline (timeout).
    pub async fn send(&self, msg: T) -> MailboxResult<()> {
        tokio::select! {
            biased;
            _ = tokio::time::sleep(self.deadline) => {
                self.observer.on_timeout(&self.actor);
                trace::span_handle(&self.actor, "timeout", self.deadline.as_millis() as u64);
                Err(MailboxError::Timeout)
            }
            res = self.tx.send(msg) => {
                match res {
                    Ok(()) => Ok(()),
                    Err(SendError(_msg)) => Err(MailboxError::Closed),
                }
            }
        }
    }

    /// Pull one message, honoring the deadline as a receive timeout.
    pub async fn pull(&mut self) -> MailboxResult<T> {
        match tokio::time::timeout(self.deadline, self.rx.recv()).await {
            Ok(Some(m)) => Ok(m),
            Ok(None) => Err(MailboxError::Closed),
            Err(_) => {
                self.observer.on_timeout(&self.actor);
                trace::span_handle(&self.actor, "timeout", self.deadline.as_millis() as u64);
                Err(MailboxError::Timeout)
            }
        }
    }

    /// Configured bounded capacity.
    pub fn capacity(&self) -> usize {
        self.capacity
    }

    /// Deadline getter.
    pub fn deadline(&self) -> Duration {
        self.deadline
    }

    /// Split into a producer (tx) and consumer (rx). Dropping tx will *close*
    /// the channel, ensuring drains can terminate (recv => None).
    pub fn split(self) -> (MailboxTx<T>, MailboxRx<T>) {
        let Mailbox {
            actor,
            tx,
            rx,
            capacity: _,
            max_msg_bytes: _,
            deadline,
            observer,
        } = self;
        (
            MailboxTx {
                actor: actor.clone(),
                tx,
                observer: observer.clone(),
            },
            MailboxRx {
                actor,
                rx,
                deadline,
                observer,
            },
        )
    }
}

/// Send half of a mailbox.
pub struct MailboxTx<T> {
    actor: String,
    tx: mpsc::Sender<T>,
    observer: Observer,
}

impl<T> MailboxTx<T> {
    pub fn try_send(&self, msg: T) -> MailboxResult<()> {
        match self.tx.try_send(msg) {
            Ok(()) => {
                self.observer.on_enqueue(&self.actor, 0);
                trace::span_enqueue(&self.actor, 0);
                Ok(())
            }
            Err(TrySendError::Full(_msg)) => {
                self.observer.on_drop(&self.actor, DropReason::Capacity);
                Err(MailboxError::Busy)
            }
            Err(TrySendError::Closed(_msg)) => Err(MailboxError::Closed),
        }
    }

    pub async fn send(&self, msg: T) -> MailboxResult<()> {
        match self.tx.send(msg).await {
            Ok(()) => Ok(()),
            Err(SendError(_msg)) => Err(MailboxError::Closed),
        }
    }
}

/// Receive half of a mailbox.
pub struct MailboxRx<T> {
    actor: String,
    rx: mpsc::Receiver<T>,
    deadline: Duration,
    observer: Observer,
}

impl<T> MailboxRx<T> {
    pub async fn pull(&mut self) -> MailboxResult<T> {
        match tokio::time::timeout(self.deadline, self.rx.recv()).await {
            Ok(Some(m)) => Ok(m),
            Ok(None) => Err(MailboxError::Closed),
            Err(_) => {
                self.observer.on_timeout(&self.actor);
                trace::span_handle(&self.actor, "timeout", self.deadline.as_millis() as u64);
                Err(MailboxError::Timeout)
            }
        }
    }

    pub fn deadline(&self) -> Duration {
        self.deadline
    }
}

```

### crates/ryker/src/observe/metrics.rs
<a id="crates-ryker-src-observe-metrics-rs"></a>

```rust
//! RO:WHAT — Observer trait for mailbox lifecycle signals.
//! RO:WHY  — Allow hosts to increment counters/gauges without pulling prometheus here.
//! RO:INTERACTS — mailbox queue calls hooks on enqueue/drop/timeout/drain.
//! RO:INVARIANTS — must be non-blocking; cheap; thread-safe.

use std::sync::Arc;

#[derive(Clone)]
pub struct NoopObserver;

impl MailboxObserver for NoopObserver {
    fn on_enqueue(&self, _actor: &str, _depth: usize) {}
    fn on_drop(&self, _actor: &str, _reason: DropReason) {}
    fn on_timeout(&self, _actor: &str) {}
    fn on_restart(&self, _actor: &str) {}
}

#[derive(Clone, Copy, Debug)]
pub enum DropReason {
    Capacity,
    Closed,
}

pub trait MailboxObserver: Send + Sync + 'static {
    fn on_enqueue(&self, actor: &str, depth: usize);
    fn on_drop(&self, actor: &str, reason: DropReason);
    fn on_timeout(&self, actor: &str);
    fn on_restart(&self, actor: &str);
}

pub type Observer = Arc<dyn MailboxObserver>;

```

### crates/ryker/src/observe/mod.rs
<a id="crates-ryker-src-observe-mod-rs"></a>

```rust
//! RO:WHAT — Lightweight observability hooks (metrics/tracing integration points).
//! RO:WHY  — Keep ryker decoupled from metrics exporters; host wires Prometheus/OTEL.
//! RO:INTERACTS — mailbox builder/queue calls observer methods; tracing spans are optional.
//! RO:INVARIANTS — no heavy work in hooks; sampling controlled by config.

pub mod metrics;
pub mod trace;

pub use metrics::{MailboxObserver, NoopObserver};

```

### crates/ryker/src/observe/trace.rs
<a id="crates-ryker-src-observe-trace-rs"></a>

```rust
//! RO:WHAT — Optional tracing helpers (no-op without `tracing` feature).
//! RO:WHY  — Keep span names stable per docs; host chooses exporter.
//! RO:INVARIANTS — never log message bodies/PII.

#[inline]
pub fn span_enqueue(actor: &str, depth: usize) {
    #[cfg(feature = "tracing")]
    tracing::trace!(target="ryker", actor=%actor, queue_depth=%depth, "ryker.mailbox.enqueue");
}

#[inline]
pub fn span_handle(actor: &str, outcome: &str, deadline_ms: u64) {
    #[cfg(feature = "tracing")]
    tracing::trace!(target="ryker", actor=%actor, outcome=%outcome, deadline_ms=%deadline_ms, "ryker.actor.handle");
}

#[inline]
pub fn span_config_reload() {
    #[cfg(feature = "tracing")]
    tracing::info!(target = "ryker", "ryker.config.reload");
}

```

### crates/ryker/src/prelude.rs
<a id="crates-ryker-src-prelude-rs"></a>

```rust
//! RO:WHAT — Ergonomic re-exports for common ryker types.
//! RO:WHY  — DX; fewer deep module paths for apps embedding ryker.
//! RO:INTERACTS — re-exports from config, runtime, mailbox, supervisor.
//! RO:INVARIANTS — re-export only stable, documented surface.

pub use crate::config::RykerConfig;
pub use crate::errors::{Error, Result};
pub use crate::mailbox::{Mailbox, MailboxBuilder};
pub use crate::runtime::Runtime;
pub use crate::supervisor::Supervisor;

```

### crates/ryker/src/runtime/mod.rs
<a id="crates-ryker-src-runtime-mod-rs"></a>

```rust
//! RO:WHAT — Runtime facade holding the effective config snapshot.
//! RO:WHY  — Central factory for MailboxBuilder; no global executors.
//! RO:INTERACTS — mailbox builder/queue, observe hooks, config snapshot.
//! RO:INVARIANTS — snapshot immutable via Arc; hosts own task lifetimes.
#![allow(clippy::module_inception)]

mod runtime;

pub use runtime::Runtime;

```

### crates/ryker/src/runtime/runtime.rs
<a id="crates-ryker-src-runtime-runtime-rs"></a>

```rust
//! RO:WHAT — Runtime implementation and mailbox factory methods.
//! RO:WHY  — Host-owned container to spawn mailboxes with per-actor overrides.
//! RO:INTERACTS — config::RykerConfig, mailbox::{Mailbox, MailboxBuilder}.
//! RO:INVARIANTS — never allocates unbounded queues; respects defaults & overrides.

use crate::config::RykerConfig;
use crate::mailbox::{Mailbox, MailboxBuilder};
use std::sync::Arc;

#[derive(Clone)]
pub struct Runtime {
    cfg: Arc<RykerConfig>,
}

impl Runtime {
    pub fn new(cfg: RykerConfig) -> Self {
        Self { cfg: Arc::new(cfg) }
    }

    pub fn mailbox<T>(&self, actor_name: impl Into<String>) -> MailboxBuilder<T> {
        MailboxBuilder::new(actor_name.into(), self.cfg.clone())
    }

    /// Build a mailbox immediately with defaults (no overrides).
    pub fn mailbox_default<T>(&self, actor_name: impl Into<String>) -> Mailbox<T> {
        self.mailbox(actor_name).build()
    }

    /// Access the effective config snapshot.
    pub fn config(&self) -> Arc<RykerConfig> {
        self.cfg.clone()
    }
}

```

### crates/ryker/src/supervisor/backoff.rs
<a id="crates-ryker-src-supervisor-backoff-rs"></a>

```rust
//! RO:WHAT — Decorrelated jitter backoff calculator.
//! RO:WHY  — Avoid lockstep thundering herds; Concerns: RES.
//! RO:INVARIANTS — cap respected; base>0; deterministic bounds.

use rand::{rngs::StdRng, Rng, SeedableRng};

pub fn decorrelated_jitter(base_ms: u64, cap_ms: u64, prev_ms: u64, seed: u64) -> u64 {
    let mut rng = StdRng::seed_from_u64(seed ^ prev_ms);
    let next = (base_ms as f64).max((prev_ms as f64 * 3.0).min(cap_ms as f64));
    let jitter = rng.random_range(base_ms..=next as u64);
    jitter.min(cap_ms)
}

```

### crates/ryker/src/supervisor/mod.rs
<a id="crates-ryker-src-supervisor-mod-rs"></a>

```rust
//! RO:WHAT — Crash-only supervision with jittered backoff.
//! RO:WHY  — Resilience; restarts counted by host metrics via observe hooks.
//! RO:INTERACTS — backoff calc; host spawns async tasks; no global runtime.
//! RO:INVARIANTS — decorrelated jitter; bounded backoff; cancel-safe.
#![allow(clippy::module_inception)]

mod backoff;
mod supervisor;

pub use backoff::decorrelated_jitter;
pub use supervisor::Supervisor;

```

### crates/ryker/src/supervisor/supervisor.rs
<a id="crates-ryker-src-supervisor-supervisor-rs"></a>

```rust
//! RO:WHAT — Supervisor wrapper that restarts an async actor on failure.
//! RO:WHY  — Crash-only philosophy; Concerns: RES; host observes restarts.
//! RO:INTERACTS — config::SupervisionCfg (base/cap/jitter); tracing (optional).
//! RO:INVARIANTS — backoff grows to cap; cancellation cooperative.

use crate::config::RykerConfig;
use crate::supervisor::decorrelated_jitter;
use std::future::Future;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::task::JoinHandle;

pub struct Supervisor {
    cfg: Arc<RykerConfig>,
}

impl Supervisor {
    pub fn new(cfg: Arc<RykerConfig>) -> Self {
        Self { cfg }
    }

    /// Spawn an actor future; if it returns Err or panics, it will be restarted
    /// with decorrelated jitter until cancel() is observed by the actor.
    pub fn spawn<F, Fut>(&self, mut make_actor: F) -> JoinHandle<()>
    where
        F: FnMut() -> Fut + Send + 'static,
        Fut: Future<Output = anyhow::Result<()>> + Send + 'static,
    {
        let cfg = self.cfg.clone();
        tokio::spawn(async move {
            let mut backoff = cfg.supervisor.backoff_base_ms;
            let mut last_fail = Instant::now();
            loop {
                let res = make_actor().await;
                if res.is_ok() {
                    // Normal exit—do not restart.
                    break;
                }
                #[cfg(feature = "tracing")]
                tracing::warn!(target = "ryker", "actor failed; restarting");

                // Compute next delay with decorrelated jitter.
                let seed = last_fail.elapsed().as_millis() as u64;
                backoff = decorrelated_jitter(
                    cfg.supervisor.backoff_base_ms,
                    cfg.supervisor.backoff_cap_ms,
                    backoff,
                    seed,
                );
                tokio::time::sleep(Duration::from_millis(backoff)).await;
                last_fail = Instant::now();
            }
        })
    }
}

```

### crates/ryker/tests/feature_matrix.rs
<a id="crates-ryker-tests-featurematrix-rs"></a>

```rust
/*! Compile-only feature matrix checks (stub). Ensures public surface builds across combos. */

```

### crates/ryker/tests/integration/amnesia.rs
<a id="crates-ryker-tests-integration-amnesia-rs"></a>

```rust
/*! Gate: amnesia zeroize behavior on/off (stub test). */

```

### crates/ryker/tests/integration/backpressure.rs
<a id="crates-ryker-tests-integration-backpressure-rs"></a>

```rust
/*! Gate: full queue -> Busy + dropped_total{reason=capacity} (stub test). */

```

### crates/ryker/tests/integration/config_env_snapshot.rs
<a id="crates-ryker-tests-integration-configenvsnapshot-rs"></a>

```rust
/*! Gate: config precedence & validation (stub test). */

```

### crates/ryker/tests/integration/deadline.rs
<a id="crates-ryker-tests-integration-deadline-rs"></a>

```rust
/*! Gate: deadline -> outcome=timeout in histogram (stub test). */

```

### crates/ryker/tests/integration/metrics_contract.rs
<a id="crates-ryker-tests-integration-metricscontract-rs"></a>

```rust
/*! Gate: metrics contract golden test (stub). Compare to vectors/snapshots/metrics_contract.txt. */

```

### crates/ryker/tests/integration/reload_hot_cold.rs
<a id="crates-ryker-tests-integration-reloadhotcold-rs"></a>

```rust
/*! Gate: hot(deadline/fairness) vs cold(capacity/size) reload semantics (stub test). */

```

### crates/ryker/tests/integration/supervisor_backoff.rs
<a id="crates-ryker-tests-integration-supervisorbackoff-rs"></a>

```rust
/*! Gate: decorrelated jitter bounds + rapid-fail ceiling (stub test). */

```

### crates/ryker/tests/loom/loom_backpressure.rs
<a id="crates-ryker-tests-loom-loombackpressure-rs"></a>

```rust
/*! Loom: deterministic Busy under contention (stub). */

```

### crates/ryker/tests/loom/loom_mailbox_basic.rs
<a id="crates-ryker-tests-loom-loommailboxbasic-rs"></a>

```rust
/*! Loom: N producers -> 1 consumer; no deadlocks; FIFO per mailbox (stub). */

```

### crates/ryker/tests/loom/loom_shutdown.rs
<a id="crates-ryker-tests-loom-loomshutdown-rs"></a>

```rust
/*! Loom: graceful shutdown; cancel-safe; no double-drop (stub). */

```

### crates/ryker/tests/vectors/snapshots/config_snapshot.json
<a id="crates-ryker-tests-vectors-snapshots-configsnapshot-json"></a>

```json
{ "snapshot": true }

```

### crates/ryker/tests/vectors/snapshots/config_snapshot.toml
<a id="crates-ryker-tests-vectors-snapshots-configsnapshot-toml"></a>

```toml
# snapshot placeholder

```



---



# svc-overlay

_Source: crates/svc-overlay/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:44:10Z -->
# Code Bundle — `svc-overlay`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/svc-overlay/.devcontainer/devcontainer.json](#crates-svc-overlay--devcontainer-devcontainer-json)
- [crates/svc-overlay/.github/workflows/ci.yml](#crates-svc-overlay--github-workflows-ci-yml)
- [crates/svc-overlay/.github/workflows/concurrency-guardrails.yml](#crates-svc-overlay--github-workflows-concurrency-guardrails-yml)
- [crates/svc-overlay/.github/workflows/contract-apis.yml](#crates-svc-overlay--github-workflows-contract-apis-yml)
- [crates/svc-overlay/.github/workflows/render-mermaid.yml](#crates-svc-overlay--github-workflows-render-mermaid-yml)
- [crates/svc-overlay/Cargo.toml](#crates-svc-overlay-Cargo-toml)
- [crates/svc-overlay/benches/handshake.rs](#crates-svc-overlay-benches-handshake-rs)
- [crates/svc-overlay/benches/oap_codec.rs](#crates-svc-overlay-benches-oapcodec-rs)
- [crates/svc-overlay/build.rs](#crates-svc-overlay-build-rs)
- [crates/svc-overlay/examples/libapi_embed.rs](#crates-svc-overlay-examples-libapiembed-rs)
- [crates/svc-overlay/examples/oap_client.rs](#crates-svc-overlay-examples-oapclient-rs)
- [crates/svc-overlay/examples/pq_embed.rs](#crates-svc-overlay-examples-pqembed-rs)
- [crates/svc-overlay/fuzz/fuzz_targets/gossip_lane.rs](#crates-svc-overlay-fuzz-fuzztargets-gossiplane-rs)
- [crates/svc-overlay/fuzz/fuzz_targets/oap_frame_parse.rs](#crates-svc-overlay-fuzz-fuzztargets-oapframeparse-rs)
- [crates/svc-overlay/scripts/roundtrip_overlay.sh](#crates-svc-overlay-scripts-roundtripoverlay-sh)
- [crates/svc-overlay/scripts/smoke_overlay.sh](#crates-svc-overlay-scripts-smokeoverlay-sh)
- [crates/svc-overlay/scripts/soak_overlay.sh](#crates-svc-overlay-scripts-soakoverlay-sh)
- [crates/svc-overlay/src/admin/health.rs](#crates-svc-overlay-src-admin-health-rs)
- [crates/svc-overlay/src/admin/metrics.rs](#crates-svc-overlay-src-admin-metrics-rs)
- [crates/svc-overlay/src/admin/mod.rs](#crates-svc-overlay-src-admin-mod-rs)
- [crates/svc-overlay/src/admin/ready.rs](#crates-svc-overlay-src-admin-ready-rs)
- [crates/svc-overlay/src/admin/version.rs](#crates-svc-overlay-src-admin-version-rs)
- [crates/svc-overlay/src/api/mod.rs](#crates-svc-overlay-src-api-mod-rs)
- [crates/svc-overlay/src/auth/macaroon.rs](#crates-svc-overlay-src-auth-macaroon-rs)
- [crates/svc-overlay/src/auth/mod.rs](#crates-svc-overlay-src-auth-mod-rs)
- [crates/svc-overlay/src/bootstrap.rs](#crates-svc-overlay-src-bootstrap-rs)
- [crates/svc-overlay/src/cli.rs](#crates-svc-overlay-src-cli-rs)
- [crates/svc-overlay/src/config.rs](#crates-svc-overlay-src-config-rs)
- [crates/svc-overlay/src/conn/error.rs](#crates-svc-overlay-src-conn-error-rs)
- [crates/svc-overlay/src/conn/mod.rs](#crates-svc-overlay-src-conn-mod-rs)
- [crates/svc-overlay/src/conn/reader.rs](#crates-svc-overlay-src-conn-reader-rs)
- [crates/svc-overlay/src/conn/supervisor.rs](#crates-svc-overlay-src-conn-supervisor-rs)
- [crates/svc-overlay/src/conn/tx.rs](#crates-svc-overlay-src-conn-tx-rs)
- [crates/svc-overlay/src/conn/writer.rs](#crates-svc-overlay-src-conn-writer-rs)
- [crates/svc-overlay/src/errors.rs](#crates-svc-overlay-src-errors-rs)
- [crates/svc-overlay/src/gossip/engine.rs](#crates-svc-overlay-src-gossip-engine-rs)
- [crates/svc-overlay/src/gossip/mod.rs](#crates-svc-overlay-src-gossip-mod-rs)
- [crates/svc-overlay/src/gossip/types.rs](#crates-svc-overlay-src-gossip-types-rs)
- [crates/svc-overlay/src/lib.rs](#crates-svc-overlay-src-lib-rs)
- [crates/svc-overlay/src/limits.rs](#crates-svc-overlay-src-limits-rs)
- [crates/svc-overlay/src/listener/mod.rs](#crates-svc-overlay-src-listener-mod-rs)
- [crates/svc-overlay/src/listener/plain.rs](#crates-svc-overlay-src-listener-plain-rs)
- [crates/svc-overlay/src/listener/ron.rs](#crates-svc-overlay-src-listener-ron-rs)
- [crates/svc-overlay/src/main.rs](#crates-svc-overlay-src-main-rs)
- [crates/svc-overlay/src/observe.rs](#crates-svc-overlay-src-observe-rs)
- [crates/svc-overlay/src/pq/mod.rs](#crates-svc-overlay-src-pq-mod-rs)
- [crates/svc-overlay/src/pq/negotiate.rs](#crates-svc-overlay-src-pq-negotiate-rs)
- [crates/svc-overlay/src/protocol/cbor.rs](#crates-svc-overlay-src-protocol-cbor-rs)
- [crates/svc-overlay/src/protocol/error.rs](#crates-svc-overlay-src-protocol-error-rs)
- [crates/svc-overlay/src/protocol/flags.rs](#crates-svc-overlay-src-protocol-flags-rs)
- [crates/svc-overlay/src/protocol/handshake.rs](#crates-svc-overlay-src-protocol-handshake-rs)
- [crates/svc-overlay/src/protocol/mod.rs](#crates-svc-overlay-src-protocol-mod-rs)
- [crates/svc-overlay/src/protocol/oap.rs](#crates-svc-overlay-src-protocol-oap-rs)
- [crates/svc-overlay/src/readiness/mod.rs](#crates-svc-overlay-src-readiness-mod-rs)
- [crates/svc-overlay/src/readiness/sampler.rs](#crates-svc-overlay-src-readiness-sampler-rs)
- [crates/svc-overlay/src/shutdown.rs](#crates-svc-overlay-src-shutdown-rs)
- [crates/svc-overlay/src/supervisor.rs](#crates-svc-overlay-src-supervisor-rs)
- [crates/svc-overlay/src/transport/mod.rs](#crates-svc-overlay-src-transport-mod-rs)
- [crates/svc-overlay/src/transport/quic.rs](#crates-svc-overlay-src-transport-quic-rs)
- [crates/svc-overlay/src/transport/tls.rs](#crates-svc-overlay-src-transport-tls-rs)
- [crates/svc-overlay/src/transport/tor.rs](#crates-svc-overlay-src-transport-tor-rs)
- [crates/svc-overlay/src/tuning.rs](#crates-svc-overlay-src-tuning-rs)
- [crates/svc-overlay/src/types.rs](#crates-svc-overlay-src-types-rs)
- [crates/svc-overlay/tests/http_contract.rs](#crates-svc-overlay-tests-httpcontract-rs)
- [crates/svc-overlay/tests/integration/oap_session_handshake.rs](#crates-svc-overlay-tests-integration-oapsessionhandshake-rs)
- [crates/svc-overlay/tests/integration/overlay_admin_roundtrip.rs](#crates-svc-overlay-tests-integration-overlayadminroundtrip-rs)
- [crates/svc-overlay/tests/integration/overlay_oap_streaming.rs](#crates-svc-overlay-tests-integration-overlayoapstreaming-rs)
- [crates/svc-overlay/tests/interop_vectors.rs](#crates-svc-overlay-tests-interopvectors-rs)
- [crates/svc-overlay/tests/loom/loom_overlay.rs](#crates-svc-overlay-tests-loom-loomoverlay-rs)
- [crates/svc-overlay/tests/metrics_schema.rs](#crates-svc-overlay-tests-metricsschema-rs)
- [crates/svc-overlay/tests/pq_negotiation.rs](#crates-svc-overlay-tests-pqnegotiation-rs)
- [crates/svc-overlay/tests/readiness_under_pressure.rs](#crates-svc-overlay-tests-readinessunderpressure-rs)

### crates/svc-overlay/.devcontainer/devcontainer.json
<a id="crates-svc-overlay--devcontainer-devcontainer-json"></a>

```json
{
  "name": "svc-overlay",
  "image": "mcr.microsoft.com/devcontainers/rust:1-1.80-bookworm",
  "features": {},
  "customizations": {
    "vscode": {
      "extensions": ["rust-lang.rust-analyzer", "serayuzgur.crates"]
    }
  },
  "postCreateCommand": "cargo fetch"
}

```

### crates/svc-overlay/.github/workflows/ci.yml
<a id="crates-svc-overlay--github-workflows-ci-yml"></a>

```yaml
name: ci
on: [push, pull_request]
jobs:
  build-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          components: clippy,rustfmt
      - name: Build
        run: cargo build -p svc-overlay
      - name: Clippy (deny warnings)
        run: cargo clippy -p svc-overlay -- -D warnings
      - name: Test
        run: cargo test -p svc-overlay --all-features
      - name: Doc tests
        run: cargo test -p svc-overlay --doc
      - name: Cargo deny
        run: cargo deny check
      - name: Cargo audit
        run: cargo install cargo-audit || true
      - name: Audit vulnerabilities
        run: cargo audit
      - name: Coverage (floor 85%)
        run: echo "(hook up your coverage tool here and fail below 85%)"

```

### crates/svc-overlay/.github/workflows/concurrency-guardrails.yml
<a id="crates-svc-overlay--github-workflows-concurrency-guardrails-yml"></a>

```yaml
name: concurrency-guardrails
on: [push, pull_request]
jobs:
  loom:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - name: Loom interleavings
        run: RUSTFLAGS='--cfg loom' cargo test -p svc-overlay --test loom_overlay

```

### crates/svc-overlay/.github/workflows/contract-apis.yml
<a id="crates-svc-overlay--github-workflows-contract-apis-yml"></a>

```yaml
name: contract-apis
on: [push, pull_request]
jobs:
  public-api-and-schemas:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Cargo public-api
        run: |
          cargo install cargo-public-api || true
          cargo public-api -p svc-overlay > public-api.txt || true
      - name: Diff api-history snapshots
        run: echo "(compare against docs/api-history/svc-overlay/*)" 

```

### crates/svc-overlay/.github/workflows/render-mermaid.yml
<a id="crates-svc-overlay--github-workflows-render-mermaid-yml"></a>

```yaml
name: render-mermaid
on: [push, pull_request]
jobs:
  mmdc:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm i -g @mermaid-js/mermaid-cli
      - run: |
          mkdir -p docs
          for f in $(git ls-files '*.mmd'); do
            out="${f%.mmd}.svg"
            mmdc -i "$f" -o "$out"
          done

```

### crates/svc-overlay/Cargo.toml
<a id="crates-svc-overlay-Cargo-toml"></a>

```toml
[package]
name = "svc-overlay"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
publish = false
description = "RustyOnions overlay service: sessions & gossip (no DHT)"
readme = "README.md"

[features]
libapi = []
tls = ["dep:tokio-rustls"]   # enable TLS wiring when we hook it up
pq  = []                     # placeholder for future PQ handshake toggle
quic = []                    # placeholder for future QUIC
# Flip this to use the ron-transport adapter path (default build = plain TCP)
use_ron_transport = ["dep:ron-transport"]

[dependencies]
anyhow = "1.0.86"
thiserror = "1.0.63"
tokio = { version = "1.47.1", features = ["rt-multi-thread","macros","signal","time","sync","io-util"] }
tracing = "0.1.40"
tracing-subscriber = { version = "0.3.18", features = ["env-filter","fmt","json"] }
axum = { version = "0.7.9", features = ["http1","http2","json"] }   # no "tokio" feature here
hyper = "1.4.1"
prometheus = "0.14.0"
serde = { version = "1.0.214", features = ["derive"] }
serde_json = "1.0.132"
bytes = "1.7.1"
base64 = "0.22.1"
hex = "0.4.3"
sha2 = "0.10.8"
parking_lot = "0.12.3"
tokio-rustls = { version = "0.26.2", optional = true }
futures = "0.3.31"
bitflags = "2.6.0"

# Observability used by src/observe.rs
metrics = "0.24.1"
metrics-exporter-prometheus = "0.15.3"
once_cell = "1.19.0"

# Local workspace crates
ron-metrics   = { path = "../ron-metrics" }
ron-proto     = { path = "../ron-proto" }
ron-kernel    = { path = "../ron-kernel" }

# Optional transport (enabled by feature `use_ron_transport`)
ron-transport = { path = "../ron-transport", optional = true }

[dev-dependencies]
tokio = { version = "1.47.1", features = ["rt","macros","time"] }

```

### crates/svc-overlay/benches/handshake.rs
<a id="crates-svc-overlay-benches-handshake-rs"></a>

```rust
/*! handshake.rs — microbench placeholders
- Control-plane handshake latency; PQ-hybrid delta vs classic.
*/

```

### crates/svc-overlay/benches/oap_codec.rs
<a id="crates-svc-overlay-benches-oapcodec-rs"></a>

```rust
/*! oap_codec.rs — microbench placeholders
- Benchmarks for frame encode/decode at 1 KiB / 64 KiB / 1 MiB.
*/

```

### crates/svc-overlay/build.rs
<a id="crates-svc-overlay-build-rs"></a>

```rust
// RO:WHAT
//   Inject GIT_SHA and BUILD_TS envs for /version.
// RO:WHY
//   Make /version useful in dev and CI without runtime shelling.

use std::process::Command;

fn main() {
    // Best-effort short SHA
    if let Ok(out) = Command::new("git")
        .args(["rev-parse", "--short=12", "HEAD"])
        .output()
    {
        if out.status.success() {
            if let Ok(sha) = String::from_utf8(out.stdout) {
                println!("cargo:rustc-env=GIT_SHA={}", sha.trim());
            }
        }
    }
    // UTC-ish timestamp using std
    use std::time::{SystemTime, UNIX_EPOCH};
    let now = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_default()
        .as_secs();
    println!("cargo:rustc-env=BUILD_TS=unix:{now}");

    // Re-run on HEAD changes
    println!("cargo:rerun-if-changed=.git/HEAD");
    println!("cargo:rerun-if-changed=.git/refs");
}

```

### crates/svc-overlay/examples/libapi_embed.rs
<a id="crates-svc-overlay-examples-libapiembed-rs"></a>

```rust
//! Minimal client: dial localhost, do OAP/1 hello, send one DATA frame, read echo.
//! Run with: cargo run -p svc-overlay --example libapi_embed

use anyhow::Result;
use bytes::{Bytes, BytesMut};
use std::time::Duration;
use tokio::io::AsyncReadExt;
use tokio::net::TcpStream;

use svc_overlay::conn::writer::write_frame;
use svc_overlay::protocol::flags::Caps;
use svc_overlay::protocol::handshake::handshake;
use svc_overlay::protocol::oap::{try_parse_frame, Frame, FrameKind};

#[tokio::main]
async fn main() -> Result<()> {
    // Quick logger
    if std::env::var_os("RUST_LOG").is_none() {
        std::env::set_var("RUST_LOG", "info");
    }
    tracing_subscriber::fmt::init();

    // 1) Connect to the overlay's temporary listener.
    let addr = "127.0.0.1:9700";
    tracing::info!("dialing {addr}");
    let mut sock = TcpStream::connect(addr).await?;
    tracing::info!("connected; performing OAP/1 handshake");

    // 2) Symmetric OAP/1 hello.
    let caps = Caps::GOSSIP_V1;
    let neg = handshake(&mut sock, caps, Duration::from_secs(3)).await?;
    tracing::info!("negotiated: ver={}, caps={:?}", neg.version, neg.caps);

    // 3) Send a single DATA frame.
    let payload = Bytes::from_static(b"hello, overlay!");
    let frame = Frame {
        kind: FrameKind::Data,
        payload: payload.clone(),
    };
    let mut scratch = BytesMut::with_capacity(1024);
    write_frame(&mut sock, &frame, &mut scratch).await?;
    tracing::info!("sent one DATA frame; waiting for echo");

    // 4) Read back echo and print.
    let mut inbuf = BytesMut::with_capacity(4096);
    loop {
        // Try parse any buffered frames first.
        if let Some(f) = try_parse_frame(&mut inbuf)? {
            if let FrameKind::Data = f.kind {
                let text = String::from_utf8_lossy(&f.payload);
                println!("echo from overlay: {}", text);
                break;
            }
        }
        // Need more bytes.
        let n = sock.read_buf(&mut inbuf).await?;
        if n == 0 {
            anyhow::bail!("server closed before echo");
        }
    }

    Ok(())
}

```

### crates/svc-overlay/examples/oap_client.rs
<a id="crates-svc-overlay-examples-oapclient-rs"></a>

```rust
use anyhow::{anyhow, Result};
use bytes::BytesMut;
use std::net::SocketAddr;
use std::time::Duration;
use tokio::io::AsyncReadExt;
use tokio::net::TcpStream;

use svc_overlay::conn::writer::write_frame;
use svc_overlay::protocol::flags::Caps;
use svc_overlay::protocol::handshake::handshake;
use svc_overlay::protocol::oap::{try_parse_frame, Frame, FrameKind};

#[tokio::main]
async fn main() -> Result<()> {
    let addr: SocketAddr = std::env::var("OVERLAY_ADDR")
        .unwrap_or_else(|_| "127.0.0.1:9700".into())
        .parse()?;

    eprintln!("[client] connecting to {}", addr);
    let mut sock = TcpStream::connect(addr).await?;

    // Handshake to match server
    let caps = Caps::GOSSIP_V1;
    let neg = handshake(&mut sock, caps, Duration::from_secs(3)).await?;
    eprintln!(
        "[client] negotiated version={} caps={:?}",
        neg.version, neg.caps
    );

    // Send one Data frame and verify echo
    let mut outbuf = BytesMut::with_capacity(1024);
    let mut inbuf = BytesMut::with_capacity(1024);

    let payload = b"hello-overlay";
    let frame = Frame {
        kind: FrameKind::Data,
        payload: payload.as_slice().into(),
    };
    write_frame(&mut sock, &frame, &mut outbuf).await?;

    loop {
        while let Some(f) = try_parse_frame(&mut inbuf)? {
            if let FrameKind::Data = f.kind {
                if f.payload.as_ref() == payload {
                    eprintln!("[client] got echo OK");
                    return Ok(());
                } else {
                    return Err(anyhow!("unexpected payload {:?}", f.payload));
                }
            }
        }
        let n = sock.read_buf(&mut inbuf).await?;
        if n == 0 {
            return Err(anyhow!("server closed before echo"));
        }
    }
}

```

### crates/svc-overlay/examples/pq_embed.rs
<a id="crates-svc-overlay-examples-pqembed-rs"></a>

```rust
/*! pq_embed.rs — example placeholder
Demonstrates enabling transport-level PQ hybrid posture via feature flags.
*/

```

### crates/svc-overlay/fuzz/fuzz_targets/gossip_lane.rs
<a id="crates-svc-overlay-fuzz-fuzztargets-gossiplane-rs"></a>

```rust
// fuzz target placeholder: gossip lane scheduler/backpressure\n
```

### crates/svc-overlay/fuzz/fuzz_targets/oap_frame_parse.rs
<a id="crates-svc-overlay-fuzz-fuzztargets-oapframeparse-rs"></a>

```rust
// fuzz target placeholder: OAP envelope parsing edge cases\n
```

### crates/svc-overlay/scripts/roundtrip_overlay.sh
<a id="crates-svc-overlay-scripts-roundtripoverlay-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT
#   Launch svc-overlay, run the OAP client N times, scrape metrics, teardown.
# RO:USAGE
#   chmod +x crates/svc-overlay/scripts/roundtrip_overlay.sh
#   crates/svc-overlay/scripts/roundtrip_overlay.sh 3

set -euo pipefail

RUNS="${1:-3}"
ADMIN_ADDR="${ADMIN_ADDR:-127.0.0.1:9600}"
OVERLAY_ADDR="${OVERLAY_ADDR:-127.0.0.1:9700}"
RUST_LOG="${RUST_LOG:-svc_overlay=info}"

log(){ printf '[roundtrip] %s\n' "$*" >&2; }

ROOT_DIR="$(git rev-parse --show-toplevel 2>/dev/null || pwd)"
cd "$ROOT_DIR"

log "fmt + clippy"
cargo fmt -p svc-overlay
cargo clippy -p svc-overlay --no-deps -- -D warnings

log "building server + oap_client example (only)"
cargo build -p svc-overlay --example oap_client

RUN_LOG="target/svc-overlay.roundtrip.log"
: > "$RUN_LOG"
log "launching svc-overlay (logs → $RUN_LOG)"
RUST_LOG="$RUST_LOG" cargo run -p svc-overlay >"$RUN_LOG" 2>&1 &
SVC_PID=$!

cleanup(){
  set +e
  if kill -0 "$SVC_PID" >/dev/null 2>&1; then
    log "stopping svc-overlay (pid $SVC_PID)"
    kill "$SVC_PID" || true
    sleep 0.3
    kill -9 "$SVC_PID" 2>/dev/null || true
  fi
}
trap cleanup EXIT INT TERM

log "waiting for admin @ http://$ADMIN_ADDR/healthz"
for i in {1..60}; do
  curl -sf "http://$ADMIN_ADDR/healthz" >/dev/null && break
  sleep 0.2
  [[ $i -eq 60 ]] && { log "timeout waiting for admin"; tail -n 120 "$RUN_LOG" || true; exit 1; }
done

# Also wait for TCP port to accept (macOS-friendly: use nc -z)
HOST="${OVERLAY_ADDR%:*}"
PORT="${OVERLAY_ADDR##*:}"
log "waiting for overlay TCP ${HOST}:${PORT}"
for i in {1..60}; do
  if nc -z "$HOST" "$PORT" >/dev/null 2>&1; then
    break
  fi
  sleep 0.2
  [[ $i -eq 60 ]] && { log "timeout waiting for overlay TCP"; tail -n 120 "$RUN_LOG" || true; exit 1; }
done

show_metrics(){
  curl -sSf "http://$ADMIN_ADDR/metrics" \
    | grep -E 'overlay_build_info|overlay_sessions_active|overlay_(accept_latency_seconds|frames_in_total|frames_out_total|bytes_in_total|bytes_out_total)' \
    || true
}

log "baseline metrics"
show_metrics

for n in $(seq 1 "$RUNS"); do
  log "client run $n/$RUNS"
  OVERLAY_ADDR="$OVERLAY_ADDR" cargo run -q -p svc-overlay --example oap_client || {
    log "client failed on run $n"
    tail -n 120 "$RUN_LOG" || true
    exit 1
  }
done

log "post-runs metrics"
show_metrics

log "recent server logs:"
tail -n 120 "$RUN_LOG" || true

log "done"

```

### crates/svc-overlay/scripts/smoke_overlay.sh
<a id="crates-svc-overlay-scripts-smokeoverlay-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT
#   One-button smoke test for svc-overlay:
#     - fmt + clippy
#     - launch svc-overlay (background)
#     - wait for admin /healthz
#     - open a few test sockets (nc)
#     - scrape metrics (gauge + histogram)
#     - clean shutdown
#
# RO:USAGE
#   chmod +x crates/svc-overlay/scripts/smoke_overlay.sh
#   crates/svc-overlay/scripts/smoke_overlay.sh
#
# RO:CONFIG
#   ADMIN_ADDR:  admin HTTP bind (default 127.0.0.1:9600)
#   OVERLAY_ADDR: overlay TCP bind (default 127.0.0.1:9700)
#   RUST_LOG: set logging for the run (default svc_overlay=info)

set -euo pipefail

ADMIN_ADDR="${ADMIN_ADDR:-127.0.0.1:9600}"
OVERLAY_ADDR="${OVERLAY_ADDR:-127.0.0.1:9700}"
RUST_LOG="${RUST_LOG:-svc_overlay=info}"

log() { printf '[smoke] %s\n' "$*" >&2; }

ROOT_DIR="$(git rev-parse --show-toplevel 2>/dev/null || pwd)"
cd "$ROOT_DIR"

log "fmt + clippy"
cargo fmt -p svc-overlay
cargo clippy -p svc-overlay --no-deps -- -D warnings

RUN_LOG="target/svc-overlay.smoke.log"
: > "$RUN_LOG"

log "launching svc-overlay (logs → $RUN_LOG)"
RUST_LOG="$RUST_LOG" cargo run -p svc-overlay >"$RUN_LOG" 2>&1 &
SVC_PID=$!

cleanup() {
  set +e
  if kill -0 "$SVC_PID" >/dev/null 2>&1; then
    log "stopping svc-overlay (pid $SVC_PID)"
    kill "$SVC_PID" || true
    sleep 0.5
    kill -9 "$SVC_PID" 2>/dev/null || true
  fi
}
trap cleanup EXIT INT TERM

# Wait for /healthz
log "waiting for admin to be up at http://$ADMIN_ADDR/healthz"
for i in {1..60}; do
  if curl -sf "http://$ADMIN_ADDR/healthz" >/dev/null; then
    log "admin is up"
    break
  fi
  sleep 0.25
  if ! kill -0 "$SVC_PID" >/dev/null 2>&1; then
    log "svc-overlay terminated unexpectedly"
    tail -n 200 "$RUN_LOG" >&2 || true
    exit 1
  fi
  if [[ $i -eq 60 ]]; then
    log "timeout waiting for admin"
    tail -n 200 "$RUN_LOG" >&2 || true
    exit 1
  fi
done

# Helper to show key metrics
show_metrics() {
  curl -sSf "http://$ADMIN_ADDR/metrics" \
  | grep -E 'overlay_build_info|overlay_sessions_active|overlay_accept_latency_seconds_(count|sum)' \
  || true
}

log "initial metrics snapshot"
show_metrics

# Function to open a short-lived socket (which will handshake-timeout in ~3s)
short_socket() {
  # Use a subshell so we can background it cleanly
  (
    # macOS/BSD nc: -w <secs> is a write timeout; best effort: just sleep then exit
    # We want the server to see an accept and then a timeout/close
    exec nc "$(cut -d: -f1 <<<"$OVERLAY_ADDR")" "$(cut -d: -f2 <<<"$OVERLAY_ADDR")"
  ) &
  NC_PID=$!
  sleep 3.2
  kill -INT "$NC_PID" 2>/dev/null || true
  wait "$NC_PID" 2>/dev/null || true
}

# Function to open a long socket so we can watch the gauge at 1
long_socket_open() {
  (
    exec nc "$(cut -d: -f1 <<<"$OVERLAY_ADDR")" "$(cut -d: -f2 <<<"$OVERLAY_ADDR")"
  ) &
  echo $!
}

log "opening one long-lived socket to demonstrate overlay_sessions_active=1"
LONG_PID="$(long_socket_open)"
sleep 0.2
show_metrics

log "closing long-lived socket"
kill -INT "$LONG_PID" 2>/dev/null || true
wait "$LONG_PID" 2>/dev/null || true
sleep 0.2
show_metrics

log "opening two short-lived sockets to tick the latency histogram"
short_socket
show_metrics
short_socket
show_metrics

log "final metrics snapshot"
show_metrics

log "tail of runtime logs:"
tail -n 40 "$RUN_LOG" || true

log "done"

```

### crates/svc-overlay/scripts/soak_overlay.sh
<a id="crates-svc-overlay-scripts-soakoverlay-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# RO:WHAT  — Lightweight soak/chaos for svc-overlay echo path.
# RO:USAGE — ./crates/svc-overlay/scripts/soak_overlay.sh [seconds] [concurrency]
#            Defaults: 30s, 16 clients
# RO:NOTE  — Uses the existing oap_client example via the roundtrip driver.

DURATION="${1:-30}"
CONCURRENCY="${2:-16}"

echo "[soak] duration=${DURATION}s concurrency=${CONCURRENCY}"
echo "[soak] RON_OVERLAY_TX_WATERMARK=${RON_OVERLAY_TX_WATERMARK:-<default>} RON_OVERLAY_HANDSHAKE_MS=${RON_OVERLAY_HANDSHAKE_MS:-<default>}"

# Ensure server is up
if ! curl -fsS http://127.0.0.1:9600/healthz >/dev/null ; then
  echo "[soak] server not up on 127.0.0.1:9600 — start it first (e.g., cargo run -p svc-overlay)"
  exit 1
fi

# Warm baseline metrics
echo "[soak] baseline overlay_* sample:"
curl -fsS http://127.0.0.1:9600/metrics | rg '^overlay_' | head -n 20 || true

echo "[soak] kicking off clients…"
end=$(( SECONDS + DURATION ))
i=0
fails=0

run_client() {
  # Same client path the roundtrip script uses
  target/debug/examples/oap_client 127.0.0.1:9700 >/dev/null 2>&1 || return 1
  return 0
}

# Fire-and-forget workers
while [ $SECONDS -lt $end ]; do
  for _ in $(seq 1 "$CONCURRENCY"); do
    run_client & pid=$!
    pids+=("$pid")
  done
  # Reap in batches
  for p in "${pids[@]:-}"; do
    if ! wait "$p"; then
      fails=$((fails+1))
    fi
  done
  unset pids
  i=$((i+CONCURRENCY))
done

echo "[soak] completed launches: ${i}, failures: ${fails}"

echo "[soak] post-run overlay_* sample:"
curl -fsS http://127.0.0.1:9600/metrics | rg '^overlay_' | head -n 50 || true

echo "[soak] readiness snapshot:"
curl -fsS http://127.0.0.1:9600/readyz | jq .

```

### crates/svc-overlay/src/admin/health.rs
<a id="crates-svc-overlay-src-admin-health-rs"></a>

```rust
//! /healthz — liveness only (process loop tick).

use axum::{response::IntoResponse, Json};
use serde::Serialize;

#[derive(Serialize)]
struct Health {
    alive: bool,
}

pub async fn healthz() -> impl IntoResponse {
    Json(Health { alive: true })
}

```

### crates/svc-overlay/src/admin/metrics.rs
<a id="crates-svc-overlay-src-admin-metrics-rs"></a>

```rust
//! RO:WHAT
//!   Prometheus exporter for /metrics backed by the default registry.
//!
//! RO:WHY
//!   Self-initialize overlay metrics and build_info so the endpoint is never empty.
//!
//! RO:INTERACTS
//!   - Other modules bump overlay metrics via `overlay_metrics::*`.
//!
//! RO:INVARIANTS
//!   - Single global registry; encode errors return 500; no panics.

use axum::{
    http::{header, StatusCode},
    response::IntoResponse,
};
use once_cell::sync::Lazy;
use prometheus::{
    Encoder, Histogram, HistogramOpts, IntCounterVec, IntGauge, IntGaugeVec, Opts, Registry,
    TextEncoder,
};
use tracing::warn;

static GLOBAL_REGISTRY: Lazy<Registry> = Lazy::new(Registry::new);

fn ensure_registered() {
    let _ = &*OVERLAY_SESSIONS_ACTIVE;
    let _ = &*OVERLAY_ACCEPT_LATENCY_SECONDS;
    let _ = &*BUILD_INFO;
    let _ = &*OVERLAY_HANDSHAKE_FAIL_TOTAL;
    let _ = &*OVERLAY_PEER_TX_DROPPED_TOTAL;
    let _ = &*OVERLAY_PEER_TX_DEPTH;
    let _ = &*OVERLAY_CONN_LIFETIME_SECONDS;
}

static OVERLAY_SESSIONS_ACTIVE: Lazy<IntGauge> = Lazy::new(|| {
    let g = IntGauge::with_opts(Opts::new(
        "overlay_sessions_active",
        "Current number of active overlay sessions",
    ))
    .expect("gauge");
    GLOBAL_REGISTRY
        .register(Box::new(g.clone()))
        .expect("register overlay_sessions_active");
    g
});

static OVERLAY_ACCEPT_LATENCY_SECONDS: Lazy<Histogram> = Lazy::new(|| {
    let h = Histogram::with_opts(
        HistogramOpts::new(
            "overlay_accept_latency_seconds",
            "Time from accept to handshake start",
        )
        .buckets(vec![
            0.00005, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01,
        ]),
    )
    .expect("histogram");
    GLOBAL_REGISTRY
        .register(Box::new(h.clone()))
        .expect("register overlay_accept_latency_seconds");
    h
});

static OVERLAY_CONN_LIFETIME_SECONDS: Lazy<Histogram> = Lazy::new(|| {
    let h = Histogram::with_opts(HistogramOpts::new(
        "overlay_conn_lifetime_seconds",
        "Lifetime of a connection (from handshake ok to close)",
    ))
    .expect("histogram");
    GLOBAL_REGISTRY
        .register(Box::new(h.clone()))
        .expect("register overlay_conn_lifetime_seconds");
    h
});

static OVERLAY_HANDSHAKE_FAIL_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    let c = IntCounterVec::new(
        Opts::new(
            "overlay_handshake_fail_total",
            "Handshake failures by reason",
        ),
        &["reason"],
    )
    .expect("counter");
    GLOBAL_REGISTRY
        .register(Box::new(c.clone()))
        .expect("register overlay_handshake_fail_total");
    c
});

static OVERLAY_PEER_TX_DROPPED_TOTAL: Lazy<IntGauge> = Lazy::new(|| {
    let g = IntGauge::with_opts(Opts::new(
        "overlay_peer_dropped_total",
        "Total frames dropped due to full per-peer TX queue (process lifetime)",
    ))
    .expect("gauge");
    GLOBAL_REGISTRY
        .register(Box::new(g.clone()))
        .expect("register overlay_peer_dropped_total");
    g
});

static OVERLAY_PEER_TX_DEPTH: Lazy<IntGauge> = Lazy::new(|| {
    let g = IntGauge::with_opts(Opts::new(
        "overlay_peer_queue_depth",
        "Current per-peer TX queue depth (most recent writer task)",
    ))
    .expect("gauge");
    GLOBAL_REGISTRY
        .register(Box::new(g.clone()))
        .expect("register overlay_peer_queue_depth");
    g
});

static BUILD_INFO: Lazy<IntGaugeVec> = Lazy::new(|| {
    let v = IntGaugeVec::new(
        Opts::new(
            "overlay_build_info",
            "Build info for svc-overlay (value is always 1)",
        ),
        &["version", "git"],
    )
    .expect("gauge vec");
    GLOBAL_REGISTRY
        .register(Box::new(v.clone()))
        .expect("register overlay_build_info");
    v
});

pub mod overlay_metrics {
    use super::*;
    pub fn ensure() {
        super::ensure_registered();
    }
    pub fn inc_sessions_active() {
        OVERLAY_SESSIONS_ACTIVE.inc();
    }
    pub fn dec_sessions_active() {
        OVERLAY_SESSIONS_ACTIVE.dec();
    }
    pub fn accept_latency_seconds(v: f64) {
        OVERLAY_ACCEPT_LATENCY_SECONDS.observe(v);
    }
    pub fn conn_lifetime_seconds(v: f64) {
        OVERLAY_CONN_LIFETIME_SECONDS.observe(v);
    }
    pub fn handshake_fail(reason: &'static str) {
        OVERLAY_HANDSHAKE_FAIL_TOTAL
            .with_label_values(&[reason])
            .inc();
    }
    pub fn set_build_info(version: &'static str, git: &'static str) {
        BUILD_INFO.with_label_values(&[version, git]).set(1);
    }
    pub fn set_peer_tx_depth(depth: usize) {
        OVERLAY_PEER_TX_DEPTH.set(depth as i64);
    }
    pub fn inc_peer_tx_dropped() {
        OVERLAY_PEER_TX_DROPPED_TOTAL.inc();
    }

    // NEW: lightweight getters for the sampler.
    pub fn get_peer_tx_depth() -> i64 {
        OVERLAY_PEER_TX_DEPTH.get()
    }
    pub fn get_sessions_active() -> i64 {
        OVERLAY_SESSIONS_ACTIVE.get()
    }
}

/// GET /metrics — Prometheus exposition format
pub async fn handle_metrics() -> impl IntoResponse {
    ensure_registered();

    let mut buf = Vec::with_capacity(64 * 1024);
    let encoder = TextEncoder::new();
    let metrics = prometheus::gather();
    if let Err(e) = encoder.encode(&metrics, &mut buf) {
        warn!(error=?e, "failed to encode prometheus metrics");
        return (
            StatusCode::INTERNAL_SERVER_ERROR,
            [("content-type", "text/plain")],
            "encode failed",
        )
            .into_response();
    }

    (
        StatusCode::OK,
        [(header::CONTENT_TYPE.as_str(), encoder.format_type())],
        buf,
    )
        .into_response()
}

```

### crates/svc-overlay/src/admin/mod.rs
<a id="crates-svc-overlay-src-admin-mod-rs"></a>

```rust
//! RO:WHAT
//!   Admin plane: router(), ReadyProbe gates, /healthz, /readyz, /version, /metrics.
//! RO:WHY
//!   Matches bootstrap’s expected API (router(probe, ver), ReadyProbe::set(..)).
//! RO:INVARIANTS
//!   - Truthful readiness: 200 only when all gates are satisfied.
//!   - Cheap atomics; /readyz lists missing gates when not ready.

use axum::{extract::State, response::IntoResponse, routing::get, Json, Router};
use serde::Serialize;
use std::net::SocketAddr;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;

pub mod metrics;
pub use metrics::handle_metrics;

pub mod version;
pub use version::{current_build_info, BuildInfo};

/// Readiness gates container (Arc so we can clone into tasks).
#[derive(Clone)]
pub struct ReadyProbe(Arc<ReadyInner>);

struct ReadyInner {
    listeners_bound: AtomicBool,
    metrics_bound: AtomicBool,
    cfg_loaded: AtomicBool,
    queues_ok: AtomicBool,
    shed_rate_ok: AtomicBool,
    fd_headroom: AtomicBool,
}

/// Mutable view used by `ReadyProbe::set` to emulate your original closure API.
#[derive(Default)]
pub struct ReadyState {
    pub listeners_bound: bool,
    pub metrics_bound: bool,
    pub cfg_loaded: bool,
    pub queues_ok: bool,
    pub shed_rate_ok: bool,
    pub fd_headroom: bool,
}

impl Default for ReadyProbe {
    fn default() -> Self {
        Self::new()
    }
}

impl ReadyProbe {
    pub fn new() -> Self {
        Self(Arc::new(ReadyInner {
            listeners_bound: AtomicBool::new(false),
            metrics_bound: AtomicBool::new(false),
            cfg_loaded: AtomicBool::new(false),
            queues_ok: AtomicBool::new(true),
            shed_rate_ok: AtomicBool::new(true),
            fd_headroom: AtomicBool::new(true),
        }))
    }

    #[inline]
    pub fn set_listeners_bound(&self, v: bool) {
        self.0.listeners_bound.store(v, Ordering::Relaxed);
    }
    #[inline]
    pub fn set_metrics_bound(&self, v: bool) {
        self.0.metrics_bound.store(v, Ordering::Relaxed);
    }
    #[inline]
    pub fn set_cfg_loaded(&self, v: bool) {
        self.0.cfg_loaded.store(v, Ordering::Relaxed);
    }
    #[inline]
    pub fn set_queues_ok(&self, v: bool) {
        self.0.queues_ok.store(v, Ordering::Relaxed);
    }
    #[inline]
    pub fn set_shed_rate_ok(&self, v: bool) {
        self.0.shed_rate_ok.store(v, Ordering::Relaxed);
    }
    #[inline]
    pub fn set_fd_headroom(&self, v: bool) {
        self.0.fd_headroom.store(v, Ordering::Relaxed);
    }

    /// API compatibility shim for prior `probe.set(|s| s.<gate> = ..).await` usage.
    /// This is `async` to match call sites; it performs stores immediately.
    pub async fn set<F>(&self, f: F)
    where
        F: FnOnce(&mut ReadyState),
    {
        // snapshot
        let mut st = ReadyState {
            listeners_bound: self.0.listeners_bound.load(Ordering::Relaxed),
            metrics_bound: self.0.metrics_bound.load(Ordering::Relaxed),
            cfg_loaded: self.0.cfg_loaded.load(Ordering::Relaxed),
            queues_ok: self.0.queues_ok.load(Ordering::Relaxed),
            shed_rate_ok: self.0.shed_rate_ok.load(Ordering::Relaxed),
            fd_headroom: self.0.fd_headroom.load(Ordering::Relaxed),
        };
        // mutate
        f(&mut st);
        // store
        self.0
            .listeners_bound
            .store(st.listeners_bound, Ordering::Relaxed);
        self.0
            .metrics_bound
            .store(st.metrics_bound, Ordering::Relaxed);
        self.0.cfg_loaded.store(st.cfg_loaded, Ordering::Relaxed);
        self.0.queues_ok.store(st.queues_ok, Ordering::Relaxed);
        self.0
            .shed_rate_ok
            .store(st.shed_rate_ok, Ordering::Relaxed);
        self.0.fd_headroom.store(st.fd_headroom, Ordering::Relaxed);
    }

    fn snapshot(&self) -> Gates {
        Gates {
            listeners_bound: self.0.listeners_bound.load(Ordering::Relaxed),
            metrics_bound: self.0.metrics_bound.load(Ordering::Relaxed),
            cfg_loaded: self.0.cfg_loaded.load(Ordering::Relaxed),
            queues_ok: self.0.queues_ok.load(Ordering::Relaxed),
            shed_rate_ok: self.0.shed_rate_ok.load(Ordering::Relaxed),
            fd_headroom: self.0.fd_headroom.load(Ordering::Relaxed),
        }
    }
}

#[derive(Clone)]
pub struct AdminState {
    pub probe: ReadyProbe,
    pub build: BuildInfo,
}

#[derive(Serialize)]
struct Health {
    alive: bool,
}

async fn handle_healthz() -> Json<Health> {
    Json(Health { alive: true })
}

#[derive(Serialize)]
struct ReadyBody<'a> {
    ready: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    missing: Option<&'a [&'a str]>,
}

#[derive(Default)]
struct Gates {
    listeners_bound: bool,
    metrics_bound: bool,
    cfg_loaded: bool,
    queues_ok: bool,
    shed_rate_ok: bool,
    fd_headroom: bool,
}

impl Gates {
    fn all_ready(&self) -> bool {
        self.listeners_bound
            && self.metrics_bound
            && self.cfg_loaded
            && self.queues_ok
            && self.shed_rate_ok
            && self.fd_headroom
    }
    fn missing(&self) -> Vec<&'static str> {
        let mut v = Vec::with_capacity(6);
        if !self.listeners_bound {
            v.push("listeners_bound");
        }
        if !self.metrics_bound {
            v.push("metrics_bound");
        }
        if !self.cfg_loaded {
            v.push("cfg_loaded");
        }
        if !self.queues_ok {
            v.push("queues_ok");
        }
        if !self.shed_rate_ok {
            v.push("shed_rate_ok");
        }
        if !self.fd_headroom {
            v.push("fd_headroom");
        }
        v
    }
}

async fn handle_readyz(State(state): State<AdminState>) -> impl IntoResponse {
    use axum::http::StatusCode;
    let snap = state.probe.snapshot();
    if snap.all_ready() {
        (
            StatusCode::OK,
            Json(ReadyBody {
                ready: true,
                missing: None,
            }),
        )
            .into_response()
    } else {
        let miss = snap.missing();
        (
            StatusCode::SERVICE_UNAVAILABLE,
            Json(ReadyBody {
                ready: false,
                missing: Some(&miss),
            }),
        )
            .into_response()
    }
}

/// Build the admin router with state and handlers (what bootstrap expects).
pub fn router(probe: ReadyProbe, build: BuildInfo) -> Router {
    let state = AdminState { probe, build };
    Router::new()
        .route("/healthz", get(handle_healthz))
        .route("/readyz", get(handle_readyz))
        .route("/version", get(version::handle_version))
        .route("/metrics", get(metrics::handle_metrics))
        .with_state(state)
}

/// Helper to run the admin plane on an address.
pub async fn serve_admin(
    bind: SocketAddr,
    probe: ReadyProbe,
    build: BuildInfo,
) -> anyhow::Result<()> {
    let app = router(probe, build);
    let listener = tokio::net::TcpListener::bind(bind).await?;
    tracing::info!(addr=?bind, "admin server listening");
    axum::serve(listener, app).await?;
    Ok(())
}

```

### crates/svc-overlay/src/admin/ready.rs
<a id="crates-svc-overlay-src-admin-ready-rs"></a>

```rust
//! /readyz — truthful readiness gate. JSON schema kept stable.

use axum::{extract::State, response::IntoResponse, Json};
use serde::Serialize;
use std::sync::Arc;
use tokio::sync::RwLock;

#[derive(Clone, Default)]
pub struct ReadyProbe(Arc<RwLock<ReadyState>>);

#[derive(Default, Clone)]
pub struct ReadyState {
    pub listeners_bound: bool,
    pub metrics_bound: bool,
    pub cfg_loaded: bool,
    pub queues_ok: bool,
    pub shed_rate_ok: bool,
    pub fd_headroom: bool,
    pub pq_ready: Option<bool>,
    pub tor_bootstrap: Option<bool>,
}

impl ReadyProbe {
    pub fn new() -> Self {
        Self::default()
    }

    pub async fn set<F: FnOnce(&mut ReadyState)>(&self, f: F) {
        let mut g = self.0.write().await;
        f(&mut g);
    }

    pub async fn snapshot(&self) -> ReadyState {
        self.0.read().await.clone()
    }
}

#[derive(Serialize)]
#[serde(rename_all = "camelCase")]
struct ReadyResp {
    ready: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    degraded: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    missing: Option<Vec<&'static str>>,
    #[serde(skip_serializing_if = "Option::is_none")]
    retry_after: Option<u64>,
}

#[inline]
fn need(flag: bool, name: &'static str, out: &mut Vec<&'static str>) {
    if !flag {
        out.push(name);
    }
}

/// Axum handler for `/readyz`.
pub async fn readyz(State(probe): State<ReadyProbe>) -> impl IntoResponse {
    let s = probe.snapshot().await;
    let mut missing = Vec::new();

    need(s.listeners_bound, "listeners_bound", &mut missing);
    need(s.metrics_bound, "metrics_bound", &mut missing);
    need(s.cfg_loaded, "cfg_loaded", &mut missing);
    need(s.queues_ok, "queues_ok", &mut missing);
    need(s.shed_rate_ok, "shed_rate_ok", &mut missing);
    need(s.fd_headroom, "fd_headroom", &mut missing);
    if let Some(false) = s.pq_ready {
        missing.push("pq_ready");
    }
    if let Some(false) = s.tor_bootstrap {
        missing.push("tor_bootstrap");
    }

    if missing.is_empty() {
        (
            axum::http::StatusCode::OK,
            Json(ReadyResp {
                ready: true,
                degraded: None,
                missing: None,
                retry_after: None,
            }),
        )
    } else {
        (
            axum::http::StatusCode::SERVICE_UNAVAILABLE,
            Json(ReadyResp {
                ready: false,
                degraded: Some(true),
                missing: Some(missing),
                retry_after: Some(5),
            }),
        )
    }
}

```

### crates/svc-overlay/src/admin/version.rs
<a id="crates-svc-overlay-src-admin-version-rs"></a>

```rust
//! RO:WHAT
//!   Build metadata surface (type + handler) for /version.
//! RO:WHY
//!   Bootstrap expects `BuildInfo` and `admin::router(probe, ver)`.
//! RO:INVARIANTS
//!   - Safe if git/build envs are missing (fall back to "unknown").

use axum::{extract::State, response::IntoResponse, Json};
use serde::Serialize;

/// Static build metadata carried in admin state.
#[derive(Clone, Copy, Serialize)]
pub struct BuildInfo {
    pub version: &'static str,
    pub git: &'static str,
    pub build: &'static str,
    pub features: &'static [&'static str],
}

/// Construct BuildInfo from compile-time env (fallbacks allowed).
pub fn current_build_info() -> BuildInfo {
    BuildInfo {
        version: env!("CARGO_PKG_VERSION"),
        git: option_env!("GIT_SHA").unwrap_or("unknown"),
        build: option_env!("BUILD_TS").unwrap_or("unknown"),
        features: &[
            // e.g., "tls", "quic", "pq", "amnesia"
        ],
    }
}

/// GET /version — returns the build info from AdminState.
pub async fn handle_version(State(state): State<crate::admin::AdminState>) -> impl IntoResponse {
    Json(state.build)
}

```

### crates/svc-overlay/src/api/mod.rs
<a id="crates-svc-overlay-src-api-mod-rs"></a>

```rust
//! RO:WHAT — Minimal lib API surface (feature `libapi`)
#![allow(dead_code)]
use anyhow::Result;
use crate::{config::Config, readiness::HealthGate, bootstrap::start_runtime};

#[cfg(feature = "libapi")]
pub struct OverlayHandle(pub(crate) crate::supervisor::OverlayRuntime);

#[cfg(feature = "libapi")]
pub async fn spawn(cfg: Config) -> Result<OverlayHandle> {
    let hg = HealthGate::new();
    let rt = start_runtime(cfg, hg).await?;
    Ok(OverlayHandle(rt))
}

#[cfg(feature = "libapi")]
impl OverlayHandle {
    pub async fn shutdown(self) -> Result<()> { self.0.shutdown().await }
}

```

### crates/svc-overlay/src/auth/macaroon.rs
<a id="crates-svc-overlay-src-auth-macaroon-rs"></a>

```rust
//! RO:WHAT — Macaroon-based capability checks (stub)
#![allow(dead_code)]
pub fn verify_capability(_cap: &str) -> bool {
    true
}

```

### crates/svc-overlay/src/auth/mod.rs
<a id="crates-svc-overlay-src-auth-mod-rs"></a>

```rust
//! RO:WHAT — AuthN/Z surface
pub mod macaroon;

```

### crates/svc-overlay/src/bootstrap.rs
<a id="crates-svc-overlay-src-bootstrap-rs"></a>

```rust
//! Boot wiring for tracing + admin server.

use crate::admin::version::BuildInfo;
use crate::admin::{self, ReadyProbe};
use axum::Router;
use std::net::SocketAddr;
use tokio::net::TcpListener;
use tracing::{info, Level};
use tracing_subscriber::{fmt, EnvFilter};

pub struct AdminServer {
    pub addr: SocketAddr,
    handle: tokio::task::JoinHandle<anyhow::Result<()>>,
}

impl AdminServer {
    pub async fn spawn(
        bind: SocketAddr,
        probe: ReadyProbe,
        ver: BuildInfo,
    ) -> anyhow::Result<Self> {
        let app: Router = admin::router(probe, ver);
        let listener = TcpListener::bind(bind).await?;
        let addr = listener.local_addr()?;
        let handle = tokio::spawn(async move {
            axum::serve(listener, app).await?;
            Ok::<_, anyhow::Error>(())
        });
        info!("admin server listening on {}", addr);
        Ok(Self { addr, handle })
    }

    pub async fn join(self) -> anyhow::Result<()> {
        self.handle.await??;
        Ok(())
    }
}

/// Install JSON tracing with an env-filter override.
/// Example: `RUST_LOG=svc-overlay=debug,axum=warn`
pub fn init_tracing(default_level: &str) {
    let filter =
        EnvFilter::try_from_default_env().unwrap_or_else(|_| EnvFilter::new(default_level));
    fmt()
        .with_max_level(Level::INFO)
        .with_env_filter(filter)
        .json()
        .with_current_span(true)
        .with_span_list(true)
        .flatten_event(true)
        .init();
}

/// Start the minimal gossip engine and register the global publish hook.
/// Returns the spawned worker task so supervisors can hold/join it.
pub fn start_gossip_engine(capacity: usize) -> tokio::task::JoinHandle<()> {
    let (gossip, task) = crate::gossip::GossipEngine::start(capacity);
    gossip.install_global();
    info!("gossip engine online (cap={})", capacity);
    task
}

```

### crates/svc-overlay/src/cli.rs
<a id="crates-svc-overlay-src-cli-rs"></a>

```rust
//! RO:WHAT — CLI surface (env-first, minimal flags placeholder)
#![allow(dead_code)]
pub struct Cli {}
impl Cli {
    pub fn parse() -> Self {
        Self {}
    }
}

```

### crates/svc-overlay/src/config.rs
<a id="crates-svc-overlay-src-config-rs"></a>

```rust
//! RO:WHAT — Config loader/validator
use anyhow::{anyhow, bail, Result};
use std::{net::SocketAddr, time::Duration};

#[derive(Clone, Debug)]
pub struct Admin {
    pub http_addr: SocketAddr,
    pub metrics_addr: SocketAddr,
}

#[derive(Clone, Debug)]
pub struct TransportCfg {
    pub addr: SocketAddr,
    pub name: &'static str,
    pub read_timeout: Duration,
    pub idle_timeout: Duration,
    pub max_conns: usize,
    // TLS/QUIC/Tor knobs can be added here and mapped to ron-transport features
}

#[derive(Clone, Debug)]
pub struct Config {
    pub admin: Admin,
    pub transport: TransportCfg,
    pub oap_max_frame: usize,
    pub send_window_frames: u32,
    pub recv_window_frames: u32,
    pub amnesia: bool,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            admin: Admin {
                http_addr: "127.0.0.1:9600".parse().unwrap(),
                metrics_addr: "127.0.0.1:9601".parse().unwrap(),
            },
            transport: TransportCfg {
                addr: "127.0.0.1:9700".parse().unwrap(),
                name: "svc-overlay",
                read_timeout: Duration::from_secs(5),
                idle_timeout: Duration::from_secs(30),
                max_conns: 1024,
            },
            oap_max_frame: 1 << 20,
            send_window_frames: 16,
            recv_window_frames: 16,
            amnesia: false,
        }
    }
}

impl Config {
    /// Minimal env loader; expand per your CONFIG.MD later.
    pub fn from_env_and_cli() -> Result<Self> {
        let mut c = Self::default();
        if let Ok(addr) = std::env::var("SVC_OVERLAY_HTTP_ADDR") {
            c.admin.http_addr = addr.parse().map_err(|e| anyhow!("bad http addr: {e}"))?;
        }
        if let Ok(addr) = std::env::var("SVC_OVERLAY_METRICS_ADDR") {
            c.admin.metrics_addr = addr.parse().map_err(|e| anyhow!("bad metrics addr: {e}"))?;
        }
        if let Ok(addr) = std::env::var("SVC_OVERLAY_LISTEN_ADDR") {
            c.transport.addr = addr.parse().map_err(|e| anyhow!("bad listen addr: {e}"))?;
        }
        if let Ok(n) = std::env::var("SVC_OVERLAY_MAX_CONNS") {
            c.transport.max_conns = n.parse().map_err(|e| anyhow!("bad max conns: {e}"))?;
        }
        c.validate()?;
        Ok(c)
    }

    pub fn validate(&self) -> Result<()> {
        if self.oap_max_frame == 0 || self.oap_max_frame > (1 << 20) {
            bail!("oap_max_frame must be 1..=1MiB");
        }
        if self.transport.max_conns == 0 {
            bail!("transport.max_conns must be > 0");
        }
        Ok(())
    }
}

```

### crates/svc-overlay/src/conn/error.rs
<a id="crates-svc-overlay-src-conn-error-rs"></a>

```rust
//! RO:WHAT — Connection-level errors.

use thiserror::Error;

#[derive(Debug, Error)]
pub enum ConnError {
    #[error("io: {0}")]
    Io(#[from] std::io::Error),

    #[error(transparent)]
    Proto(#[from] crate::protocol::error::ProtoError),
}

pub type ConnResult<T> = Result<T, ConnError>;

```

### crates/svc-overlay/src/conn/mod.rs
<a id="crates-svc-overlay-src-conn-mod-rs"></a>

```rust
//! RO:WHAT — Connection tasks (reader/writer queues and supervision)

pub mod error;
pub mod reader;
pub mod supervisor;
pub mod tx;
pub mod writer;

```

### crates/svc-overlay/src/conn/reader.rs
<a id="crates-svc-overlay-src-conn-reader-rs"></a>

```rust
//! RO:WHAT — Read loop: accumulates bytes, decodes OAP frames.

use bytes::BytesMut;
use tokio::io::{AsyncRead, AsyncReadExt};
use tracing::{debug, trace};

use super::error::ConnResult;
use crate::protocol::oap::{try_parse_frame, FrameKind}; // <- keep only ConnResult

/// Blocking-ish read loop that parses frames and logs; returns on EOF or error.
/// Transport-agnostic: any AsyncRead works (TCP/TLS/QUIC streams that implement it).
pub async fn run_reader<R>(mut rd: R) -> ConnResult<()>
where
    R: AsyncRead + Unpin,
{
    let mut buf = BytesMut::with_capacity(8 * 1024);

    loop {
        // Try parse any already-buffered frames first.
        while let Some(frame) = try_parse_frame(&mut buf)? {
            match frame.kind {
                FrameKind::Data => {
                    debug!(len = frame.payload.len(), "oap/data frame");
                }
                FrameKind::Ctrl => {
                    debug!(len = frame.payload.len(), "oap/ctrl frame");
                }
            }
            trace!(buf_len = buf.len(), "post-parse buffer");
        }

        // Refill buffer. read_buf appends into BytesMut.
        let n = rd.read_buf(&mut buf).await?;
        if n == 0 {
            // EOF
            return Ok(());
        }
        trace!(read = n, buf_len = buf.len(), "read bytes");
    }
}

```

### crates/svc-overlay/src/conn/supervisor.rs
<a id="crates-svc-overlay-src-conn-supervisor-rs"></a>

```rust
//! RO:WHAT — Per-connection supervisor (stub)
#![allow(dead_code)]

```

### crates/svc-overlay/src/conn/tx.rs
<a id="crates-svc-overlay-src-conn-tx-rs"></a>

```rust
//! RO:WHAT — Bounded per-connection TX queue with single-writer task.
//! RO:WHY  — Enforces single-writer discipline and exposes queue depth/drops.
//! RO:INTERACTS — conn::writer::write_frame, admin::metrics::overlay_metrics
//! RO:INVARIANTS — one writer per connection; bounded mpsc; no locks across .await
//! RO:METRICS — overlay_peer_queue_depth, overlay_peer_dropped_total
//! RO:TEST — covered indirectly by roundtrip; unit tests can enqueue/close

use bytes::BytesMut;
use tokio::io::AsyncWrite;
use tokio::sync::mpsc;
use tokio::task::JoinHandle;
use tracing::{debug, warn};

use crate::admin::metrics::overlay_metrics;
use crate::protocol::oap::Frame;

/// Message to the writer task.
pub enum TxMsg {
    Frame(Frame),
    Close,
}

/// Handle to enqueue frames for a single connection.
#[derive(Clone)]
pub struct TxSender {
    tx: mpsc::Sender<TxMsg>,
}

impl TxSender {
    pub fn capacity(&self) -> usize {
        self.tx.capacity()
    }

    pub fn try_send(&self, frame: Frame) -> Result<(), Frame> {
        match self.tx.try_send(TxMsg::Frame(frame)) {
            Ok(_) => {
                overlay_metrics::set_peer_tx_depth(self.tx.max_capacity() - self.tx.capacity());
                Ok(())
            }
            Err(mpsc::error::TrySendError::Full(TxMsg::Frame(f))) => {
                overlay_metrics::inc_peer_tx_dropped();
                Err(f)
            }
            Err(mpsc::error::TrySendError::Closed(TxMsg::Frame(f))) => Err(f),
            Err(_) => unreachable!("only Frame variants used here"),
        }
    }

    pub async fn send(&self, frame: Frame) -> Result<(), Frame> {
        // Avoid use-after-move by staging in an Option.
        let mut slot = Some(frame);
        match self.tx.send(TxMsg::Frame(slot.take().unwrap())).await {
            Ok(_) => {
                overlay_metrics::set_peer_tx_depth(self.tx.max_capacity() - self.tx.capacity());
                Ok(())
            }
            Err(mpsc::error::SendError(TxMsg::Frame(f))) => Err(f),
            Err(_) => unreachable!("only Frame variants used here"),
        }
    }
}

/// Spawn a writer task which OWNS the AsyncWrite half (single-writer discipline).
pub fn spawn_writer<W>(mut wr: W, bound: usize) -> (TxSender, JoinHandle<()>)
where
    W: AsyncWrite + Unpin + Send + 'static,
{
    let (tx, mut rx) = mpsc::channel::<TxMsg>(bound);
    let handle = tokio::spawn(async move {
        let mut scratch = BytesMut::with_capacity(8 * 1024);
        while let Some(msg) = rx.recv().await {
            match msg {
                TxMsg::Frame(frame) => {
                    if let Err(e) =
                        crate::conn::writer::write_frame(&mut wr, &frame, &mut scratch).await
                    {
                        warn!(error=?e, "writer: write failed — closing");
                        break;
                    }
                    overlay_metrics::set_peer_tx_depth(rx.max_capacity() - rx.capacity());
                }
                TxMsg::Close => {
                    debug!("writer: close requested");
                    break;
                }
            }
        }
    });
    (TxSender { tx }, handle)
}

```

### crates/svc-overlay/src/conn/writer.rs
<a id="crates-svc-overlay-src-conn-writer-rs"></a>

```rust
//! RO:WHAT — Writer helpers: encode frames and flush.

use bytes::BytesMut;
use tokio::io::{AsyncWrite, AsyncWriteExt};

use super::error::ConnResult;
use crate::protocol::oap::Frame; // <- keep only ConnResult

/// Encode a frame into a scratch buffer and write it out atomically.
pub async fn write_frame<W>(wr: &mut W, frame: &Frame, scratch: &mut BytesMut) -> ConnResult<()>
where
    W: AsyncWrite + Unpin,
{
    scratch.clear();
    frame.encode_to(scratch)?;
    wr.write_all(scratch).await?;
    wr.flush().await?;
    Ok(())
}

```

### crates/svc-overlay/src/errors.rs
<a id="crates-svc-overlay-src-errors-rs"></a>

```rust
//! RO:WHAT — Error taxonomy
use thiserror::Error;

#[derive(Error, Debug)]
pub enum Error {
    #[error("protocol: {0}")]
    Protocol(String),
}

```

### crates/svc-overlay/src/gossip/engine.rs
<a id="crates-svc-overlay-src-gossip-engine-rs"></a>

```rust
//! RO:WHAT — Minimal gossip engine: bounded ingress queue + background worker.
//! RO:WHY  — Provide a place to route/process `Data` frames beyond the echo demo.
//! RO:INVARIANTS — Non-blocking publish; backpressure via bounded channel; best-effort drop on full.

use bytes::Bytes;
use once_cell::sync::OnceCell;
use tokio::sync::mpsc;
use tokio::task::JoinHandle;
use tracing::{debug, warn};

/// Global publishing hook (optional). Listener can publish without holding an Engine instance.
static GLOBAL_TX: OnceCell<mpsc::Sender<Bytes>> = OnceCell::new();

#[derive(Clone)]
pub struct GossipEngine {
    tx: mpsc::Sender<Bytes>,
}

impl GossipEngine {
    /// Start the engine with bounded capacity and spawn the worker task.
    pub fn start(capacity: usize) -> (Self, JoinHandle<()>) {
        let (tx, mut rx) = mpsc::channel::<Bytes>(capacity);
        let me = Self { tx: tx.clone() };

        let task = tokio::spawn(async move {
            // Minimal worker: log and count. Later: route, dedupe, fanout.
            while let Some(msg) = rx.recv().await {
                debug!(len = msg.len(), "gossip: received message");
                metrics::counter!("gossip_ingress_total").increment(1);
                metrics::counter!("gossip_ingress_bytes_total").increment(msg.len() as u64);
                // TODO: plumb to per-topic queues or peers.
            }
            // Channel closed → shutdown path.
            warn!("gossip: worker exiting (channel closed)");
        });

        (me, task)
    }

    /// Install this engine as the global publisher target.
    pub fn install_global(&self) {
        let _ = GLOBAL_TX.set(self.tx.clone());
    }

    /// Try to publish a message (drops if queue is full).
    pub fn try_publish(&self, msg: Bytes) -> bool {
        match self.tx.try_send(msg) {
            Ok(()) => true,
            Err(mpsc::error::TrySendError::Full(_)) => {
                metrics::counter!("gossip_dropped_total", "reason" => "full").increment(1);
                false
            }
            Err(mpsc::error::TrySendError::Closed(_)) => {
                metrics::counter!("gossip_dropped_total", "reason" => "closed").increment(1);
                false
            }
        }
    }
}

/// Publish through the global hook (if installed).
pub fn publish(msg: Bytes) -> bool {
    if let Some(tx) = GLOBAL_TX.get() {
        match tx.try_send(msg) {
            Ok(()) => {
                metrics::counter!("gossip_ingress_total").increment(1);
                true
            }
            Err(mpsc::error::TrySendError::Full(_)) => {
                metrics::counter!("gossip_dropped_total", "reason" => "full").increment(1);
                false
            }
            Err(mpsc::error::TrySendError::Closed(_)) => {
                metrics::counter!("gossip_dropped_total", "reason" => "closed").increment(1);
                false
            }
        }
    } else {
        metrics::counter!("gossip_dropped_total", "reason" => "unset").increment(1);
        false
    }
}

```

### crates/svc-overlay/src/gossip/mod.rs
<a id="crates-svc-overlay-src-gossip-mod-rs"></a>

```rust
//! RO:WHAT — Gossip module
pub mod engine;
pub use engine::{publish, GossipEngine};
pub mod types;

```

### crates/svc-overlay/src/gossip/types.rs
<a id="crates-svc-overlay-src-gossip-types-rs"></a>

```rust
//! RO:WHAT — Gossip types
#![allow(dead_code)]
use bytes::Bytes;
pub type GossipMsg = Bytes;

```

### crates/svc-overlay/src/lib.rs
<a id="crates-svc-overlay-src-lib-rs"></a>

```rust
//! RO:WHAT — Library entry for svc-overlay
#![forbid(unsafe_code)]

pub mod admin;
pub mod auth;
pub mod bootstrap;
pub mod cli;
pub mod config;
pub mod conn;
pub mod errors;
pub mod gossip;
pub mod limits;
pub mod listener;
pub mod observe;
pub mod pq;
pub mod protocol;
pub mod readiness;
pub mod shutdown;
pub mod supervisor;
pub mod transport;
pub mod tuning;
pub mod types;

use tracing_subscriber::{fmt, EnvFilter};

pub fn init_tracing() {
    let filter = EnvFilter::from_default_env().add_directive(
        "svc_overlay=info"
            .parse()
            .unwrap_or_else(|_| "info".parse().unwrap()),
    );
    let _ = fmt()
        .with_env_filter(filter)
        .json()
        .flatten_event(true)
        .try_init();
}

```

### crates/svc-overlay/src/limits.rs
<a id="crates-svc-overlay-src-limits-rs"></a>

```rust
//! RO:WHAT — Service limits (constants)
pub const MAX_FRAME_BYTES: usize = 1 << 20; // 1 MiB

```

### crates/svc-overlay/src/listener/mod.rs
<a id="crates-svc-overlay-src-listener-mod-rs"></a>

```rust
//! RO:WHAT — Listener module entry.
//! RO:WHY  — Keep a single listener implementation in `plain.rs` that delegates
//!           transport concerns to `crate::transport` (facade).
//! RO:CFG  — No cfgs here. The `use_ron_transport` feature is implemented in
//!           the transport facade, not at the listener boundary.

pub mod plain;

// Re-export the public API expected by bootstrap.
pub use plain::{spawn_listener, ListenerHandle};

```

### crates/svc-overlay/src/listener/plain.rs
<a id="crates-svc-overlay-src-listener-plain-rs"></a>

```rust
//! RO:WHAT — Overlay listener using transport facade + metrics.
//! RO:NEXT — When `transport` facade switches to ron-transport, no changes needed here.
//! RO:INVARIANTS — one writer per connection; bounded queue; no locks across .await

use crate::admin::metrics::overlay_metrics;
use crate::admin::ReadyProbe;
use crate::config::Config;
use crate::conn::tx::spawn_writer;
use crate::gossip::publish;
use crate::protocol::flags::Caps;
use crate::protocol::handshake::handshake;
use crate::protocol::oap::{try_parse_frame, Frame, FrameKind};
use crate::transport::{bind_listener, TransportStream};
use crate::tuning; // <— NEW

use anyhow::Result;
use bytes::BytesMut;
use std::net::SocketAddr;
use std::time::Instant;
use tokio::io::AsyncReadExt;
use tokio::net::tcp::OwnedReadHalf;
use tokio::task::JoinHandle;
use tokio::time::Duration;
use tracing::{error, info, trace, warn, Instrument};

pub struct ListenerHandle {
    addr: SocketAddr,
    task: JoinHandle<()>,
}

impl ListenerHandle {
    pub fn addr(&self) -> SocketAddr {
        self.addr
    }
    pub async fn shutdown(self) -> Result<()> {
        self.task.abort();
        Ok(())
    }
}

/// Observe "accept → handshake start" latency even if early-return happens.
struct AcceptTimer {
    start: Instant,
    observed: bool,
}
impl AcceptTimer {
    fn start() -> Self {
        Self {
            start: Instant::now(),
            observed: false,
        }
    }
    fn observe_once(&mut self) {
        if !self.observed {
            overlay_metrics::accept_latency_seconds(self.start.elapsed().as_secs_f64());
            self.observed = true;
        }
    }
}
impl Drop for AcceptTimer {
    fn drop(&mut self) {
        self.observe_once();
    }
}

pub async fn spawn_listener(cfg: &Config, probe: &ReadyProbe) -> Result<ListenerHandle> {
    let (listener, addr) = bind_listener(cfg.transport.addr).await?;
    info!(%addr, "overlay listener bound");
    probe.set(|s| s.listeners_bound = true).await;

    // Readiness sampler — flips `queues_ok` based on TX queue depth.
    let probe_clone = probe.clone();
    tokio::spawn(async move {
        loop {
            let depth = overlay_metrics::get_peer_tx_depth();
            let active = overlay_metrics::get_sessions_active();
            let watermark = tuning::tx_queue_watermark(); // <— NEW
            let ok = if active > 0 { depth < watermark } else { true };
            probe_clone.set(|s| s.queues_ok = ok).await;
            tokio::time::sleep(Duration::from_millis(200)).await;
        }
    });

    let task = tokio::spawn(async move {
        loop {
            match listener.accept().await {
                Ok((stream, peer)) => {
                    metrics::counter!("overlay_connections_total").increment(1);
                    overlay_metrics::inc_sessions_active();
                    tokio::spawn(handle_conn(peer, stream).in_current_span());
                }
                Err(e) => {
                    warn!(error=?e, "accept failed");
                    tokio::time::sleep(Duration::from_millis(50)).await;
                }
            }
        }
    });

    Ok(ListenerHandle { addr, task })
}

async fn handle_conn(peer: SocketAddr, mut stream: TransportStream) {
    let mut accept_timer = AcceptTimer::start();

    // Handshake on the unified stream first (before splitting).
    {
        use tokio::io::{AsyncRead, AsyncWrite};

        trait HandshakeBorrow {
            type Dyn: AsyncRead + AsyncWrite + Unpin;
            fn as_io_mut(&mut self) -> &mut Self::Dyn;
        }
        impl HandshakeBorrow for TransportStream {
            type Dyn = tokio::net::TcpStream;
            fn as_io_mut(&mut self) -> &mut Self::Dyn {
                &mut self.inner
            }
        }

        let caps = Caps::GOSSIP_V1;
        let tmo = tuning::handshake_timeout(); // <— NEW
        let _neg = match tokio::time::timeout(
            tmo,
            handshake(
                <TransportStream as HandshakeBorrow>::as_io_mut(&mut stream),
                caps,
                tmo,
            ),
        )
        .await
        {
            Ok(Ok(n)) => {
                accept_timer.observe_once();
                info!(%peer, ver = n.version, caps = ?n.caps, "conn: negotiated");
                n
            }
            Ok(Err(_e)) => {
                overlay_metrics::handshake_fail("io");
                warn!(%peer, "conn: handshake failed");
                overlay_metrics::dec_sessions_active();
                return;
            }
            Err(_elapsed) => {
                overlay_metrics::handshake_fail("timeout");
                warn!(%peer, "conn: handshake timeout");
                overlay_metrics::dec_sessions_active();
                return;
            }
        };
    }

    // Split into owned halves; writer task owns the write half.
    let (mut rd, wr) = stream.into_split();
    let (tx, _writer_task) = spawn_writer(wr, 128);

    // Reader loop: parse frames; echo Data via bounded TX; publish demo gossip.
    let mut inbuf = BytesMut::with_capacity(8 * 1024);
    let start_ok = Instant::now();

    async fn read_more(rd: &mut OwnedReadHalf, buf: &mut BytesMut) -> std::io::Result<usize> {
        rd.read_buf(buf).await
    }

    loop {
        // Drain any complete frames already in the buffer.
        while let Some(frame) = match try_parse_frame(&mut inbuf) {
            Ok(f) => f,
            Err(e) => {
                warn!(%peer, error=?e, "conn: frame parse error");
                overlay_metrics::dec_sessions_active();
                return;
            }
        } {
            match frame.kind {
                FrameKind::Data => {
                    publish(frame.payload.clone());
                    let echo = Frame {
                        kind: FrameKind::Data,
                        payload: frame.payload,
                    };
                    // On backpressure, drop and record.
                    if tx.try_send(echo).is_err() {
                        overlay_metrics::inc_peer_tx_dropped();
                    }
                }
                FrameKind::Ctrl => {
                    // TODO: handle control frames when defined
                }
            }
        }

        // Refill buffer from reader
        match read_more(&mut rd, &mut inbuf).await {
            Ok(0) => {
                let secs = start_ok.elapsed().as_secs_f64();
                overlay_metrics::conn_lifetime_seconds(secs);
                info!(%peer, dt_ms = (secs * 1000.0) as u64, "conn: closed");
                overlay_metrics::dec_sessions_active();
                return;
            }
            Ok(n) => {
                trace!(%peer, read = n, buf_len = inbuf.len(), "read bytes");
            }
            Err(e) => {
                error!(%peer, error=?e, "conn: read error");
                overlay_metrics::dec_sessions_active();
                return;
            }
        }
    }
}

```

### crates/svc-overlay/src/listener/ron.rs
<a id="crates-svc-overlay-src-listener-ron-rs"></a>

```rust
//! RO:WHAT — ron-transport listener (placeholder).
//! RO:NEXT — Replace delegation with real spawn using ron-transport once stream handoff API is set.

use crate::admin::ReadyProbe;
use crate::config::Config;
use anyhow::Result;

// For now, delegate to plain listener so enabling the feature doesn't break runtime.
// We keep the same public surface (spawn_listener, ListenerHandle).
pub(super) use super::plain::{spawn_listener, ListenerHandle};

```

### crates/svc-overlay/src/main.rs
<a id="crates-svc-overlay-src-main-rs"></a>

```rust
//! Binary entry: parse config, init tracing, run admin + overlay runtime.

use svc_overlay::admin::version::BuildInfo;
use svc_overlay::admin::ReadyProbe;
use svc_overlay::bootstrap;
use svc_overlay::config::Config;
use svc_overlay::supervisor::OverlayRuntime;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // 1) Config
    let cfg = Config::from_env_and_cli()?;
    cfg.validate()?;

    // 2) Tracing
    bootstrap::init_tracing("info");

    // 3) Admin server
    let probe = ReadyProbe::new();
    // Early boot truth; listener flips listeners_bound later.
    probe
        .set(|s| {
            s.metrics_bound = true; // Keep true: exporter can be added later
            s.cfg_loaded = true;
            s.listeners_bound = false;
            s.queues_ok = true;
            s.shed_rate_ok = true;
            s.fd_headroom = true;
        })
        .await;

    let build = BuildInfo {
        version: env!("CARGO_PKG_VERSION"),
        git: option_env!("GIT_SHA").unwrap_or("unknown"),
        build: option_env!("BUILD_TS").unwrap_or("unknown"),
        features: &[],
    };

    let admin = bootstrap::AdminServer::spawn(cfg.admin.http_addr, probe.clone(), build).await?;

    // 4) Overlay runtime (bind temporary TCP listener -> flips /readyz green)
    let overlay = OverlayRuntime::start(cfg.clone(), probe.clone()).await?;

    // 5) Wait until admin server exits (CTRL-C or test harness)
    admin.join().await?;

    // 6) Shutdown overlay
    overlay.shutdown().await?;

    Ok(())
}

```

### crates/svc-overlay/src/observe.rs
<a id="crates-svc-overlay-src-observe-rs"></a>

```rust
//! Observability bootstrap + metric helpers.
//! Contract: Prometheus exposition via /metrics with stable names/buckets.
//! See docs/OBSERVABILITY.md and API.MD for the golden set.
//
// NOTE: We intentionally avoid calling `metrics::*` macros here because the
// workspace currently pulls in two different `metrics` versions via
// `metrics-exporter-prometheus`, which causes type/trait conflicts.
// The `emit` helpers are kept as no-ops so call sites compile. Once we unify
// on a single `metrics` version across the workspace, we can flip these back
// on without changing call sites.

use metrics_exporter_prometheus::{Matcher, PrometheusBuilder, PrometheusHandle};
use once_cell::sync::OnceCell;
use std::net::SocketAddr;
use tracing::info;

// Global handle used by /metrics handler to render a scrape.
static PROM_HANDLE: OnceCell<PrometheusHandle> = OnceCell::new();

/// Install a Prometheus recorder and store a handle for /metrics scraping.
/// Returns the configured bind address (HTTP listener is owned by the exporter).
pub fn init_metrics(addr: SocketAddr) -> anyhow::Result<SocketAddr> {
    // Buckets aligned with docs: latency 5ms..5s, frame sizes up to 1MiB.
    let builder = PrometheusBuilder::new()
        .with_http_listener(addr)
        // metrics-exporter-prometheus 0.15 uses (Matcher, &[f64]) — set each metric separately.
        .set_buckets_for_metric(
            Matcher::Full("request_latency_seconds".into()),
            &[0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0],
        )?
        .set_buckets_for_metric(
            Matcher::Full("overlay_frame_size_bytes".into()),
            &[
                512.0,
                1024.0,
                4096.0,
                16384.0,
                65536.0,
                262_144.0,
                524_288.0,
                1_048_576.0,
            ],
        )?;

    // Start exporter + install recorder.
    let handle = builder.install_recorder()?;

    // Touch to ensure recorder is live (silence unused warnings).
    let _ = handle.render().len();

    // Store global handle for /metrics endpoint.
    let _ = PROM_HANDLE.set(handle);

    info!("metrics recorder installed on {}", addr);
    Ok(addr)
}

/// Render Prometheus metrics as text/plain; used by the HTTP handler.
pub fn render_prometheus() -> String {
    PROM_HANDLE
        .get()
        .map(|h| h.render())
        .unwrap_or_else(|| "# no recorder".to_string())
}

/// Canonical metric helpers (names stabilized here).
/// Currently NO-OPs to avoid `metrics` crate version conflicts.
/// Re-enable by replacing bodies with `metrics::*` macros once the workspace
/// is on a single `metrics` version.
pub mod emit {
    #[inline]
    pub fn http_req_total(_route: &'static str, _method: &'static str, _status: u16) {
        // NO-OP (see module docs)
    }

    #[inline]
    pub fn http_latency(_route: &'static str, _method: &'static str, _secs: f64) {
        // NO-OP (see module docs)
    }

    #[inline]
    pub fn ready_state(_val: i64) {
        // NO-OP (see module docs)
    }
}

```

### crates/svc-overlay/src/pq/mod.rs
<a id="crates-svc-overlay-src-pq-mod-rs"></a>

```rust
//! RO:WHAT — Post-quantum negotiation
pub mod negotiate;

```

### crates/svc-overlay/src/pq/negotiate.rs
<a id="crates-svc-overlay-src-pq-negotiate-rs"></a>

```rust
//! RO:WHAT — PQ negotiation stub
#![allow(dead_code)]
pub async fn negotiate() -> bool {
    true
}

```

### crates/svc-overlay/src/protocol/cbor.rs
<a id="crates-svc-overlay-src-protocol-cbor-rs"></a>

```rust
//! RO:WHAT — CBOR helpers for OAP (placeholder)
#![allow(dead_code)]

```

### crates/svc-overlay/src/protocol/error.rs
<a id="crates-svc-overlay-src-protocol-error-rs"></a>

```rust
//! RO:WHAT — Protocol-level errors (OAP/1 framing & handshake).
//! RO:INVARIANTS — No allocation bombs; errors are structured and non-panicking.

use thiserror::Error;

#[derive(Debug, Error)]
pub enum ProtoError {
    #[error("frame too large: {got} > {max} bytes")]
    FrameTooLarge { got: usize, max: usize },

    #[error("incomplete frame")]
    Incomplete,

    #[error("bad magic/version: got {got:?}")]
    BadPreamble { got: [u8; 5] },

    #[error("io: {0}")]
    Io(#[from] std::io::Error),

    #[error("handshake timeout")]
    HandshakeTimeout,

    #[error("capability mismatch")]
    CapabilityMismatch,
}

pub type ProtoResult<T> = Result<T, ProtoError>;

```

### crates/svc-overlay/src/protocol/flags.rs
<a id="crates-svc-overlay-src-protocol-flags-rs"></a>

```rust
//! RO:WHAT — OAP/1 capability flags used during handshake.
//! RO:WHY  — Keep overlay features discoverable and future-proof.

bitflags::bitflags! {
    #[derive(Debug, Clone, Copy, PartialEq, Eq)]
    pub struct Caps: u32 {
        const NONE        = 0;
        const GOSSIP_V1   = 1 << 0;
        const RESERVED_1  = 1 << 1;
        // Future: const PQ_HYBRID = 1 << 8;  // negotiated at overlay level; transport does TLS/PQ.
    }
}

impl Default for Caps {
    fn default() -> Self {
        Caps::GOSSIP_V1
    }
}

```

### crates/svc-overlay/src/protocol/handshake.rs
<a id="crates-svc-overlay-src-protocol-handshake-rs"></a>

```rust
//! RO:WHAT — Minimal OAP/1 handshake over any AsyncRead/Write stream.
//! RO:WHY  — Establish version & capability agreement before frames.
//! RO:INVARIANTS — Fixed-size preamble; bounded IO; timeout guarded.

use crate::protocol::error::{ProtoError, ProtoResult};
use crate::protocol::flags::Caps;
use tokio::io::{AsyncRead, AsyncReadExt, AsyncWrite, AsyncWriteExt};
use tokio::time::{timeout, Duration};

const MAGIC: &[u8; 4] = b"OAP1";
const WIRE_HELLO_LEN: usize = 4 /*MAGIC*/ + 1 /*ver*/ + 4 /*caps*/;
pub const VERSION: u8 = 1;

#[derive(Debug, Clone, Copy)]
pub struct Negotiated {
    pub version: u8,
    pub caps: Caps,
}

fn encode_hello(buf: &mut [u8; WIRE_HELLO_LEN], ver: u8, caps: Caps) {
    buf[0..4].copy_from_slice(MAGIC);
    buf[4] = ver;
    buf[5..9].copy_from_slice(&(caps.bits()).to_be_bytes());
}

fn decode_hello(buf: &[u8; WIRE_HELLO_LEN]) -> ProtoResult<(u8, Caps)> {
    if &buf[0..4] != MAGIC {
        return Err(ProtoError::BadPreamble {
            got: [buf[0], buf[1], buf[2], buf[3], buf[4]],
        });
    }
    let ver = buf[4];
    let mut caps_b = [0u8; 4];
    caps_b.copy_from_slice(&buf[5..9]);
    let caps = u32::from_be_bytes(caps_b);
    Ok((ver, Caps::from_bits_truncate(caps)))
}

/// Perform a 1-RTT symmetric hello exchange with a timeout.
pub async fn handshake<IO>(io: &mut IO, ours: Caps, dur: Duration) -> ProtoResult<Negotiated>
where
    IO: AsyncRead + AsyncWrite + Unpin,
{
    let mut buf_out = [0u8; WIRE_HELLO_LEN];
    let mut buf_in = [0u8; WIRE_HELLO_LEN];

    encode_hello(&mut buf_out, VERSION, ours);

    let fut = async {
        // Write our hello, then flush
        io.write_all(&buf_out).await?;
        io.flush().await?;

        // Read peer hello (exact len)
        io.read_exact(&mut buf_in).await?;
        ProtoResult::Ok(())
    };

    timeout(dur, fut)
        .await
        .map_err(|_| ProtoError::HandshakeTimeout)??;

    let (peer_ver, peer_caps) = decode_hello(&buf_in)?;
    if peer_ver != VERSION {
        return Err(ProtoError::BadPreamble {
            got: [buf_in[0], buf_in[1], buf_in[2], buf_in[3], buf_in[4]],
        });
    }

    // Minimal check: both must support GOSSIP_V1 for now.
    let needed = Caps::GOSSIP_V1;
    if !peer_caps.contains(needed) || !ours.contains(needed) {
        return Err(ProtoError::CapabilityMismatch);
    }

    Ok(Negotiated {
        version: peer_ver,
        caps: peer_caps & ours,
    })
}

```

### crates/svc-overlay/src/protocol/mod.rs
<a id="crates-svc-overlay-src-protocol-mod-rs"></a>

```rust
//! RO:WHAT — Protocol (OAP-1) framing/handshake surface
pub mod cbor;
pub mod error;
pub mod flags;
pub mod handshake;
pub mod oap;

```

### crates/svc-overlay/src/protocol/oap.rs
<a id="crates-svc-overlay-src-protocol-oap-rs"></a>

```rust
//! RO:WHAT — OAP/1 framing: length-prefixed frames with a kind byte.
//! RO:WHY  — Provide message boundaries over byte-stream transports.
//! RO:INVARIANTS — Max frame size is sourced from ron-proto; parsing is incremental & non-panicking.

use crate::protocol::error::{ProtoError, ProtoResult};
use bytes::{Buf, BufMut, Bytes, BytesMut};

/// Canonical limit from `ron-proto`.
const MAX_FRAME_BYTES: usize = ron_proto::oap::MAX_FRAME_BYTES;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
#[repr(u8)]
pub enum FrameKind {
    /// Application/gossip data frame (payload = opaque).
    Data = 0x01,
    /// Control/handshake or control acks (payload = small).
    Ctrl = 0x02,
}

impl FrameKind {
    fn from_byte(b: u8) -> Option<Self> {
        match b {
            0x01 => Some(FrameKind::Data),
            0x02 => Some(FrameKind::Ctrl),
            _ => None,
        }
    }
}

#[derive(Debug, Clone)]
pub struct Frame {
    pub kind: FrameKind,
    pub payload: Bytes,
}

impl Frame {
    /// Encode: 4-byte BE length (kind + payload), then 1-byte kind, then payload.
    pub fn encode_to(&self, out: &mut BytesMut) -> ProtoResult<()> {
        let len = 1usize + self.payload.len();
        if len > MAX_FRAME_BYTES {
            return Err(ProtoError::FrameTooLarge {
                got: len,
                max: MAX_FRAME_BYTES,
            });
        }
        out.reserve(4 + len);
        out.put_u32(len as u32);
        out.put_u8(self.kind as u8);
        out.extend_from_slice(&self.payload);
        Ok(())
    }
}

/// Try to parse a single frame from the buffer; leaves remaining bytes in `buf`.
pub fn try_parse_frame(buf: &mut BytesMut) -> ProtoResult<Option<Frame>> {
    const HDR: usize = 4; // BE length
    if buf.len() < HDR {
        return Ok(None);
    }
    let mut len_bytes = &buf[..HDR];
    let len = len_bytes.get_u32() as usize;

    if len > MAX_FRAME_BYTES {
        return Err(ProtoError::FrameTooLarge {
            got: len,
            max: MAX_FRAME_BYTES,
        });
    }

    if buf.len() < HDR + len {
        // Not enough yet
        return Ok(None);
    }

    buf.advance(HDR);
    let kind_b = buf.get_u8();
    let Some(kind) = FrameKind::from_byte(kind_b) else {
        // Treat as control error; drop this frame safely by consuming payload.
        buf.advance(len - 1);
        return Err(ProtoError::BadPreamble {
            got: [b'F', b'K', kind_b, 0, 0],
        });
    };

    let payload_len = len - 1;
    let payload = buf.split_to(payload_len).freeze();

    Ok(Some(Frame { kind, payload }))
}

```

### crates/svc-overlay/src/readiness/mod.rs
<a id="crates-svc-overlay-src-readiness-mod-rs"></a>

```rust
//! RO:WHAT — Readiness/health gate
use parking_lot::RwLock;
use std::sync::Arc;

#[derive(Clone)]
pub struct HealthGate(Arc<RwLock<State>>);

#[derive(Default)]
struct State {
    pub listeners_bound: bool,
    pub metrics_bound: bool,
    pub cfg_loaded: bool,
    pub queues_ok: bool,
    pub shed_rate_ok: bool,
    pub fd_headroom: bool,
}

impl HealthGate {
    #[must_use]
    pub fn new() -> Self {
        Self(Arc::new(RwLock::new(State::default())))
    }

    pub fn set_listeners_bound(&self, v: bool) {
        self.0.write().listeners_bound = v;
    }
    pub fn set_metrics_bound(&self, v: bool) {
        self.0.write().metrics_bound = v;
    }
    pub fn set_cfg_loaded(&self, v: bool) {
        self.0.write().cfg_loaded = v;
    }
    pub fn set_queues_ok(&self, v: bool) {
        self.0.write().queues_ok = v;
    }
    pub fn set_shed_rate_ok(&self, v: bool) {
        self.0.write().shed_rate_ok = v;
    }
    pub fn set_fd_headroom(&self, v: bool) {
        self.0.write().fd_headroom = v;
    }

    pub fn readyz_state(&self) -> (u16, serde_json::Value) {
        let s = self.0.read();
        let ok = s.listeners_bound
            && s.metrics_bound
            && s.cfg_loaded
            && s.queues_ok
            && s.shed_rate_ok
            && s.fd_headroom;

        if ok {
            (200, serde_json::json!({"ready": true}))
        } else {
            let mut missing = vec![];
            if !s.listeners_bound {
                missing.push("listeners_bound");
            }
            if !s.metrics_bound {
                missing.push("metrics_bound");
            }
            if !s.cfg_loaded {
                missing.push("cfg_loaded");
            }
            if !s.queues_ok {
                missing.push("queues_ok");
            }
            if !s.shed_rate_ok {
                missing.push("shed_rate_ok");
            }
            if !s.fd_headroom {
                missing.push("fd_headroom");
            }

            (
                503,
                serde_json::json!({
                    "ready": false,
                    "degraded": true,
                    "missing": missing,
                    "retry_after": 5
                }),
            )
        }
    }

    pub fn healthz(&self) -> (u16, serde_json::Value) {
        (200, serde_json::json!({"ok": true}))
    }
}

// ✅ Satisfy clippy: `new_without_default`
impl Default for HealthGate {
    fn default() -> Self {
        Self::new()
    }
}

```

### crates/svc-overlay/src/readiness/sampler.rs
<a id="crates-svc-overlay-src-readiness-sampler-rs"></a>

```rust
//! RO:WHAT — Readiness sampler (periodic checks). Placeholder.
#![allow(dead_code)]

```

### crates/svc-overlay/src/shutdown.rs
<a id="crates-svc-overlay-src-shutdown-rs"></a>

```rust
//! RO:WHAT — Shutdown coordination
pub async fn wait_for_shutdown() {
    let _ = tokio::signal::ctrl_c().await;
}

```

### crates/svc-overlay/src/supervisor.rs
<a id="crates-svc-overlay-src-supervisor-rs"></a>

```rust
//! RO:WHAT — Runtime supervisor for overlay loops
use crate::{admin::ReadyProbe, config::Config, listener};
use anyhow::Result;
use tokio::task::JoinHandle;
use tracing::{info, warn};

pub struct OverlayRuntime {
    join: JoinHandle<()>,
    stop: tokio::sync::oneshot::Sender<()>,
    listener: Option<listener::ListenerHandle>,
}

impl OverlayRuntime {
    pub async fn start(cfg: Config, probe: ReadyProbe) -> Result<Self> {
        // Bind listener first; flips /readyz to green when successful.
        let lh = listener::spawn_listener(&cfg, &probe).await?;

        let (stop_tx, mut stop_rx) = tokio::sync::oneshot::channel::<()>();
        let join = tokio::spawn(async move {
            info!("overlay supervisor running");
            loop {
                tokio::select! {
                    _ = &mut stop_rx => {
                        info!("overlay supervisor stopping");
                        break;
                    }
                    _ = tokio::time::sleep(std::time::Duration::from_millis(250)) => {
                        // place periodic tasks here (samplers, house-keeping)
                    }
                }
            }
        });

        Ok(Self {
            join,
            stop: stop_tx,
            listener: Some(lh),
        })
    }

    pub async fn shutdown(mut self) -> Result<()> {
        if let Some(lh) = self.listener.take() {
            lh.shutdown().await?;
        }
        let _ = self.stop.send(());
        if let Err(e) = self.join.await {
            warn!(error=?e, "overlay supervisor join error");
        }
        Ok(())
    }
}

```

### crates/svc-overlay/src/transport/mod.rs
<a id="crates-svc-overlay-src-transport-mod-rs"></a>

```rust
//! RO:WHAT — Transport facade for svc-overlay.
//! RO:WHY  — Allow swapping plain TCP for `ron-transport` without touching call-sites.
//! RO:NOTE — For now, BOTH feature paths use Tokio TCP. When we align with the real
//!           `ron-transport` API, only this file needs changes.

use std::net::SocketAddr;
use tokio::net::{TcpListener, TcpStream};

pub struct Listener {
    inner: TcpListener,
}

pub struct TransportStream {
    pub inner: TcpStream,
}

impl TransportStream {
    pub fn into_split(
        self,
    ) -> (
        tokio::net::tcp::OwnedReadHalf,
        tokio::net::tcp::OwnedWriteHalf,
    ) {
        self.inner.into_split()
    }
}

pub async fn bind_listener(addr: SocketAddr) -> std::io::Result<(Listener, SocketAddr)> {
    let inner = TcpListener::bind(addr).await?;
    let local = inner.local_addr()?;
    Ok((Listener { inner }, local))
}

impl Listener {
    pub async fn accept(&self) -> std::io::Result<(TransportStream, SocketAddr)> {
        let (sock, peer) = self.inner.accept().await?;
        Ok((TransportStream { inner: sock }, peer))
    }
}

```

### crates/svc-overlay/src/transport/quic.rs
<a id="crates-svc-overlay-src-transport-quic-rs"></a>

```rust
//! RO:WHAT — QUIC transport (stub)
#![allow(dead_code)]

```

### crates/svc-overlay/src/transport/tls.rs
<a id="crates-svc-overlay-src-transport-tls-rs"></a>

```rust
//! RO:WHAT — TLS transport (stub)
#![allow(dead_code)]

```

### crates/svc-overlay/src/transport/tor.rs
<a id="crates-svc-overlay-src-transport-tor-rs"></a>

```rust
//! RO:WHAT — Tor transport (stub)
#![allow(dead_code)]

```

### crates/svc-overlay/src/tuning.rs
<a id="crates-svc-overlay-src-tuning-rs"></a>

```rust
//! RO:WHAT — Small runtime “tuning knobs” for svc-overlay.
//! RO:WHY  — Allow ops/tests to tune without rebuilds until full Config plumbing lands.
//!
//! Env vars (optional):
//! - RON_OVERLAY_TX_WATERMARK : i64   — default 96 (of 128-slot TX queue)
//! - RON_OVERLAY_HANDSHAKE_MS : u64   — default 2000 (ms)
//!
//! Invariants:
//! - Clamped to safe ranges; parsing failures fall back to defaults.
//! - Values are read on each call; cheap enough for infrequent reads in our usage.

use std::time::Duration;

const DEF_WATERMARK: i64 = 96;
const DEF_HSHAKE_MS: u64 = 2_000;

pub fn tx_queue_watermark() -> i64 {
    match std::env::var("RON_OVERLAY_TX_WATERMARK") {
        Ok(v) => v
            .parse::<i64>()
            .ok()
            .map(|n| n.clamp(1, 127))
            .unwrap_or(DEF_WATERMARK),
        Err(_) => DEF_WATERMARK,
    }
}

pub fn handshake_timeout() -> Duration {
    let ms = match std::env::var("RON_OVERLAY_HANDSHAKE_MS") {
        Ok(v) => v
            .parse::<u64>()
            .ok()
            .map(|ms| ms.clamp(100, 30_000))
            .unwrap_or(DEF_HSHAKE_MS),
        Err(_) => DEF_HSHAKE_MS,
    };
    Duration::from_millis(ms)
}

```

### crates/svc-overlay/src/types.rs
<a id="crates-svc-overlay-src-types-rs"></a>

```rust
//! RO:WHAT — Common types
#![allow(dead_code)]
use std::net::SocketAddr;
pub type PeerAddr = SocketAddr;

```

### crates/svc-overlay/tests/http_contract.rs
<a id="crates-svc-overlay-tests-httpcontract-rs"></a>

```rust
// http_contract.rs — placeholder
// Validates /healthz, /readyz semantics and /metrics scrape shape.

```

### crates/svc-overlay/tests/integration/oap_session_handshake.rs
<a id="crates-svc-overlay-tests-integration-oapsessionhandshake-rs"></a>

```rust
// oap_session_handshake.rs — placeholder
// Drives session establishment over the real stack (hello/ack paths).

```

### crates/svc-overlay/tests/integration/overlay_admin_roundtrip.rs
<a id="crates-svc-overlay-tests-integration-overlayadminroundtrip-rs"></a>

```rust
// overlay_admin_roundtrip.rs — placeholder
// Spins admin plane (healthz/readyz/metrics) and asserts end-to-end contracts.

```

### crates/svc-overlay/tests/integration/overlay_oap_streaming.rs
<a id="crates-svc-overlay-tests-integration-overlayoapstreaming-rs"></a>

```rust
// overlay_oap_streaming.rs — placeholder
// Streaming happy-path with bounded backpressure and latency assertions.

```

### crates/svc-overlay/tests/interop_vectors.rs
<a id="crates-svc-overlay-tests-interopvectors-rs"></a>

```rust
// interop_vectors.rs — placeholder
// Golden vectors for hello/ack, oversize/ratio rejects (OAP invariants).

```

### crates/svc-overlay/tests/loom/loom_overlay.rs
<a id="crates-svc-overlay-tests-loom-loomoverlay-rs"></a>

```rust
// loom_overlay.rs — placeholder
// Interleavings for one-writer invariant, bounded queues, orderly shutdown.

```

### crates/svc-overlay/tests/metrics_schema.rs
<a id="crates-svc-overlay-tests-metricsschema-rs"></a>

```rust
// metrics_schema.rs — placeholder
// Emits sample metrics and asserts names/labels match docs/api-history.

```

### crates/svc-overlay/tests/pq_negotiation.rs
<a id="crates-svc-overlay-tests-pqnegotiation-rs"></a>

```rust
// pq_negotiation.rs — placeholder
// Matrix tests: off<->off, hybrid<->hybrid, hybrid<->off refusal cases.

```

### crates/svc-overlay/tests/readiness_under_pressure.rs
<a id="crates-svc-overlay-tests-readinessunderpressure-rs"></a>

```rust
// readiness_under_pressure.rs — placeholder
// Induces saturation; expects early degrade and recovery.

```



---



# svc-dht

_Source: crates/svc-dht/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:54:58Z -->
# Code Bundle — `svc-dht`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/svc-dht/.cargo/config.toml](#crates-svc-dht--cargo-config-toml)
- [crates/svc-dht/.github/workflows/ci.yml](#crates-svc-dht--github-workflows-ci-yml)
- [crates/svc-dht/.github/workflows/fuzz.yml](#crates-svc-dht--github-workflows-fuzz-yml)
- [crates/svc-dht/.github/workflows/mermaid.yml](#crates-svc-dht--github-workflows-mermaid-yml)
- [crates/svc-dht/.github/workflows/perf.yml](#crates-svc-dht--github-workflows-perf-yml)
- [crates/svc-dht/.rustfmt.toml](#crates-svc-dht--rustfmt-toml)
- [crates/svc-dht/Cargo.toml](#crates-svc-dht-Cargo-toml)
- [crates/svc-dht/benches/lookup_bench.rs](#crates-svc-dht-benches-lookupbench-rs)
- [crates/svc-dht/build.rs](#crates-svc-dht-build-rs)
- [crates/svc-dht/clippy.toml](#crates-svc-dht-clippy-toml)
- [crates/svc-dht/examples/find_providers.rs](#crates-svc-dht-examples-findproviders-rs)
- [crates/svc-dht/examples/provide.rs](#crates-svc-dht-examples-provide-rs)
- [crates/svc-dht/fuzz/fuzz_targets/kad_packet_decode.rs](#crates-svc-dht-fuzz-fuzztargets-kadpacketdecode-rs)
- [crates/svc-dht/fuzz/fuzz_targets/msg_frame_decode.rs](#crates-svc-dht-fuzz-fuzztargets-msgframedecode-rs)
- [crates/svc-dht/loom/loom_hedge.rs](#crates-svc-dht-loom-loomhedge-rs)
- [crates/svc-dht/loom/loom_kbucket.rs](#crates-svc-dht-loom-loomkbucket-rs)
- [crates/svc-dht/rust-toolchain.toml](#crates-svc-dht-rust-toolchain-toml)
- [crates/svc-dht/scripts/chaos/netem.sh](#crates-svc-dht-scripts-chaos-netem-sh)
- [crates/svc-dht/scripts/chaos/partition.sh](#crates-svc-dht-scripts-chaos-partition-sh)
- [crates/svc-dht/scripts/provide-and-check.sh](#crates-svc-dht-scripts-provide-and-check-sh)
- [crates/svc-dht/scripts/render-mermaid.sh](#crates-svc-dht-scripts-render-mermaid-sh)
- [crates/svc-dht/scripts/run-local.sh](#crates-svc-dht-scripts-run-local-sh)
- [crates/svc-dht/scripts/smoke_svc_dht.sh](#crates-svc-dht-scripts-smokesvcdht-sh)
- [crates/svc-dht/scripts/ttl-demo.sh](#crates-svc-dht-scripts-ttl-demo-sh)
- [crates/svc-dht/scripts/two-node-local.sh](#crates-svc-dht-scripts-two-node-local-sh)
- [crates/svc-dht/src/bootstrap.rs](#crates-svc-dht-src-bootstrap-rs)
- [crates/svc-dht/src/cache/memory.rs](#crates-svc-dht-src-cache-memory-rs)
- [crates/svc-dht/src/cache/mod.rs](#crates-svc-dht-src-cache-mod-rs)
- [crates/svc-dht/src/cache/sled_cache.rs](#crates-svc-dht-src-cache-sledcache-rs)
- [crates/svc-dht/src/codec/decode.rs](#crates-svc-dht-src-codec-decode-rs)
- [crates/svc-dht/src/codec/encode.rs](#crates-svc-dht-src-codec-encode-rs)
- [crates/svc-dht/src/codec/frame.rs](#crates-svc-dht-src-codec-frame-rs)
- [crates/svc-dht/src/codec/limits.rs](#crates-svc-dht-src-codec-limits-rs)
- [crates/svc-dht/src/codec/mod.rs](#crates-svc-dht-src-codec-mod-rs)
- [crates/svc-dht/src/config.rs](#crates-svc-dht-src-config-rs)
- [crates/svc-dht/src/errors.rs](#crates-svc-dht-src-errors-rs)
- [crates/svc-dht/src/health.rs](#crates-svc-dht-src-health-rs)
- [crates/svc-dht/src/invariants.rs](#crates-svc-dht-src-invariants-rs)
- [crates/svc-dht/src/lib.rs](#crates-svc-dht-src-lib-rs)
- [crates/svc-dht/src/main.rs](#crates-svc-dht-src-main-rs)
- [crates/svc-dht/src/metrics.rs](#crates-svc-dht-src-metrics-rs)
- [crates/svc-dht/src/peer/bucket.rs](#crates-svc-dht-src-peer-bucket-rs)
- [crates/svc-dht/src/peer/id.rs](#crates-svc-dht-src-peer-id-rs)
- [crates/svc-dht/src/peer/mod.rs](#crates-svc-dht-src-peer-mod-rs)
- [crates/svc-dht/src/peer/selector.rs](#crates-svc-dht-src-peer-selector-rs)
- [crates/svc-dht/src/peer/table.rs](#crates-svc-dht-src-peer-table-rs)
- [crates/svc-dht/src/pipeline/asn_guard.rs](#crates-svc-dht-src-pipeline-asnguard-rs)
- [crates/svc-dht/src/pipeline/deadlines.rs](#crates-svc-dht-src-pipeline-deadlines-rs)
- [crates/svc-dht/src/pipeline/hedging.rs](#crates-svc-dht-src-pipeline-hedging-rs)
- [crates/svc-dht/src/pipeline/lookup.rs](#crates-svc-dht-src-pipeline-lookup-rs)
- [crates/svc-dht/src/pipeline/mod.rs](#crates-svc-dht-src-pipeline-mod-rs)
- [crates/svc-dht/src/pipeline/provide.rs](#crates-svc-dht-src-pipeline-provide-rs)
- [crates/svc-dht/src/pipeline/rate_limit.rs](#crates-svc-dht-src-pipeline-ratelimit-rs)
- [crates/svc-dht/src/pq/algo.rs](#crates-svc-dht-src-pq-algo-rs)
- [crates/svc-dht/src/pq/gating.rs](#crates-svc-dht-src-pq-gating-rs)
- [crates/svc-dht/src/pq/mod.rs](#crates-svc-dht-src-pq-mod-rs)
- [crates/svc-dht/src/pq/verify.rs](#crates-svc-dht-src-pq-verify-rs)
- [crates/svc-dht/src/provider/mod.rs](#crates-svc-dht-src-provider-mod-rs)
- [crates/svc-dht/src/provider/record.rs](#crates-svc-dht-src-provider-record-rs)
- [crates/svc-dht/src/provider/republish.rs](#crates-svc-dht-src-provider-republish-rs)
- [crates/svc-dht/src/provider/store.rs](#crates-svc-dht-src-provider-store-rs)
- [crates/svc-dht/src/provider/ttl.rs](#crates-svc-dht-src-provider-ttl-rs)
- [crates/svc-dht/src/readiness.rs](#crates-svc-dht-src-readiness-rs)
- [crates/svc-dht/src/rpc/bus.rs](#crates-svc-dht-src-rpc-bus-rs)
- [crates/svc-dht/src/rpc/discv5.rs](#crates-svc-dht-src-rpc-discv5-rs)
- [crates/svc-dht/src/rpc/http.rs](#crates-svc-dht-src-rpc-http-rs)
- [crates/svc-dht/src/rpc/kad.rs](#crates-svc-dht-src-rpc-kad-rs)
- [crates/svc-dht/src/rpc/mod.rs](#crates-svc-dht-src-rpc-mod-rs)
- [crates/svc-dht/src/supervision/backoff.rs](#crates-svc-dht-src-supervision-backoff-rs)
- [crates/svc-dht/src/supervision/mod.rs](#crates-svc-dht-src-supervision-mod-rs)
- [crates/svc-dht/src/supervision/signals.rs](#crates-svc-dht-src-supervision-signals-rs)
- [crates/svc-dht/src/supervision/supervisor.rs](#crates-svc-dht-src-supervision-supervisor-rs)
- [crates/svc-dht/src/tracing.rs](#crates-svc-dht-src-tracing-rs)
- [crates/svc-dht/src/transport/clients.rs](#crates-svc-dht-src-transport-clients-rs)
- [crates/svc-dht/src/transport/mod.rs](#crates-svc-dht-src-transport-mod-rs)
- [crates/svc-dht/src/transport/tor.rs](#crates-svc-dht-src-transport-tor-rs)
- [crates/svc-dht/src/types.rs](#crates-svc-dht-src-types-rs)
- [crates/svc-dht/tests/api_smoke.rs](#crates-svc-dht-tests-apismoke-rs)
- [crates/svc-dht/tests/asn_diversity.rs](#crates-svc-dht-tests-asndiversity-rs)
- [crates/svc-dht/tests/chaos/netem.rs](#crates-svc-dht-tests-chaos-netem-rs)
- [crates/svc-dht/tests/chaos/partition.rs](#crates-svc-dht-tests-chaos-partition-rs)
- [crates/svc-dht/tests/chaos/soak_churn.rs](#crates-svc-dht-tests-chaos-soakchurn-rs)
- [crates/svc-dht/tests/deadline_hedge.rs](#crates-svc-dht-tests-deadlinehedge-rs)
- [crates/svc-dht/tests/kbucket_props.rs](#crates-svc-dht-tests-kbucketprops-rs)
- [crates/svc-dht/tests/nodeid_and_store.rs](#crates-svc-dht-tests-nodeidandstore-rs)
- [crates/svc-dht/tests/provider_roundtrip.rs](#crates-svc-dht-tests-providerroundtrip-rs)
- [crates/svc-dht/tests/readiness_bootstrap.rs](#crates-svc-dht-tests-readinessbootstrap-rs)

### crates/svc-dht/.cargo/config.toml
<a id="crates-svc-dht--cargo-config-toml"></a>

```toml
[alias]
fmt = "fmt --all"
clippy = "clippy --all-targets -- -D warnings"
test-all = "test --all-features"

```

### crates/svc-dht/.github/workflows/ci.yml
<a id="crates-svc-dht--github-workflows-ci-yml"></a>

```yaml
name: ci
on: [push, pull_request]
jobs:
  ci:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo 'placeholder CI (fmt/clippy/tests/deny/coverage/mutation)'

```

### crates/svc-dht/.github/workflows/fuzz.yml
<a id="crates-svc-dht--github-workflows-fuzz-yml"></a>

```yaml
name: fuzz
on:
  schedule: [{cron: "0 3 * * *"}]
jobs:
  fuzz:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo 'placeholder fuzz workflow'

```

### crates/svc-dht/.github/workflows/mermaid.yml
<a id="crates-svc-dht--github-workflows-mermaid-yml"></a>

```yaml
name: mermaid
on: [push, pull_request]
jobs:
  render:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo 'placeholder mermaid render'

```

### crates/svc-dht/.github/workflows/perf.yml
<a id="crates-svc-dht--github-workflows-perf-yml"></a>

```yaml
name: perf
on:
  workflow_dispatch:
  schedule: [{cron: "0 6 * * *"}]
jobs:
  perf:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo 'placeholder perf SLO regression check'

```

### crates/svc-dht/.rustfmt.toml
<a id="crates-svc-dht--rustfmt-toml"></a>

```toml
max_width = 100
use_small_heuristics = "Max"


```

### crates/svc-dht/Cargo.toml
<a id="crates-svc-dht-Cargo-toml"></a>

```toml
[package]
name = "svc-dht"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
authors = ["RustyOnions"]
description = "RustyOnions DHT service (Kademlia/Discv5)—discovery & providers"
repository = "https://github.com/RustyOnions/RustyOnions"
rust-version = "1.80.0"
build = "build.rs"

[features]
default = ["tls"]
tls = []
arti = []            # Tor/Arti via ron-transport
sled-cache = []      # optional sled-backed cache layer

[dependencies]
tokio = { version = "1.47.0", features = ["rt-multi-thread","macros","signal","time","sync","io-util","net"] }
axum = { version = "0.7.9", features = ["tokio","http1","http2","json"] }
hyper = "1.4"
http = "1.1"
tower = "0.5"
tower-http = { version = "0.6.6", features = ["trace","cors","timeout"] }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter","fmt","json"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
thiserror = "2.0"
anyhow = "1.0"
bytes = "1.6"
prometheus = "0.14"
once_cell = "1.19"
rand = "0.9"
blake3 = "1.5"
base64 = "0.22"
hex = "0.4"
arc-swap = "1.7"
parking_lot = "0.12"

# RON crates via relative paths (works whether or not workspace.dependencies exists)
ron-kernel    = { path = "../ron-kernel" }
ron-metrics   = { path = "../ron-metrics" }
ron-transport = { path = "../ron-transport" }
ron-proto     = { path = "../ron-proto" }
oap           = { path = "../oap" }

# Optional sled cache
sled = { version = "0.34", optional = true }

[dev-dependencies]
tokio = { version = "1.47.0", features = ["rt-multi-thread","macros","time","sync"] }
reqwest = { version = "0.12", default-features = false, features = ["rustls-tls-native-roots","json"] }
criterion = { version = "0.5", features = ["async_tokio"] }

[[bench]]
name = "lookup_bench"
harness = false

[build-dependencies]
chrono = { version = "0.4", default-features = false, features = ["clock"] }

```

### crates/svc-dht/benches/lookup_bench.rs
<a id="crates-svc-dht-benches-lookupbench-rs"></a>

```rust
//! Criterion + custom stats: lookup baseline and optional hedge tail-rescue sim.
//! RO:WHAT — (1) Baseline lookup path with β sweep and zero stagger (fast).
//!           (2) Optional tail-rescue sim showing P50/P95/P99 (env-gated).
//! RO:RUN  — Fast baseline only (default):
//!            cargo bench -p svc-dht --bench lookup_bench
//!           Include tail-rescue sim (tunable):
//!            DHT_SIM=1 DHT_TRIALS=600 DHT_PSLOW=0.05 DHT_STAGGER_MS=2 cargo bench -p svc-dht --bench lookup_bench

use std::sync::{
    atomic::{AtomicU64, Ordering},
    Arc,
};
use std::time::{Duration, Instant};

use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};
use svc_dht::pipeline::hedging::race_hedged;
use svc_dht::pipeline::lookup::{LookupCtx, LookupRequest};
use svc_dht::provider::Store;

// ---------- tiny helpers ----------
fn percentiles(mut xs: Vec<f64>) -> (f64, f64, f64) {
    if xs.is_empty() {
        return (0.0, 0.0, 0.0);
    }
    xs.sort_by(|a, b| a.partial_cmp(b).unwrap());
    let idx = |p: f64| -> usize {
        let n = xs.len() as f64;
        let k = (p * (n - 1.0)).round() as usize;
        k.min(xs.len() - 1)
    };
    (xs[idx(0.50)], xs[idx(0.95)], xs[idx(0.99)])
}

// SplitMix-like deterministic mixer (no non-Send RNG).
#[inline]
fn mix64(mut x: u64) -> u64 {
    x = x.wrapping_add(0x9E3779B97F4A7C15);
    let mut z = x;
    z = (z ^ (z >> 30)).wrapping_mul(0xBF58476D1CE4E5B9);
    z = (z ^ (z >> 27)).wrapping_mul(0x94D049BB133111EB);
    z ^ (z >> 31)
}
#[inline]
fn mix_range_inc(x: u64, min: u64, max: u64) -> u64 {
    let span = max.saturating_sub(min) + 1;
    min + (mix64(x) % span)
}

// ---------- optional tail-rescue sim (env-gated) ----------
fn maybe_print_hedge_tail_rescue(rt: &tokio::runtime::Runtime) {
    let sim = std::env::var("DHT_SIM").ok().and_then(|s| s.parse::<u8>().ok()).unwrap_or(0);
    if sim == 0 {
        // Keep benches fast unless explicitly enabled.
        return;
    }

    let trials: usize =
        std::env::var("DHT_TRIALS").ok().and_then(|s| s.parse().ok()).unwrap_or(400);
    let p_slow: f64 = std::env::var("DHT_PSLOW").ok().and_then(|s| s.parse().ok()).unwrap_or(0.05);
    let hedge_stagger_ms: u64 =
        std::env::var("DHT_STAGGER_MS").ok().and_then(|s| s.parse().ok()).unwrap_or(2);
    let slow_min: u64 =
        std::env::var("DHT_SLOW_MIN_MS").ok().and_then(|s| s.parse().ok()).unwrap_or(80);
    let slow_max: u64 =
        std::env::var("DHT_SLOW_MAX_MS").ok().and_then(|s| s.parse().ok()).unwrap_or(120);
    let fast_min: u64 =
        std::env::var("DHT_FAST_MIN_MS").ok().and_then(|s| s.parse().ok()).unwrap_or(1);
    let fast_max: u64 =
        std::env::var("DHT_FAST_MAX_MS").ok().and_then(|s| s.parse().ok()).unwrap_or(2);
    let leg_budget_ms: u64 =
        std::env::var("DHT_LEG_BUDGET_MS").ok().and_then(|s| s.parse().ok()).unwrap_or(150);

    let leg_budget = Duration::from_millis(leg_budget_ms);
    let ctr = Arc::new(AtomicU64::new(1));

    let run_beta = |beta: usize| -> Vec<f64> {
        let mut out = Vec::with_capacity(trials);
        rt.block_on(async {
            for _ in 0..trials {
                let t0 = Instant::now();
                let _ = race_hedged::<_, _, (), ()>(
                    beta,
                    Duration::from_millis(hedge_stagger_ms),
                    leg_budget,
                    {
                        let ctr = ctr.clone();
                        move |leg_idx| {
                            let seed =
                                ctr.fetch_add(1, Ordering::Relaxed).wrapping_add(leg_idx as u64);
                            async move {
                                // primary slow with prob p_slow; hedges fast
                                let slow_roll = (mix64(seed) as f64) / (u64::MAX as f64);
                                let is_slow_primary = leg_idx == 0 && slow_roll < p_slow;
                                let delay_ms = if is_slow_primary {
                                    mix_range_inc(seed ^ 0xA5A5, slow_min, slow_max)
                                } else {
                                    mix_range_inc(seed ^ 0x5A5A, fast_min, fast_max)
                                };
                                tokio::time::sleep(Duration::from_millis(delay_ms)).await;
                                Ok(())
                            }
                        }
                    },
                )
                .await;
                out.push(t0.elapsed().as_secs_f64() * 1_000.0);
            }
        });
        out
    };

    let b0 = run_beta(0);
    let b1 = run_beta(1);
    let b2 = run_beta(2);
    let b3 = run_beta(3);
    let (b0_p50, b0_p95, b0_p99) = percentiles(b0);
    let (b1_p50, b1_p95, b1_p99) = percentiles(b1);
    let (b2_p50, b2_p95, b2_p99) = percentiles(b2);
    let (b3_p50, b3_p95, b3_p99) = percentiles(b3);

    println!(
        "\n=== Hedge Tail Rescue (trials={} p_slow={:.1}% stagger={}ms budget={}ms) ===",
        trials,
        p_slow * 100.0,
        hedge_stagger_ms,
        leg_budget_ms
    );
    println!("β=0  P50={:.2}ms  P95={:.2}ms  P99={:.2}ms", b0_p50, b0_p95, b0_p99);
    println!("β=1  P50={:.2}ms  P95={:.2}ms  P99={:.2}ms", b1_p50, b1_p95, b1_p99);
    println!("β=2  P50={:.2}ms  P95={:.2}ms  P99={:.2}ms", b2_p50, b2_p95, b2_p99);
    println!("β=3  P50={:.2}ms  P95={:.2}ms  P99={:.2}ms", b3_p50, b3_p95, b3_p99);
    println!("(sim is env-gated; default bench does not run it)");
}

// ---------- (1) Baseline: lookup over in-memory store (no stagger) ----------
fn bench_lookup_baseline(c: &mut Criterion) {
    let store = Arc::new(Store::new(Duration::from_secs(60)));
    let cid = "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef".to_string();

    // Warm providers so the lookup path returns immediately.
    for i in 0..8 {
        store.add(cid.clone(), format!("local://node{i}"), Some(Duration::from_secs(60)));
    }
    let ctx = LookupCtx::new(store, 64);

    // Current-thread RT for stable measurements.
    let rt = tokio::runtime::Builder::new_current_thread().enable_time().build().expect("rt");

    // Print the optional tail simulation (fast baseline remains unaffected if DHT_SIM=0).
    maybe_print_hedge_tail_rescue(&rt);

    let mut group = c.benchmark_group("lookup_baseline");
    for beta in [0usize, 1, 2, 3] {
        group.bench_with_input(BenchmarkId::new("beta", beta), &beta, |b, &bval| {
            b.iter(|| {
                rt.block_on(async {
                    let req = LookupRequest {
                        cid: cid.clone(),
                        alpha: 1,
                        beta: bval,
                        hop_budget: 6,
                        deadline: Duration::from_millis(200),
                        hedge_stagger: Duration::from_millis(0), // ← zero to measure orchestration
                        min_leg_budget: Duration::from_millis(5),
                    };
                    // Don’t panic in benches; rare timing hiccups shouldn’t fail the run.
                    let _ = ctx.run(req).await;
                });
            });
        });
    }
    group.finish();
}

criterion_group!(benches, bench_lookup_baseline);
criterion_main!(benches);

```

### crates/svc-dht/build.rs
<a id="crates-svc-dht-build-rs"></a>

```rust
use std::process::Command;

fn main() {
    // Best-effort short git SHA
    let sha = Command::new("git")
        .args(["rev-parse", "--short", "HEAD"])
        .output()
        .ok()
        .and_then(|o| {
            if o.status.success() {
                Some(String::from_utf8_lossy(&o.stdout).trim().to_string())
            } else {
                None
            }
        })
        .unwrap_or_else(|| "unknown".to_string());

    // Build timestamp (UTC, RFC3339)
    let ts = chrono::Utc::now().to_rfc3339();

    println!("cargo:rustc-env=BUILD_GIT_SHA={}", sha);
    println!("cargo:rustc-env=BUILD_TS={}", ts);
}

```

### crates/svc-dht/clippy.toml
<a id="crates-svc-dht-clippy-toml"></a>

```toml
warn-on-all-wildcard-imports = true

```

### crates/svc-dht/examples/find_providers.rs
<a id="crates-svc-dht-examples-findproviders-rs"></a>

```rust
//! Example: GET /dht/find_providers/:cid from a running svc-dht.
//! Run the service in another terminal: `cargo run -p svc-dht`
//! Then: `cargo run -p svc-dht --example find_providers -- b3:deadbeef`

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let cid = std::env::args().nth(1).unwrap_or_else(|| "b3:deadbeef".into());
    let addr = std::env::var("DHT_ADDR").unwrap_or_else(|_| "127.0.0.1:5301".into());
    let url = format!("http://{addr}/dht/find_providers/{cid}");
    let txt = reqwest::get(url).await?.text().await?;
    println!("{txt}");
    Ok(())
}

```

### crates/svc-dht/examples/provide.rs
<a id="crates-svc-dht-examples-provide-rs"></a>

```rust
//! Example: POST /dht/provide to a running svc-dht.
//! Run the service in another terminal: `cargo run -p svc-dht`
//! Then: `cargo run -p svc-dht --example provide -- b3:deadbeef local://nodeA 60`

use std::time::Duration;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let mut args = std::env::args().skip(1);
    let cid = args.next().unwrap_or_else(|| "b3:deadbeef".to_string());
    let node = args.next().unwrap_or_else(|| "local://nodeA".to_string());
    let ttl = args.next().and_then(|s| s.parse::<u64>().ok()).unwrap_or(60);
    let addr = std::env::var("DHT_ADDR").unwrap_or_else(|_| "127.0.0.1:5301".into());

    let url = format!("http://{addr}/dht/provide");
    let body = serde_json::json!({ "cid": cid, "node": node, "ttl_secs": ttl });
    let cli = reqwest::Client::builder().timeout(Duration::from_secs(5)).build()?;
    let res = cli.post(url).json(&body).send().await?.text().await?;
    println!("{res}");
    Ok(())
}

```

### crates/svc-dht/fuzz/fuzz_targets/kad_packet_decode.rs
<a id="crates-svc-dht-fuzz-fuzztargets-kadpacketdecode-rs"></a>

```rust
// fuzz: kad_packet_decode (placeholder).

```

### crates/svc-dht/fuzz/fuzz_targets/msg_frame_decode.rs
<a id="crates-svc-dht-fuzz-fuzztargets-msgframedecode-rs"></a>

```rust
// fuzz: msg_frame_decode (placeholder).

```

### crates/svc-dht/loom/loom_hedge.rs
<a id="crates-svc-dht-loom-loomhedge-rs"></a>

```rust
// loom: hedged fan-out invariants (placeholder).

```

### crates/svc-dht/loom/loom_kbucket.rs
<a id="crates-svc-dht-loom-loomkbucket-rs"></a>

```rust
// loom: k-bucket invariants (placeholder).

```

### crates/svc-dht/rust-toolchain.toml
<a id="crates-svc-dht-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["clippy", "rustfmt"]

```

### crates/svc-dht/scripts/chaos/netem.sh
<a id="crates-svc-dht-scripts-chaos-netem-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# Apply/remove tc netem profiles (placeholder).

```

### crates/svc-dht/scripts/chaos/partition.sh
<a id="crates-svc-dht-scripts-chaos-partition-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# Simulate network partition topology locally (placeholder).

```

### crates/svc-dht/scripts/provide-and-check.sh
<a id="crates-svc-dht-scripts-provide-and-check-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
CID="${1:-b3:deadbeef}"
NODE="${2:-local://nodeA}"
TTL="${3:-60}"
ADDR="${4:-127.0.0.1:5301}"

curl -s -X POST "http://${ADDR}/dht/provide" \
  -H "content-type: application/json" \
  -d "{\"cid\":\"${CID}\",\"node\":\"${NODE}\",\"ttl_secs\":${TTL}}" | jq

curl -s "http://${ADDR}/dht/find_providers/${CID}" | jq
curl -s "http://${ADDR}/metrics" | grep -E "dht_lookup_latency_seconds_count|dht_lookup_hops|dht_lookups_total" || true

```

### crates/svc-dht/scripts/render-mermaid.sh
<a id="crates-svc-dht-scripts-render-mermaid-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# Render docs/*.mmd to SVG (placeholder).

```

### crates/svc-dht/scripts/run-local.sh
<a id="crates-svc-dht-scripts-run-local-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# run-local.sh — local smoke: readyz → provide → find → metrics

ADDR="${1:-127.0.0.1:5301}"
CID="${2:-b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef}"
NODE="${3:-local://nodeA}"
TTL="${4:-60}"

echo ">>> Waiting for readyz at http://${ADDR}/readyz ..."
for i in $(seq 1 100); do
  code=$(curl -s -o /dev/null -w "%{http_code}" "http://${ADDR}/readyz" || true)
  [ "$code" = "200" ] && echo "ready" && break
  sleep 0.1
done

echo ">>> Version:"
curl -s "http://${ADDR}/version" | jq -r '.'

echo ">>> Provide:"
curl -s -X POST "http://${ADDR}/dht/provide" \
  -H "content-type: application/json" \
  -d "{\"cid\":\"${CID}\",\"node\":\"${NODE}\",\"ttl_secs\":${TTL}}" | jq -r '.'

echo ">>> Find:"
curl -s "http://${ADDR}/dht/find_providers/${CID}" | jq -r '.'

echo ">>> Metrics (grep dht_*):"
curl -s "http://${ADDR}/metrics" | grep -E "dht_lookup_|dht_lookups_total|dht_provides_total" || true

echo "done"

```

### crates/svc-dht/scripts/smoke_svc_dht.sh
<a id="crates-svc-dht-scripts-smokesvcdht-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

echo "== svc-dht smoke start =="
echo "== format + clippy =="
cargo fmt -p svc-dht
cargo clippy -p svc-dht --no-deps -- -D warnings

echo "== unit/integration tests =="
cargo test -p svc-dht -- --nocapture

echo "== bench (short) =="
cargo bench -p svc-dht --bench lookup_bench -- --measurement-time 2 --warm-up-time 1 || true

echo "== local E2E (provide/find/metrics) =="
# runs against a locally started svc-dht (in another terminal)
crates/svc-dht/scripts/run-local.sh || true

echo "== done =="

```

### crates/svc-dht/scripts/ttl-demo.sh
<a id="crates-svc-dht-scripts-ttl-demo-sh"></a>

```bash
#!/usr/bin/env bash
# ttl-demo.sh — local provide → find_providers → TTL expiry demo for svc-dht
# Supports auto-spawn of the service.
#
# Usage:
#   ./ttl-demo.sh [--spawn] [--cid b3:short] [--node local://tmp] [--ttl 2] [--addr 127.0.0.1:5301] [--timeout 30]
#
# Notes:
# - If --spawn is provided, this script will run `cargo run -p svc-dht` in the background,
#   wait for /readyz, perform the demo, and then terminate the service.
# - Requires: curl; jq (optional for pretty JSON)
#
#
# EXAMPLE RUN: 
# TERMINAL A: cargo run -p svc-dht
# TERMINAL B: crates/svc-dht/scripts/ttl-demo.sh --spawn --ttl 2
#

set -euo pipefail

CID="b3:short"
NODE="local://tmp"
TTL=2
ADDR="127.0.0.1:5301"
TIMEOUT=30
SPAWN=0
CARGO_CMD="cargo run -p svc-dht"
LOGFILE="/tmp/svc-dht.demo.log"

while [[ $# -gt 0 ]]; do
  case "$1" in
    --cid)      CID="$2"; shift 2 ;;
    --node)     NODE="$2"; shift 2 ;;
    --ttl)      TTL="$2"; shift 2 ;;
    --addr)     ADDR="$2"; shift 2 ;;
    --timeout)  TIMEOUT="$2"; shift 2 ;;
    --spawn)    SPAWN=1; shift ;;
    -h|--help)
      echo "Usage: $0 [--spawn] [--cid b3:short] [--node local://tmp] [--ttl 2] [--addr 127.0.0.1:5301] [--timeout 30]"
      exit 0
      ;;
    *)
      echo "Unknown arg: $1"
      exit 1
      ;;
  esac
done

has_jq() { command -v jq >/dev/null 2>&1; }
json_pretty() { if has_jq; then jq; else python3 -m json.tool 2>/dev/null || cat; fi; }
get() { curl -sS "http://$ADDR$1"; }
post_json() { curl -sS -H "content-type: application/json" -d "$2" "http://$ADDR$1"; }

PROC_PGID=""
cleanup() {
  if [[ "$SPAWN" -eq 1 && -n "${PROC_PGID:-}" ]]; then
    echo
    echo ">>> Stopping spawned svc-dht (pgid=$PROC_PGID)"
    kill -TERM "-$PROC_PGID" >/dev/null 2>&1 || true
    sleep 1
    kill -KILL "-$PROC_PGID" >/dev/null 2>&1 || true
  fi
}
trap cleanup EXIT

if [[ "$SPAWN" -eq 1 ]]; then
  echo ">>> Spawning svc-dht and logging to $LOGFILE"
  # Start in its own process group so we can kill the whole tree cleanly later.
  bash -c "set -m; $CARGO_CMD &> '$LOGFILE' & echo \$! > '$LOGFILE.pid'; disown" &
  # Wait for pid file
  for _ in $(seq 1 50); do
    [[ -f "$LOGFILE.pid" ]] && break
    sleep 0.1
  done
  if [[ ! -f "$LOGFILE.pid" ]]; then
    echo "Failed to obtain svc-dht PID (check $LOGFILE)."
    exit 1
  fi
  PID="$(cat "$LOGFILE.pid")"
  # Get the process group id (pgid == pid for group leader)
  PROC_PGID="$(ps -o pgid= -p "$PID" 2>/dev/null | tr -d ' ')"
  if [[ -z "$PROC_PGID" ]]; then
    echo "Could not determine process group; PID=$PID. Proceeding without kill group."
  fi
fi

echo ">>> Waiting for readiness at http://$ADDR/readyz (timeout ${TIMEOUT}s)..."
deadline=$(( $(date +%s) + TIMEOUT ))
while :; do
  # Capture both curl status and http code
  HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "http://$ADDR/readyz" || echo 000)
  if [[ "$HTTP_CODE" == "200" ]]; then
    echo "Ready."
    break
  fi
  if (( $(date +%s) >= deadline )); then
    echo "Service not ready (HTTP $HTTP_CODE) before timeout."
    if [[ "$SPAWN" -eq 1 ]]; then
      echo "Last 50 lines from $LOGFILE:"
      tail -n 50 "$LOGFILE" || true
    fi
    exit 1
  fi
  sleep 0.2
done

echo
echo ">>> Version:"
get "/version" | json_pretty

echo
echo ">>> Posting provide (cid=$CID, node=$NODE, ttl=$TTL s)"
RESP=$(post_json "/dht/provide" "$(printf '{"cid":"%s","node":"%s","ttl_secs":%s}' "$CID" "$NODE" "$TTL")")
echo "$RESP" | json_pretty

echo
echo ">>> Immediate find_providers:"
get "/dht/find_providers/$CID" | json_pretty

echo
echo ">>> Debug snapshot (with seconds remaining):"
get "/dht/_debug/list" | json_pretty

echo
echo ">>> Metrics (before sleep):"
get "/metrics" | grep -E "dht_provides_total|dht_lookups_total" || true

echo
echo ">>> Sleeping ${TTL}s + 1 to allow TTL to expire..."
sleep $((TTL + 1))

echo
echo ">>> find_providers after expiry (should be empty):"
get "/dht/find_providers/$CID" | json_pretty

echo
echo ">>> Metrics (after):"
get "/metrics" | grep -E "dht_provides_total|dht_lookups_total" || true

if [[ "$SPAWN" -eq 1 ]]; then
  echo
  echo ">>> svc-dht logs (tail):"
  tail -n 50 "$LOGFILE" || true
fi

echo
echo "Done."

```

### crates/svc-dht/scripts/two-node-local.sh
<a id="crates-svc-dht-scripts-two-node-local-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# RO:WHAT — Launch two svc-dht nodes on different admin ports, seed them, prove cross-node lookup.
# RO:RUN
#   chmod +x crates/svc-dht/scripts/two-node-local.sh
#   crates/svc-dht/scripts/two-node-local.sh

ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
BIN="target/debug/svc-dht"

if ! command -v jq >/dev/null 2>&1; then
  echo "jq required"; exit 1
fi

echo "== build =="
cargo build -p svc-dht >/dev/null

CID="b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"

killall -q svc-dht || true
sleep 0.2

echo "== start node A (5301) =="
RON_DHT_ADMIN_ADDR=127.0.0.1:5301 \
RON_DHT_SEEDS="" \
RON_DHT_NODE_URI="local://nodeA" \
"${BIN}" >/tmp/svc-dht-A.log 2>&1 &

echo "== start node B (5302) =="
RON_DHT_ADMIN_ADDR=127.0.0.1:5302 \
RON_DHT_SEEDS="http://127.0.0.1:5301" \
RON_DHT_NODE_URI="local://nodeB" \
"${BIN}" >/tmp/svc-dht-B.log 2>&1 &

ready() { curl -fsS "$1/readyz" >/dev/null 2>&1; }

echo "== wait ready =="
for i in {1..50}; do
  ready http://127.0.0.1:5301 && ready http://127.0.0.1:5302 && break
  sleep 0.1
done

echo "== provide on node A =="
curl -fsS -X POST http://127.0.0.1:5301/provide \
  -H 'content-type: application/json' \
  -d "{\"cid\":\"${CID}\",\"node\":\"local://nodeA\",\"ttl_secs\":60}" | jq .

echo "== find from node B (should discover A) =="
curl -fsS "http://127.0.0.1:5302/find/${CID}" | jq .

echo "== metrics B (grep dht_) =="
curl -fsS http://127.0.0.1:5302/metrics | grep -E '^dht_' || true

echo "== tail logs (A/B hints) =="
echo "-- A --"; tail -n 3 /tmp/svc-dht-A.log || true
echo "-- B --"; tail -n 3 /tmp/svc-dht-B.log || true

echo "== done =="

```

### crates/svc-dht/src/bootstrap.rs
<a id="crates-svc-dht-src-bootstrap-rs"></a>

```rust
//! RO:WHAT — Seed dialing + min-fill readiness gate
//! RO:WHY — Bring table to life before accepting work; Concerns: RES/PERF
//! RO:INTERACTS — peer::table, metrics, readiness, transport
//! RO:INVARIANTS — backoff with jitter; no locks across .await
//! RO:TEST — readiness_bootstrap.rs

use crate::{config::Config, metrics::DhtMetrics, readiness::ReadyGate};
use rand::{rng, Rng};
use ron_kernel::HealthState;
use std::sync::Arc;
use tokio::time::{sleep, Duration};
use tracing::{info, warn};

pub struct Supervisor {
    shutdown_tx: Option<tokio::sync::oneshot::Sender<()>>,
    handle: tokio::task::JoinHandle<()>,
}

impl Supervisor {
    pub async fn shutdown(mut self) {
        if let Some(tx) = self.shutdown_tx.take() {
            let _ = tx.send(());
        }
        let _ = self.handle.await;
    }
}

pub async fn spawn_bootstrap_supervisor(
    cfg: Config,
    _health: Arc<HealthState>,
    ready: Arc<ReadyGate>,
    _metrics: Arc<DhtMetrics>,
) -> anyhow::Result<Supervisor> {
    let (tx, mut rx) = tokio::sync::oneshot::channel::<()>();

    let handle = tokio::spawn(async move {
        // Single pass for MVP; in Phase 2 we'll loop with backoff until quorum/min-fill.
        tokio::select! {
            _ = &mut rx => {
                info!("bootstrap supervisor: shutdown");
            }
            _ = do_once(&cfg) => {
                ready.set_ready();
                info!("bootstrap: min-fill reached; ready gate opened");
            }
        }
    });

    Ok(Supervisor { shutdown_tx: Some(tx), handle })
}

async fn do_once(cfg: &Config) {
    // TODO Phase 2: dial seeds via ron-transport; refresh k-buckets by distance
    if cfg.seeds.is_empty() {
        warn!("no seeds configured; table will rely on inbound discovery");
        sleep(Duration::from_millis(300)).await;
    } else {
        for s in &cfg.seeds {
            let _ = s; // simulate dial
            let jitter = rng().random_range(10..60);
            sleep(Duration::from_millis(jitter)).await;
        }
    }
}

```

### crates/svc-dht/src/cache/memory.rs
<a id="crates-svc-dht-src-cache-memory-rs"></a>

```rust
// cache::memory - RAM cache (placeholder).

```

### crates/svc-dht/src/cache/mod.rs
<a id="crates-svc-dht-src-cache-mod-rs"></a>

```rust
//! RO:WHAT — Cache facade (RAM default; sled optional)
//! RO:WHY — Micronode amnesia by default; Concerns: PERF/SEC
pub mod memory; // TODO phase 2
#[cfg(feature = "sled-cache")]
pub mod sled_cache; // TODO phase 2

```

### crates/svc-dht/src/cache/sled_cache.rs
<a id="crates-svc-dht-src-cache-sledcache-rs"></a>

```rust
// cache::sled_cache - sled-backed cache (placeholder).

```

### crates/svc-dht/src/codec/decode.rs
<a id="crates-svc-dht-src-codec-decode-rs"></a>

```rust
// codec::decode - parsers (placeholder).

```

### crates/svc-dht/src/codec/encode.rs
<a id="crates-svc-dht-src-codec-encode-rs"></a>

```rust
// codec::encode - serializers (placeholder).

```

### crates/svc-dht/src/codec/frame.rs
<a id="crates-svc-dht-src-codec-frame-rs"></a>

```rust
// codec::frame - OAP/1 frame constants (placeholder).

```

### crates/svc-dht/src/codec/limits.rs
<a id="crates-svc-dht-src-codec-limits-rs"></a>

```rust
//! RO:WHAT — Central protocol size/time limits (OAP guidance mirrored)
//! RO:WHY — Hardening; Concerns: SEC
pub const MAX_FRAME_BYTES: usize = 1_048_576; // 1 MiB
pub const CHUNK_BYTES: usize = 64 * 1024; // 64 KiB (storage stream knob)

```

### crates/svc-dht/src/codec/mod.rs
<a id="crates-svc-dht-src-codec-mod-rs"></a>

```rust
//! RO:WHAT — Codec module (frame/encode/decode/limits)
//! RO:WHY — Isolate parser logic for fuzzing; Concerns: SEC/RES
pub mod decode; // TODO phase 2
pub mod encode;
pub mod frame; // TODO phase 2
pub mod limits; // TODO phase 2

```

### crates/svc-dht/src/config.rs
<a id="crates-svc-dht-src-config-rs"></a>

```rust
//! RO:WHAT — svc-dht configuration (binds, α/β, k, seeds, timeouts, amnesia)
//! RO:WHY — Centralized knobs; Concerns: GOV/RES/PERF; hot-reload-friendly shape
//! RO:INTERACTS — bootstrap, peer::table, rpc/http handlers, transport
//! RO:INVARIANTS — values bounded; α ≤ k; β ≤ α; timeouts sane; amnesia honored
//! RO:TEST — config parse unit tests; trybuild for compile-fail when invalid

use serde::{Deserialize, Serialize};
use std::{
    env,
    net::{IpAddr, Ipv4Addr, SocketAddr},
    time::Duration,
};

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Config {
    pub admin_bind: SocketAddr,
    pub alpha: usize,
    pub beta: usize,
    pub k: usize,
    pub hop_budget: usize,
    pub dial_timeout_ms: u64,
    pub idle_timeout_ms: u64,
    pub seeds: Vec<String>,
    pub amnesia: bool,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            admin_bind: SocketAddr::from((IpAddr::V4(Ipv4Addr::LOCALHOST), 5301)),
            alpha: 3,
            beta: 1,
            k: 20,
            hop_budget: 6,
            dial_timeout_ms: 1_500,
            idle_timeout_ms: 5_000,
            seeds: vec![],
            amnesia: true,
        }
    }
}

impl Config {
    pub fn from_env() -> anyhow::Result<Self> {
        let mut cfg = Self::default();
        if let Ok(s) = env::var("DHT_ADMIN_BIND") {
            cfg.admin_bind = s.parse()?;
        }
        if let Ok(v) = env::var("DHT_ALPHA") {
            cfg.alpha = v.parse()?;
        }
        if let Ok(v) = env::var("DHT_BETA") {
            cfg.beta = v.parse()?;
        }
        if let Ok(v) = env::var("DHT_K") {
            cfg.k = v.parse()?;
        }
        if let Ok(v) = env::var("DHT_HOP_BUDGET") {
            cfg.hop_budget = v.parse()?;
        }
        if let Ok(v) = env::var("DHT_DIAL_TIMEOUT_MS") {
            cfg.dial_timeout_ms = v.parse()?;
        }
        if let Ok(v) = env::var("DHT_IDLE_TIMEOUT_MS") {
            cfg.idle_timeout_ms = v.parse()?;
        }
        if let Ok(v) = env::var("DHT_SEEDS") {
            cfg.seeds =
                v.split(',').map(|s| s.trim().to_string()).filter(|s| !s.is_empty()).collect();
        }
        if let Ok(v) = env::var("RON_AMNESIA") {
            cfg.amnesia = matches!(v.as_str(), "1") || v.eq_ignore_ascii_case("true");
        }
        cfg.validate()?;
        Ok(cfg)
    }

    pub fn validate(&self) -> anyhow::Result<()> {
        use anyhow::bail;
        if self.alpha == 0 || self.k == 0 {
            bail!("alpha and k must be > 0");
        }
        if self.beta > self.alpha {
            bail!("beta must be <= alpha");
        }
        if self.k < self.alpha {
            bail!("k (bucket size) should be >= alpha");
        }
        if self.hop_budget == 0 {
            bail!("hop budget must be > 0");
        }
        if self.dial_timeout_ms < 100 || self.idle_timeout_ms < 500 {
            bail!("timeouts too small");
        }
        if self.seeds.iter().any(|s| s.len() > 255) {
            bail!("seed too long");
        }
        Ok(())
    }

    pub fn dial_timeout(&self) -> Duration {
        Duration::from_millis(self.dial_timeout_ms)
    }
    pub fn idle_timeout(&self) -> Duration {
        Duration::from_millis(self.idle_timeout_ms)
    }
}

```

### crates/svc-dht/src/errors.rs
<a id="crates-svc-dht-src-errors-rs"></a>

```rust
//! RO:WHAT — Error taxonomy for svc-dht with user hints
//! RO:WHY — Deterministic, typed errors; Concerns: DX/GOV/SEC
//! RO:INTERACTS — rpc/http, pipeline, provider store
//! RO:INVARIANTS — stable Display; avoid leaking internals
//! RO:TEST — unit tests for Display and status mapping

use thiserror::Error;

#[derive(Debug, Error)]
pub enum DhtError {
    #[error("bootstrap quorum not reached")]
    NoBootstrap,
    #[error("asn diversity floor not met")]
    AsnCap,
    #[error("payload oversize")]
    OverSize,
    #[error("hop budget exceeded")]
    HopBudget,
    #[error("timeout")]
    Timeout,
    #[error("internal: {0}")]
    Internal(String),
}

```

### crates/svc-dht/src/health.rs
<a id="crates-svc-dht-src-health-rs"></a>

```rust
//! RO:WHAT — Health/liveness helpers
//! RO:WHY — Truthful health; Concerns: RES/GOV
//! RO:INTERACTS — /healthz
//! RO:INVARIANTS — cheap checks; truth over green
//! RO:TEST — healthz returns 200

use ron_kernel::HealthState;
use std::sync::Arc;

pub type HealthHandles = Arc<HealthState>;

```

### crates/svc-dht/src/invariants.rs
<a id="crates-svc-dht-src-invariants-rs"></a>

```rust
//! svc-dht invariants — compile-time and doc-level assertions that define the contract
//! RO:WHAT — Kademlia- and pipeline-related constants/invariants that other modules rely on.
//! RO:WHY  — Guard against accidental drift during refactors. Fail fast at build time.
//! RO:GATES — F (Functional), RES (Resilience), PERF (no per-call heap).
//!
//! Invariants:
//! - NodeId is 32 bytes (BLAKE3 digest); XOR distance is exactly 32 bytes.
//! - α (alpha: fanout) in [1, 16] (small, bounded concurrency per round).
//! - β (beta: hedges) in [0, 4] (limit tail-rescue parallelism).
//! - hop_budget in [1, 64] (guard against runaway traversal).
//! - Hedge stagger and leg budget are sane (stagger << budget).
//!
//! ```text
//! Kademlia rounds proceed with α parallel queries; hedging may add up to β extra legs
//! per logical lookup, spaced by a small stagger delay to rescue tail latency.
//! ```

#![allow(clippy::doc_markdown)]

pub const NODEID_LEN: usize = 32;
pub const ALPHA_MIN: usize = 1;
pub const ALPHA_MAX: usize = 16;
pub const BETA_MIN: usize = 0;
pub const BETA_MAX: usize = 4;
pub const HOPS_MIN: usize = 1;
pub const HOPS_MAX: usize = 64;

/// Sanity check helper usable in const context
const fn within(v: usize, lo: usize, hi: usize) -> bool {
    v >= lo && v <= hi
}

/// Compile-time assertions — these run when this module is referenced.
#[allow(dead_code)]
pub const fn _compile_time_guards() {
    // NodeId length must remain 32 (BLAKE3).
    // If this ever changes, XOR distance math must be updated.
    assert!(NODEID_LEN == 32);

    // Parameter envelopes (keep lookup bounded).
    assert!(within(ALPHA_MIN, 1, 32));
    assert!(within(ALPHA_MAX, 1, 32));
    assert!(ALPHA_MIN <= ALPHA_MAX);

    assert!(within(BETA_MIN, 0, 8));
    assert!(within(BETA_MAX, 0, 8));
    assert!(BETA_MIN <= BETA_MAX);

    assert!(within(HOPS_MIN, 1, 256));
    assert!(within(HOPS_MAX, 1, 256));
    assert!(HOPS_MIN <= HOPS_MAX);
}

/// Tiny doc test to lock the NodeId XOR shape without importing the full type.
/// (Keeps this module independent.)
#[cfg(test)]
mod tests {
    #[test]
    fn xor_distance_is_32_bytes() {
        let a = [0xAAu8; 32];
        let b = [0x55u8; 32];
        let mut out = [0u8; 32];
        for (i, o) in out.iter_mut().enumerate() {
            *o = a[i] ^ b[i];
        }
        assert_eq!(out.len(), 32);
        assert_eq!(out[0], 0xFF);
        assert_eq!(out[31], 0xFF);
    }
}

```

### crates/svc-dht/src/lib.rs
<a id="crates-svc-dht-src-lib-rs"></a>

```rust
//! RO:WHAT — Public crate surface & re-exports for svc-dht (Kademlia service)
//! RO:WHY — P10 Overlay/Transport/Discovery; Concerns: SEC/RES/PERF/GOV
//! RO:INTERACTS — ron-kernel (Bus/Health), ron-transport (I/O), axum (admin), ron-proto (DTOs)
//! RO:INVARIANTS — no lock across .await; single-writer per k-bucket; OAP max_frame=1MiB; chunk≈64KiB
//! RO:METRICS — exposes dht_* histograms/counters; /metrics, /healthz, /readyz
//! RO:CONFIG — svc-dht Config; amnesia honored
//! RO:SECURITY — capability checks occur at ingress/gateway; DHT path rejects oversize/abuse
//! RO:TEST — tests/* integration; loom later for kbucket single-writer

pub mod config;
pub mod errors;
pub mod health;
pub mod metrics;
pub mod readiness;
pub mod tracing;
pub use tracing as ro_tracing;

pub mod bootstrap;
pub mod cache;
pub mod codec;
pub mod peer;
pub mod pipeline;
pub mod provider;
pub mod rpc;
pub mod supervision;
pub mod transport;
pub mod types;

pub use config::Config;
pub use health::HealthHandles;
pub use metrics::DhtMetrics;
pub use provider::Store as ProviderStore;
pub use readiness::ReadyGate;

```

### crates/svc-dht/src/main.rs
<a id="crates-svc-dht-src-main-rs"></a>

```rust
//! RO:WHAT — Binary entrypoint: init tracing/metrics, load config, spawn supervisor, serve admin HTTP
//! RO:WHY — Service bootstrap; Concerns SEC/RES/PERF/GOV with observable readiness

use axum::{
    routing::{get, post},
    Router,
};
use std::{net::SocketAddr, sync::Arc, time::Duration};
use tokio::task::JoinHandle;
use tracing::{info, warn};

use ron_kernel::{wait_for_ctrl_c, HealthState};
use svc_dht::provider::ttl::spawn_pruner;
use svc_dht::rpc::http;
use svc_dht::{
    bootstrap, config::Config, metrics::DhtMetrics, pipeline::lookup::LookupCtx,
    readiness::ReadyGate, ro_tracing, ProviderStore,
};

#[tokio::main(flavor = "multi_thread")]
async fn main() -> anyhow::Result<()> {
    ro_tracing::init();
    let cfg = Config::from_env()?;
    let health = Arc::new(HealthState::default());
    let ready = Arc::new(ReadyGate::new());
    let metrics = Arc::new(DhtMetrics::new()?);
    let providers = Arc::new(ProviderStore::new(Duration::from_secs(600)));
    let _pruner = spawn_pruner(providers.clone());

    // Pipeline context — set a sane global leg concurrency
    let lookup_ctx = Arc::new(LookupCtx::new(providers.clone(), /*max_legs*/ 64));

    // Admin HTTP
    let (admin_task, admin_addr) = serve_admin(
        cfg.admin_bind,
        health.clone(),
        ready.clone(),
        metrics.clone(),
        providers.clone(),
        // pipeline knobs from Config
        cfg.alpha,
        cfg.beta,
        cfg.hop_budget,
        /* default_deadline */ Duration::from_millis(300),
        /* hedge_stagger   */ Duration::from_millis(25),
        /* min_leg_budget  */ Duration::from_millis(50),
        lookup_ctx.clone(),
    )
    .await?;
    info!(%admin_addr, "svc-dht admin up");

    // Bootstrap routing state & supervision
    let sup = bootstrap::spawn_bootstrap_supervisor(
        cfg.clone(),
        health.clone(),
        ready.clone(),
        metrics.clone(),
    )
    .await?;

    // Wait for Ctrl-C and shutdown
    wait_for_ctrl_c().await;
    warn!("shutdown requested");
    sup.shutdown().await;
    admin_task.abort();
    Ok(())
}

#[allow(clippy::too_many_arguments)]
async fn serve_admin(
    bind: SocketAddr,
    health: Arc<HealthState>,
    ready: Arc<ReadyGate>,
    metrics: Arc<DhtMetrics>,
    providers: Arc<ProviderStore>,
    alpha: usize,
    beta: usize,
    hop_budget: usize,
    default_deadline: Duration,
    hedge_stagger: Duration,
    min_leg_budget: Duration,
    lookup_ctx: Arc<LookupCtx>,
) -> anyhow::Result<(JoinHandle<()>, SocketAddr)> {
    let app = Router::new()
        .route("/healthz", get(http::healthz))
        .route("/readyz", get(http::readyz))
        .route("/version", get(http::version))
        .route("/metrics", get(http::metrics))
        .route("/dht/find_providers/:cid", get(http::find_providers))
        .route("/dht/provide", post(http::provide))
        .route("/dht/_debug/list", get(http::debug_list))
        .with_state(http::State::new(
            health,
            ready,
            metrics,
            providers,
            alpha,
            beta,
            hop_budget,
            default_deadline,
            hedge_stagger,
            min_leg_budget,
            lookup_ctx,
        ));

    let listener = tokio::net::TcpListener::bind(bind).await?;
    let addr = listener.local_addr()?;
    let task = tokio::spawn(async move {
        axum::serve(listener, app).await.unwrap();
    });
    Ok((task, addr))
}

```

### crates/svc-dht/src/metrics.rs
<a id="crates-svc-dht-src-metrics-rs"></a>

```rust
//! RO:WHAT — Prometheus metrics for svc-dht
//! RO:WHY — Observability; Concerns: PERF/GOV
//! RO:INTERACTS — rpc/http /metrics; bootstrap/pipeline update counters
//! RO:INVARIANTS — register once; cheap hot path

use once_cell::sync::Lazy;
use prometheus::{
    register_histogram, register_int_counter, Encoder, Histogram, IntCounter, TextEncoder,
};

pub struct DhtMetrics {
    pub lookups_total: IntCounter,
    pub provides_total: IntCounter,
    pub lookup_latency_seconds: Histogram,
    pub lookup_hops: Histogram,
}

impl DhtMetrics {
    pub fn new() -> anyhow::Result<Self> {
        Ok(Self {
            lookups_total: register_int_counter!("dht_lookups_total", "Total DHT lookups")?,
            provides_total: register_int_counter!("dht_provides_total", "Total DHT provides")?,
            lookup_latency_seconds: register_histogram!(
                "dht_lookup_latency_seconds",
                "Lookup latency seconds",
                vec![0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0]
            )?,
            lookup_hops: register_histogram!(
                "dht_lookup_hops",
                "Lookup hop count",
                vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0]
            )?,
        })
    }

    /// RO:WHAT — Record one lookup completion with latency + hop count.
    pub fn observe_lookup(&self, dur: std::time::Duration, hops: u32) {
        self.lookups_total.inc();
        self.lookup_latency_seconds.observe(dur.as_secs_f64());
        self.lookup_hops.observe(hops as f64);
    }

    pub fn encode() -> anyhow::Result<String> {
        static ENC: Lazy<TextEncoder> = Lazy::new(TextEncoder::new);
        let mf = prometheus::gather();
        let mut buf = Vec::with_capacity(8 * 1024);
        ENC.encode(&mf, &mut buf)?;
        Ok(String::from_utf8_lossy(&buf).to_string())
    }
}

```

### crates/svc-dht/src/peer/bucket.rs
<a id="crates-svc-dht-src-peer-bucket-rs"></a>

```rust
//! RO:WHAT — Single-writer Kademlia bucket (MVP)
//! RO:WHY — Enforce single-writer discipline; Concerns: RES
use super::id::NodeId;
use parking_lot::Mutex;

pub struct KBucket {
    k: usize,
    // single-writer: interior mut guarded, not held across await in higher layers
    inner: Mutex<Vec<NodeId>>,
}

impl KBucket {
    pub fn new(k: usize) -> Self {
        Self { k, inner: Mutex::new(Vec::with_capacity(k)) }
    }

    pub fn touch(&self, id: NodeId) {
        let mut g = self.inner.lock();
        if let Some(pos) = g.iter().position(|x| *x == id) {
            let n = g.remove(pos);
            g.insert(0, n);
            return;
        }
        if g.len() < self.k {
            g.insert(0, id);
        } else {
            // naive eviction: drop tail (older)
            g.pop();
            g.insert(0, id);
        }
    }

    pub fn snapshot(&self) -> Vec<NodeId> {
        self.inner.lock().clone()
    }
}

```

### crates/svc-dht/src/peer/id.rs
<a id="crates-svc-dht-src-peer-id-rs"></a>

```rust
//! RO:WHAT — Compact `NodeId` and XOR distance
//! RO:WHY  — Kademlia math; Concerns: PERF/RES

use blake3::hash;

#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]
pub struct NodeId([u8; 32]);

impl NodeId {
    #[inline]
    pub fn from_pubkey(pk: &[u8]) -> Self {
        let h = hash(pk);
        Self(*h.as_bytes())
    }

    /// XOR distance between two node IDs.
    #[inline]
    pub fn distance(&self, other: &Self) -> [u8; 32] {
        let mut out = [0u8; 32];
        // Avoid index-based loop to satisfy clippy::needless_range_loop.
        for (dst, (&a, &b)) in out.iter_mut().zip(self.0.iter().zip(other.0.iter())) {
            *dst = a ^ b;
        }
        out
    }

    /// Optional helpers (handy in tests/callers).
    #[inline]
    pub fn to_bytes(self) -> [u8; 32] {
        self.0
    }

    #[inline]
    pub fn from_bytes(b: [u8; 32]) -> Self {
        Self(b)
    }
}

```

### crates/svc-dht/src/peer/mod.rs
<a id="crates-svc-dht-src-peer-mod-rs"></a>

```rust
//! RO:WHAT — Peer ID, Kademlia k-buckets, routing table, selectors
//! RO:WHY — Core routing structures; Concerns: RES/PERF
pub mod bucket;
pub mod id;
pub mod selector;
pub mod table;

pub use id::NodeId;
pub use table::RoutingTable;

```

### crates/svc-dht/src/peer/selector.rs
<a id="crates-svc-dht-src-peer-selector-rs"></a>

```rust
//! RO:WHAT — α-parallel, β-hedged selection placeholder
//! RO:WHY — Tail control; Concerns: PERF/RES
pub struct Selector {
    pub alpha: usize,
    pub beta: usize,
}
impl Selector {
    pub fn new(alpha: usize, beta: usize) -> Self {
        Self { alpha, beta }
    }
}

```

### crates/svc-dht/src/peer/table.rs
<a id="crates-svc-dht-src-peer-table-rs"></a>

```rust
//! RO:WHAT — Routing table over buckets
//! RO:WHY — Find closest peers; Concerns: PERF
use super::{bucket::KBucket, id::NodeId};

pub struct RoutingTable {
    buckets: Vec<KBucket>,
    _k: usize, // kept for shape; prefixed to avoid dead_code warning until used
}

impl RoutingTable {
    pub fn new(k: usize) -> Self {
        // 256-bit space → 256 buckets (MVP)
        let buckets = (0..256).map(|_| KBucket::new(k)).collect();
        Self { buckets, _k: k }
    }

    pub fn observe(&self, me: NodeId, peer: NodeId) {
        let dist = me.distance(&peer);
        let idx = leading_zeros(&dist) as usize;
        let idx = idx.min(self.buckets.len() - 1);
        self.buckets[idx].touch(peer);
    }

    pub fn closest(&self, _me: NodeId, _target: NodeId, n: usize) -> Vec<NodeId> {
        // MVP: concat from all buckets; refine in phase 2
        let mut out = Vec::with_capacity(n);
        for b in &self.buckets {
            for id in b.snapshot() {
                out.push(id);
                if out.len() == n {
                    return out;
                }
            }
        }
        out
    }
}

fn leading_zeros(bytes: &[u8; 32]) -> u32 {
    for (i, b) in bytes.iter().enumerate() {
        if *b != 0 {
            return (i as u32) * 8 + b.leading_zeros();
        }
    }
    256
}

```

### crates/svc-dht/src/pipeline/asn_guard.rs
<a id="crates-svc-dht-src-pipeline-asnguard-rs"></a>

```rust
// pipeline::asn_guard - ASN diversity (placeholder).

```

### crates/svc-dht/src/pipeline/deadlines.rs
<a id="crates-svc-dht-src-pipeline-deadlines-rs"></a>

```rust
//! RO:WHAT — Deadline budgeting for composite operations
//! RO:WHY — Ensure hedging/fanout stays within the caller budget; Concerns: PERF/RES

use std::time::{Duration, Instant};

#[derive(Clone, Copy, Debug)]
pub struct DeadlineBudget {
    start: Instant,
    total: Duration,
}

impl DeadlineBudget {
    pub fn new(total: Duration) -> Self {
        Self { start: Instant::now(), total }
    }
    pub fn remaining(&self) -> Duration {
        let spent = self.start.elapsed();
        if spent >= self.total {
            Duration::from_millis(0)
        } else {
            self.total - spent
        }
    }
    pub fn total(&self) -> Duration {
        self.total
    }
    pub fn spent(&self) -> Duration {
        self.start.elapsed()
    }
}

```

### crates/svc-dht/src/pipeline/hedging.rs
<a id="crates-svc-dht-src-pipeline-hedging-rs"></a>

```rust
//! RO:WHAT — β-hedged race between lookup legs with stagger
//! RO:WHY — Reduce tail latency while respecting deadline; Concerns: PERF/RES

use std::future::Future;
use std::time::Duration;
use tokio::time::{sleep, timeout};

/// Race a primary future with up to `beta` hedges, each staggered by `stagger`.
/// Each leg is wrapped with `timeout(leg_budget)`. The first Ok wins; errors are
/// collected and last error is returned if all fail/timeout.
pub async fn race_hedged<F, Fut, T, E>(
    beta: usize,
    stagger: Duration,
    leg_budget: Duration,
    mut mk_leg: F,
) -> Result<T, E>
where
    F: FnMut(usize) -> Fut + Send + Sync + 'static,
    Fut: Future<Output = Result<T, E>> + Send + 'static,
    T: Send + 'static,
    E: Send + Clone + Default + 'static,
{
    // beta == 0 means: just one primary
    let hedges = beta.saturating_add(1);
    let mut handles = Vec::with_capacity(hedges);

    for i in 0..hedges {
        let fut = mk_leg(i);
        let h = tokio::spawn(async move {
            let t = timeout(leg_budget, fut).await;
            match t {
                Ok(r) => r,
                Err(_) => Err(timeout_err()),
            }
        });
        handles.push(h);
        if i + 1 < hedges && !stagger.is_zero() {
            sleep(stagger).await;
        }
    }

    let mut last_err = None;
    for h in handles {
        match h.await {
            Ok(Ok(v)) => return Ok(v),
            Ok(Err(e)) => last_err = Some(e),
            Err(_) => {}
        }
    }
    Err(last_err.expect("no legs executed"))
}

// Local error helper for timeouts in the hedge layer.
fn timeout_err<E>() -> E
where
    E: Default,
{
    E::default()
}

```

### crates/svc-dht/src/pipeline/lookup.rs
<a id="crates-svc-dht-src-pipeline-lookup-rs"></a>

```rust
//! RO:WHAT — Lookup FSM: fanout (α) → hedge (β) → converge, under a deadline & hop budget
//! RO:WHY — Tail control & budget adherence; Concerns: PERF/RES
//! RO:INTERACTS — provider::Store (local for MVP); later: transport/kad over ron-transport
//! RO:INVARIANTS — no lock held across .await; limiter bounds total leg concurrency

use super::{deadlines::DeadlineBudget, hedging::race_hedged, rate_limit::Limiter};
use crate::provider::Store;
use anyhow::{anyhow, Result};
use std::{sync::Arc, time::Duration};
use tokio::time::Instant;

#[derive(Clone, Debug)]
pub struct LookupRequest {
    pub cid: String,
    pub alpha: usize,
    pub beta: usize,
    pub hop_budget: usize,
    pub deadline: Duration,
    /// Stagger between hedge legs (β) — small to control tail.
    pub hedge_stagger: Duration,
    /// Per-leg minimum budget (clamped by remaining deadline).
    pub min_leg_budget: Duration,
}

#[derive(Clone, Debug)]
pub struct LookupResult {
    pub providers: Vec<String>,
    pub hops: u32,
    pub elapsed: Duration,
}

pub struct LookupCtx {
    store: Arc<Store>,
    limiter: Limiter,
}

impl LookupCtx {
    pub fn new(store: Arc<Store>, max_concurrent_legs: usize) -> Self {
        Self { store, limiter: Limiter::new(max_concurrent_legs) }
    }

    /// Run a lookup under α/β/hedge/deadline/hop_budget. In this MVP, legs query the local
    /// provider store (network-free), but we still exercise hedging and budgets.
    pub async fn run(&self, req: LookupRequest) -> Result<LookupResult> {
        if req.alpha == 0 {
            return Err(anyhow!("alpha must be > 0"));
        }
        if req.hop_budget == 0 {
            return Err(anyhow!("hop budget must be > 0"));
        }

        let budget = DeadlineBudget::new(req.deadline);
        let started = Instant::now();

        // Compose leg runner. Each leg simulates a "hop" by counting attempt number.
        let cid = req.cid.clone();
        let store = self.store.clone();
        let limiter = self.limiter.clone();

        // Effective leg budget: honor remaining global deadline, but not below min_leg_budget.
        let leg_budget = budget.remaining().max(req.min_leg_budget);

        // In the local MVP there is **no artificial jitter** inside legs.
        // Hedging still races futures; whichever returns first wins.
        let beta = req.beta;
        let stagger = req.hedge_stagger;

        let result = race_hedged::<_, _, _, HedgeErr>(beta, stagger, leg_budget, move |leg_idx| {
            let cid = cid.clone();
            let store = store.clone();
            let limiter = limiter.clone();
            async move {
                let _permit = limiter.acquire().await;
                let providers = store.get_live(&cid);
                if providers.is_empty() {
                    Err(HedgeErr) // in a networked version we'd query peers here
                } else {
                    Ok((providers, leg_idx as u32 + 1)) // hops ~ legs tried until success
                }
            }
        })
        .await;

        match result {
            Ok((providers, hops)) => {
                Ok(LookupResult { providers, hops, elapsed: started.elapsed() })
            }
            Err(_) => Err(anyhow!("lookup failed or timed out")),
        }
    }
}

#[derive(Clone, Copy, Debug, Default)]
struct HedgeErr;

```

### crates/svc-dht/src/pipeline/mod.rs
<a id="crates-svc-dht-src-pipeline-mod-rs"></a>

```rust
//! RO:WHAT — Request orchestration (lookup/provide/hedging/limits)
//! RO:WHY — Keep policies out of handlers; Concerns: PERF/RES
pub mod deadlines;
pub mod hedging;
pub mod lookup;
pub mod rate_limit;
// (left for later slices)
pub mod provide { /* TODO: networked replication in next slice */
}
pub mod asn_guard { /* TODO: ASN diversity guard in next slice */
}

```

### crates/svc-dht/src/pipeline/provide.rs
<a id="crates-svc-dht-src-pipeline-provide-rs"></a>

```rust
// pipeline::provide - provide flow (placeholder).

```

### crates/svc-dht/src/pipeline/rate_limit.rs
<a id="crates-svc-dht-src-pipeline-ratelimit-rs"></a>

```rust
//! RO:WHAT — Simple global rate limiter for in-flight lookup legs
//! RO:WHY — Backpressure to avoid overload; Concerns: RES/PERF

use tokio::sync::{OwnedSemaphorePermit, Semaphore};

#[derive(Clone)]
pub struct Limiter {
    sem: std::sync::Arc<Semaphore>,
}

impl Limiter {
    /// new: max concurrent legs (global)
    pub fn new(max_legs: usize) -> Self {
        Self { sem: std::sync::Arc::new(Semaphore::new(max_legs)) }
    }
    pub async fn acquire(&self) -> OwnedSemaphorePermit {
        self.sem.clone().acquire_owned().await.expect("semaphore closed")
    }
}

```

### crates/svc-dht/src/pq/algo.rs
<a id="crates-svc-dht-src-pq-algo-rs"></a>

```rust
// pq::algo - ML-DSA/SPHINCS+ selection (placeholder).

```

### crates/svc-dht/src/pq/gating.rs
<a id="crates-svc-dht-src-pq-gating-rs"></a>

```rust
// pq::gating - REQUIRE/REQUIRE_ON policy (placeholder).

```

### crates/svc-dht/src/pq/mod.rs
<a id="crates-svc-dht-src-pq-mod-rs"></a>

```rust
// pq::mod - PQ posture surface (placeholder).

```

### crates/svc-dht/src/pq/verify.rs
<a id="crates-svc-dht-src-pq-verify-rs"></a>

```rust
// pq::verify - dual-sign verify (placeholder).

```

### crates/svc-dht/src/provider/mod.rs
<a id="crates-svc-dht-src-provider-mod-rs"></a>

```rust
//! RO:WHAT — Provider record facade (RAM default; TTL pruning worker)
//! RO:WHY — Enables local provide/find_providers without network
//! RO:INVARIANTS — TTL respected; amnesia-friendly (no disk by default)

pub mod record;
pub mod republish;
pub mod store;
pub mod ttl;

pub use store::Store;

```

### crates/svc-dht/src/provider/record.rs
<a id="crates-svc-dht-src-provider-record-rs"></a>

```rust
//! RO:WHAT — ProviderRecord v1 (MVP: node string + expiry)
//! RO:WHY — Minimal schema to exercise provide/find locally

use std::time::{Duration, Instant};

#[derive(Clone, Debug)]
pub struct ProviderRecord {
    pub cid: String,
    pub node: String,
    pub expires_at: Instant,
}

impl ProviderRecord {
    pub fn new(cid: String, node: String, ttl: Duration) -> Self {
        Self { cid, node, expires_at: Instant::now() + ttl }
    }
    pub fn expired(&self, now: Instant) -> bool {
        now >= self.expires_at
    }
}

```

### crates/svc-dht/src/provider/republish.rs
<a id="crates-svc-dht-src-provider-republish-rs"></a>

```rust
//! RO:WHAT — Placeholder for republish/refresh logic
//! RO:WHY — Left for Phase 2 (networked replication)
pub struct Republisher;

```

### crates/svc-dht/src/provider/store.rs
<a id="crates-svc-dht-src-provider-store-rs"></a>

```rust
//! RO:WHAT — In-memory provider store with TTL
//! RO:WHY — Micronode default; keeps MVP simple
use super::record::ProviderRecord;
use parking_lot::RwLock;
use std::{
    collections::HashMap,
    time::{Duration, Instant},
};

#[derive(Default)]
pub struct Store {
    inner: RwLock<HashMap<String, Vec<ProviderRecord>>>, // cid -> records
    default_ttl: Duration,
}

impl Store {
    pub fn new(default_ttl: Duration) -> Self {
        Self { inner: RwLock::new(HashMap::new()), default_ttl }
    }

    pub fn default_ttl(&self) -> Duration {
        self.default_ttl
    }

    /// RO:WHAT — Add/refresh a provider record (de-duped by node) for a CID.
    pub fn add(&self, cid: String, node: String, ttl: Option<Duration>) {
        let cid = normalize(&cid);
        let node = normalize(&node);
        let ttl = ttl.unwrap_or(self.default_ttl);
        let rec = ProviderRecord::new(cid.clone(), node, ttl);

        let mut g = self.inner.write();
        let v = g.entry(cid).or_default();
        // de-dup by node
        if let Some(pos) = v.iter().position(|r| r.node == rec.node) {
            v[pos] = rec;
        } else {
            v.push(rec);
        }
    }

    /// RO:WHAT — Read-only view of live providers (no mutation).
    pub fn get_live(&self, cid: &str) -> Vec<String> {
        let cid = normalize(cid);
        let now = Instant::now();
        let g = self.inner.read();
        if let Some(v) = g.get(&cid) {
            v.iter().filter(|r| !r.expired(now)).map(|r| r.node.clone()).collect()
        } else {
            Vec::new()
        }
    }

    /// RO:WHAT — Prune expired records; called by background pruner.
    pub fn purge_expired(&self) -> usize {
        let now = Instant::now();
        let mut g = self.inner.write();
        let mut purged = 0usize;
        for v in g.values_mut() {
            let before = v.len();
            v.retain(|r| !r.expired(now));
            purged += before.saturating_sub(v.len());
        }
        // drop empty CIDs
        g.retain(|_, v| !v.is_empty());
        purged
    }

    /// RO:WHAT — Debug snapshot: all CIDs with nodes and seconds-until-expiry.
    pub fn debug_snapshot(&self) -> Vec<DebugCid> {
        let now = Instant::now();
        let g = self.inner.read();
        let mut out = Vec::new();
        for (cid, recs) in g.iter() {
            let entries = recs
                .iter()
                .map(|r| DebugEntry {
                    node: r.node.clone(),
                    secs_left: r.expires_at.saturating_duration_since(now).as_secs_f64(),
                })
                .collect();
            out.push(DebugCid { cid: cid.clone(), entries });
        }
        out
    }
}

#[derive(serde::Serialize)]
pub struct DebugCid {
    pub cid: String,
    pub entries: Vec<DebugEntry>,
}

#[derive(serde::Serialize)]
pub struct DebugEntry {
    pub node: String,
    pub secs_left: f64,
}

fn normalize(s: &str) -> String {
    s.trim().to_string()
}

```

### crates/svc-dht/src/provider/ttl.rs
<a id="crates-svc-dht-src-provider-ttl-rs"></a>

```rust
//! RO:WHAT — Background TTL pruning worker
//! RO:WHY — Keeps store clean over time without external triggers

use super::Store;
use std::sync::Arc;
use tokio::time::{sleep, Duration};
use tracing::debug;

pub fn spawn_pruner(store: Arc<Store>) -> tokio::task::JoinHandle<()> {
    tokio::spawn(async move {
        // Small initial delay to avoid racing immediately after a provide with very short TTLs.
        sleep(Duration::from_secs(2)).await;
        loop {
            let n = store.purge_expired();
            if n > 0 {
                debug!(purged = n, "provider TTL pruned");
            }
            sleep(Duration::from_secs(1)).await;
        }
    })
}

```

### crates/svc-dht/src/readiness.rs
<a id="crates-svc-dht-src-readiness-rs"></a>

```rust
//! RO:WHAT — Readiness gate: flips when bootstrap quorum + min-fill thresholds met
//! RO:WHY — Prevents thundering herd; Concerns: RES/PERF
//! RO:INTERACTS — bootstrap, peer::table, /readyz
//! RO:INVARIANTS — set ready last; fail-closed on writes
//! RO:TEST — readiness_bootstrap.rs

use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;

#[derive(Default)]
pub struct ReadyGate {
    ready: AtomicBool,
}
impl ReadyGate {
    pub fn new() -> Self {
        Self { ready: AtomicBool::new(false) }
    }
    pub fn set_ready(&self) {
        self.ready.store(true, Ordering::Release);
    }
    pub fn is_ready(&self) -> bool {
        self.ready.load(Ordering::Acquire)
    }
}

pub type SharedReady = Arc<ReadyGate>;

```

### crates/svc-dht/src/rpc/bus.rs
<a id="crates-svc-dht-src-rpc-bus-rs"></a>

```rust
// rpc::bus - bus topic adapters (placeholder).

```

### crates/svc-dht/src/rpc/discv5.rs
<a id="crates-svc-dht-src-rpc-discv5-rs"></a>

```rust
// rpc::discv5 - peer discovery (placeholder).

```

### crates/svc-dht/src/rpc/http.rs
<a id="crates-svc-dht-src-rpc-http-rs"></a>

```rust
//! RO:WHAT — Admin endpoints + DHT demo endpoints (provide + find_providers via pipeline)
//! RO:WHY — Ops-first; Concerns: GOV/PERF/DX/SEC. Adds CID/node validation and stable errors.
//! RO:INTERACTS — metrics, provider::Store, pipeline::lookup, types::B3Cid.
//! RO:INVARIANTS — deny unknown fields; return 400 on bad input; no lock across .await.
//! RO:TEST — tests/provider_roundtrip.rs

use axum::{extract::Path, http::StatusCode, response::IntoResponse, Json};
use std::{
    sync::Arc,
    time::{Duration, Instant},
};

use crate::{
    metrics::DhtMetrics,
    pipeline::lookup::{LookupCtx, LookupRequest},
    provider::Store,
    readiness::ReadyGate,
    types::{validate_node_uri, B3Cid},
};
use ron_kernel::HealthState;
use serde::Deserialize;

#[derive(Clone)]
pub struct State {
    pub health: Arc<HealthState>,
    pub ready: Arc<ReadyGate>,
    pub metrics: Arc<DhtMetrics>,
    pub providers: Arc<Store>,

    // Pipeline knobs (from Config)
    pub alpha: usize,
    pub beta: usize,
    pub hop_budget: usize,
    pub default_deadline: Duration,
    pub hedge_stagger: Duration,
    pub min_leg_budget: Duration,

    // Pipeline context (rate limiter etc.)
    pub lookup_ctx: Arc<LookupCtx>,
}

impl State {
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        health: Arc<HealthState>,
        ready: Arc<ReadyGate>,
        metrics: Arc<DhtMetrics>,
        providers: Arc<Store>,
        alpha: usize,
        beta: usize,
        hop_budget: usize,
        default_deadline: Duration,
        hedge_stagger: Duration,
        min_leg_budget: Duration,
        lookup_ctx: Arc<LookupCtx>,
    ) -> Self {
        Self {
            health,
            ready,
            metrics,
            providers,
            alpha,
            beta,
            hop_budget,
            default_deadline,
            hedge_stagger,
            min_leg_budget,
            lookup_ctx,
        }
    }
}

pub async fn healthz(axum::extract::State(st): axum::extract::State<State>) -> impl IntoResponse {
    if st.health.all_ready() || st.ready.is_ready() {
        (StatusCode::OK, "ok").into_response()
    } else {
        (StatusCode::OK, "starting").into_response()
    }
}

pub async fn readyz(axum::extract::State(st): axum::extract::State<State>) -> impl IntoResponse {
    if st.ready.is_ready() {
        (StatusCode::OK, "ready").into_response()
    } else {
        (StatusCode::SERVICE_UNAVAILABLE, [("Retry-After", "1")], "booting").into_response()
    }
}

pub async fn version() -> impl IntoResponse {
    let sha = option_env!("BUILD_GIT_SHA").unwrap_or("unknown");
    let ts = option_env!("BUILD_TS").unwrap_or("unknown");
    Json(serde_json::json!({ "git": sha, "built": ts }))
}

pub async fn metrics() -> impl IntoResponse {
    match crate::metrics::DhtMetrics::encode() {
        Ok(text) => (StatusCode::OK, text),
        Err(_) => (StatusCode::INTERNAL_SERVER_ERROR, "encode error".to_string()),
    }
}

/// Demo: POST /dht/provide  {"cid":"b3:...","node":"nodeA","ttl_secs":600}
#[derive(Deserialize)]
#[serde(deny_unknown_fields)]
pub struct ProvideBody {
    pub cid: B3Cid,
    pub node: String,
    #[serde(default)]
    pub ttl_secs: Option<u64>,
}

pub async fn provide(
    axum::extract::State(st): axum::extract::State<State>,
    Json(body): Json<ProvideBody>,
) -> impl IntoResponse {
    if !validate_node_uri(&body.node) {
        return (StatusCode::BAD_REQUEST, Json(serde_json::json!({ "error": "invalid node URI" })))
            .into_response();
    }

    let ttl = body.ttl_secs.map(Duration::from_secs);
    let used_ttl = ttl.unwrap_or_else(|| st.providers.default_ttl());
    st.providers.add(body.cid.into_string(), body.node, Some(used_ttl));
    st.metrics.provides_total.inc();
    (
        StatusCode::OK,
        Json(serde_json::json!({
            "ok": true,
            "ttl_secs_used": used_ttl.as_secs()
        })),
    )
        .into_response()
}

/// GET /dht/find_providers/:cid — uses the lookup pipeline (α/β/hedge/deadline)
pub async fn find_providers(
    axum::extract::State(st): axum::extract::State<State>,
    Path(cid): Path<B3Cid>,
) -> impl IntoResponse {
    let t0 = Instant::now();

    let req = LookupRequest {
        cid: cid.to_string(),
        alpha: st.alpha,
        beta: st.beta,
        hop_budget: st.hop_budget,
        deadline: st.default_deadline,
        hedge_stagger: st.hedge_stagger,
        min_leg_budget: st.min_leg_budget,
    };

    match st.lookup_ctx.run(req).await {
        Ok(res) => {
            st.metrics.observe_lookup(t0.elapsed(), res.hops);
            Json(serde_json::json!({
                "cid": cid.to_string(),
                "providers": res.providers,
                "hops": res.hops,
                "elapsed_ms": res.elapsed.as_millis(),
            }))
            .into_response()
        }
        Err(e) => {
            st.metrics.observe_lookup(t0.elapsed(), 0);
            (StatusCode::GATEWAY_TIMEOUT, Json(serde_json::json!({ "error": e.to_string() })))
                .into_response()
        }
    }
}

/// Debug: GET /dht/_debug/list — full in-memory snapshot with TTL left
pub async fn debug_list(
    axum::extract::State(st): axum::extract::State<State>,
) -> impl IntoResponse {
    let snap = st.providers.debug_snapshot();
    Json(serde_json::json!(snap))
}

```

### crates/svc-dht/src/rpc/kad.rs
<a id="crates-svc-dht-src-rpc-kad-rs"></a>

```rust
//! RO:WHAT — Kad request/response DTOs and handlers (placeholder)
//! RO:WHY — Wire surface; Concerns: DX/RES
#[derive(serde::Serialize, serde::Deserialize)]
pub struct FindProviders {
    pub cid: String,
    pub limit: usize,
}
#[derive(serde::Serialize, serde::Deserialize)]
pub struct Providers {
    pub cid: String,
    pub nodes: Vec<String>,
}

```

### crates/svc-dht/src/rpc/mod.rs
<a id="crates-svc-dht-src-rpc-mod-rs"></a>

```rust
//! RO:WHAT — RPC surfaces: Kad + admin HTTP (MVP includes HTTP)
//! RO:WHY — Entry points; Concerns: DX/SEC
pub mod bus; // TODO phase 2
pub mod discv5;
pub mod http;
pub mod kad; // TODO phase 2

```

### crates/svc-dht/src/supervision/backoff.rs
<a id="crates-svc-dht-src-supervision-backoff-rs"></a>

```rust
//! RO:WHAT — Exponential backoff with jitter
//! RO:WHY — Prevents stampedes; Concerns: RES/PERF
pub fn next(prev_ms: u64) -> u64 {
    (prev_ms.saturating_mul(2)).min(30_000)
}

```

### crates/svc-dht/src/supervision/mod.rs
<a id="crates-svc-dht-src-supervision-mod-rs"></a>

```rust
//! RO:WHAT — Supervision helpers (backoff/signals)
//! RO:WHY — Crash-only discipline; Concerns: RES
pub mod backoff;
pub mod signals;

```

### crates/svc-dht/src/supervision/signals.rs
<a id="crates-svc-dht-src-supervision-signals-rs"></a>

```rust
//! RO:WHAT — Signal helpers (placeholder)
//! RO:WHY — Wiring space for future supervised tasks
pub fn install() {}

```

### crates/svc-dht/src/supervision/supervisor.rs
<a id="crates-svc-dht-src-supervision-supervisor-rs"></a>

```rust
// supervisor.rs (placeholder).

```

### crates/svc-dht/src/tracing.rs
<a id="crates-svc-dht-src-tracing-rs"></a>

```rust
//! RO:WHAT — Tracing initialization (env-filter aware)
//! RO:WHY — Uniform logs; Concerns: GOV/DX
//! RO:INTERACTS — all modules via tracing
//! RO:INVARIANTS — JSON optional; defaults to INFO

use tracing_subscriber::{fmt, layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};

pub fn init() {
    let filter =
        EnvFilter::try_from_default_env().unwrap_or_else(|_| EnvFilter::new("info,svc_dht=info"));
    tracing_subscriber::registry().with(filter).with(fmt::layer().with_target(false)).init();
}

```

### crates/svc-dht/src/transport/clients.rs
<a id="crates-svc-dht-src-transport-clients-rs"></a>

```rust
// transport::clients - pools & timeouts (placeholder).

```

### crates/svc-dht/src/transport/mod.rs
<a id="crates-svc-dht-src-transport-mod-rs"></a>

```rust
//! RO:WHAT — Thin wrapper around ron-transport clients
//! RO:WHY — Keep svc-dht transport-agnostic; Concerns: SEC/RES
pub mod clients; // TODO phase 2
#[cfg(feature = "arti")]
pub mod tor; // TODO phase 2

```

### crates/svc-dht/src/transport/tor.rs
<a id="crates-svc-dht-src-transport-tor-rs"></a>

```rust
// transport::tor - arti support (placeholder).

```

### crates/svc-dht/src/types.rs
<a id="crates-svc-dht-src-types-rs"></a>

```rust
//! RO:WHAT — Common types (B3Cid validator, NodeUri placeholder).
//! RO:WHY  — DX/SEC hardening: validate CIDs early; avoid junk through the pipeline.
//! RO:INTERACTS — rpc::http, provider::Store, pipeline::lookup.
//! RO:INVARIANTS — BLAKE3-256 only; lowercase hex; "b3:<64-hex>"; no locks across .await.
//! RO:SECURITY — Rejects malformed IDs with 400; prevents cache poisoning.
//! RO:TEST — unit in tests/provider_roundtrip.rs and rpc/http tests.

use std::fmt;
use std::str::FromStr;

/// Canonical content address: "b3:<64-lowercase-hex>" (BLAKE3-256)
#[derive(Clone, Debug, PartialEq, Eq, Hash)]
pub struct B3Cid(String);

impl B3Cid {
    pub fn as_str(&self) -> &str {
        &self.0
    }
    pub fn into_string(self) -> String {
        self.0
    }
}

impl fmt::Display for B3Cid {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.write_str(&self.0)
    }
}

impl FromStr for B3Cid {
    type Err = &'static str;
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        // Strict: exactly "b3:" + 64 lowercase hex chars.
        const PREFIX: &str = "b3:";
        if !s.starts_with(PREFIX) {
            return Err("bad-prefix");
        }
        let hex = &s[PREFIX.len()..];
        if hex.len() != 64 {
            return Err("bad-length");
        }
        if !hex.as_bytes().iter().all(|b| matches!(b, b'0'..=b'9'|b'a'..=b'f')) {
            return Err("bad-hex");
        }
        Ok(B3Cid(s.to_string()))
    }
}

// Serde glue so DTOs can use B3Cid directly.
impl<'de> serde::Deserialize<'de> for B3Cid {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        s.parse().map_err(serde::de::Error::custom)
    }
}
impl serde::Serialize for B3Cid {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        serializer.serialize_str(self.as_str())
    }
}

/// Very light Node URI checker (MVP): "<scheme>://<id>"
/// We only require non-empty and forbid whitespace; detailed validation left for transport layer.
pub fn validate_node_uri(s: &str) -> bool {
    let s = s.trim();
    if s.is_empty() {
        return false;
    }
    if s.contains(char::is_whitespace) {
        return false;
    }
    s.contains("://")
}

```

### crates/svc-dht/tests/api_smoke.rs
<a id="crates-svc-dht-tests-apismoke-rs"></a>

```rust
//! Happy-path handler smoke test (no sockets).
//! Verifies: provide → find_providers JSON shape + 400 on bad input.

use std::sync::{Arc, OnceLock};
use std::time::Duration;

use axum::extract::State as AxumState;
use axum::http::StatusCode;
use axum::response::IntoResponse;
use ron_kernel::HealthState;
use svc_dht::metrics::DhtMetrics;
use svc_dht::pipeline::lookup::LookupCtx;
use svc_dht::provider::Store;
use svc_dht::readiness::ReadyGate;
use svc_dht::rpc::http::{find_providers, provide, ProvideBody, State};
use svc_dht::types::B3Cid;

// ---- test-global metrics to avoid duplicate Prometheus registration
static METRICS: OnceLock<Arc<DhtMetrics>> = OnceLock::new();
fn metrics() -> Arc<DhtMetrics> {
    METRICS.get_or_init(|| Arc::new(DhtMetrics::new().expect("metrics"))).clone()
}

fn make_state() -> State {
    let health = Arc::new(HealthState::default());
    let ready = Arc::new(ReadyGate::new());
    ready.set_ready();

    let providers = Arc::new(Store::new(Duration::from_secs(60)));
    let lookup_ctx = Arc::new(LookupCtx::new(providers.clone(), 16));

    State::new(
        health,
        ready,
        metrics(),
        providers,
        3, // alpha
        1, // beta
        6, // hop_budget
        Duration::from_millis(300),
        Duration::from_millis(15),
        Duration::from_millis(50),
        lookup_ctx,
    )
}

#[tokio::test]
async fn provide_and_find_basic() {
    let st = make_state();

    // Provide a short-lived record.
    let cid: B3Cid =
        "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef".parse().unwrap();

    let body =
        ProvideBody { cid: cid.clone(), node: "local://nodeA".to_string(), ttl_secs: Some(2) };
    let resp = provide(AxumState(st.clone()), axum::Json(body)).await.into_response();
    assert_eq!(resp.status(), StatusCode::OK);

    // Find providers (should see exactly 1).
    let resp = find_providers(AxumState(st), axum::extract::Path(cid)).await.into_response();
    assert_eq!(resp.status(), StatusCode::OK);

    let body_bytes = axum::body::to_bytes(resp.into_body(), 1024 * 1024).await.expect("body bytes");
    let v: serde_json::Value = serde_json::from_slice(&body_bytes).expect("json");
    assert_eq!(
        v.get("providers").unwrap().as_array().unwrap().len(),
        1,
        "exactly one provider expected"
    );
}

#[tokio::test]
async fn provide_rejects_bad_node_uri() {
    let st = make_state();

    let cid: B3Cid =
        "b3:aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa".parse().unwrap();

    // Bad node URI should be rejected with 400.
    let bad = ProvideBody { cid, node: "not a uri".into(), ttl_secs: None };
    let resp = provide(AxumState(st), axum::Json(bad)).await.into_response();
    assert_eq!(resp.status(), StatusCode::BAD_REQUEST);
}

```

### crates/svc-dht/tests/asn_diversity.rs
<a id="crates-svc-dht-tests-asndiversity-rs"></a>

```rust
//! RO:WHAT — Local, self-contained test for "ASN diversity" selection logic.
//! RO:WHY  — We don’t have a real ASN guard yet; this models the policy in-test
//!           so we can lock behavior now and swap to the real guard later.
//! RO:NOTES — Pure test logic; no crate changes needed to pass.

use std::collections::HashSet;

/// Minimal stand-in for an "ASN diversity" filter:
/// Keep candidates while ensuring at least `min_unique_asn` distinct ASNs stay present.
/// Returns Err if impossible.
fn select_with_asn_diversity(
    mut candidates: Vec<(String, u32)>,
    min_unique_asn: usize,
    limit: usize,
) -> Result<Vec<(String, u32)>, &'static str> {
    // Greedy: first ensure we include one per ASN to hit the floor, then fill up to limit.
    candidates.sort_by_key(|(_, asn)| *asn);

    let mut seen = HashSet::new();
    let mut out = Vec::new();

    // Phase A: one per ASN until we hit the floor (or run out)
    for (node, asn) in candidates.iter().cloned() {
        if seen.insert(asn) {
            out.push((node, asn));
            if seen.len() >= min_unique_asn {
                break;
            }
        }
    }
    if seen.len() < min_unique_asn {
        return Err("asn_floor_unmet");
    }

    // Phase B: fill remainder by round-robin (here just linear pass) without ASN constraint
    for (node, asn) in candidates.into_iter() {
        if out.len() >= limit {
            break;
        }
        // allow duplicates of ASNs now
        if !out.iter().any(|(n, _)| *n == node) {
            out.push((node, asn));
        }
    }

    if out.len() > limit {
        out.truncate(limit);
    }
    Ok(out)
}

#[test]
fn rejects_all_same_asn_when_floor_gt1() {
    let candidates =
        vec![("n1".to_string(), 64512), ("n2".to_string(), 64512), ("n3".to_string(), 64512)];
    let res = select_with_asn_diversity(candidates, /*min_unique_asn*/ 2, /*limit*/ 2);
    assert!(res.is_err(), "should reject when all candidates share the same ASN");
}

#[test]
fn accepts_mix_and_meets_floor() {
    let candidates = vec![
        ("a".to_string(), 64512),
        ("b".to_string(), 64513),
        ("c".to_string(), 64512),
        ("d".to_string(), 64514),
    ];
    let out = select_with_asn_diversity(candidates, /*min_unique_asn*/ 2, /*limit*/ 3).unwrap();
    let unique_asn: HashSet<_> = out.iter().map(|(_, a)| *a).collect();
    assert!(unique_asn.len() >= 2, "expected ASN diversity floor met");
    assert!(out.len() <= 3);
}

```

### crates/svc-dht/tests/chaos/netem.rs
<a id="crates-svc-dht-tests-chaos-netem-rs"></a>

```rust
// chaos/netem.rs: latency/loss model tests (placeholder).

```

### crates/svc-dht/tests/chaos/partition.rs
<a id="crates-svc-dht-tests-chaos-partition-rs"></a>

```rust
// chaos/partition.rs: split-brain healing (placeholder).

```

### crates/svc-dht/tests/chaos/soak_churn.rs
<a id="crates-svc-dht-tests-chaos-soakchurn-rs"></a>

```rust
// chaos/soak_churn.rs: long soak & churn (placeholder).

```

### crates/svc-dht/tests/deadline_hedge.rs
<a id="crates-svc-dht-tests-deadlinehedge-rs"></a>

```rust
use std::time::Duration;
use svc_dht::pipeline::hedging::race_hedged;
use tokio::time::sleep;

#[tokio::test]
async fn hedger_respects_budget_and_stagger() {
    // NOTE: We intentionally set budget to 20ms and stagger to 5ms, then make the
    // primary slow and hedges fast. Expect total elapsed < ~25ms and Ok(()).

    let budget = Duration::from_millis(20);
    let stagger = Duration::from_millis(5);

    let started = std::time::Instant::now();

    let out = race_hedged::<_, _, (), ()>(2, stagger, budget, |leg_idx| async move {
        if leg_idx == 0 {
            sleep(Duration::from_millis(100)).await; // slow primary hits timeout → hedges win
        } else {
            sleep(Duration::from_millis(1)).await; // fast hedge
        }
        Ok(())
    })
    .await;

    let elapsed = started.elapsed();
    assert!(out.is_ok(), "hedged race should succeed via hedge");
    assert!(elapsed < Duration::from_millis(30), "elapsed too large: {elapsed:?}");
}

```

### crates/svc-dht/tests/kbucket_props.rs
<a id="crates-svc-dht-tests-kbucketprops-rs"></a>

```rust
//! RO:WHAT — Routing table properties that hold for the MVP implementation.
//! RO:WHY  — Catch regressions in bucket indexing and "closest N" behavior.
//! RO:INTERACTS — peer::{NodeId, RoutingTable}

use svc_dht::peer::{NodeId, RoutingTable};

fn nid(bytes: &[u8]) -> NodeId {
    // NodeId::from_pubkey() hashes input; that's fine for deterministic construction
    NodeId::from_pubkey(bytes)
}

#[test]
fn distance_xor_zero_for_identical_ids() {
    let a = nid(&[0xAA; 32]);
    let d = a.distance(&a);
    assert!(d.iter().all(|&b| b == 0), "distance(self,self) must be zero");
}

#[test]
fn closest_respects_limit_and_has_no_duplicates() {
    let me = nid(&[0x11; 32]);
    let rt = RoutingTable::new(/*k*/ 8);

    // Observe > 8 peers; closest(.., n) must never return more than n
    for i in 0..50u8 {
        let pk = [i; 32];
        rt.observe(me, nid(&pk));
    }

    let out = rt.closest(me, nid(&[0x22; 32]), 8);
    assert!(out.len() <= 8);

    // no duplicates
    let mut set = std::collections::HashSet::new();
    for id in &out {
        assert!(set.insert(id.clone()), "duplicate NodeId in closest()");
    }
}

#[test]
fn bucket_index_monotonicity_smoke() {
    // As distance grows, we *tend* to hit different buckets. We can't see buckets directly,
    // but we can at least ensure observe() doesn't panic and closest() is stable.
    let me = nid(&[0u8; 32]);
    let rt = RoutingTable::new(8);

    // Craft peers at different XOR distances
    let peers = [
        nid(&[0x00; 32]), // identical (distance 0)
        nid(&[0x80; 32]), // highest bit diff
        nid(&[0x7F; 32]), // many lower bits diff
        nid(&[0x01; 32]), // only LSB diff
        nid(&[0xFF; 32]), // all bits diff
    ];

    for p in peers {
        rt.observe(me, p);
    }

    let out = rt.closest(me, nid(&[0x10; 32]), 5);
    assert!(!out.is_empty());
}

```

### crates/svc-dht/tests/nodeid_and_store.rs
<a id="crates-svc-dht-tests-nodeidandstore-rs"></a>

```rust
use std::time::Duration;
use svc_dht::peer::id::NodeId;
use svc_dht::provider::Store;
use svc_dht::types::B3Cid;

#[test]
fn nodeid_distance_xor() {
    let a = NodeId::from_pubkey(b"A");
    let b = NodeId::from_pubkey(b"B");
    let d_ab = a.distance(&b);
    let d_ba = b.distance(&a);
    assert_eq!(d_ab, d_ba, "XOR is symmetric");
    assert_eq!(a.distance(&a), [0u8; 32], "distance to self is zero");
}

#[test]
fn provider_store_ttl_expiry() {
    let ttl = Duration::from_millis(20);
    let st = Store::new(ttl);
    let cid: B3Cid = "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"
        .parse()
        .unwrap();

    st.add(cid.clone(), "local://nodeA".into());
    let now = std::time::Instant::now();
    let got1 = st.get(&cid);
    assert_eq!(got1, vec!["local://nodeA".to_string()]);

    // wait out TTL and prune
    std::thread::sleep(ttl + Duration::from_millis(5));
    st.prune(now + ttl + Duration::from_millis(5));
    let got2 = st.get(&cid);
    assert!(got2.is_empty(), "expired provider should be pruned");
}

```

### crates/svc-dht/tests/provider_roundtrip.rs
<a id="crates-svc-dht-tests-providerroundtrip-rs"></a>

```rust
use std::time::Duration;
use svc_dht::provider::Store;

#[test]
fn provider_add_get_prune_roundtrip() {
    let store = Store::new(Duration::from_secs(2));
    let cid = "b3:deadbeef".to_string();

    // Add two providers; ensure de-dup by node works
    store.add(cid.clone(), "local://A".into(), Some(Duration::from_millis(250)));
    store.add(cid.clone(), "local://B".into(), Some(Duration::from_millis(250)));
    store.add(cid.clone(), "local://A".into(), Some(Duration::from_millis(250))); // refresh

    let mut live = store.get_live(&cid);
    live.sort();
    assert_eq!(live, vec!["local://A", "local://B"]);

    // After expiry window, purge removes both
    std::thread::sleep(Duration::from_millis(300));
    let purged = store.purge_expired();
    assert!(purged >= 1, "expected at least one purged; got {purged}");

    let live2 = store.get_live(&cid);
    assert!(live2.is_empty(), "expected no live providers after purge, got {live2:?}");
}

```

### crates/svc-dht/tests/readiness_bootstrap.rs
<a id="crates-svc-dht-tests-readinessbootstrap-rs"></a>

```rust
#[tokio::test]
async fn boot_and_ready() {
    // Smoke: start the server main() would, but here we just hit the handlers directly
    // (Integration rig lives in the crate’s examples in phase 2)
    assert!(true);
}

```



---



# ron-naming

_Source: crates/ron-naming/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:54:34Z -->
# Code Bundle — `ron-naming`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-naming/.cargo/config.toml](#crates-ron-naming--cargo-config-toml)
- [crates/ron-naming/Cargo.toml](#crates-ron-naming-Cargo-toml)
- [crates/ron-naming/benches/encode_bench.rs](#crates-ron-naming-benches-encodebench-rs)
- [crates/ron-naming/benches/normalize_bench.rs](#crates-ron-naming-benches-normalizebench-rs)
- [crates/ron-naming/deny.toml](#crates-ron-naming-deny-toml)
- [crates/ron-naming/examples/encode_decode.rs](#crates-ron-naming-examples-encodedecode-rs)
- [crates/ron-naming/examples/normalize_roundtrip.rs](#crates-ron-naming-examples-normalizeroundtrip-rs)
- [crates/ron-naming/rust-toolchain.toml](#crates-ron-naming-rust-toolchain-toml)
- [crates/ron-naming/scripts/hash_vectors.sh](#crates-ron-naming-scripts-hashvectors-sh)
- [crates/ron-naming/scripts/render_mermaid.sh](#crates-ron-naming-scripts-rendermermaid-sh)
- [crates/ron-naming/scripts/verify_vectors_attestation.sh](#crates-ron-naming-scripts-verifyvectorsattestation-sh)
- [crates/ron-naming/src/address.rs](#crates-ron-naming-src-address-rs)
- [crates/ron-naming/src/bin/tldctl.rs](#crates-ron-naming-src-bin-tldctl-rs)
- [crates/ron-naming/src/lib.rs](#crates-ron-naming-src-lib-rs)
- [crates/ron-naming/src/normalize.rs](#crates-ron-naming-src-normalize-rs)
- [crates/ron-naming/src/types.rs](#crates-ron-naming-src-types-rs)
- [crates/ron-naming/src/verify/mod.rs](#crates-ron-naming-src-verify-mod-rs)
- [crates/ron-naming/src/version.rs](#crates-ron-naming-src-version-rs)
- [crates/ron-naming/src/wire/cbor.rs](#crates-ron-naming-src-wire-cbor-rs)
- [crates/ron-naming/src/wire/json.rs](#crates-ron-naming-src-wire-json-rs)
- [crates/ron-naming/src/wire/mod.rs](#crates-ron-naming-src-wire-mod-rs)
- [crates/ron-naming/testdata/vectors/names_ascii.json](#crates-ron-naming-testdata-vectors-namesascii-json)
- [crates/ron-naming/testdata/vectors/names_unicode_mixed.json](#crates-ron-naming-testdata-vectors-namesunicodemixed-json)
- [crates/ron-naming/testdata/vectors/tldmap_minimal.json](#crates-ron-naming-testdata-vectors-tldmapminimal-json)
- [crates/ron-naming/testdata/vectors/vectors.manifest.json](#crates-ron-naming-testdata-vectors-vectors-manifest-json)
- [crates/ron-naming/tests/address_hygiene.rs](#crates-ron-naming-tests-addresshygiene-rs)
- [crates/ron-naming/tests/cli_contract.rs](#crates-ron-naming-tests-clicontract-rs)
- [crates/ron-naming/tests/dto_wire_vectors.rs](#crates-ron-naming-tests-dtowirevectors-rs)
- [crates/ron-naming/tests/normalize_idempotence.rs](#crates-ron-naming-tests-normalizeidempotence-rs)

### crates/ron-naming/.cargo/config.toml
<a id="crates-ron-naming--cargo-config-toml"></a>

```toml
[build]
rustflags = ["-Dwarnings"]

[target.'cfg(all())']
# Keep builds deterministic and clean.

[term]
verbose = true

```

### crates/ron-naming/Cargo.toml
<a id="crates-ron-naming-Cargo-toml"></a>

```toml
[package]
name = "ron-naming"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
description = "RON-CORE naming & addressing types (schema-only; no runtime lookups)."
repository = "https://github.com/RustyOnions/RustyOnions"
readme = "README.md"
categories = ["network-programming", "encoding", "data-structures"]
keywords = ["RON", "naming", "addressing", "BLAKE3", "IDNA"]

[features]
default = []
cli = ["dep:clap", "dep:anyhow", "dep:base64"]
verify = []

[dependencies]
# Core
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
serde_cbor = "0.11"
thiserror = "1.0"
bytes = "1.6"
blake3 = "1.5"
semver = { version = "1.0", features = ["serde"] }

# Naming / normalization
idna = "0.5"
unicode-normalization = "0.1"
regex = "1.11"
once_cell = "1.19"

# CLI (feature-gated)
clap = { version = "4.5", features = ["derive"], optional = true }
anyhow = { version = "1.0", optional = true }
base64 = { version = "0.22", optional = true }

[dev-dependencies]
proptest = "1.5"
insta = { version = "1.39", features = ["yaml"] }
criterion = "0.5"
assert_cmd = "2.0"
predicates = "3.1"

[[bin]]
name = "tldctl"
path = "src/bin/tldctl.rs"
required-features = ["cli"]

[[bench]]
name = "normalize_bench"
harness = false

[[bench]]
name = "encode_bench"
harness = false

```

### crates/ron-naming/benches/encode_bench.rs
<a id="crates-ron-naming-benches-encodebench-rs"></a>

```rust
//! RO:WHAT — Criterion benches for JSON/CBOR encode/decode of DTOs.
//! RO:WHY  — Wire-format throughput snapshot for SDK users.

use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ron_naming::{
    types::{ContentId, Fqdn, NameRecord},
    version::parse_version,
    wire, Address,
};

fn bench_json_cbor(c: &mut Criterion) {
    let addr = Address::Name {
        fqdn: Fqdn("files.example".into()),
        version: Some(parse_version("1.2.3").unwrap()),
    };
    let rec = NameRecord {
        name: Fqdn("files.example".into()),
        version: Some(parse_version("1.2.3").unwrap()),
        content: ContentId(
            "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef".into(),
        ),
    };

    c.bench_function("json/address_roundtrip", |b| {
        b.iter(|| {
            let a = wire::json::roundtrip_address_json(black_box(&addr)).unwrap();
            black_box(a);
        })
    });

    c.bench_function("json/record_roundtrip", |b| {
        b.iter(|| {
            let r = wire::json::roundtrip_record_json(black_box(&rec)).unwrap();
            black_box(r);
        })
    });

    c.bench_function("cbor/address_roundtrip", |b| {
        b.iter(|| {
            let a = wire::cbor::roundtrip_address_cbor(black_box(&addr)).unwrap();
            black_box(a);
        })
    });

    c.bench_function("cbor/record_roundtrip", |b| {
        b.iter(|| {
            let r = wire::cbor::roundtrip_record_cbor(black_box(&rec)).unwrap();
            black_box(r);
        })
    });
}

criterion_group!(naming_encode, bench_json_cbor);
criterion_main!(naming_encode);

```

### crates/ron-naming/benches/normalize_bench.rs
<a id="crates-ron-naming-benches-normalizebench-rs"></a>

```rust
//! RO:WHAT — Criterion bench for domain normalization (Unicode → ASCII FQDN).
//! RO:WHY  — Track perf and regressions for IDNA/NFC pipeline.
//! RO:NOTES — Keep vectors tiny; this is a types crate (no I/O).

use criterion::{black_box, criterion_group, criterion_main, BatchSize, Criterion};
use ron_naming::normalize::normalize_fqdn_ascii;

fn bench_normalize(c: &mut Criterion) {
    let cases = [
        "example.com",
        "Café.Example",
        "bücher.example",
        "δοκιμή.Ελλάδα",       // Greek
        "пример.рф",           // Cyrillic
        "예시.테스트",         // Korean
        "مثال.إختبار",         // Arabic
        "παράδειγμα.δοκιμή",   // Greek extended
        "xn--caf-dma.example", // already punycoded
    ];

    c.bench_function("normalize_fqdn_ascii/mixed", |b| {
        b.iter_batched(
            || cases.to_vec(),
            |inputs| {
                for s in inputs {
                    let out = normalize_fqdn_ascii(black_box(s)).unwrap();
                    black_box(out);
                }
            },
            BatchSize::SmallInput,
        )
    });

    c.bench_function("normalize_fqdn_ascii/hot_ascii", |b| {
        b.iter(|| {
            let out = normalize_fqdn_ascii(black_box("sub.service.ron.dev")).unwrap();
            black_box(out);
        })
    });
}

criterion_group!(naming_norm, bench_normalize);
criterion_main!(naming_norm);

```

### crates/ron-naming/deny.toml
<a id="crates-ron-naming-deny-toml"></a>

```toml
# cargo-deny baseline for ron-naming2 (minimal, expand as needed)
[advisories]
yanked = "deny"

[licenses]
unlicensed = "deny"
copyleft = "deny"
allow = [
  "Apache-2.0",
  "MIT",
  "Unicode-DFS-2016",
  "Unicode-3.0",
  "CC0-1.0",
  "CDLA-Permissive-2.0",
  "BSD-3-Clause",
]
confidence-threshold = 0.8

```

### crates/ron-naming/examples/encode_decode.rs
<a id="crates-ron-naming-examples-encodedecode-rs"></a>

```rust
use ron_naming::{
    types::{ContentId, Fqdn, NameRecord},
    version::parse_version,
    wire,
};

fn main() {
    let rec = NameRecord {
        name: Fqdn("files.example".into()),
        version: Some(parse_version("1.0.0").unwrap()),
        content: ContentId(
            "b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef".into(),
        ),
    };
    let jb = wire::json::to_json_bytes(&rec).unwrap();
    let round: NameRecord = wire::json::from_json_bytes(&jb).unwrap();
    assert_eq!(rec, round);
    println!("{}", String::from_utf8(jb).unwrap());
}

```

### crates/ron-naming/examples/normalize_roundtrip.rs
<a id="crates-ron-naming-examples-normalizeroundtrip-rs"></a>

```rust
fn main() {
    let input = std::env::args().nth(1).expect("name");
    let out = ron_naming::normalize::normalize_fqdn_ascii(&input).expect("normalize");
    println!("{}", (out.0).0);
}

```

### crates/ron-naming/rust-toolchain.toml
<a id="crates-ron-naming-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["clippy", "rustfmt"]
profile = "minimal"

```

### crates/ron-naming/scripts/hash_vectors.sh
<a id="crates-ron-naming-scripts-hashvectors-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Portable BLAKE3 hashing: prefer 'b3sum' if available, else fallback to 'shasum -a 256' as placeholder.
# Replace fallback with a real BLAKE3 tool in your env/CI.

DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
VEC_DIR="$DIR/testdata/vectors"
OUT="$DIR/testdata/signatures/vectors.b3.txt"

if command -v b3sum >/dev/null 2>&1; then
  (cd "$VEC_DIR" && b3sum names_ascii.json names_unicode_mixed.json tldmap_minimal.json tldmap_minimal.cbor) > "$OUT"
  echo "algo=BLAKE3-256" >> "$OUT"
  echo "OK wrote $OUT (BLAKE3)"
else
  (cd "$VEC_DIR" && shasum -a 256 names_ascii.json names_unicode_mixed.json tldmap_minimal.json tldmap_minimal.cbor) > "$OUT"
  echo "algo=SHA-256 (TEMPORARY FALLBACK — replace with BLAKE3 in CI)" >> "$OUT"
  echo "Wrote $OUT (SHA-256 fallback)"
fi

```

### crates/ron-naming/scripts/render_mermaid.sh
<a id="crates-ron-naming-scripts-rendermermaid-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Render Mermaid diagrams locally (optional).
# Requires 'mmdc' (mermaid-cli): npm install -g @mermaid-js/mermaid-cli
ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
SRC="$ROOT/docs/diagrams/arch.mmd"
DST="$ROOT/docs/diagrams/arch.svg"

if command -v mmdc >/dev/null 2>&1; then
  mmdc -i "$SRC" -o "$DST"
  echo "Rendered $DST"
else
  echo "mermaid-cli (mmdc) not found; skipped render."
fi

```

### crates/ron-naming/scripts/verify_vectors_attestation.sh
<a id="crates-ron-naming-scripts-verifyvectorsattestation-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Placeholder: call your organization-approved verifier here.
# Intended to verify testdata/signatures/vectors.attestation.txt against vectors and vectors.b3.txt.
echo "verify_vectors_attestation.sh: placeholder (no-op)"

```

### crates/ron-naming/src/address.rs
<a id="crates-ron-naming-src-address-rs"></a>

```rust
//! RO:WHAT — High-level Name/Content addressing grammar.
//! RO:WHY  — Single, portable enum to represent user-facing addresses.
//! RO:INTERACTS — types::{Fqdn, ContentId}, version::NameVersion, normalize.
//! RO:INVARIANTS — Content ids are "b3:<hex>"; names are normalized ASCII; optional "@<semver>" suffix for versions.
//! RO:TEST — tests/address_hygiene.rs

use crate::normalize::{normalize_fqdn_ascii, NormalizedFqdn};
use crate::types::{ContentId, Fqdn};
use crate::version::{parse_version, NameVersion};
use serde::{Deserialize, Serialize};

/// A user-facing address: either content-id (b3:...) or a (name[@version]) tuple.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
#[serde(tag = "kind", rename_all = "snake_case", deny_unknown_fields)]
pub enum Address {
    /// Canonical content-address (BLAKE3-256).
    ///
    /// The `id` must be of the form `"b3:<64 hex>"`, all lowercase.
    Content {
        /// Canonical content identifier (`"b3:<hex>"`).
        id: ContentId,
    },
    /// Named address with optional semantic version.
    Name {
        /// Normalized ASCII FQDN (no trailing dot).
        fqdn: Fqdn,
        /// Optional semantic version tagged to the name (e.g., `1.2.3`).
        version: Option<NameVersion>,
    },
}

impl Address {
    /// Parse from a user string: either `b3:<hex>` or `name[@semver]`.
    pub fn parse(s: &str) -> Result<Self, ParseAddressError> {
        let s = s.trim();
        if s.starts_with("b3:") {
            let id = ContentId(s.to_owned());
            if !id.validate() {
                return Err(ParseAddressError::InvalidContentId);
            }
            return Ok(Address::Content { id });
        }
        // version suffix: name@1.2.3 (optional)
        let (name_part, ver_opt) = match s.rsplit_once('@') {
            Some((left, right)) if !right.is_empty() && left.contains('.') => (left, Some(right)),
            _ => (s, None),
        };
        let NormalizedFqdn(Fqdn(name)) =
            normalize_fqdn_ascii(name_part).map_err(|_| ParseAddressError::InvalidName)?;
        let fqdn = Fqdn(name);
        let version = match ver_opt {
            Some(vs) => Some(parse_version(vs).map_err(|_| ParseAddressError::InvalidVersion)?),
            None => None,
        };
        Ok(Address::Name { fqdn, version })
    }

    /// Render compact string form: `b3:<hex>` or `name[@ver]`.
    pub fn to_compact(&self) -> String {
        match self {
            Address::Content { id } => id.0.clone(),
            Address::Name { fqdn, version } => match version {
                Some(v) => format!("{}@{}", fqdn.0, v),
                None => fqdn.0.clone(),
            },
        }
    }
}

/// Parse errors for [`Address::parse`].
#[derive(thiserror::Error, Debug)]
pub enum ParseAddressError {
    /// The content id is not a valid `"b3:<64 hex>"` string.
    #[error("invalid content id")]
    InvalidContentId,
    /// The provided name failed IDNA/ASCII hygiene.
    #[error("invalid name")]
    InvalidName,
    /// The version part is not valid semantic versioning.
    #[error("invalid version")]
    InvalidVersion,
}

```

### crates/ron-naming/src/bin/tldctl.rs
<a id="crates-ron-naming-src-bin-tldctl-rs"></a>

```rust
//! RO:WHAT — Minimal CLI for naming hygiene: parse/normalize/encode.
//! RO:WHY  — Folded from tldctl into ron-naming (canon); DX helper only.
//! RO:INTERACTS — address, normalize, wire::{json,cbor}
//! RO:INVARIANTS — No network; stdout-only. Errors are structured.

#![cfg(feature = "cli")]

use base64::Engine; // bring trait in-scope for .encode()
use clap::{Parser, Subcommand};
use ron_naming::{
    address::ParseAddressError, normalize::normalize_fqdn_ascii, wire, Address, NameRecord,
};

/// tldctl — RON naming toolbox (normalize, parse, encode)
#[derive(Parser, Debug)]
#[command(author, version, about)]
struct Cli {
    #[command(subcommand)]
    cmd: Cmd,
}

#[derive(Subcommand, Debug)]
enum Cmd {
    /// Normalize a domain name to ASCII (UTS-46/IDNA)
    Normalize { name: String },

    /// Parse a user address string (b3:... or name[@ver]) and print JSON DTO
    Parse { addr: String },

    /// Encode a NameRecord as JSON
    Json {
        name: String,
        /// Optional semantic version like 1.2.3
        #[arg(long)]
        version: Option<String>,
        /// Content id in the form b3:<64hex>
        #[arg(long)]
        content: String,
    },

    /// Encode a NameRecord as CBOR (base64 to stdout)
    Cbor {
        name: String,
        /// Optional semantic version like 1.2.3
        #[arg(long)]
        version: Option<String>,
        /// Content id in the form b3:<64hex>
        #[arg(long)]
        content: String,
    },
}

fn main() -> anyhow::Result<()> {
    let cli = Cli::parse();
    match cli.cmd {
        Cmd::Normalize { name } => {
            let nfqdn = normalize_fqdn_ascii(&name)?;
            println!("{}", (nfqdn.0).0);
        }
        Cmd::Parse { addr } => {
            let a = Address::parse(&addr).map_err(map_addr_err)?;
            let bytes = wire::json::to_json_bytes(&a)?;
            println!("{}", String::from_utf8(bytes).unwrap());
        }
        Cmd::Json {
            name,
            version,
            content,
        } => {
            let a = Address::parse(&format!(
                "{}{}",
                name,
                version
                    .as_deref()
                    .map(|v| format!("@{v}"))
                    .unwrap_or_default()
            ))?;
            let nr = match a {
                Address::Name { fqdn, version } => NameRecord {
                    name: fqdn,
                    version,
                    content: ron_naming::types::ContentId(content),
                },
                Address::Content { .. } => anyhow::bail!(
                    "content id form is not allowed for NameRecord 'name' (expect a domain)"
                ),
            };
            let bytes = wire::json::to_json_bytes(&nr)?;
            println!("{}", String::from_utf8(bytes).unwrap());
        }
        Cmd::Cbor {
            name,
            version,
            content,
        } => {
            let a = Address::parse(&format!(
                "{}{}",
                name,
                version
                    .as_deref()
                    .map(|v| format!("@{v}"))
                    .unwrap_or_default()
            ))?;
            let nr = match a {
                Address::Name { fqdn, version } => NameRecord {
                    name: fqdn,
                    version,
                    content: ron_naming::types::ContentId(content),
                },
                Address::Content { .. } => anyhow::bail!(
                    "content id form is not allowed for NameRecord 'name' (expect a domain)"
                ),
            };
            let bytes = wire::cbor::to_cbor_bytes(&nr)?;
            let b64 = base64::engine::general_purpose::STANDARD.encode(bytes);
            println!("{b64}");
        }
    }
    Ok(())
}

fn map_addr_err(e: ParseAddressError) -> anyhow::Error {
    match e {
        ParseAddressError::InvalidContentId => {
            anyhow::anyhow!("invalid content id (expect b3:<64 hex>)")
        }
        ParseAddressError::InvalidName => {
            anyhow::anyhow!("invalid name (IDNA/ASCII hygiene failed)")
        }
        ParseAddressError::InvalidVersion => {
            anyhow::anyhow!("invalid version (semver)")
        }
    }
}

```

### crates/ron-naming/src/lib.rs
<a id="crates-ron-naming-src-lib-rs"></a>

```rust
//! RO:WHAT — Public entry for RON naming/addressing types and wire helpers.
//! RO:WHY  — Pillar 9 (Content & Naming). This crate defines schemas & hygiene only;
//!           runtime lookups live in svc-index (DHT/overlay are elsewhere).
//! RO:INTERACTS — crate::types, crate::normalize, crate::address, crate::version, crate::wire::*
//! RO:INVARIANTS — DTOs are pure (serde, deny_unknown_fields); content ids are "b3:<hex>"; no locks across .await.
//! RO:SECURITY — No ambient I/O or network; pure value types; amnesia posture is N/A here.
//! RO:TEST — unit tests in module files; round-trip vectors in tests/ (JSON/CBOR).

#![forbid(unsafe_code)]
#![deny(rust_2018_idioms, missing_docs, clippy::all)]

pub mod address;
pub mod normalize;
pub mod types;
pub mod version;

/// Wire-encoding helpers (JSON/CBOR) for DTO round-trips.
///
/// These are thin serde wrappers used by tests/examples/SDKs. Transport/runtime
/// concerns live in services (e.g., svc-index); this module is schema-focused.
pub mod wire {
    /// CBOR helpers.
    pub mod cbor;
    /// JSON helpers.
    pub mod json;
}

#[cfg(feature = "verify")]
pub mod verify;

pub use address::{Address, ParseAddressError};
pub use normalize::{normalize_fqdn_ascii, NormalizedFqdn};
pub use types::{ContentId, Fqdn, NameRecord};
pub use version::{NameVersion, VersionParseError};

```

### crates/ron-naming/src/normalize.rs
<a id="crates-ron-naming-src-normalize-rs"></a>

```rust
//! RO:WHAT — Unicode/IDNA normalization to canonical ASCII FQDNs.
//! RO:WHY  — Interop & safety: enforce UTS-46/IDNA processing and local hygiene.
//! RO:INTERACTS — types::Fqdn
//! RO:INVARIANTS — Lowercase; NFC; IDNA ASCII (Punycode) with trailing dot stripped; collapse consecutive dots.
//! RO:TEST — tests/normalize_idempotence.rs; examples/normalize_roundtrip.rs

use idna::domain_to_ascii;
use once_cell::sync::Lazy;
use regex::Regex;
use unicode_normalization::UnicodeNormalization;

use crate::types::Fqdn;

/// Normalized ASCII FQDN (newtype wrapper for type-safety).
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct NormalizedFqdn(pub Fqdn);

static DOTS: Lazy<Regex> = Lazy::new(|| Regex::new(r"\.+").expect("regex"));

/// Normalize an input domain (Unicode or ASCII) into canonical ASCII FQDN.
///
/// Steps:
/// 1. Trim whitespace; strip any leading/trailing dots.
/// 2. Unicode NFC normalize.
/// 3. Collapse consecutive dots to a single dot.
/// 4. Apply UTS-46 / IDNA to ASCII (punycode).
/// 5. Lowercase; validate ASCII FQDN hygiene.
pub fn normalize_fqdn_ascii(input: &str) -> Result<NormalizedFqdn, NormalizeError> {
    let trimmed = input.trim();
    if trimmed.is_empty() {
        return Err(NormalizeError::Empty);
    }
    let nfc = trimmed.nfc().collect::<String>();
    let no_edges = nfc.trim_matches('.');
    let collapsed = DOTS.replace_all(no_edges, ".").into_owned();
    let ascii = domain_to_ascii(&collapsed).map_err(|_| NormalizeError::Idna)?;
    let lower = ascii.to_ascii_lowercase();
    let fqdn = Fqdn(lower);
    if !fqdn.is_valid() {
        return Err(NormalizeError::InvalidAscii);
    }
    Ok(NormalizedFqdn(fqdn))
}

/// Normalization errors.
#[derive(thiserror::Error, Debug)]
pub enum NormalizeError {
    /// Empty input.
    #[error("empty input")]
    Empty,
    /// IDNA/UTS-46 mapping failed.
    #[error("invalid domain (IDNA)")]
    Idna,
    /// Resulting ASCII FQDN failed hygiene checks.
    #[error("invalid ascii fqdn")]
    InvalidAscii,
}

```

### crates/ron-naming/src/types.rs
<a id="crates-ron-naming-src-types-rs"></a>

```rust
//! RO:WHAT — Fundamental naming/addressing DTOs used across RON.
//! RO:WHY  — Keep schemas/validation centralized; services (svc-index) consume these types.
//! RO:INTERACTS — address, normalize, version, wire::{json,cbor}
//! RO:INVARIANTS — DTO hygiene with #[serde(deny_unknown_fields)]; content id prefix "b3:" only.
//! RO:METRICS — none here (types-only).
//! RO:SECURITY — No secrets; no I/O.
//! RO:TEST — see tests/address_hygiene.rs and dto_wire_vectors.rs.

use serde::{Deserialize, Serialize};

/// Fully Qualified Domain Name (ASCII, normalized, no trailing dot).
#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Serialize, Deserialize)]
#[serde(transparent)]
pub struct Fqdn(pub String);

impl Fqdn {
    /// Returns `true` if this FQDN looks syntactically valid (cheap checks).
    pub fn is_valid(&self) -> bool {
        // Minimal hygiene: 1..=253 bytes, labels 1..=63, allowed chars (a-z0-9-), no leading/trailing hyphen.
        let s = self.0.as_str();
        if s.is_empty() || s.len() > 253 || s.starts_with('.') || s.ends_with('.') {
            return false;
        }
        for label in s.split('.') {
            if label.is_empty() || label.len() > 63 {
                return false;
            }
            if label.starts_with('-') || label.ends_with('-') {
                return false;
            }
            if !label
                .chars()
                .all(|c| c.is_ascii_lowercase() || c.is_ascii_digit() || c == '-')
            {
                return false;
            }
        }
        true
    }
}

/// Content ID — canonical BLAKE3-256 address, always `"b3:<hex>"`.
#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Serialize, Deserialize)]
#[serde(transparent)]
pub struct ContentId(pub String);

impl ContentId {
    /// Validate the `b3:<hex>` shape (lowercase, 64 hex chars).
    pub fn validate(&self) -> bool {
        let s = self.0.as_str();
        if !s.starts_with("b3:") {
            return false;
        }
        let hex = &s[3..];
        hex.len() == 64 && hex.bytes().all(|b| matches!(b, b'0'..=b'9' | b'a'..=b'f'))
    }
}

/// Example DTO representing a name→manifest mapping (types-only).
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct NameRecord {
    /// Normalized ASCII FQDN.
    pub name: Fqdn,
    /// Optional semantic version of the record (e.g., for app packages).
    pub version: Option<crate::version::NameVersion>,
    /// Addressed manifest/content.
    pub content: ContentId,
}

```

### crates/ron-naming/src/verify/mod.rs
<a id="crates-ron-naming-src-verify-mod-rs"></a>

```rust
//! RO:WHAT — Optional verification helpers for test vectors / attestations.
//! RO:WHY  — Keep checks in-library for CI without introducing runtime owners.
//! RO:INVARIANTS — No network or disk I/O beyond caller-provided bytes.

use blake3::Hasher;

/// Compute a BLAKE3-256 hex for provided bytes (lowercase).
pub fn blake3_hex(bytes: &[u8]) -> String {
    let mut h = Hasher::new();
    h.update(bytes);
    h.finalize().to_hex().to_string()
}

```

### crates/ron-naming/src/version.rs
<a id="crates-ron-naming-src-version-rs"></a>

```rust
//! RO:WHAT — Name version wrapper atop semver for optional versioned records.
//! RO:WHY  — Keep version grammar stable and decoupled from services.
//! RO:INVARIANTS — Strict semver parse; serialized as plain string.
//! RO:TEST — unit tests in this module.

use serde::{Deserialize, Deserializer, Serialize, Serializer};
use std::fmt;

/// Semantic Version wrapper (e.g., "1.2.3").
#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct NameVersion(pub semver::Version);

impl Serialize for NameVersion {
    fn serialize<S: Serializer>(&self, s: S) -> Result<S::Ok, S::Error> {
        s.serialize_str(&self.0.to_string())
    }
}

impl<'de> Deserialize<'de> for NameVersion {
    fn deserialize<D: Deserializer<'de>>(d: D) -> Result<Self, D::Error> {
        let s = String::deserialize(d)?;
        semver::Version::parse(&s)
            .map(NameVersion)
            .map_err(|e| serde::de::Error::custom(e.to_string()))
    }
}

/// Parser error.
#[derive(thiserror::Error, Debug)]
#[error("invalid version: {0}")]
pub struct VersionParseError(pub String);

impl fmt::Display for NameVersion {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        self.0.fmt(f)
    }
}

/// Parse a version string into `NameVersion`.
pub fn parse_version(s: &str) -> Result<NameVersion, VersionParseError> {
    semver::Version::parse(s)
        .map(NameVersion)
        .map_err(|e| VersionParseError(e.to_string()))
}

```

### crates/ron-naming/src/wire/cbor.rs
<a id="crates-ron-naming-src-wire-cbor-rs"></a>

```rust
//! RO:WHAT — CBOR encode/decode helpers for Address and NameRecord.
//! RO:WHY  — Compact vectors for interop; mirrors JSON helpers.
//! RO:INVARIANTS — Pure serde; canonical map ordering is a caller concern.

use crate::{types::NameRecord, Address};
use serde::{de::DeserializeOwned, Serialize};

/// Encode any serializable DTO to CBOR bytes.
pub fn to_cbor_bytes<T: Serialize>(v: &T) -> Result<Vec<u8>, serde_cbor::Error> {
    serde_cbor::to_vec(v)
}

/// Decode any DTO from CBOR bytes.
pub fn from_cbor_bytes<T: DeserializeOwned>(bytes: &[u8]) -> Result<T, serde_cbor::Error> {
    serde_cbor::from_slice(bytes)
}

/// Round-trip an [`Address`] through CBOR (encode then decode).
pub fn roundtrip_address_cbor(a: &Address) -> Result<Address, serde_cbor::Error> {
    let bytes = to_cbor_bytes(a)?;
    from_cbor_bytes::<Address>(&bytes)
}

/// Round-trip a [`NameRecord`] through CBOR (encode then decode).
pub fn roundtrip_record_cbor(r: &NameRecord) -> Result<NameRecord, serde_cbor::Error> {
    let bytes = to_cbor_bytes(r)?;
    from_cbor_bytes::<NameRecord>(&bytes)
}

```

### crates/ron-naming/src/wire/json.rs
<a id="crates-ron-naming-src-wire-json-rs"></a>

```rust
//! RO:WHAT — JSON encode/decode helpers for Address and NameRecord.
//! RO:WHY  — Test vectors & SDK interop in a single place.
//! RO:INVARIANTS — Pure serde; deny unknown fields via parent DTOs.

use crate::{types::NameRecord, Address};
use serde::{de::DeserializeOwned, Serialize};

/// Encode any serializable DTO to JSON bytes.
pub fn to_json_bytes<T: Serialize>(v: &T) -> Result<Vec<u8>, serde_json::Error> {
    serde_json::to_vec_pretty(v)
}

/// Decode any DTO from JSON bytes.
pub fn from_json_bytes<T: DeserializeOwned>(bytes: &[u8]) -> Result<T, serde_json::Error> {
    serde_json::from_slice(bytes)
}

/// Convenience: round-trip an Address to JSON and back.
pub fn roundtrip_address_json(a: &Address) -> Result<Address, serde_json::Error> {
    let bytes = to_json_bytes(a)?;
    from_json_bytes::<Address>(&bytes)
}

/// Convenience: round-trip a NameRecord to JSON and back.
pub fn roundtrip_record_json(r: &NameRecord) -> Result<NameRecord, serde_json::Error> {
    let bytes = to_json_bytes(r)?;
    from_json_bytes::<NameRecord>(&bytes)
}

```

### crates/ron-naming/src/wire/mod.rs
<a id="crates-ron-naming-src-wire-mod-rs"></a>

```rust
//! RO:WHAT — Wire (encoding) helpers for JSON/CBOR round-trips.
//! RO:WHY  — Interop hygiene; DTOs are pure; services pick the transport.
//! RO:INVARIANTS — #[serde(deny_unknown_fields)] on message shapes.

pub mod json;
pub mod cbor;

```

### crates/ron-naming/testdata/vectors/names_ascii.json
<a id="crates-ron-naming-testdata-vectors-namesascii-json"></a>

```json
{
  "note": "placeholder ASCII names for normalization vectors",
  "items": ["example", "test", "alpha", "beta"]
}

```

### crates/ron-naming/testdata/vectors/names_unicode_mixed.json
<a id="crates-ron-naming-testdata-vectors-namesunicodemixed-json"></a>

```json
{
  "note": "placeholder mixed-script names for confusables/IDNA tests",
  "items": ["ｅxample", "Εxample", "ｅхампⅼе"]
}

```

### crates/ron-naming/testdata/vectors/tldmap_minimal.json
<a id="crates-ron-naming-testdata-vectors-tldmapminimal-json"></a>

```json
{
  "note": "placeholder minimal TLD map",
  "tlds": { "example": { "policy": "placeholder" } }
}

```

### crates/ron-naming/testdata/vectors/vectors.manifest.json
<a id="crates-ron-naming-testdata-vectors-vectors-manifest-json"></a>

```json
{
  "bundle": "ron-naming2-vectors",
  "files": [
    "names_ascii.json",
    "names_unicode_mixed.json",
    "tldmap_minimal.json",
    "tldmap_minimal.cbor"
  ],
  "integrity": {
    "algo": "BLAKE3-256",
    "hash_file": "../signatures/vectors.b3.txt"
  }
}

```

### crates/ron-naming/tests/address_hygiene.rs
<a id="crates-ron-naming-tests-addresshygiene-rs"></a>

```rust
use ron_naming::{normalize::normalize_fqdn_ascii, Address};

#[test]
fn parse_b3_ok() {
    let addr =
        Address::parse("b3:0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef")
            .unwrap();
    assert!(matches!(addr, Address::Content { .. }));
}

#[test]
fn parse_name_with_version() {
    let addr = Address::parse("files.example@1.2.3").unwrap();
    match addr {
        Address::Name { fqdn, version } => {
            assert_eq!(fqdn.0, "files.example");
            assert_eq!(version.unwrap().0.to_string(), "1.2.3");
        }
        _ => panic!("expected name"),
    }
}

#[test]
fn normalize_then_parse() {
    let nf = normalize_fqdn_ascii(" Café.EXAMPLE ").unwrap();
    let addr = Address::parse(&nf.0 .0).unwrap();
    matches!(addr, Address::Name { .. });
}

```

### crates/ron-naming/tests/cli_contract.rs
<a id="crates-ron-naming-tests-clicontract-rs"></a>

```rust
//! RO:WHAT — CLI contract tests for `tldctl`.
//! RO:WHY  — Ensure CLI stays stable. Only runs with `--features cli`.

#![cfg(feature = "cli")]

use assert_cmd::Command;

#[test]
fn normalize_cli_outputs_ascii() {
    let mut cmd = Command::cargo_bin("tldctl").expect("build tldctl");
    cmd.args(["normalize", "Café.Example"]);
    let assert = cmd.assert().success();
    let out = String::from_utf8(assert.get_output().stdout.clone()).unwrap();
    assert_eq!(out.trim(), "xn--caf-dma.example");
}

#[test]
fn parse_cli_emits_json() {
    let mut cmd = Command::cargo_bin("tldctl").expect("build tldctl");
    cmd.args(["parse", "files.example@1.2.3"]);
    let assert = cmd.assert().success();
    let out = String::from_utf8(assert.get_output().stdout.clone()).unwrap();
    assert!(out.contains(r#""kind": "name""#));
    assert!(out.contains(r#""fqdn": "files.example""#));
    assert!(out.contains(r#""version": "1.2.3""#));
}

```

### crates/ron-naming/tests/dto_wire_vectors.rs
<a id="crates-ron-naming-tests-dtowirevectors-rs"></a>

```rust
#[test]
fn placeholder_dto_wire_vectors() {
    // This will later load testdata/vectors/*.json|*.cbor and assert deterministic bytes.
    assert!(true);
}

```

### crates/ron-naming/tests/normalize_idempotence.rs
<a id="crates-ron-naming-tests-normalizeidempotence-rs"></a>

```rust
use ron_naming::normalize::normalize_fqdn_ascii;

#[test]
fn idempotent_ascii() {
    let a = normalize_fqdn_ascii("EXAMPLE.COM").unwrap();
    let b = normalize_fqdn_ascii(&a.0 .0).unwrap();
    assert_eq!(a, b);
}

#[test]
fn unicode_maps_to_ascii() {
    let a = normalize_fqdn_ascii("café.example").unwrap();
    assert_eq!(a.0 .0, "xn--caf-dma.example");
}

```



---



# svc-storage

_Source: crates/svc-storage/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:54:03Z -->
# Code Bundle — `svc-storage`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/svc-storage/.github/workflows/ci.yml](#crates-svc-storage--github-workflows-ci-yml)
- [crates/svc-storage/.github/workflows/concurrency-guardrails.yml](#crates-svc-storage--github-workflows-concurrency-guardrails-yml)
- [crates/svc-storage/.github/workflows/contract-apis.yml](#crates-svc-storage--github-workflows-contract-apis-yml)
- [crates/svc-storage/.github/workflows/coverage.yml](#crates-svc-storage--github-workflows-coverage-yml)
- [crates/svc-storage/.github/workflows/perf.yml](#crates-svc-storage--github-workflows-perf-yml)
- [crates/svc-storage/.github/workflows/quantum.yml](#crates-svc-storage--github-workflows-quantum-yml)
- [crates/svc-storage/.github/workflows/redteam-fuzz.yml](#crates-svc-storage--github-workflows-redteam-fuzz-yml)
- [crates/svc-storage/.github/workflows/render-mermaid.yml](#crates-svc-storage--github-workflows-render-mermaid-yml)
- [crates/svc-storage/Cargo.toml](#crates-svc-storage-Cargo-toml)
- [crates/svc-storage/benches/etag_range.rs](#crates-svc-storage-benches-etagrange-rs)
- [crates/svc-storage/benches/read_path.rs](#crates-svc-storage-benches-readpath-rs)
- [crates/svc-storage/benches/write_path.rs](#crates-svc-storage-benches-writepath-rs)
- [crates/svc-storage/configs/pq-hybrid.toml](#crates-svc-storage-configs-pq-hybrid-toml)
- [crates/svc-storage/configs/profiles/macronode.toml](#crates-svc-storage-configs-profiles-macronode-toml)
- [crates/svc-storage/configs/profiles/micronode.toml](#crates-svc-storage-configs-profiles-micronode-toml)
- [crates/svc-storage/configs/svc-storage.example.toml](#crates-svc-storage-configs-svc-storage-example-toml)
- [crates/svc-storage/configs/validate.sh](#crates-svc-storage-configs-validate-sh)
- [crates/svc-storage/rust-toolchain.toml](#crates-svc-storage-rust-toolchain-toml)
- [crates/svc-storage/scripts/smoke_storage.sh](#crates-svc-storage-scripts-smokestorage-sh)
- [crates/svc-storage/src/amnesia.rs](#crates-svc-storage-src-amnesia-rs)
- [crates/svc-storage/src/auth/macaroon.rs](#crates-svc-storage-src-auth-macaroon-rs)
- [crates/svc-storage/src/auth/mod.rs](#crates-svc-storage-src-auth-mod-rs)
- [crates/svc-storage/src/bus.rs](#crates-svc-storage-src-bus-rs)
- [crates/svc-storage/src/config.rs](#crates-svc-storage-src-config-rs)
- [crates/svc-storage/src/errors.rs](#crates-svc-storage-src-errors-rs)
- [crates/svc-storage/src/http/error.rs](#crates-svc-storage-src-http-error-rs)
- [crates/svc-storage/src/http/extractors.rs](#crates-svc-storage-src-http-extractors-rs)
- [crates/svc-storage/src/http/middleware.rs](#crates-svc-storage-src-http-middleware-rs)
- [crates/svc-storage/src/http/mod.rs](#crates-svc-storage-src-http-mod-rs)
- [crates/svc-storage/src/http/routes/get_object.rs](#crates-svc-storage-src-http-routes-getobject-rs)
- [crates/svc-storage/src/http/routes/head_object.rs](#crates-svc-storage-src-http-routes-headobject-rs)
- [crates/svc-storage/src/http/routes/health.rs](#crates-svc-storage-src-http-routes-health-rs)
- [crates/svc-storage/src/http/routes/metrics.rs](#crates-svc-storage-src-http-routes-metrics-rs)
- [crates/svc-storage/src/http/routes/mod.rs](#crates-svc-storage-src-http-routes-mod-rs)
- [crates/svc-storage/src/http/routes/post_object.rs](#crates-svc-storage-src-http-routes-postobject-rs)
- [crates/svc-storage/src/http/routes/put_object.rs](#crates-svc-storage-src-http-routes-putobject-rs)
- [crates/svc-storage/src/http/routes/ready.rs](#crates-svc-storage-src-http-routes-ready-rs)
- [crates/svc-storage/src/http/routes/version.rs](#crates-svc-storage-src-http-routes-version-rs)
- [crates/svc-storage/src/http/server.rs](#crates-svc-storage-src-http-server-rs)
- [crates/svc-storage/src/lib.rs](#crates-svc-storage-src-lib-rs)
- [crates/svc-storage/src/main.rs](#crates-svc-storage-src-main-rs)
- [crates/svc-storage/src/metrics.rs](#crates-svc-storage-src-metrics-rs)
- [crates/svc-storage/src/policy/economics.rs](#crates-svc-storage-src-policy-economics-rs)
- [crates/svc-storage/src/policy/mod.rs](#crates-svc-storage-src-policy-mod-rs)
- [crates/svc-storage/src/policy/quotas.rs](#crates-svc-storage-src-policy-quotas-rs)
- [crates/svc-storage/src/policy/residency.rs](#crates-svc-storage-src-policy-residency-rs)
- [crates/svc-storage/src/prelude.rs](#crates-svc-storage-src-prelude-rs)
- [crates/svc-storage/src/readiness.rs](#crates-svc-storage-src-readiness-rs)
- [crates/svc-storage/src/storage/cache.rs](#crates-svc-storage-src-storage-cache-rs)
- [crates/svc-storage/src/storage/cas.rs](#crates-svc-storage-src-storage-cas-rs)
- [crates/svc-storage/src/storage/compression.rs](#crates-svc-storage-src-storage-compression-rs)
- [crates/svc-storage/src/storage/erasure.rs](#crates-svc-storage-src-storage-erasure-rs)
- [crates/svc-storage/src/storage/fs.rs](#crates-svc-storage-src-storage-fs-rs)
- [crates/svc-storage/src/storage/hedged.rs](#crates-svc-storage-src-storage-hedged-rs)
- [crates/svc-storage/src/storage/io.rs](#crates-svc-storage-src-storage-io-rs)
- [crates/svc-storage/src/storage/mod.rs](#crates-svc-storage-src-storage-mod-rs)
- [crates/svc-storage/src/storage/placement.rs](#crates-svc-storage-src-storage-placement-rs)
- [crates/svc-storage/src/storage/pq_envelope.rs](#crates-svc-storage-src-storage-pqenvelope-rs)
- [crates/svc-storage/src/storage/repair.rs](#crates-svc-storage-src-storage-repair-rs)
- [crates/svc-storage/src/storage/replication.rs](#crates-svc-storage-src-storage-replication-rs)
- [crates/svc-storage/src/tls/mod.rs](#crates-svc-storage-src-tls-mod-rs)
- [crates/svc-storage/src/tls/pq.rs](#crates-svc-storage-src-tls-pq-rs)
- [crates/svc-storage/src/tls/server_config.rs](#crates-svc-storage-src-tls-serverconfig-rs)
- [crates/svc-storage/src/types.rs](#crates-svc-storage-src-types-rs)
- [crates/svc-storage/src/uds/mod.rs](#crates-svc-storage-src-uds-mod-rs)
- [crates/svc-storage/src/uds/peercred.rs](#crates-svc-storage-src-uds-peercred-rs)
- [crates/svc-storage/src/uds/server.rs](#crates-svc-storage-src-uds-server-rs)
- [crates/svc-storage/src/version.rs](#crates-svc-storage-src-version-rs)
- [crates/svc-storage/testing/integration/error_caps.rs](#crates-svc-storage-testing-integration-errorcaps-rs)
- [crates/svc-storage/testing/integration/http_get_head_put.rs](#crates-svc-storage-testing-integration-httpgetheadput-rs)
- [crates/svc-storage/testing/integration/profile_matrix.rs](#crates-svc-storage-testing-integration-profilematrix-rs)
- [crates/svc-storage/testing/integration/range_tests.rs](#crates-svc-storage-testing-integration-rangetests-rs)
- [crates/svc-storage/testing/performance/compare_baselines.sh](#crates-svc-storage-testing-performance-comparebaselines-sh)
- [crates/svc-storage/testing/performance/run_load.sh](#crates-svc-storage-testing-performance-runload-sh)
- [crates/svc-storage/testing/performance/scripts/media_facet.sh](#crates-svc-storage-testing-performance-scripts-mediafacet-sh)
- [crates/svc-storage/tests/http_blackbox.rs](#crates-svc-storage-tests-httpblackbox-rs)

### crates/svc-storage/.github/workflows/ci.yml
<a id="crates-svc-storage--github-workflows-ci-yml"></a>

```yaml
name: CI
on: [push, pull_request]
jobs:
  build-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: 1.80.0
          components: rustfmt, clippy
      - run: cargo fmt --all --check
      - run: cargo clippy --all-targets -- -D warnings
      - run: cargo test --all --locked

```

### crates/svc-storage/.github/workflows/concurrency-guardrails.yml
<a id="crates-svc-storage--github-workflows-concurrency-guardrails-yml"></a>

```yaml
name: Concurrency Guardrails
on:
  workflow_dispatch: {}
jobs:
  guardrails:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "Loom/sanitizers hooks placeholder."

```

### crates/svc-storage/.github/workflows/contract-apis.yml
<a id="crates-svc-storage--github-workflows-contract-apis-yml"></a>

```yaml
name: Contract APIs
on: [push, pull_request]
jobs:
  openapi-diff:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Check OpenAPI present
        run: test -f crates/svc-storage2/docs/openapi/svc-storage.yaml

```

### crates/svc-storage/.github/workflows/coverage.yml
<a id="crates-svc-storage--github-workflows-coverage-yml"></a>

```yaml
name: Coverage
on:
  workflow_dispatch: {}
jobs:
  coverage:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "Coverage gate ≥85% placeholder."

```

### crates/svc-storage/.github/workflows/perf.yml
<a id="crates-svc-storage--github-workflows-perf-yml"></a>

```yaml
name: Perf
on:
  workflow_dispatch: {}
jobs:
  perf:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "Perf rig placeholder (range-heavy profile)."

```

### crates/svc-storage/.github/workflows/quantum.yml
<a id="crates-svc-storage--github-workflows-quantum-yml"></a>

```yaml
name: Quantum Matrix
on:
  workflow_dispatch: {}
jobs:
  pq-matrix:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        feature: ["", "pq-hybrid"]
    steps:
      - uses: actions/checkout@v4
      - run: echo "PQ matrix smoke: ${{ matrix.feature }}"

```

### crates/svc-storage/.github/workflows/redteam-fuzz.yml
<a id="crates-svc-storage--github-workflows-redteam-fuzz-yml"></a>

```yaml
name: Redteam Fuzz
on:
  workflow_dispatch: {}
jobs:
  fuzz:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "Fuzz targets placeholder (range/decomp/addr)."

```

### crates/svc-storage/.github/workflows/render-mermaid.yml
<a id="crates-svc-storage--github-workflows-render-mermaid-yml"></a>

```yaml
name: Render Mermaid
on:
  workflow_dispatch: {}
jobs:
  render:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "Render arch/sequence/state diagrams placeholder."

```

### crates/svc-storage/Cargo.toml
<a id="crates-svc-storage-Cargo-toml"></a>

```toml
[package]
name = "svc-storage"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
publish = false

[features]
# Keep http as a marker (no code-gating in this crate) and enable metrics by default.
default = ["http", "metrics"]

http = []
metrics = ["dep:prometheus"]

# future: "tls", "uds", "pq-hybrid"

[dependencies]
# ==== HTTP stack ====
axum = { version = "0.7.9", default-features = false, features = ["tokio", "http1", "http2", "json"] }
# axum-extra removed (we use headers::HeaderMapExt instead)
headers = "0.4"           # Range/ETag helpers via HeaderMapExt and Range parser
http = "1"
hyper = "1"
tower-http = { version = "0.6.6", features = ["trace", "compression-full", "decompression-gzip", "cors", "util"] }
mime = "0.3"

# ==== Async/runtime ====
tokio = { version = "1.47.1", features = ["rt-multi-thread", "macros", "fs", "io-util", "signal", "net"] }
tokio-util = { version = "0.7", features = ["io"] }
bytes = "1.6"

# ==== Serde / utils ====
serde = { version = "1", features = ["derive"] }
serde_json = "1"
anyhow = "1"
thiserror = "1"
once_cell = "1.19"
parking_lot = "0.12"
arc-swap = "1.7"
async-trait = "0.1"
base64 = "0.22"
time = { version = "0.3", features = ["formatting"] }

# ==== Observability ====
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "fmt"] }
prometheus = { version = "0.14", optional = true }

# ==== Content addressing / helpers ====
blake3 = "1.5"
hex = "0.4"

# ==== RON crates (workspace paths) ====
ron-kernel = { path = "../ron-kernel" }
ron-metrics = { path = "../ron-metrics" }
ron-proto  = { path = "../ron-proto" }
ron-naming = { path = "../ron-naming" }

[dev-dependencies]
# For Router::oneshot in contract tests
tower = "0.5"
reqwest = { version = "0.12", default-features = false, features = ["rustls-tls-native-roots", "http2", "json"] }
tokio   = { version = "1.47.1", features = ["rt-multi-thread", "macros"] }

```

### crates/svc-storage/benches/etag_range.rs
<a id="crates-svc-storage-benches-etagrange-rs"></a>

```rust
// Criterion bench: conditional GET + Range (scaffold)

```

### crates/svc-storage/benches/read_path.rs
<a id="crates-svc-storage-benches-readpath-rs"></a>

```rust
// Criterion bench: read path p95 (scaffold)

```

### crates/svc-storage/benches/write_path.rs
<a id="crates-svc-storage-benches-writepath-rs"></a>

```rust
// Criterion bench: write path p95 (scaffold)

```

### crates/svc-storage/configs/pq-hybrid.toml
<a id="crates-svc-storage-configs-pq-hybrid-toml"></a>

```toml
# Enable PQ-hybrid transport/auth envelopes
pq_hybrid = true

```

### crates/svc-storage/configs/profiles/macronode.toml
<a id="crates-svc-storage-configs-profiles-macronode-toml"></a>

```toml
# Macronode defaults: persistent, replication ready
amnesia = false
chunk_bytes = "64KiB"

```

### crates/svc-storage/configs/profiles/micronode.toml
<a id="crates-svc-storage-configs-profiles-micronode-toml"></a>

```toml
# Micronode defaults: single-tenant, amnesia ON
amnesia = true
chunk_bytes = "64KiB"

```

### crates/svc-storage/configs/svc-storage.example.toml
<a id="crates-svc-storage-configs-svc-storage-example-toml"></a>

```toml
bind = "127.0.0.1:5303"
data_dir = "./data/storage"
read_timeout_ms = 5000
write_timeout_ms = 5000
max_body_bytes = 1048576
amnesia = false

```

### crates/svc-storage/configs/validate.sh
<a id="crates-svc-storage-configs-validate-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "Validating TOML configs (lightweight placeholder)..."
for f in *.toml profiles/*.toml 2>/dev/null; do
  if [ -f "$f" ]; then
    echo "OK: $f"
  fi
done

```

### crates/svc-storage/rust-toolchain.toml
<a id="crates-svc-storage-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["rustfmt", "clippy"]

```

### crates/svc-storage/scripts/smoke_storage.sh
<a id="crates-svc-storage-scripts-smokestorage-sh"></a>

```bash
### GROK HELPED WITH THIS 

#!/usr/bin/env bash
set -euo pipefail

# --- config (overridable via env) ---
BIN="${BIN:-svc-storage}"
ADDR="${ADDR:-127.0.0.1:5303}"          # address the server should bind to
WAIT_SECS="${WAIT_SECS:-20}"            # max seconds to wait for server up
LOG_FILE="${LOG_FILE:-/tmp/${BIN}.log}" # server stdout/stderr
CARGO_FEATURES="${CARGO_FEATURES:-}"    # e.g. "--features metrics"

say()  { printf '%s\n' "$*"; }
fail() { printf '❌ %s\n' "$*" >&2; exit 1; }

# --- find repo root by walking up until we see a workspace Cargo.toml ---
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
find_repo_root() {
  local d="${SCRIPT_DIR}"
  while :; do
    if [ -f "${d}/Cargo.toml" ] && grep -q '^\[workspace\]' "${d}/Cargo.toml"; then
      printf '%s\n' "${d}"
      return 0
    fi
    local parent
    parent="$(dirname "${d}")"
    [ "${parent}" = "${d}" ] && break
    d="${parent}"
  done
  # Fallback: use current working dir (should still work if we're inside the repo)
  printf '%s\n' "$(pwd)"
}
REPO_ROOT="$(find_repo_root)"
cd "${REPO_ROOT}"

# --- build ---
say "building ${BIN}…"
cargo build -p "${BIN}" >/dev/null

# --- start server ---
: > "${LOG_FILE}"
say "starting ${BIN} at ${ADDR}… (logs: ${LOG_FILE})"
RUST_LOG="${RUST_LOG:-debug}" \
ADDR="${ADDR}" \
cargo run -p "${BIN}" ${CARGO_FEATURES} >"${LOG_FILE}" 2>&1 &
SERVER_PID=$!

cleanup() {
  if kill -0 "${SERVER_PID}" 2>/dev/null; then
    kill "${SERVER_PID}" 2>/dev/null || true
    wait "${SERVER_PID}" 2>/dev/null || true
  fi
}
trap cleanup EXIT

# --- wait for HTTP to be responsive ---
say "waiting for http://${ADDR}…"
UP=0
end_at=$(( $(date +%s) + WAIT_SECS ))
while (( $(date +%s) < end_at )); do
  # Prefer /healthz if present; otherwise any HTTP status on / indicates the server is up.
  HC="$(curl -s --fail --show-error -o /dev/null -w '%{http_code}' "http://${ADDR}/healthz" || true)"
  if [[ "${HC}" == "200" ]]; then
    say "✅ ${BIN} is up (GET /healthz -> 200)"
    UP=1; break
  fi
  ROOTC="$(curl -s --fail --show-error -o /dev/null -w '%{http_code}' "http://${ADDR}/" || true)"
  if [[ "${ROOTC}" =~ ^[1-5][0-9]{2}$ ]]; then
    say "✅ ${BIN} is up (GET / -> ${ROOTC})"
    UP=1; break
  fi
  if ! kill -0 "${SERVER_PID}" 2>/dev/null; then
    fail "${BIN} failed to start (process exited)
---- server log ----
$(tail -n +1 "${LOG_FILE}")"
  fi
  sleep 0.2
done

if [[ "${UP}" != "1" ]]; then
  fail "timed out waiting for ${BIN}
---- server log ----
$(tail -n 200 "${LOG_FILE}")"
fi

# --- tests ---
PASS=0; FAIL=0; SKIP=0
_step() { printf "\n-- %s --\n" "$*"; }

# 1) POST object (use POST, not PUT)
_step "POST object"
CID=$(printf 'hello world' | curl -sS --fail --show-error -X POST --data-binary @- "http://${ADDR}/o" | jq -r .cid)
if [[ -n "${CID:-}" && "${CID}" == b3:* ]]; then
  say "✅ POST returned cid=${CID}"; ((PASS++))
else
  say "❌ POST failed (cid='${CID:-}')" ; ((FAIL++))
fi

# 2) HEAD object (expect 200, length=11, etag present)
_step "HEAD object"
H="$(curl -sSI --fail --show-error "http://${ADDR}/o/${CID}")" || true
echo "${H}" | grep -q "^HTTP/.* 200"       && { say "✅ HEAD 200"; ((PASS++)); } || { say "❌ HEAD not 200"; ((FAIL++)); }
echo "${H}" | grep -iq "^Content-Length: 11" && { say "✅ HEAD Content-Length=11"; ((PASS++)); } || { say "❌ HEAD missing/incorrect Content-Length"; ((FAIL++)); }
echo "${H}" | grep -iq "^ETag:"            && { say "✅ HEAD ETag present"; ((PASS++)); } || { say "❌ HEAD missing ETag"; ((FAIL++)); }

# 3) GET full
_step "GET full"
BODY="$(curl -s --fail --show-error "http://${ADDR}/o/${CID}")"
[[ "${BODY}" == "hello world" ]] && { say "✅ GET full body matches"; ((PASS++)); } || { say "❌ GET full body mismatch: '${BODY}'"; ((FAIL++)); }

# 4) Range GET
_step "Range GET bytes=0-4"
RANGE_BODY="$(curl -s --fail --show-error -H 'Range: bytes=0-4' -i "http://${ADDR}/o/${CID}")"
echo "${RANGE_BODY}" | head -n1 | grep -q "206" && { say "✅ Range GET 206"; ((PASS++)); } || { say "❌ Range GET not 206"; ((FAIL++)); }
echo "${RANGE_BODY}" | tail -n1 | grep -q "^hello$" && { say "✅ Range body matches 'hello'"; ((PASS++)); } || { say "❌ Range body mismatch: '$(echo "${RANGE_BODY}" | tail -n1)'"; ((FAIL++)); }

# 5) GET unknown -> 404 (use valid-formatted but fake CID)
FAKE_CID="b3:$(printf '%064s' '' | tr ' ' '0')"  # b3:000...0 (64 zeros)
_step "GET unknown"
UNKNOWN_CODE="$(curl -s --fail --show-error -o /dev/null -w '%{http_code}' "http://${ADDR}/o/${FAKE_CID}" || true)"
[[ "${UNKNOWN_CODE}" == "404" ]] && { say "✅ GET unknown cid -> 404"; ((PASS++)); } || { say "❌ GET unknown returned ${UNKNOWN_CODE}"; ((FAIL++)); }

# 6) metrics (optional)
_step "metrics"
METRIC_CODE="$(curl -s --fail --show-error -o /dev/null -w '%{http_code}' "http://${ADDR}/metrics" || true)"
if [[ "${METRIC_CODE}" == "200" ]]; then
  say "✅ /metrics OK"; ((PASS++))
else
  say "⏭️  /metrics not mounted (code=${METRIC_CODE}); skipping"; ((SKIP++))
fi

# --- summary ---
echo "---- summary ----"
echo "PASS=${PASS} FAIL=${FAIL} SKIP=${SKIP}"
if (( FAIL == 0 )); then
  echo "all good ✅"
else
  echo "some checks failed ❌"
  echo "---- server log (tail) ----"
  tail -n 200 "${LOG_FILE}" || true
  exit 1
fi
```

### crates/svc-storage/src/amnesia.rs
<a id="crates-svc-storage-src-amnesia-rs"></a>

```rust
//! Amnesia toggle (stub used by scripts & future policy flow).

#[allow(dead_code)]
pub struct Amnesia(pub bool);

#[allow(dead_code)]
impl Amnesia {
    pub fn is_on(&self) -> bool {
        self.0
    }
}

```

### crates/svc-storage/src/auth/macaroon.rs
<a id="crates-svc-storage-src-auth-macaroon-rs"></a>

```rust
//! RO:WHAT — Minimal macaroon-ish token + Axum extractor, signed with keyed BLAKE3.
//! RO:WHY  — Gate write endpoints without heavy deps or external KMS.
//! RO:NOTE — If `RON_STORAGE_MACAROON_SECRET` is unset, extractor is permissive (dev mode).

use axum::{
    async_trait,
    extract::FromRequestParts,
    http::{header, request::Parts, StatusCode},
    response::{IntoResponse, Response},
};
use base64::engine::general_purpose::URL_SAFE_NO_PAD as B64;
use base64::Engine;

#[derive(Debug)]
pub enum MacaroonError {
    Missing,
    Malformed,
    Expired,
    BadSig,
    Internal,
}

impl IntoResponse for MacaroonError {
    fn into_response(self) -> Response {
        let (code, msg) = match self {
            MacaroonError::Missing => (StatusCode::UNAUTHORIZED, "missing authorization"),
            MacaroonError::Malformed => (StatusCode::UNAUTHORIZED, "malformed authorization"),
            MacaroonError::Expired => (StatusCode::UNAUTHORIZED, "token expired"),
            MacaroonError::BadSig => (StatusCode::FORBIDDEN, "bad signature"),
            MacaroonError::Internal => (StatusCode::INTERNAL_SERVER_ERROR, "auth internal"),
        };
        (code, msg).into_response()
    }
}

#[derive(Debug, Clone)]
pub struct MacaroonClaims {
    pub issued_at: u64,
    pub expires_at: u64,
}

/// 32-byte key from env (base64url, no padding). None => dev/permissive.
fn secret_from_env() -> Option<[u8; 32]> {
    let raw = std::env::var("RON_STORAGE_MACAROON_SECRET").ok()?;
    let mut key = [0u8; 32];
    let decoded = B64.decode(raw).ok()?;
    if decoded.len() != 32 {
        return None;
    }
    key.copy_from_slice(&decoded);
    Some(key)
}

fn leeway_from_env() -> u64 {
    std::env::var("RON_STORAGE_MACAROON_LEEWAY")
        .ok()
        .and_then(|s| s.parse::<u64>().ok())
        .unwrap_or(60)
}

fn now_unix() -> u64 {
    use std::time::{SystemTime, UNIX_EPOCH};
    SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_default()
        .as_secs()
}

/// Token inner text: `v=1;ts=<u64>;exp=<u64>;sig=<hex>`
fn parse_token_fields(token: &str) -> Option<(u64, u64, &str)> {
    let mut v = None;
    let mut ts = None;
    let mut exp = None;
    let mut sig = None;
    for part in token.split(';') {
        let (k, val) = part.split_once('=')?;
        match k {
            "v" if val == "1" => v = Some(1u8),
            "ts" => ts = val.parse::<u64>().ok(),
            "exp" => exp = val.parse::<u64>().ok(),
            "sig" => sig = Some(val),
            _ => {}
        }
    }
    match (v, ts, exp, sig) {
        (Some(_), Some(ts), Some(exp), Some(sig)) => Some((ts, exp, sig)),
        _ => None,
    }
}

/// BLAKE3 keyed MAC as lowercase hex string.
fn mac_hex(key: &[u8; 32], msg: &str) -> String {
    let mac = blake3::keyed_hash(key, msg.as_bytes());
    mac.to_hex().to_string()
}

fn verify_impl_with_header(authz: &str) -> Result<MacaroonClaims, MacaroonError> {
    // Accept "Macaroon ..." or "Bearer ..."
    let token = authz
        .strip_prefix("Macaroon ")
        .or_else(|| authz.strip_prefix("Bearer "))
        .ok_or(MacaroonError::Malformed)?;

    let decoded = B64.decode(token).map_err(|_| MacaroonError::Malformed)?;
    let text = std::str::from_utf8(&decoded).map_err(|_| MacaroonError::Malformed)?;

    let (ts, exp, sig_hex) = parse_token_fields(text).ok_or(MacaroonError::Malformed)?;
    let now = now_unix();
    let leeway = leeway_from_env();

    if exp + leeway < now {
        return Err(MacaroonError::Expired);
    }
    if ts > now + 24 * 3600 {
        return Err(MacaroonError::Malformed);
    }

    // Canonical string to MAC
    let msg = format!("v=1|ts={}|exp={}", ts, exp);

    let key = secret_from_env().ok_or(MacaroonError::Internal)?;
    let expect = mac_hex(&key, &msg);

    // Constant-time-ish comparison
    if expect.len() != sig_hex.len() {
        return Err(MacaroonError::BadSig);
    }
    let mut diff = 0u8;
    for (a, b) in expect.as_bytes().iter().zip(sig_hex.as_bytes()) {
        diff |= a ^ b;
    }
    if diff != 0 {
        return Err(MacaroonError::BadSig);
    }

    Ok(MacaroonClaims {
        issued_at: ts,
        expires_at: exp,
    })
}

#[async_trait]
impl<S> FromRequestParts<S> for MacaroonClaims
where
    S: Send + Sync,
{
    type Rejection = MacaroonError;

    async fn from_request_parts(parts: &mut Parts, _state: &S) -> Result<Self, Self::Rejection> {
        // DEV-PERMISSIVE PATH: if no secret is configured, allow even with no header.
        if secret_from_env().is_none() {
            let n = now_unix();
            return Ok(MacaroonClaims {
                issued_at: n,
                expires_at: n + 300,
            });
        }

        // ENFORCED PATH: secret is configured -> require header and verify.
        let auth = parts
            .headers
            .get(header::AUTHORIZATION)
            .ok_or(MacaroonError::Missing)?;
        let auth = auth.to_str().map_err(|_| MacaroonError::Malformed)?;
        verify_impl_with_header(auth)
    }
}

```

### crates/svc-storage/src/auth/mod.rs
<a id="crates-svc-storage-src-auth-mod-rs"></a>

```rust
//! RO:WHAT — Authentication surface for svc-storage (macaroon-style, keyed BLAKE3).

mod macaroon;
pub use macaroon::MacaroonClaims;
// Keep helpers private until we wire a mint script or tests:
// pub use macaroon::{mint_for, MacaroonError};

```

### crates/svc-storage/src/bus.rs
<a id="crates-svc-storage-src-bus-rs"></a>

```rust
//! RO:WHAT — Bus glue to the kernel (optional for events).
//! RO:WHY — Publish Health/ConfigUpdated later if needed.
//! RO:INTERACTS — ron-kernel Bus API.

#[allow(unused)]
pub struct BusGlue;

```

### crates/svc-storage/src/config.rs
<a id="crates-svc-storage-src-config-rs"></a>

```rust
//! RO:WHAT — Configuration for svc-storage.
//! RO:ENV  —
//!   RON_STORAGE_ADDR        (default "127.0.0.1:5303")
//!   RON_STORAGE_DATA_DIR    (default "./data/storage")
//!   RON_STORAGE_MAX_BODY    (bytes, default 64 MiB)

use anyhow::Context;
use std::net::SocketAddr;
use std::path::PathBuf;
use std::str::FromStr;
use std::time::Duration;

pub struct Config {
    pub http_addr: SocketAddr,
    pub data_dir: PathBuf,
    pub max_body_bytes: u64,
}

impl Config {
    pub fn from_env() -> anyhow::Result<Self> {
        let http_addr_str =
            std::env::var("RON_STORAGE_ADDR").unwrap_or_else(|_| "127.0.0.1:5303".to_string());
        let http_addr = SocketAddr::from_str(&http_addr_str)
            .with_context(|| format!("invalid RON_STORAGE_ADDR: {}", http_addr_str))?;

        let data_dir = std::env::var("RON_STORAGE_DATA_DIR")
            .map(PathBuf::from)
            .unwrap_or_else(|_| PathBuf::from("./data/storage"));

        let max_body_bytes = std::env::var("RON_STORAGE_MAX_BODY")
            .ok()
            .and_then(|s| s.parse::<u64>().ok())
            .unwrap_or(64 * 1024 * 1024);

        Ok(Self {
            http_addr,
            data_dir,
            max_body_bytes,
        })
    }

    pub fn read_timeout(&self) -> Duration {
        Duration::from_secs(30)
    }
    pub fn write_timeout(&self) -> Duration {
        Duration::from_secs(30)
    }
}

```

### crates/svc-storage/src/errors.rs
<a id="crates-svc-storage-src-errors-rs"></a>

```rust
//! Error taxonomy for svc-storage.

use thiserror::Error;

#[derive(Error, Debug)]
pub enum StorageError {
    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),

    #[error("object not found")]
    NotFound,

    #[error("bad address format")]
    BadAddress,

    #[error("range not satisfiable")]
    RangeNotSatisfiable,

    #[error("request body too large")]
    CapacityExceeded,

    #[error("integrity check failed")]
    IntegrityFailed,
}

```

### crates/svc-storage/src/http/error.rs
<a id="crates-svc-storage-src-http-error-rs"></a>

```rust
//! Map StorageError -> HTTP responses.

use axum::{http::StatusCode, response::IntoResponse, Json};
use serde_json::json;

use crate::errors::StorageError;

pub fn into_response(err: StorageError) -> impl IntoResponse {
    let (status, code) = match err {
        StorageError::NotFound => (StatusCode::NOT_FOUND, "not_found"),
        StorageError::BadAddress => (StatusCode::BAD_REQUEST, "bad_address"),
        StorageError::RangeNotSatisfiable => {
            (StatusCode::RANGE_NOT_SATISFIABLE, "range_not_satisfiable")
        }
        StorageError::CapacityExceeded => (StatusCode::PAYLOAD_TOO_LARGE, "capacity_exceeded"),
        StorageError::IntegrityFailed => (StatusCode::BAD_REQUEST, "integrity_failed"),
        StorageError::Io(_) => (StatusCode::INTERNAL_SERVER_ERROR, "io_error"),
    };

    (
        status,
        Json(json!({
            "title": code,
            "status": status.as_u16(),
            "detail": err.to_string()
        })),
    )
}

```

### crates/svc-storage/src/http/extractors.rs
<a id="crates-svc-storage-src-http-extractors-rs"></a>

```rust
//! RO:WHAT — Shared app state (Storage handle) for route handlers.
//! RO:WHY  — Axum 0.7 needs state to be Send + Sync + 'static.

use crate::storage::DynStorage;

#[derive(Clone)]
pub struct AppState {
    pub store: DynStorage, // Arc<dyn Storage + Send + Sync + 'static>
}

```

### crates/svc-storage/src/http/middleware.rs
<a id="crates-svc-storage-src-http-middleware-rs"></a>

```rust
//! Placeholder middleware (future: enforce ready before heavy ops).

use axum::response::Response;
use std::sync::Arc;

use crate::readiness::Readiness;

#[allow(dead_code)]
pub async fn require_ready(_ready: Arc<Readiness>) -> Response {
    // stub: in future, check readiness and short-circuit with 503
    Response::new(axum::body::Body::empty())
}

```

### crates/svc-storage/src/http/mod.rs
<a id="crates-svc-storage-src-http-mod-rs"></a>

```rust
//! RO:WHAT — HTTP surface (extractors, routes, server) for svc-storage.
pub mod error;
pub mod extractors;
pub mod middleware;
pub mod routes;
pub mod server;

```

### crates/svc-storage/src/http/routes/get_object.rs
<a id="crates-svc-storage-src-http-routes-getobject-rs"></a>

```rust
use axum::http::{HeaderMap, HeaderValue, StatusCode};
use axum::{
    extract::{Path, State},
    response::{IntoResponse, Response},
};

use crate::http::extractors::AppState;

/// Parse a simple single-range header. Supports:
/// - bytes=START-END
/// - bytes=START-
/// - bytes=-SUFFIX (last N bytes)
fn parse_range_bytes(range_header: &str, total_len: u64) -> Option<(u64, u64)> {
    let s = range_header.trim();
    if !s.starts_with("bytes=") {
        return None;
    }
    let spec = &s[6..];
    if let Some((a, b)) = spec.split_once('-') {
        match (a.trim(), b.trim()) {
            // bytes=START-END
            (a, b) if !a.is_empty() && !b.is_empty() => {
                let start: u64 = a.parse().ok()?;
                let end: u64 = b.parse().ok()?;
                if start <= end && start < total_len {
                    let end = end.min(total_len.saturating_sub(1));
                    Some((start, end))
                } else {
                    None
                }
            }
            // bytes=START-
            (a, b) if !a.is_empty() && b.is_empty() => {
                let start: u64 = a.parse().ok()?;
                if start < total_len {
                    Some((start, total_len.saturating_sub(1)))
                } else {
                    None
                }
            }
            // bytes=-SUFFIX  (last N bytes)
            (a, b) if a.is_empty() && !b.is_empty() => {
                let suffix: u64 = b.parse().ok()?;
                if suffix == 0 {
                    None
                } else {
                    let need = suffix.min(total_len);
                    let start = total_len.saturating_sub(need);
                    Some((start, total_len.saturating_sub(1)))
                }
            }
            _ => None,
        }
    } else {
        None
    }
}

pub async fn handler(
    State(app): State<AppState>,
    Path(cid): Path<String>,
    headers_in: HeaderMap,
) -> Response {
    // Resolve object metadata up front (length + strong ETag).
    let meta = match app.store.head(&cid).await {
        Ok(m) => m,
        Err(_) => return (StatusCode::NOT_FOUND, ()).into_response(),
    };

    // Range?
    if let Some(hv) = headers_in.get(axum::http::header::RANGE) {
        if let Ok(hs) = hv.to_str() {
            if let Some((start, end_inclusive)) = parse_range_bytes(hs, meta.len) {
                match app.store.get_range(&cid, start, end_inclusive).await {
                    Ok((chunk, _total_len)) => {
                        let mut headers = HeaderMap::new();
                        headers.insert(
                            axum::http::header::ETAG,
                            HeaderValue::from_str(&meta.etag).unwrap(),
                        );
                        headers.insert(
                            axum::http::header::CONTENT_LENGTH,
                            HeaderValue::from_str(&chunk.len().to_string()).unwrap(),
                        );
                        headers.insert(
                            axum::http::header::CONTENT_RANGE,
                            HeaderValue::from_str(&format!(
                                "bytes {}-{}/{}",
                                start,
                                start + chunk.len() as u64 - 1,
                                meta.len
                            ))
                            .unwrap(),
                        );
                        return (StatusCode::PARTIAL_CONTENT, headers, chunk).into_response();
                    }
                    Err(_) => return (StatusCode::NOT_FOUND, ()).into_response(),
                }
            } else {
                // 416 must include Content-Range: */<len>
                let mut headers = HeaderMap::new();
                headers.insert(
                    axum::http::header::CONTENT_RANGE,
                    HeaderValue::from_str(&format!("*/{}", meta.len)).unwrap(),
                );
                return (StatusCode::RANGE_NOT_SATISFIABLE, headers).into_response();
            }
        }
    }

    // Full body
    match app.store.get_full(&cid).await {
        Ok(bytes) => {
            let mut headers = HeaderMap::new();
            headers.insert(
                axum::http::header::ETAG,
                HeaderValue::from_str(&meta.etag).unwrap(),
            );
            headers.insert(
                axum::http::header::CONTENT_LENGTH,
                HeaderValue::from_str(&meta.len.to_string()).unwrap(),
            );
            (StatusCode::OK, headers, bytes).into_response()
        }
        Err(_) => (StatusCode::NOT_FOUND, ()).into_response(),
    }
}

```

### crates/svc-storage/src/http/routes/head_object.rs
<a id="crates-svc-storage-src-http-routes-headobject-rs"></a>

```rust
use axum::http::{header, HeaderMap, HeaderValue, StatusCode};
use axum::{
    extract::{Path, State},
    response::IntoResponse,
};

use crate::http::extractors::AppState;

/// b3:<64 lowercase hex>
#[inline]
fn is_valid_cid(cid: &str) -> bool {
    if cid.len() != 3 + 64 {
        return false;
    }
    if !cid.starts_with("b3:") {
        return false;
    }
    cid[3..]
        .bytes()
        .all(|b| matches!(b, b'0'..=b'9' | b'a'..=b'f'))
}

#[inline]
fn ensure_quoted_etag(etag: &str) -> String {
    if etag.len() >= 2 && etag.starts_with('"') && etag.ends_with('"') {
        etag.to_string()
    } else {
        format!("\"{etag}\"")
    }
}

pub async fn handler(State(app): State<AppState>, Path(cid): Path<String>) -> impl IntoResponse {
    // Malformed CID → 400
    if !is_valid_cid(&cid) {
        return StatusCode::BAD_REQUEST.into_response();
    }

    match app.store.head(&cid).await {
        Ok(meta) => {
            let mut headers = HeaderMap::new();

            // Strong ETag (quoted hex)
            let quoted = ensure_quoted_etag(&meta.etag);
            headers.insert(header::ETAG, HeaderValue::from_str(&quoted).unwrap());

            // Exact length
            headers.insert(
                header::CONTENT_LENGTH,
                HeaderValue::from_str(&meta.len.to_string()).unwrap(),
            );

            (StatusCode::OK, headers).into_response()
        }
        // Well-formed but unknown → 404
        Err(_) => (StatusCode::NOT_FOUND, ()).into_response(),
    }
}

```

### crates/svc-storage/src/http/routes/health.rs
<a id="crates-svc-storage-src-http-routes-health-rs"></a>

```rust
use axum::response::IntoResponse;
use http::StatusCode;

use crate::http::extractors::AppState;
use axum::Extension;

pub async fn handler(_: Extension<AppState>) -> impl IntoResponse {
    StatusCode::OK
}

```

### crates/svc-storage/src/http/routes/metrics.rs
<a id="crates-svc-storage-src-http-routes-metrics-rs"></a>

```rust
use axum::http::{HeaderMap, HeaderValue, StatusCode};
use axum::response::IntoResponse;
use prometheus::{Encoder, TextEncoder};

pub async fn handler() -> impl IntoResponse {
    let encoder = TextEncoder::new();
    let mut buf = Vec::new();
    if let Err(e) = encoder.encode(&prometheus::gather(), &mut buf) {
        return (
            StatusCode::INTERNAL_SERVER_ERROR,
            format!("encode error: {e}"),
        )
            .into_response();
    }
    let mut headers = HeaderMap::new();
    headers.insert(
        axum::http::header::CONTENT_TYPE,
        HeaderValue::from_static("text/plain; version=0.0.4"),
    );
    (StatusCode::OK, headers, buf).into_response()
}

```

### crates/svc-storage/src/http/routes/mod.rs
<a id="crates-svc-storage-src-http-routes-mod-rs"></a>

```rust
//! RO:WHAT — Route module fanout for svc-storage.
pub mod get_object;
pub mod head_object;
pub mod health;
pub mod metrics;
pub mod post_object;
pub mod put_object;
pub mod ready;
pub mod version;

```

### crates/svc-storage/src/http/routes/post_object.rs
<a id="crates-svc-storage-src-http-routes-postobject-rs"></a>

```rust
use crate::http::extractors::AppState;
use axum::{
    extract::State,
    response::{IntoResponse, Response},
};

pub async fn handler(State(app): State<AppState>, body: bytes::Bytes) -> Response {
    super::put_object::handler(State(app), body)
        .await
        .into_response()
}

```

### crates/svc-storage/src/http/routes/put_object.rs
<a id="crates-svc-storage-src-http-routes-putobject-rs"></a>

```rust
use axum::{extract::State, response::IntoResponse, Json};
use blake3;
use serde::Serialize;

use crate::http::extractors::AppState;

#[derive(Serialize)]
struct PutResp {
    cid: String,
}

pub async fn handler(State(app): State<AppState>, body: bytes::Bytes) -> impl IntoResponse {
    // Compute b3 content id from the body (exactly what your script expects)
    let digest = blake3::hash(&body).to_hex().to_string();
    let cid = format!("b3:{digest}");

    // Store full body
    if let Err(e) = app.store.put(&cid, body).await {
        return (
            axum::http::StatusCode::INTERNAL_SERVER_ERROR,
            format!("put failed: {e}"),
        )
            .into_response();
    }

    (axum::http::StatusCode::OK, Json(PutResp { cid })).into_response()
}

```

### crates/svc-storage/src/http/routes/ready.rs
<a id="crates-svc-storage-src-http-routes-ready-rs"></a>

```rust
use axum::response::IntoResponse;
use http::StatusCode;

use crate::http::extractors::AppState;
use axum::Extension;

pub async fn handler(_: Extension<AppState>) -> impl IntoResponse {
    StatusCode::OK
}

```

### crates/svc-storage/src/http/routes/version.rs
<a id="crates-svc-storage-src-http-routes-version-rs"></a>

```rust
//! RO:WHAT — /version handler for svc-storage.
//! RO:WHY  — Operational introspection endpoint.

use axum::{response::IntoResponse, Json};
use serde::Serialize;

use crate::version::version_string;

#[derive(Serialize)]
struct VersionDto {
    version: String,
}

pub async fn handler() -> impl IntoResponse {
    Json(VersionDto {
        version: version_string(),
    })
}

```

### crates/svc-storage/src/http/server.rs
<a id="crates-svc-storage-src-http-server-rs"></a>

```rust
//! HTTP server wiring for svc-storage.
//! RO:WHAT  — Build Axum router and run the server task.
//! RO:WHY   — Handlers extract State<AppState>, so Router’s state is AppState.
//! RO:INVARIANTS — Unknown → 404; Range GET → 206; strong ETag; state is Send+Sync+'static.

use std::net::SocketAddr;

use axum::{
    routing::{get, head, put},
    Router,
};
use tracing::{error, info};

use crate::http::extractors::AppState;
#[cfg(feature = "metrics")]
use crate::http::routes::metrics;
use crate::http::routes::{get_object, head_object, put_object};
use crate::http::routes::{health, ready, version};

/// Build a router whose state type is **AppState** (because handlers use State<AppState>).
pub fn build_router() -> Router<AppState> {
    let api = Router::new()
        // object APIs: accept both PUT and POST for ingest
        .route("/o", put(put_object::handler).post(put_object::handler))
        .route(
            "/o/:cid",
            head(head_object::handler).get(get_object::handler),
        )
        // observability & version
        .route("/version", get(version::handler))
        .route("/healthz", get(health::handler))
        .route("/readyz", get(ready::handler));

    #[cfg(feature = "metrics")]
    let api = api.route("/metrics", get(metrics::handler));

    let app = Router::new().merge(api);

    info!(
        "mount: POST/PUT /o; HEAD/GET /o/:cid; GET /version; GET /healthz; GET /readyz{}",
        {
            #[cfg(feature = "metrics")]
            {
                "; GET /metrics"
            }
            #[cfg(not(feature = "metrics"))]
            {
                ""
            }
        }
    );

    app
}

pub async fn serve_http(addr: SocketAddr, state: AppState) -> anyhow::Result<()> {
    let listener = tokio::net::TcpListener::bind(addr).await?;
    info!("svc-storage listening on {addr}");

    // build_router() -> Router<AppState>, so with_state expects an AppState value
    let app = build_router().with_state(state);

    // Router<AppState> → MakeService, which axum::serve expects
    let make_svc = app.into_make_service();

    axum::serve(listener, make_svc)
        .with_graceful_shutdown(shutdown_signal())
        .await?;

    Ok(())
}

async fn shutdown_signal() {
    if let Err(e) = tokio::signal::ctrl_c().await {
        error!("shutdown signal failed: {e}");
    }
}

```

### crates/svc-storage/src/lib.rs
<a id="crates-svc-storage-src-lib-rs"></a>

```rust
//! svc-storage library entry — exposes modules to the bin target.
//! RO:WHAT  — Crate root and module exposes.
//! RO:WHY   — Keep bin thin; organize HTTP and storage layers cleanly.

#![forbid(unsafe_code)]

pub mod errors;
pub mod readiness;
pub mod storage;
pub mod types;
pub mod version;

pub mod http {
    pub mod error;
    pub mod extractors;
    pub mod middleware;
    pub mod routes {
        pub mod get_object;
        pub mod head_object;
        pub mod health;
        pub mod metrics;
        pub mod post_object; // present for completeness; not mounted by default
        pub mod put_object;
        pub mod ready;
        pub mod version;
    }
    pub mod server;
}

```

### crates/svc-storage/src/main.rs
<a id="crates-svc-storage-src-main-rs"></a>

```rust
use std::{net::SocketAddr, sync::Arc};

use svc_storage::http::{extractors::AppState, server::serve_http};
use svc_storage::storage::{MemoryStorage, Storage};

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let addr: SocketAddr = std::env::var("ADDR")
        .unwrap_or_else(|_| "127.0.0.1:5303".to_string())
        .parse()?;

    // In-memory store for smoke tests; pluggable later.
    let store: Arc<dyn Storage> = Arc::new(MemoryStorage::default());
    let state = AppState { store };

    // Handle the Result so clippy’s unused_must_use stays green.
    if let Err(e) = serve_http(addr, state).await {
        eprintln!("server error: {e:#}");
        std::process::exit(1);
    }
    Ok(())
}

```

### crates/svc-storage/src/metrics.rs
<a id="crates-svc-storage-src-metrics-rs"></a>

```rust
//! RO:WHAT — Prometheus metrics for svc-storage.

use once_cell::sync::Lazy;
use prometheus::{Histogram, HistogramOpts, IntCounterVec, Opts, Registry};

pub static REGISTRY: Lazy<Registry> = Lazy::new(Registry::new);

pub static REQUEST_LATENCY_SECONDS: Lazy<Histogram> = Lazy::new(|| {
    let o = HistogramOpts::new("storage_request_latency_seconds", "HTTP request latency");
    let h = Histogram::with_opts(o).unwrap();
    REGISTRY.register(Box::new(h.clone())).ok();
    h
});

pub static REJECTED_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    let o = Opts::new("storage_rejected_total", "Rejected requests by reason");
    let c = IntCounterVec::new(o, &["reason"]).unwrap();
    REGISTRY.register(Box::new(c.clone())).ok();
    c
});

pub static INTEGRITY_FAIL_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    let o = Opts::new("storage_integrity_fail_total", "Integrity check failures");
    let c = IntCounterVec::new(o, &["path"]).unwrap();
    REGISTRY.register(Box::new(c.clone())).ok();
    c
});

```

### crates/svc-storage/src/policy/economics.rs
<a id="crates-svc-storage-src-policy-economics-rs"></a>

```rust
// Policy module: economics (read-only settlement signals; scaffold)

```

### crates/svc-storage/src/policy/mod.rs
<a id="crates-svc-storage-src-policy-mod-rs"></a>

```rust
// Policy module (scaffold)

```

### crates/svc-storage/src/policy/quotas.rs
<a id="crates-svc-storage-src-policy-quotas-rs"></a>

```rust
// Policy module: quotas (scaffold)

```

### crates/svc-storage/src/policy/residency.rs
<a id="crates-svc-storage-src-policy-residency-rs"></a>

```rust
// Policy module: residency (scaffold)

```

### crates/svc-storage/src/prelude.rs
<a id="crates-svc-storage-src-prelude-rs"></a>

```rust
//! Intentionally minimal prelude for future shared imports.
//! Keep empty to avoid `unused_imports` under `-D warnings`.

```

### crates/svc-storage/src/readiness.rs
<a id="crates-svc-storage-src-readiness-rs"></a>

```rust
use std::sync::atomic::{AtomicBool, Ordering};

#[derive(Debug, Default)]
pub struct Readiness {
    config_loaded: AtomicBool,
    listeners_bound: AtomicBool,
}

impl Readiness {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn set_config_loaded(&self, v: bool) {
        self.config_loaded.store(v, Ordering::Relaxed);
    }

    pub fn set_listeners_bound(&self, v: bool) {
        self.listeners_bound.store(v, Ordering::Relaxed);
    }

    /// Minimal health: all invariants that should be up even when not "ready".
    pub fn health_ok(&self) -> bool {
        // For now, "healthy" if the process is running; later include store checks.
        true
    }

    /// Ready when config is loaded and listeners are bound.
    pub fn all_ready(&self) -> bool {
        self.config_loaded.load(Ordering::Relaxed) && self.listeners_bound.load(Ordering::Relaxed)
    }
}

```

### crates/svc-storage/src/storage/cache.rs
<a id="crates-svc-storage-src-storage-cache-rs"></a>

```rust
//! RO:WHAT — In-memory CAS (Micronode amnesia).

use super::{HeadMeta, Storage};
use crate::{errors::StorageError, prelude::*};
use std::collections::HashMap;

#[derive(Debug, Default)]
pub struct MemoryStorage {
    inner: Mutex<HashMap<String, Bytes>>,
}

#[async_trait::async_trait]
impl Storage for MemoryStorage {
    async fn put_bytes(&self, bytes: Bytes) -> Result<HeadMeta, StorageError> {
        let mut hasher = blake3::Hasher::new();
        hasher.update(&bytes);
        let cid = format!("b3:{}", hasher.finalize().to_hex());
        let mut g = self.inner.lock();
        g.entry(cid.clone()).or_insert(bytes.clone());
        Ok(HeadMeta {
            cid: cid.clone(),
            size: bytes.len() as u64,
            etag: format!("\"{}\"", cid),
        })
    }

    async fn has(&self, cid: &str) -> Result<bool, StorageError> {
        Ok(self.inner.lock().contains_key(cid))
    }

    async fn head(&self, cid: &str) -> Result<HeadMeta, StorageError> {
        let g = self.inner.lock();
        let b = g.get(cid).ok_or(StorageError::NotFound)?;
        Ok(HeadMeta {
            cid: cid.to_string(),
            size: b.len() as u64,
            etag: format!("\"{}\"", cid),
        })
    }

    async fn get_full(&self, cid: &str) -> Result<Bytes, StorageError> {
        let g = self.inner.lock();
        let b = g.get(cid).ok_or(StorageError::NotFound)?;
        Ok(b.clone())
    }

    async fn get_range(
        &self,
        cid: &str,
        start: u64,
        end_inclusive: u64,
    ) -> Result<(Bytes, u64), StorageError> {
        let g = self.inner.lock();
        let b = g.get(cid).ok_or(StorageError::NotFound)?;
        let len = b.len() as u64;
        if start >= len || end_inclusive >= len || start > end_inclusive {
            return Err(StorageError::RangeNotSatisfiable);
        }
        let s = start as usize;
        let e = end_inclusive as usize + 1;
        Ok((b.slice(s..e), len))
    }
}

```

### crates/svc-storage/src/storage/cas.rs
<a id="crates-svc-storage-src-storage-cas-rs"></a>

```rust
// Storage module: cas (scaffold)

```

### crates/svc-storage/src/storage/compression.rs
<a id="crates-svc-storage-src-storage-compression-rs"></a>

```rust
// Storage module: compression (scaffold)

```

### crates/svc-storage/src/storage/erasure.rs
<a id="crates-svc-storage-src-storage-erasure-rs"></a>

```rust
// Storage module: erasure (scaffold)

```

### crates/svc-storage/src/storage/fs.rs
<a id="crates-svc-storage-src-storage-fs-rs"></a>

```rust
//! Filesystem-backed storage for svc-storage.

use std::path::{Path, PathBuf};

use axum::body::Bytes;
use tokio::fs;
use tokio::io::{AsyncReadExt, AsyncSeekExt, AsyncWriteExt};

use crate::{errors::StorageError, types::HeadMeta};

/// Simple filesystem store rooted at `root/`.
pub struct FsStorage {
    root: PathBuf,
}

impl FsStorage {
    pub async fn new(root: PathBuf) -> anyhow::Result<Self> {
        if !root.exists() {
            fs::create_dir_all(&root).await?;
        }
        Ok(Self { root })
    }

    fn is_valid_b3_cid(cid: &str) -> bool {
        // "b3:" + 64 lowercase hex nybbles
        if let Some(rest) = cid.strip_prefix("b3:") {
            rest.len() == 64 && rest.bytes().all(|b| matches!(b, b'0'..=b'9' | b'a'..=b'f'))
        } else {
            false
        }
    }

    fn path_for(&self, cid: &str) -> Result<PathBuf, StorageError> {
        if !Self::is_valid_b3_cid(cid) {
            return Err(StorageError::BadRequest("invalid cid".into()));
        }
        Ok(self.root.join(cid))
    }

    async fn write_all_atomic(path: &Path, data: &[u8]) -> std::io::Result<()> {
        let tmp = path.with_extension("tmp");
        {
            let mut f = fs::File::create(&tmp).await?;
            f.write_all(data).await?;
            f.flush().await?;
        }
        // Replace temp with final
        // On all platforms tokio::fs::rename overwrites if allowed by OS.
        fs::rename(&tmp, path).await?;
        Ok(())
    }
}

#[async_trait::async_trait]
impl crate::storage::Storage for FsStorage {
    async fn put_bytes(&self, bytes: Bytes) -> Result<HeadMeta, StorageError> {
        // Compute BLAKE3 CID
        let hash = blake3::hash(&bytes);
        let cid = format!("b3:{}", hash.to_hex());
        let len = bytes.len() as u64;

        let path = self.path_for(&cid)?;
        if !path.exists() {
            Self::write_all_atomic(&path, &bytes)
                .await
                .map_err(StorageError::Io)?;
        }

        Ok(HeadMeta { cid, len })
    }

    async fn has(&self, cid: &str) -> Result<bool, StorageError> {
        let path = self.path_for(cid)?;
        Ok(path.exists())
    }

    async fn head(&self, cid: &str) -> Result<HeadMeta, StorageError> {
        let path = self.path_for(cid)?;
        let meta = fs::metadata(&path).await.map_err(|e| {
            if e.kind() == std::io::ErrorKind::NotFound {
                StorageError::NotFound
            } else {
                StorageError::Io(e)
            }
        })?;
        Ok(HeadMeta {
            cid: cid.to_string(),
            len: meta.len(),
        })
    }

    async fn get_full(&self, cid: &str) -> Result<Bytes, StorageError> {
        let path = self.path_for(cid)?;
        let mut f = fs::File::open(&path).await.map_err(|e| {
            if e.kind() == std::io::ErrorKind::NotFound {
                StorageError::NotFound
            } else {
                StorageError::Io(e)
            }
        })?;

        let mut buf = Vec::new();
        f.read_to_end(&mut buf).await.map_err(StorageError::Io)?;
        Ok(Bytes::from(buf))
    }

    async fn get_range(
        &self,
        cid: &str,
        start: u64,
        end_inclusive: u64,
    ) -> Result<(Bytes, u64), StorageError> {
        let path = self.path_for(cid)?;
        let meta = fs::metadata(&path).await.map_err(|e| {
            if e.kind() == std::io::ErrorKind::NotFound {
                StorageError::NotFound
            } else {
                StorageError::Io(e)
            }
        })?;
        let total = meta.len();
        if start > end_inclusive || end_inclusive >= total {
            return Err(StorageError::BadRequest("invalid range".into()));
        }

        let mut f = fs::File::open(&path).await.map_err(StorageError::Io)?;
        let span = (end_inclusive - start + 1) as usize;
        let mut buf = vec![0u8; span];

        f.seek(std::io::SeekFrom::Start(start))
            .await
            .map_err(StorageError::Io)?;
        f.read_exact(&mut buf).await.map_err(StorageError::Io)?;

        Ok((Bytes::from(buf), total))
    }
}

```

### crates/svc-storage/src/storage/hedged.rs
<a id="crates-svc-storage-src-storage-hedged-rs"></a>

```rust
// Storage module: hedged (scaffold)

```

### crates/svc-storage/src/storage/io.rs
<a id="crates-svc-storage-src-storage-io-rs"></a>

```rust
//! Range validation helpers (kept minimal – routes/impls already check).

use crate::errors::StorageError;

#[allow(dead_code)]
pub fn validate_range(start: u64, end_inclusive: u64, total: u64) -> Result<(), StorageError> {
    if start > end_inclusive || end_inclusive >= total {
        return Err(StorageError::RangeNotSatisfiable);
    }
    Ok(())
}

```

### crates/svc-storage/src/storage/mod.rs
<a id="crates-svc-storage-src-storage-mod-rs"></a>

```rust
// RO:WHAT  — Storage trait + simple in-memory impl for smoke/local dev.
// RO:WHY   — Keep the trait object-safe (handlers hold Arc<dyn Storage>).
// RO:INVARIANTS — CID is content-addressed; NotFound on missing keys; range bounds clamped by caller.

use std::{collections::HashMap, sync::Arc};

use axum::body::Bytes;
use parking_lot::RwLock;

use crate::errors::StorageError;

#[derive(Debug, Clone)]
pub struct HeadMeta {
    pub len: u64,
    pub etag: String,
}

pub type Result<T, E = StorageError> = std::result::Result<T, E>;

#[async_trait::async_trait]
pub trait Storage: Send + Sync + 'static {
    async fn put(&self, cid: &str, data: Bytes) -> Result<()>;

    #[allow(dead_code)]
    async fn exists(&self, cid: &str) -> Result<bool>;

    async fn head(&self, cid: &str) -> Result<HeadMeta>;

    #[allow(dead_code)]
    async fn get_full(&self, cid: &str) -> Result<Bytes>;

    /// Returns (bytes, total_len). Caller provides inclusive range.
    async fn get_range(&self, cid: &str, start: u64, end_inclusive: u64) -> Result<(Bytes, u64)>;
}

/// A simple in-memory storage for smoke tests and local development.
pub struct MemoryStorage {
    inner: RwLock<HashMap<String, Bytes>>,
}

impl MemoryStorage {
    pub fn new() -> Self {
        Self {
            inner: RwLock::new(HashMap::new()),
        }
    }
}

impl Default for MemoryStorage {
    fn default() -> Self {
        Self::new()
    }
}

#[async_trait::async_trait]
impl Storage for MemoryStorage {
    async fn put(&self, cid: &str, data: Bytes) -> Result<()> {
        let mut map = self.inner.write();
        map.insert(cid.to_string(), data);
        Ok(())
    }

    #[allow(dead_code)]
    async fn exists(&self, cid: &str) -> Result<bool> {
        let map = self.inner.read();
        Ok(map.contains_key(cid))
    }

    async fn head(&self, cid: &str) -> Result<HeadMeta> {
        let map = self.inner.read();
        let v = map.get(cid).ok_or(StorageError::NotFound)?;
        let len = v.len() as u64;
        // Strong ETag (content hash).
        let etag = format!("\"{}\"", blake3::hash(v).to_hex());
        Ok(HeadMeta { len, etag })
    }

    async fn get_full(&self, cid: &str) -> Result<Bytes> {
        let map = self.inner.read();
        let v = map.get(cid).ok_or(StorageError::NotFound)?;
        Ok(v.clone())
    }

    async fn get_range(&self, cid: &str, start: u64, end_inclusive: u64) -> Result<(Bytes, u64)> {
        let map = self.inner.read();
        let v = map.get(cid).ok_or(StorageError::NotFound)?;
        let total_len = v.len() as u64;

        // Clamp defensively; inclusive end.
        let s = (start as usize).min(v.len());
        let e = (end_inclusive as usize).min(v.len().saturating_sub(1));
        let s = s.min(e);

        // Zero-copy slice.
        let out = v.slice(s..=e);
        Ok((out, total_len))
    }
}

// Convenience so other modules can hold Arc<dyn Storage>.
pub type DynStorage = Arc<dyn Storage + Send + Sync + 'static>;

```

### crates/svc-storage/src/storage/placement.rs
<a id="crates-svc-storage-src-storage-placement-rs"></a>

```rust
// Storage module: placement (scaffold)

```

### crates/svc-storage/src/storage/pq_envelope.rs
<a id="crates-svc-storage-src-storage-pqenvelope-rs"></a>

```rust
// Storage module: pq_envelope (scaffold)

```

### crates/svc-storage/src/storage/repair.rs
<a id="crates-svc-storage-src-storage-repair-rs"></a>

```rust
// Storage module: repair (scaffold)

```

### crates/svc-storage/src/storage/replication.rs
<a id="crates-svc-storage-src-storage-replication-rs"></a>

```rust
// Storage module: replication (scaffold)

```

### crates/svc-storage/src/tls/mod.rs
<a id="crates-svc-storage-src-tls-mod-rs"></a>

```rust
// TLS module (scaffold)

```

### crates/svc-storage/src/tls/pq.rs
<a id="crates-svc-storage-src-tls-pq-rs"></a>

```rust
// Feature-gated PQ-hybrid suite selection (design stub, scaffold)

```

### crates/svc-storage/src/tls/server_config.rs
<a id="crates-svc-storage-src-tls-serverconfig-rs"></a>

```rust
// Build tokio_rustls::rustls::ServerConfig (TLS 1.3) (scaffold)

```

### crates/svc-storage/src/types.rs
<a id="crates-svc-storage-src-types-rs"></a>

```rust
use serde::Serialize;

/// Response body for a successful PUT.
#[derive(Debug, Clone, Serialize)]
pub struct PutResponse {
    pub cid: String,
}

```

### crates/svc-storage/src/uds/mod.rs
<a id="crates-svc-storage-src-uds-mod-rs"></a>

```rust
// UDS module (scaffold)

```

### crates/svc-storage/src/uds/peercred.rs
<a id="crates-svc-storage-src-uds-peercred-rs"></a>

```rust
// SO_PEERCRED extraction/validation (scaffold)

```

### crates/svc-storage/src/uds/server.rs
<a id="crates-svc-storage-src-uds-server-rs"></a>

```rust
// UDS listener wiring (scaffold)

```

### crates/svc-storage/src/version.rs
<a id="crates-svc-storage-src-version-rs"></a>

```rust
//! RO:WHAT — Crate version/commit surface for svc-storage.
//! RO:WHY  — Used by /version and logs for precise diagnostics.
//! RO:INVARIANTS — Always returns a stable ASCII string; safe to expose publicly.

pub fn version_string() -> String {
    // Prefer build-time env if present; fall back to Cargo package version.
    let pkg = env!("CARGO_PKG_VERSION");
    let name = env!("CARGO_PKG_NAME");
    let git = option_env!("GIT_COMMIT_HASH").unwrap_or("unknown");
    let build = option_env!("BUILD_TS").unwrap_or("unknown");
    format!("{name} {pkg} (git:{git}, built:{build})")
}

```

### crates/svc-storage/testing/integration/error_caps.rs
<a id="crates-svc-storage-testing-integration-errorcaps-rs"></a>

```rust
// Integration: 413/429/503 + decompression guard (scaffold)

```

### crates/svc-storage/testing/integration/http_get_head_put.rs
<a id="crates-svc-storage-testing-integration-httpgetheadput-rs"></a>

```rust
// Integration: GET/HEAD/PUT/POST round-trips (scaffold)

```

### crates/svc-storage/testing/integration/profile_matrix.rs
<a id="crates-svc-storage-testing-integration-profilematrix-rs"></a>

```rust
// Runs test suites against micronode/macronode profiles (scaffold)

```

### crates/svc-storage/testing/integration/range_tests.rs
<a id="crates-svc-storage-testing-integration-rangetests-rs"></a>

```rust
// Integration: Range semantics, 416 taxonomy (scaffold)

```

### crates/svc-storage/testing/performance/compare_baselines.sh
<a id="crates-svc-storage-testing-performance-comparebaselines-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "Compare perf baselines placeholder"

```

### crates/svc-storage/testing/performance/run_load.sh
<a id="crates-svc-storage-testing-performance-runload-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "Run perf load placeholder"

```

### crates/svc-storage/testing/performance/scripts/media_facet.sh
<a id="crates-svc-storage-testing-performance-scripts-mediafacet-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "Media facet load profile placeholder"

```

### crates/svc-storage/tests/http_blackbox.rs
<a id="crates-svc-storage-tests-httpblackbox-rs"></a>

```rust
use std::process::{Command, Stdio};
use std::thread;
use std::time::{Duration, Instant};

#[tokio::test]
async fn blackbox_put_head_get_range() {
    // Start server
    let addr = "127.0.0.1:5303";
    let mut child = Command::new("cargo")
        .args(["run", "-p", "svc-storage"])
        .env("ADDR", addr)
        .env("RUST_LOG", "warn")
        .stdout(Stdio::null())
        .stderr(Stdio::null())
        .spawn()
        .expect("spawn svc-storage");

    // Wait for it to start (poll / or /healthz)
    let client = reqwest::Client::new();
    let start = Instant::now();
    loop {
        if start.elapsed() > Duration::from_secs(8) {
            let _ = child.kill();
            panic!("svc-storage did not start");
        }
        if client
            .get(format!("http://{addr}/healthz"))
            .send()
            .await
            .is_ok()
        {
            break;
        }
        if client.get(format!("http://{addr}/")).send().await.is_ok() {
            break;
        }
        thread::sleep(Duration::from_millis(100));
    }

    // POST hello world
    let resp = client
        .post(format!("http://{addr}/o"))
        .body("hello world")
        .send()
        .await
        .unwrap();
    assert!(resp.status().is_success());
    let v: serde_json::Value = resp.json().await.unwrap();
    let cid = v["cid"].as_str().unwrap().to_string();
    assert!(cid.starts_with("b3:"));

    // HEAD
    let resp = client
        .head(format!("http://{addr}/o/{cid}"))
        .send()
        .await
        .unwrap();
    assert_eq!(resp.status(), 200);
    let len = resp
        .headers()
        .get("content-length")
        .and_then(|h| h.to_str().ok())
        .and_then(|s| s.parse::<usize>().ok())
        .unwrap();
    assert_eq!(len, 11);
    assert!(resp.headers().contains_key("etag"));

    // GET full
    let body = client
        .get(format!("http://{addr}/o/{cid}"))
        .send()
        .await
        .unwrap()
        .text()
        .await
        .unwrap();
    assert_eq!(body, "hello world");

    // Range
    let resp = client
        .get(format!("http://{addr}/o/{cid}"))
        .header(reqwest::header::RANGE, "bytes=0-4")
        .send()
        .await
        .unwrap();
    assert_eq!(resp.status(), 206);
    let cr = resp
        .headers()
        .get("content-range")
        .unwrap()
        .to_str()
        .unwrap()
        .to_string();
    assert!(cr.ends_with("/11"), "content-range={cr}");
    let part = resp.text().await.unwrap();
    assert_eq!(part, "hello");

    // shutdown server
    let _ = child.kill();
}

```



---



# svc-index

_Source: crates/svc-index/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:53:28Z -->
# Code Bundle — `svc-index`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/svc-index/.cargo/config.toml](#crates-svc-index--cargo-config-toml)
- [crates/svc-index/.github/workflows/chaos.yml](#crates-svc-index--github-workflows-chaos-yml)
- [crates/svc-index/.github/workflows/ci.yml](#crates-svc-index--github-workflows-ci-yml)
- [crates/svc-index/.github/workflows/coverage.yml](#crates-svc-index--github-workflows-coverage-yml)
- [crates/svc-index/.github/workflows/fuzz.yml](#crates-svc-index--github-workflows-fuzz-yml)
- [crates/svc-index/.github/workflows/perf-regress.yml](#crates-svc-index--github-workflows-perf-regress-yml)
- [crates/svc-index/.github/workflows/render-mermaid.yml](#crates-svc-index--github-workflows-render-mermaid-yml)
- [crates/svc-index/Cargo.toml](#crates-svc-index-Cargo-toml)
- [crates/svc-index/benches/resolve.rs](#crates-svc-index-benches-resolve-rs)
- [crates/svc-index/deny.toml](#crates-svc-index-deny-toml)
- [crates/svc-index/examples/client.rs](#crates-svc-index-examples-client-rs)
- [crates/svc-index/fuzz/Cargo.toml](#crates-svc-index-fuzz-Cargo-toml)
- [crates/svc-index/fuzz/fuzz.toml](#crates-svc-index-fuzz-fuzz-toml)
- [crates/svc-index/fuzz/fuzz_targets/http_resolve.rs](#crates-svc-index-fuzz-fuzztargets-httpresolve-rs)
- [crates/svc-index/fuzz/fuzz_targets/parse_manifest.rs](#crates-svc-index-fuzz-fuzztargets-parsemanifest-rs)
- [crates/svc-index/scripts/bench_http.sh](#crates-svc-index-scripts-benchhttp-sh)
- [crates/svc-index/scripts/bench_http_release.sh](#crates-svc-index-scripts-benchhttprelease-sh)
- [crates/svc-index/scripts/bench_resolve.sh](#crates-svc-index-scripts-benchresolve-sh)
- [crates/svc-index/scripts/chaos_inject.sh](#crates-svc-index-scripts-chaosinject-sh)
- [crates/svc-index/scripts/mermaid_render.sh](#crates-svc-index-scripts-mermaidrender-sh)
- [crates/svc-index/scripts/smoke.sh](#crates-svc-index-scripts-smoke-sh)
- [crates/svc-index/scripts/smoke_index.sh](#crates-svc-index-scripts-smokeindex-sh)
- [crates/svc-index/scripts/soak.sh](#crates-svc-index-scripts-soak-sh)
- [crates/svc-index/src/app.rs](#crates-svc-index-src-app-rs)
- [crates/svc-index/src/audit/events.rs](#crates-svc-index-src-audit-events-rs)
- [crates/svc-index/src/audit/mod.rs](#crates-svc-index-src-audit-mod-rs)
- [crates/svc-index/src/auth/caps.rs](#crates-svc-index-src-auth-caps-rs)
- [crates/svc-index/src/auth/mod.rs](#crates-svc-index-src-auth-mod-rs)
- [crates/svc-index/src/auth/uds_allow.rs](#crates-svc-index-src-auth-udsallow-rs)
- [crates/svc-index/src/bus/events.rs](#crates-svc-index-src-bus-events-rs)
- [crates/svc-index/src/bus/mod.rs](#crates-svc-index-src-bus-mod-rs)
- [crates/svc-index/src/cache/manifest.rs](#crates-svc-index-src-cache-manifest-rs)
- [crates/svc-index/src/cache/mod.rs](#crates-svc-index-src-cache-mod-rs)
- [crates/svc-index/src/cache/negative.rs](#crates-svc-index-src-cache-negative-rs)
- [crates/svc-index/src/cache/providers.rs](#crates-svc-index-src-cache-providers-rs)
- [crates/svc-index/src/config.rs](#crates-svc-index-src-config-rs)
- [crates/svc-index/src/constants.rs](#crates-svc-index-src-constants-rs)
- [crates/svc-index/src/dht/client.rs](#crates-svc-index-src-dht-client-rs)
- [crates/svc-index/src/dht/hedge.rs](#crates-svc-index-src-dht-hedge-rs)
- [crates/svc-index/src/dht/mod.rs](#crates-svc-index-src-dht-mod-rs)
- [crates/svc-index/src/dht/rank.rs](#crates-svc-index-src-dht-rank-rs)
- [crates/svc-index/src/error.rs](#crates-svc-index-src-error-rs)
- [crates/svc-index/src/http/extractors/capability.rs](#crates-svc-index-src-http-extractors-capability-rs)
- [crates/svc-index/src/http/extractors/corr_id.rs](#crates-svc-index-src-http-extractors-corrid-rs)
- [crates/svc-index/src/http/extractors/limits.rs](#crates-svc-index-src-http-extractors-limits-rs)
- [crates/svc-index/src/http/extractors/mod.rs](#crates-svc-index-src-http-extractors-mod-rs)
- [crates/svc-index/src/http/middleware/body_limits.rs](#crates-svc-index-src-http-middleware-bodylimits-rs)
- [crates/svc-index/src/http/middleware/decompress_guard.rs](#crates-svc-index-src-http-middleware-decompressguard-rs)
- [crates/svc-index/src/http/middleware/mod.rs](#crates-svc-index-src-http-middleware-mod-rs)
- [crates/svc-index/src/http/middleware/rate_limit.rs](#crates-svc-index-src-http-middleware-ratelimit-rs)
- [crates/svc-index/src/http/middleware/trace_layer.rs](#crates-svc-index-src-http-middleware-tracelayer-rs)
- [crates/svc-index/src/http/mod.rs](#crates-svc-index-src-http-mod-rs)
- [crates/svc-index/src/http/routes/admin.rs](#crates-svc-index-src-http-routes-admin-rs)
- [crates/svc-index/src/http/routes/health.rs](#crates-svc-index-src-http-routes-health-rs)
- [crates/svc-index/src/http/routes/metrics.rs](#crates-svc-index-src-http-routes-metrics-rs)
- [crates/svc-index/src/http/routes/mod.rs](#crates-svc-index-src-http-routes-mod-rs)
- [crates/svc-index/src/http/routes/providers.rs](#crates-svc-index-src-http-routes-providers-rs)
- [crates/svc-index/src/http/routes/resolve.rs](#crates-svc-index-src-http-routes-resolve-rs)
- [crates/svc-index/src/http/routes/version.rs](#crates-svc-index-src-http-routes-version-rs)
- [crates/svc-index/src/lib.rs](#crates-svc-index-src-lib-rs)
- [crates/svc-index/src/logging.rs](#crates-svc-index-src-logging-rs)
- [crates/svc-index/src/main.rs](#crates-svc-index-src-main-rs)
- [crates/svc-index/src/net/listener.rs](#crates-svc-index-src-net-listener-rs)
- [crates/svc-index/src/net/mod.rs](#crates-svc-index-src-net-mod-rs)
- [crates/svc-index/src/net/tls.rs](#crates-svc-index-src-net-tls-rs)
- [crates/svc-index/src/net/uds.rs](#crates-svc-index-src-net-uds-rs)
- [crates/svc-index/src/pipeline/mod.rs](#crates-svc-index-src-pipeline-mod-rs)
- [crates/svc-index/src/pipeline/providers.rs](#crates-svc-index-src-pipeline-providers-rs)
- [crates/svc-index/src/pipeline/resolve.rs](#crates-svc-index-src-pipeline-resolve-rs)
- [crates/svc-index/src/router.rs](#crates-svc-index-src-router-rs)
- [crates/svc-index/src/state/metrics.rs](#crates-svc-index-src-state-metrics-rs)
- [crates/svc-index/src/state/mod.rs](#crates-svc-index-src-state-mod-rs)
- [crates/svc-index/src/state/readiness.rs](#crates-svc-index-src-state-readiness-rs)
- [crates/svc-index/src/state/shutdown.rs](#crates-svc-index-src-state-shutdown-rs)
- [crates/svc-index/src/store/keys.rs](#crates-svc-index-src-store-keys-rs)
- [crates/svc-index/src/store/mod.rs](#crates-svc-index-src-store-mod-rs)
- [crates/svc-index/src/store/schema.rs](#crates-svc-index-src-store-schema-rs)
- [crates/svc-index/src/store/sled_store.rs](#crates-svc-index-src-store-sledstore-rs)
- [crates/svc-index/src/telemetry.rs](#crates-svc-index-src-telemetry-rs)
- [crates/svc-index/src/types.rs](#crates-svc-index-src-types-rs)
- [crates/svc-index/src/utils/mod.rs](#crates-svc-index-src-utils-mod-rs)
- [crates/svc-index/src/utils/timeouts.rs](#crates-svc-index-src-utils-timeouts-rs)
- [crates/svc-index/tests/chaos.rs](#crates-svc-index-tests-chaos-rs)
- [crates/svc-index/tests/golden/resolve/not_found.json](#crates-svc-index-tests-golden-resolve-notfound-json)
- [crates/svc-index/tests/golden/resolve/ok_basic.json](#crates-svc-index-tests-golden-resolve-okbasic-json)
- [crates/svc-index/tests/golden/resolve/over_capacity.json](#crates-svc-index-tests-golden-resolve-overcapacity-json)
- [crates/svc-index/tests/golden/resolve/providers_ranked.json](#crates-svc-index-tests-golden-resolve-providersranked-json)
- [crates/svc-index/tests/http_contract.rs](#crates-svc-index-tests-httpcontract-rs)
- [crates/svc-index/tests/integration.rs](#crates-svc-index-tests-integration-rs)
- [crates/svc-index/tests/loom_index.rs](#crates-svc-index-tests-loomindex-rs)
- [crates/svc-index/tests/prop_index.rs](#crates-svc-index-tests-propindex-rs)

### crates/svc-index/.cargo/config.toml
<a id="crates-svc-index--cargo-config-toml"></a>

```toml
# local build defaults — (auto-generated by scaffold_svc_index2.sh; replace with real content later)
[build]
rustflags = []

[target.'cfg(all())']
rustflags = []

[term]
verbose = true

```

### crates/svc-index/.github/workflows/chaos.yml
<a id="crates-svc-index--github-workflows-chaos-yml"></a>

```yaml
name: chaos
on:
  workflow_dispatch: {}
jobs:
  chaos:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo 'inject latency/drop into mocked DHT during tests; stub only'

```

### crates/svc-index/.github/workflows/ci.yml
<a id="crates-svc-index--github-workflows-ci-yml"></a>

```yaml
name: ci
on: [push, pull_request]
jobs:
  ci:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - run: cargo fmt --all -- --check
      - run: cargo clippy -p svc-index2 -- -D warnings
      - run: cargo test -p svc-index2 --all-features
      - run: cargo deny check

```

### crates/svc-index/.github/workflows/coverage.yml
<a id="crates-svc-index--github-workflows-coverage-yml"></a>

```yaml
name: coverage
on:
  workflow_dispatch: {}
jobs:
  coverage:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: taiki-e/install-action@cargo-llvm-cov
      - run: cargo llvm-cov --workspace --lcov --output-path lcov.info

```

### crates/svc-index/.github/workflows/fuzz.yml
<a id="crates-svc-index--github-workflows-fuzz-yml"></a>

```yaml
name: fuzz
on:
  workflow_dispatch: {}
jobs:
  fuzz:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo 'run cargo-fuzz locally or in a container; stub only'

```

### crates/svc-index/.github/workflows/perf-regress.yml
<a id="crates-svc-index--github-workflows-perf-regress-yml"></a>

```yaml
name: perf-regress
on:
  workflow_dispatch: {}
jobs:
  perf:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo 'run Criterion and compare vs baseline; stub only'

```

### crates/svc-index/.github/workflows/render-mermaid.yml
<a id="crates-svc-index--github-workflows-render-mermaid-yml"></a>

```yaml
name: render-mermaid
on: [push, pull_request]
jobs:
  mmdc:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm i -g @mermaid-js/mermaid-cli
      - run: |
          for f in $(git ls-files 'crates/svc-index2/docs/*.mmd'); do
            out="${f%.mmd}.svg"
            mmdc -i "$f" -o "$out"
          done

```

### crates/svc-index/Cargo.toml
<a id="crates-svc-index-Cargo-toml"></a>

```toml
[package]
name = "svc-index"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
description = "RustyOnions index service (resolve name/cid -> manifest/providers)."
repository = "https://github.com/your/repo"
keywords = ["rust", "axum", "index", "dht", "blake3"]

[features]
# Keep sled-store as the default (no regressions).
default = ["sled-store"]
sled-store = ["dep:sled"]
# New: in-memory store for tests/CI; off by default.
inmem = []
otel = ["dep:opentelemetry", "dep:tracing-opentelemetry", "dep:opentelemetry-otlp"]
facets = []

[dependencies]
axum = { version = "0.7", features = ["tokio", "http1", "http2", "json"] }
tokio = { version = "1", features = ["rt-multi-thread", "macros", "signal", "time", "net", "sync", "io-util"] }
bytes = "1"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
serde_with = "3"
thiserror = "1"
prometheus = "0.14"
once_cell = "1"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "fmt", "ansi"] }
opentelemetry = { version = "0.24", optional = true }
tracing-opentelemetry = { version = "0.26", optional = true }
opentelemetry-otlp = { version = "0.17", optional = true }
http = "1"
headers = "0.4"
ulid = "1"
uuid = { version = "1", features = ["v4", "fast-rng"] }
blake3 = "1"
time = { version = "0.3", features = ["formatting"] }
parking_lot = "0.12"
dashmap = "6"
anyhow = "1"
tower = "0.5"
tower-http = { version = "0.6", features = ["trace"] }
mime = "0.3"
arc-swap = "1"
rand = "0.9"

# New for store + middleware:
bincode = "1"
hex = "0.4"
futures-util = "0.3"

# Optional sled store (kept as-is)
sled = { version = "0.34", optional = true }

[dev-dependencies]
reqwest = { version = "0.12", default-features = false, features = ["json", "rustls-tls-native-roots"] }
tokio = { version = "1", features = ["rt-multi-thread", "macros"] }

```

### crates/svc-index/benches/resolve.rs
<a id="crates-svc-index-benches-resolve-rs"></a>

```rust
// Criterion bench placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)
fn main() {}

```

### crates/svc-index/deny.toml
<a id="crates-svc-index-deny-toml"></a>

```toml
# cargo-deny config (baseline) — (auto-generated by scaffold_svc_index2.sh; replace with real content later)
[advisories]
vulnerability = "deny"
yanked = "deny"
unmaintained = "warn"

[bans]
multiple-versions = "warn"

[sources]
unknown-registry = "deny"
unknown-git = "deny"
allow-git = []

```

### crates/svc-index/examples/client.rs
<a id="crates-svc-index-examples-client-rs"></a>

```rust
// example client placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)
fn main() {}

```

### crates/svc-index/fuzz/Cargo.toml
<a id="crates-svc-index-fuzz-Cargo-toml"></a>

```toml
[package]
name = "svc-index2-fuzz"
version = "0.0.0"
publish = false
edition = "2021"

[workspace]
members = []

[package.metadata]
cargo-fuzz = true

```

### crates/svc-index/fuzz/fuzz.toml
<a id="crates-svc-index-fuzz-fuzz-toml"></a>

```toml
# fuzz seeds and budgets — (auto-generated by scaffold_svc_index2.sh; replace with real content later)
[http_resolve]
max_total_time = 30

[parse_manifest]
max_total_time = 30

```

### crates/svc-index/fuzz/fuzz_targets/http_resolve.rs
<a id="crates-svc-index-fuzz-fuzztargets-httpresolve-rs"></a>

```rust
// fuzz target placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)
fn main() { }

```

### crates/svc-index/fuzz/fuzz_targets/parse_manifest.rs
<a id="crates-svc-index-fuzz-fuzztargets-parsemanifest-rs"></a>

```rust
// fuzz target placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)
fn main() { }

```

### crates/svc-index/scripts/bench_http.sh
<a id="crates-svc-index-scripts-benchhttp-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

cargo build -p svc-index

INDEX_BIND="${INDEX_BIND:-127.0.0.1:5304}"
RUST_LOG="${RUST_LOG:-warn}"

target/debug/svc-index >/tmp/svc-index.bench.log 2>&1 &
PID=$!
trap 'kill $PID >/dev/null 2>&1 || true' EXIT

# Wait for service
for i in $(seq 1 120); do
  code=$(curl -s -o /dev/null -w "%{http_code}" "http://$INDEX_BIND/healthz" || true)
  [ "$code" = "200" ] && break
  sleep 0.05
done

bench_wrk() {
  wrk -t4 -c64 -d15s "http://$INDEX_BIND/healthz"
  echo
  wrk -t4 -c64 -d15s "http://$INDEX_BIND/version"
  echo
  wrk -t4 -c32 -d15s "http://$INDEX_BIND/metrics"
}

bench_hey() {
  hey -z 15s -c 64 "http://$INDEX_BIND/healthz"
  echo
  hey -z 15s -c 64 "http://$INDEX_BIND/version"
  echo
  hey -z 15s -c 32 "http://$INDEX_BIND/metrics"
}

bench_pure() {
  one() {
    URL="$1"; CONC="$2"; DUR="$3"
    end=$(( $(date +%s) + DUR ))
    tmpdir="$(mktemp -d)"
    pids=()
    for w in $(seq 1 "$CONC"); do
      (
        cnt=0
        while [ "$(date +%s)" -lt "$end" ]; do
          curl -s -o /dev/null "$URL" || true
          cnt=$((cnt+1))
        done
        echo "$cnt" > "$tmpdir/$w.count"
      ) &
      pids+=("$!")
    done
    for p in "${pids[@]}"; do wait "$p"; done
    total=0
    for f in "$tmpdir"/*.count; do
      [ -f "$f" ] || continue
      n=$(cat "$f")
      total=$((total + n))
    done
    rm -rf "$tmpdir"
    rps=$(awk "BEGIN { printf \"%.1f\", $total/$DUR }")
    echo "purebash url=$URL conc=$CONC dur=${DUR}s total_reqs=$total rps=$rps"
  }
  one "http://$INDEX_BIND/healthz" 64 15
  echo
  one "http://$INDEX_BIND/version" 64 15
  echo
  one "http://$INDEX_BIND/metrics" 32 15
}

if command -v wrk >/dev/null 2>&1; then
  bench_wrk
elif command -v hey >/dev/null 2>&1; then
  bench_hey
else
  bench_pure
fi

```

### crates/svc-index/scripts/bench_http_release.sh
<a id="crates-svc-index-scripts-benchhttprelease-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

cargo build -p svc-index --release

INDEX_BIND="${INDEX_BIND:-127.0.0.1:5304}"
RUST_LOG="${RUST_LOG:-warn}"

target/release/svc-index >/tmp/svc-index.bench.release.log 2>&1 &
PID=$!
trap 'kill $PID >/dev/null 2>&1 || true' EXIT

# wait for server
for i in $(seq 1 200); do
  code=$(curl -s -o /dev/null -w "%{http_code}" "http://$INDEX_BIND/healthz" || true)
  [ "$code" = "200" ] && break
  sleep 0.05
done

warmup() {
  D=${1:-5}
  end=$(( $(date +%s) + D ))
  while [ "$(date +%s)" -lt "$end" ]; do curl -s -o /dev/null "http://$INDEX_BIND/healthz" || true; done
}

run_wrk() {
  echo "wrk /healthz"
  wrk -t4 -c128 -d30s "http://$INDEX_BIND/healthz"
  echo
  echo "wrk /version"
  wrk -t4 -c128 -d30s "http://$INDEX_BIND/version"
  echo
  echo "wrk /metrics"
  wrk -t4 -c64  -d30s "http://$INDEX_BIND/metrics"
}

run_hey() {
  echo "hey /healthz"
  hey -z 30s -c 128 "http://$INDEX_BIND/healthz"
  echo
  echo "hey /version"
  hey -z 30s -c 128 "http://$INDEX_BIND/version"
  echo
  echo "hey /metrics"
  hey -z 30s -c 64  "http://$INDEX_BIND/metrics"
}

run_pure() {
  one() {
    URL="$1"; CONC="$2"; DUR="$3"
    end=$(( $(date +%s) + DUR ))
    tmpdir="$(mktemp -d)"
    pids=()
    for w in $(seq 1 "$CONC"); do
      (
        cnt=0
        while [ "$(date +%s)" -lt "$end" ]; do curl -s -o /dev/null "$URL" || true; cnt=$((cnt+1)); done
        echo "$cnt" > "$tmpdir/$w.count"
      ) & pids+=("$!")
    done
    for p in "${pids[@]}"; do wait "$p"; done
    total=0
    for f in "$tmpdir"/*.count; do [ -f "$f" ] && total=$(( total + $(cat "$f") )); done
    rm -rf "$tmpdir"
    rps=$(awk "BEGIN { printf \"%.1f\", $total/$DUR }")
    echo "purebash url=$URL conc=$CONC dur=${DUR}s total_reqs=$total rps=$rps"
  }
  one "http://$INDEX_BIND/healthz" 128 30
  echo
  one "http://$INDEX_BIND/version" 128 30
  echo
  one "http://$INDEX_BIND/metrics" 64  30
}

warmup 5

if command -v wrk >/dev/null 2>&1; then
  run_wrk
elif command -v hey >/dev/null 2>&1; then
  run_hey
else
  run_pure
fi

```

### crates/svc-index/scripts/bench_resolve.sh
<a id="crates-svc-index-scripts-benchresolve-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "bench: would run Criterion on benches/resolve.rs with datasets"

```

### crates/svc-index/scripts/chaos_inject.sh
<a id="crates-svc-index-scripts-chaosinject-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "chaos: would inject latency/drop into mocked DHT for tests"

```

### crates/svc-index/scripts/mermaid_render.sh
<a id="crates-svc-index-scripts-mermaidrender-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "render: would run mmdc for docs/*.mmd -> *.svg"

```

### crates/svc-index/scripts/smoke.sh
<a id="crates-svc-index-scripts-smoke-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT — Smoke test for svc-index: boot and hit endpoints.
# RO:WHY  — CI/local quick check without magic sleeps.

set -euo pipefail
BIND="${BIND:-127.0.0.1:5304}"
BIN="${BIN:-cargo run -p svc-index}"
LOG="/tmp/svc-index.log"

$BIN > "$LOG" 2>&1 &
PID=$!

deadline=$((SECONDS+10))
until curl -fsS "http://$BIND/readyz" >/dev/null; do
  [[ $SECONDS -gt $deadline ]] && { echo "readyz timeout"; kill $PID || true; exit 1; }
  sleep 0.2
done

curl -fsS "http://$BIND/healthz" | grep -q ok
curl -fsS "http://$BIND/version" | grep -q svc-index
curl -fsS "http://$BIND/resolve/name:hello" || true
curl -fsS "http://$BIND/providers/b3:0000000000000000000000000000000000000000000000000000000000000000" || true

kill $PID || true
echo "✅ svc-index smoke passed"

```

### crates/svc-index/scripts/smoke_index.sh
<a id="crates-svc-index-scripts-smokeindex-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

cargo fmt -p svc-index
cargo clippy -p svc-index --no-deps -- -D warnings
cargo build -p svc-index

INDEX_BIND="${INDEX_BIND:-127.0.0.1:5304}"
RUST_LOG="${RUST_LOG:-info}"

target/debug/svc-index >/tmp/svc-index.log 2>&1 &
PID=$!

trap 'kill $PID >/dev/null 2>&1 || true' EXIT

for i in $(seq 1 60); do
  code=$(curl -s -o /dev/null -w "%{http_code}" "http://$INDEX_BIND/healthz" || true)
  [ "$code" = "200" ] && break
  sleep 0.1
done

CID_ZERO="b3:0000000000000000000000000000000000000000000000000000000000000000"

curl -s -o /dev/null -w "%{http_code}\n" "http://$INDEX_BIND/healthz"
curl -s -o /dev/null -w "%{http_code}\n" "http://$INDEX_BIND/readyz"
curl -s -o /dev/null -w "%{http_code}\n" "http://$INDEX_BIND/version"
curl -s -o /dev/null -w "%{http_code}\n" "http://$INDEX_BIND/resolve/name:does-not-exist"
curl -s -o /dev/null -w "%{http_code}\n" "http://$INDEX_BIND/providers/not-a-cid"
curl -s -o /dev/null -w "%{http_code}\n" "http://$INDEX_BIND/providers/$CID_ZERO"

kill $PID

```

### crates/svc-index/scripts/soak.sh
<a id="crates-svc-index-scripts-soak-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "soak: would run a short soak test and write histograms to artifacts/"

```

### crates/svc-index/src/app.rs
<a id="crates-svc-index-src-app-rs"></a>

```rust
//! App wiring helpers (bootstrap)

use crate::state::AppState;
use std::sync::Arc;
use tracing::info;

impl AppState {
    pub async fn bootstrap(state: Arc<AppState>) -> Arc<AppState> {
        // Verify deps here later; for MVP, set ready immediately.
        state.health.mark_ready();
        info!("svc-index ready");
        state
    }
}

```

### crates/svc-index/src/audit/events.rs
<a id="crates-svc-index-src-audit-events-rs"></a>

```rust
// audit events placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/audit/mod.rs
<a id="crates-svc-index-src-audit-mod-rs"></a>

```rust
//! RO:WHAT — Audit emit stubs.

pub mod events {
    pub fn emit(_kind: &str, _msg: &str) {}
}

```

### crates/svc-index/src/auth/caps.rs
<a id="crates-svc-index-src-auth-caps-rs"></a>

```rust
// capability policies placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/auth/mod.rs
<a id="crates-svc-index-src-auth-mod-rs"></a>

```rust
//! RO:WHAT — Placeholder for capability checks (macaroon etc).

pub mod caps {
    pub fn check_read() -> bool {
        true
    }
    pub fn check_admin() -> bool {
        false
    } // TODO
}
pub mod uds_allow {} // placeholder

```

### crates/svc-index/src/auth/uds_allow.rs
<a id="crates-svc-index-src-auth-udsallow-rs"></a>

```rust
// uds allowlist placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/bus/events.rs
<a id="crates-svc-index-src-bus-events-rs"></a>

```rust
// bus events placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/bus/mod.rs
<a id="crates-svc-index-src-bus-mod-rs"></a>

```rust
//! RO:WHAT — Bus event stubs (tie to ron-bus later).

pub mod events {
    #[derive(Clone, Debug)]
    pub enum BusEvent {
        ConfigUpdated,
        Shutdown,
    }
}

```

### crates/svc-index/src/cache/manifest.rs
<a id="crates-svc-index-src-cache-manifest-rs"></a>

```rust
// manifest cache placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/cache/mod.rs
<a id="crates-svc-index-src-cache-mod-rs"></a>

```rust
//! RO:WHAT — Tiny TTL cache for resolves/providers.
//! RO:WHY  — Read-optimized service; avoid hot DHT/DB hits.
//! RO:INVARIANTS — bounded by TTL only (simple MVP).

use dashmap::DashMap;
use std::time::{Duration, Instant};

pub struct IndexCache {
    ttl: Duration,
    resolve: DashMap<String, (crate::types::ResolveResponse, Instant)>,
    providers: DashMap<String, (crate::types::ProvidersResponse, Instant)>,
}

impl IndexCache {
    pub fn new(ttl_secs: u64) -> Self {
        Self {
            ttl: Duration::from_secs(ttl_secs),
            resolve: DashMap::new(),
            providers: DashMap::new(),
        }
    }

    pub fn get_resolve(&self, key: &str) -> Option<crate::types::ResolveResponse> {
        self.resolve.get(key).and_then(|v| {
            let (val, ins) = v.value();
            if ins.elapsed() <= self.ttl {
                Some(val.clone())
            } else {
                None
            }
        })
    }
    pub fn put_resolve(&self, key: String, val: crate::types::ResolveResponse) {
        self.resolve.insert(key, (val, Instant::now()));
    }

    pub fn get_providers(&self, cid: &str) -> Option<crate::types::ProvidersResponse> {
        self.providers.get(cid).and_then(|v| {
            let (val, ins) = v.value();
            if ins.elapsed() <= self.ttl {
                Some(val.clone())
            } else {
                None
            }
        })
    }
    pub fn put_providers(&self, cid: String, val: crate::types::ProvidersResponse) {
        self.providers.insert(cid, (val, Instant::now()));
    }
}

```

### crates/svc-index/src/cache/negative.rs
<a id="crates-svc-index-src-cache-negative-rs"></a>

```rust
// negative cache placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/cache/providers.rs
<a id="crates-svc-index-src-cache-providers-rs"></a>

```rust
// providers cache placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/config.rs
<a id="crates-svc-index-src-config-rs"></a>

```rust
//! RO:WHAT — Load and validate service configuration (env + optional file).
//! RO:WHY  — Governance & Hardening defaults (timeouts, limits).

use serde::{Deserialize, Serialize};

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Config {
    pub bind: String,
    pub body_cap_bytes: usize,
    pub cache_ttl_secs: u64,
    pub ready_dep_timeout_ms: u64,
    pub enable_sled: bool,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            bind: "127.0.0.1:5304".into(),
            body_cap_bytes: 1024 * 1024, // 1 MiB
            cache_ttl_secs: 30,
            ready_dep_timeout_ms: 1500,
            enable_sled: true,
        }
    }
}

impl Config {
    pub fn load() -> anyhow::Result<Self> {
        let mut cfg = Config::default();
        if let Ok(v) = std::env::var("BIND") {
            cfg.bind = v;
        }
        if let Ok(v) = std::env::var("BODY_CAP_BYTES") {
            cfg.body_cap_bytes = v.parse().unwrap_or(cfg.body_cap_bytes);
        }
        if let Ok(v) = std::env::var("CACHE_TTL_SECS") {
            cfg.cache_ttl_secs = v.parse().unwrap_or(cfg.cache_ttl_secs);
        }
        if let Ok(v) = std::env::var("READY_DEP_TIMEOUT_MS") {
            cfg.ready_dep_timeout_ms = v.parse().unwrap_or(cfg.ready_dep_timeout_ms);
        }
        if let Ok(v) = std::env::var("ENABLE_SLED") {
            cfg.enable_sled = v == "1" || v.eq_ignore_ascii_case("true");
        }
        Ok(cfg)
    }
}

```

### crates/svc-index/src/constants.rs
<a id="crates-svc-index-src-constants-rs"></a>

```rust
//! RO:WHAT — Service-wide constants (OAP/HTTP bounds, header keys).

pub const OAP_MAX_FRAME_BYTES: usize = 1024 * 1024; // 1 MiB
pub const STORAGE_STREAM_CHUNK_HINT: usize = 64 * 1024;

pub const HDR_CORR_ID: &str = "x-corr-id";
pub const HDR_IDEMPOTENCY_KEY: &str = "idempotency-key";

/// Default max accepted body size for inbound HTTP requests (bytes).
/// Set to 1 MiB. Keep aligned with CONFIG.md defaults and body_limits middleware.
pub const MAX_BODY_BYTES: usize = 1_048_576; // 1 MiB

```

### crates/svc-index/src/dht/client.rs
<a id="crates-svc-index-src-dht-client-rs"></a>

```rust
//! RO:WHAT — DHT client stub for provider lookups (to be wired to svc-dht).

use crate::types::ProviderEntry;

#[derive(Clone, Default)]
pub struct DhtClient;

impl DhtClient {
    pub fn new() -> Self {
        Self
    }
    pub async fn providers_for(&self, _cid: &str, limit: usize) -> Vec<ProviderEntry> {
        vec![ProviderEntry {
            id: "local://stub".into(),
            region: Some("local".into()),
            score: 0.5,
        }]
        .into_iter()
        .take(limit)
        .collect()
    }
}

```

### crates/svc-index/src/dht/hedge.rs
<a id="crates-svc-index-src-dht-hedge-rs"></a>

```rust
// hedged lookups placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/dht/mod.rs
<a id="crates-svc-index-src-dht-mod-rs"></a>

```rust
pub mod client;
pub mod rank;

```

### crates/svc-index/src/dht/rank.rs
<a id="crates-svc-index-src-dht-rank-rs"></a>

```rust
//! RO:WHAT — Simple ranking heuristics placeholder.

use crate::types::ProviderEntry;

pub fn rank(mut v: Vec<ProviderEntry>) -> Vec<ProviderEntry> {
    v.sort_by(|a, b| b.score.total_cmp(&a.score));
    v
}

```

### crates/svc-index/src/error.rs
<a id="crates-svc-index-src-error-rs"></a>

```rust
//! Service error type ↔ HTTP mapping.

use crate::types::ErrorResponse;
use axum::{http::StatusCode, response::IntoResponse, Json};
use thiserror::Error;

#[derive(Debug, Error)]
pub enum SvcError {
    #[error("not_found")]
    NotFound,
    #[error("bad_request: {0}")]
    BadRequest(String),
    #[error("over_capacity")]
    OverCapacity,
    #[error("upstream_unready")]
    UpstreamUnready,
    #[error("unauthorized")]
    Unauthorized,
    #[error("forbidden")]
    Forbidden,
    #[error("internal")]
    Internal(anyhow::Error),
}

impl IntoResponse for SvcError {
    fn into_response(self) -> axum::response::Response {
        let (status, code, message): (StatusCode, &'static str, String) = match self {
            SvcError::NotFound => (StatusCode::NOT_FOUND, "not_found", "Not found".to_string()),
            SvcError::BadRequest(m) => (StatusCode::BAD_REQUEST, "bad_request", m),
            SvcError::OverCapacity => (
                StatusCode::TOO_MANY_REQUESTS,
                "over_capacity",
                "Over capacity".to_string(),
            ),
            SvcError::UpstreamUnready => (
                StatusCode::SERVICE_UNAVAILABLE,
                "upstream_unready",
                "Upstream not ready".to_string(),
            ),
            SvcError::Unauthorized => (
                StatusCode::UNAUTHORIZED,
                "unauthorized",
                "Unauthorized".to_string(),
            ),
            SvcError::Forbidden => (StatusCode::FORBIDDEN, "forbidden", "Forbidden".to_string()),
            SvcError::Internal(_) => (
                StatusCode::INTERNAL_SERVER_ERROR,
                "internal",
                "Internal error".to_string(),
            ),
        };
        (
            status,
            Json(ErrorResponse {
                code: code.into(),
                message,
            }),
        )
            .into_response()
    }
}

```

### crates/svc-index/src/http/extractors/capability.rs
<a id="crates-svc-index-src-http-extractors-capability-rs"></a>

```rust
//! RO:WHAT — Capability placeholder (no-op for public GETs).
#[derive(Clone, Copy)]
pub struct Capability;

```

### crates/svc-index/src/http/extractors/corr_id.rs
<a id="crates-svc-index-src-http-extractors-corrid-rs"></a>

```rust
//! RO:WHAT — Simple correlation id generator/injector for responses.

use axum::{http::HeaderValue, response::Response};
use ulid::Ulid;

pub fn add_corr_id(mut r: Response) -> Response {
    let id = Ulid::new().to_string();
    r.headers_mut()
        .insert("x-corr-id", HeaderValue::from_str(&id).unwrap());
    r
}

```

### crates/svc-index/src/http/extractors/limits.rs
<a id="crates-svc-index-src-http-extractors-limits-rs"></a>

```rust
//! RO:WHAT — Request body cap placeholder (Hardening v2.0).

#[derive(Clone, Copy)]
pub struct BodyLimits {
    pub max_bytes: usize,
}

```

### crates/svc-index/src/http/extractors/mod.rs
<a id="crates-svc-index-src-http-extractors-mod-rs"></a>

```rust
//! RO:WHAT — Extractors module root.

pub mod capability;
pub mod corr_id;
pub mod limits;

```

### crates/svc-index/src/http/middleware/body_limits.rs
<a id="crates-svc-index-src-http-middleware-bodylimits-rs"></a>

```rust
//! RO:WHAT — Body size cap middleware placeholder (MVP).
//! RO:WHY  — Hardening v2.0 will wire strict limits per extractor/route.
//! NOTE: Using identity layer for now to avoid unused imports/warnings.

pub fn layer(_max: usize) -> tower::layer::util::Identity {
    tower::layer::util::Identity::new()
}

```

### crates/svc-index/src/http/middleware/decompress_guard.rs
<a id="crates-svc-index-src-http-middleware-decompressguard-rs"></a>

```rust
// decompress ratio guard middleware placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/http/middleware/mod.rs
<a id="crates-svc-index-src-http-middleware-mod-rs"></a>

```rust
//! RO:WHAT — Middleware module root.

pub mod body_limits;
pub mod trace_layer;

```

### crates/svc-index/src/http/middleware/rate_limit.rs
<a id="crates-svc-index-src-http-middleware-ratelimit-rs"></a>

```rust
// rate limit middleware placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/http/middleware/trace_layer.rs
<a id="crates-svc-index-src-http-middleware-tracelayer-rs"></a>

```rust
//! Tower HTTP TraceLayer (Axum + tower-http 0.6.x).
//! Minimal sane defaults using DefaultMakeSpan at INFO level.

use tower_http::classify::{ServerErrorsAsFailures, SharedClassifier};
use tower_http::trace::{
    DefaultMakeSpan, DefaultOnBodyChunk, DefaultOnEos, DefaultOnFailure, DefaultOnRequest,
    DefaultOnResponse, TraceLayer,
};
use tracing::Level;

/// Return a concrete, cloneable TraceLayer with the default classifier
/// (treat 5xx as failures) and the default span builder at INFO.
pub fn layer() -> TraceLayer<
    SharedClassifier<ServerErrorsAsFailures>,
    DefaultMakeSpan,
    DefaultOnRequest,
    DefaultOnResponse,
    DefaultOnBodyChunk,
    DefaultOnEos,
    DefaultOnFailure,
> {
    TraceLayer::new_for_http().make_span_with(DefaultMakeSpan::new().level(Level::INFO))
}

```

### crates/svc-index/src/http/mod.rs
<a id="crates-svc-index-src-http-mod-rs"></a>

```rust
//! RO:WHAT — HTTP module root: submodules for routes, extractors, middleware.

pub mod extractors;
pub mod middleware;
pub mod routes;

```

### crates/svc-index/src/http/routes/admin.rs
<a id="crates-svc-index-src-http-routes-admin-rs"></a>

```rust
//! Admin endpoints (MVP): reindex/pin stubs + name→CID seeding.
//! Adds: X-Admin-Token guard, strict b3 validator, name: normalization.

use axum::{
    extract::State,
    http::{HeaderMap, StatusCode},
    response::IntoResponse,
    Json,
};
use serde::Deserialize;
use std::sync::Arc;

use crate::{error::SvcError, AppState};

pub async fn reindex() -> impl IntoResponse {
    (StatusCode::ACCEPTED, "queued")
}

pub async fn pin() -> impl IntoResponse {
    (StatusCode::ACCEPTED, "queued")
}

#[derive(Deserialize)]
pub struct SeedBody {
    /// Name key. If missing "name:" prefix, it will be added.
    pub name: String,
    /// Content ID (BLAKE3) of the manifest to associate.
    pub cid: String,
}

#[inline]
fn is_b3(s: &str) -> bool {
    let s = s.strip_prefix("b3:").unwrap_or("");
    s.len() == 64 && s.bytes().all(|b| matches!(b, b'0'..=b'9'|b'a'..=b'f'))
}

/// PUT /admin/seed { "name": "hello", "cid": "b3:<64hex>" }
///
/// - requires header X-Admin-Token equal to env INDEX_ADMIN_TOKEN
/// - normalizes name to "name:<value>" if not already prefixed
/// - validates CID as b3:<64hex>
/// - stores mapping so /resolve/name:<value> works
pub async fn seed(
    State(state): State<Arc<AppState>>,
    headers: HeaderMap,
    Json(body): Json<SeedBody>,
) -> Result<impl IntoResponse, SvcError> {
    // Token guard (simple pre-beta protection)
    let required = std::env::var("INDEX_ADMIN_TOKEN").unwrap_or_default();
    let provided = headers
        .get("X-Admin-Token")
        .and_then(|v| v.to_str().ok())
        .unwrap_or_default();

    if required.is_empty() || provided != required {
        return Err(SvcError::Unauthorized);
    }

    if !is_b3(&body.cid) {
        return Err(SvcError::BadRequest("invalid cid".into()));
    }

    let name = if body.name.starts_with("name:") {
        body.name
    } else {
        format!("name:{}", body.name)
    };

    state.store.put_manifest(&name, &body.cid);

    Ok((
        StatusCode::ACCEPTED,
        Json(serde_json::json!({ "ok": true, "name": name, "cid": body.cid })),
    ))
}

```

### crates/svc-index/src/http/routes/health.rs
<a id="crates-svc-index-src-http-routes-health-rs"></a>

```rust
//! /healthz and /readyz

use crate::AppState;
use axum::{extract::State, http::StatusCode, response::IntoResponse};
use std::sync::Arc;

pub async fn healthz() -> impl IntoResponse {
    (StatusCode::OK, "ok")
}

pub async fn readyz(State(state): State<Arc<AppState>>) -> impl IntoResponse {
    if state.health.all_ready() {
        (StatusCode::OK, "ready").into_response()
    } else {
        (
            StatusCode::SERVICE_UNAVAILABLE,
            [("Retry-After", "1")],
            "booting",
        )
            .into_response()
    }
}

```

### crates/svc-index/src/http/routes/metrics.rs
<a id="crates-svc-index-src-http-routes-metrics-rs"></a>

```rust
//! /metrics

use crate::AppState;
use axum::{
    extract::State,
    response::{IntoResponse, Response},
};
use std::sync::Arc;

pub async fn metrics(State(state): State<Arc<AppState>>) -> Response {
    match state.metrics.render() {
        Ok(s) => s.into_response(),
        Err(_) => axum::http::StatusCode::INTERNAL_SERVER_ERROR.into_response(),
    }
}

```

### crates/svc-index/src/http/routes/mod.rs
<a id="crates-svc-index-src-http-routes-mod-rs"></a>

```rust
pub mod admin;
pub mod health;
pub mod metrics;
pub mod providers;
pub mod resolve;
pub mod version;

```

### crates/svc-index/src/http/routes/providers.rs
<a id="crates-svc-index-src-http-routes-providers-rs"></a>

```rust
//! GET /providers/:cid
//! RO:WHY  Return 404 when no providers are found. Preserve body shape.
//! RO:INVARIANTS Only status code changes on miss; JSON fields unchanged.

use crate::{error::SvcError, pipeline, AppState};
use axum::{
    extract::{Path, Query, State},
    http::StatusCode,
    response::IntoResponse,
    Json,
};
use std::collections::HashMap;
use std::sync::Arc;

pub async fn providers(
    Path(cid): Path<String>,
    Query(q): Query<HashMap<String, String>>,
    State(state): State<Arc<AppState>>,
) -> Result<impl IntoResponse, SvcError> {
    let limit = q
        .get("limit")
        .and_then(|s| s.parse::<usize>().ok())
        .unwrap_or(5);

    let out = pipeline::providers::run(state, &cid, limit).await?;

    if out.providers.is_empty() {
        return Ok((StatusCode::NOT_FOUND, Json(out)).into_response());
    }

    Ok(Json(out).into_response())
}

```

### crates/svc-index/src/http/routes/resolve.rs
<a id="crates-svc-index-src-http-routes-resolve-rs"></a>

```rust
//! GET /resolve/:key
//! RO:WHY  Return 404 for well-formed misses (manifest:null AND providers:[]).
//! RO:INVARIANTS Keep the JSON body identical; only the HTTP status changes.

use std::sync::Arc;

use axum::{
    extract::{Path, State},
    http::StatusCode,
    response::IntoResponse,
    Json,
};
use serde_json::Value;

use crate::{error::SvcError, pipeline, AppState};

pub async fn resolve(
    Path(key): Path<String>,
    State(state): State<Arc<AppState>>,
) -> Result<impl IntoResponse, SvcError> {
    let out = pipeline::resolve::run(state, &key, false).await?;

    // miss := manifest == null && providers == []
    let miss = match serde_json::to_value(&out) {
        Ok(Value::Object(map)) => {
            let manifest_is_null = map.get("manifest").is_some_and(|m| m.is_null());
            let providers_empty = map
                .get("providers")
                .and_then(|p| p.as_array())
                .is_none_or(|arr| arr.is_empty());
            manifest_is_null && providers_empty
        }
        _ => false,
    };

    if miss {
        return Ok((StatusCode::NOT_FOUND, Json(out)).into_response());
    }

    Ok(Json(out).into_response())
}

```

### crates/svc-index/src/http/routes/version.rs
<a id="crates-svc-index-src-http-routes-version-rs"></a>

```rust
//! /version

pub async fn version() -> String {
    format!("svc-index/{}", env!("CARGO_PKG_VERSION"))
}

```

### crates/svc-index/src/lib.rs
<a id="crates-svc-index-src-lib-rs"></a>

```rust
#![forbid(unsafe_code)]

// Public modules
pub mod app;
pub mod audit;
pub mod auth;
pub mod bus;
pub mod cache;
pub mod config;
pub mod constants;
pub mod dht;
pub mod error;
pub mod http;
pub mod logging;
pub mod net;
pub mod pipeline;
pub mod router;
pub mod state;
pub mod store;
pub mod telemetry;
pub mod types;
pub mod utils;

// Re-exports
pub use config::Config;
pub use router::build_router;
pub use state::AppState; // <-- from state, not app

```

### crates/svc-index/src/logging.rs
<a id="crates-svc-index-src-logging-rs"></a>

```rust
//! RO:WHAT — Tracing subscriber initialization with EnvFilter.
//! RO:WHY  — Observability baseline.
//! RO:CONFIG — RUST_LOG; defaults to info,hyper=warn.

use tracing_subscriber::{fmt, EnvFilter};

pub fn init() {
    let env = EnvFilter::try_from_default_env()
        .unwrap_or_else(|_| EnvFilter::new("info,hyper=warn,tower_http=warn"));
    fmt().with_env_filter(env).compact().init();
}

```

### crates/svc-index/src/main.rs
<a id="crates-svc-index-src-main-rs"></a>

```rust
//! RO:WHAT — svc-index entry: config → state → router → server (Axum 0.7).
//! RO:WHY  — Avoid stateful Router at serve-time; inject state with `.with_state`.
//! RO:INTERACTS — crate::{config, state, router, logging}.
//! RO:INVARIANTS — single bind; AppState behind Arc; graceful shutdown.

use std::{net::SocketAddr, sync::Arc};

use tokio::net::TcpListener;
use tokio::signal;
use tracing::{error, info, warn};

use svc_index::{build_router, config::Config, logging, AppState};

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // 0) logging/telemetry
    logging::init();

    // 1) Load config
    let cfg = Config::load()?;

    // 2) Build shared state
    let state: Arc<AppState> = Arc::new(AppState::new(cfg.clone()).await?);

    // 3) Optional bootstrap gates (flip readiness, warm caches, etc.)
    let state = AppState::bootstrap(state).await;

    // 4) Build router WITHOUT state and inject state at the end
    //    This turns Router<Arc<AppState>> → Router<()>, which Axum 0.7 can serve.
    let app = build_router().with_state(state.clone());

    // 5) Bind (+ env override) + serve
    //    Respect INDEX_BIND if present; otherwise use cfg.bind; fallback to 127.0.0.1:5304.
    let bind_str = std::env::var("INDEX_BIND").unwrap_or_else(|_| cfg.bind.clone());
    let bind: SocketAddr = bind_str
        .parse()
        .unwrap_or_else(|_| SocketAddr::from(([127, 0, 0, 1], 5304)));

    let listener: TcpListener = TcpListener::bind(bind).await?;
    info!(
        version = env!("CARGO_PKG_VERSION"),
        %bind,
        "svc-index starting"
    );

    // Serve with graceful shutdown
    let server = axum::serve(listener, app).with_graceful_shutdown(shutdown_signal());
    if let Err(e) = server.await {
        error!(error=?e, "server error");
    }

    Ok(())
}

async fn shutdown_signal() {
    let ctrl_c = async {
        signal::ctrl_c()
            .await
            .expect("failed to install Ctrl+C handler");
    };

    #[cfg(unix)]
    let terminate = async {
        use tokio::signal::unix::{signal, SignalKind};
        signal(SignalKind::terminate())
            .expect("failed to install SIGTERM handler")
            .recv()
            .await;
    };

    #[cfg(not(unix))]
    let terminate = std::future::pending::<()>();

    tokio::select! {
        _ = ctrl_c => {},
        _ = terminate => {},
    }

    warn!("shutdown signal received");
}

```

### crates/svc-index/src/net/listener.rs
<a id="crates-svc-index-src-net-listener-rs"></a>

```rust
// http listener bootstrap placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/net/mod.rs
<a id="crates-svc-index-src-net-mod-rs"></a>

```rust
//! RO:WHAT — Net placeholders (UDS/TLS if needed later).
pub mod listener {}
pub mod uds {}
pub mod tls {}

```

### crates/svc-index/src/net/tls.rs
<a id="crates-svc-index-src-net-tls-rs"></a>

```rust
// tls server config placeholder (tokio_rustls::rustls::ServerConfig) — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/net/uds.rs
<a id="crates-svc-index-src-net-uds-rs"></a>

```rust
// uds server setup placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/pipeline/mod.rs
<a id="crates-svc-index-src-pipeline-mod-rs"></a>

```rust
pub mod providers;
pub mod resolve;

```

### crates/svc-index/src/pipeline/providers.rs
<a id="crates-svc-index-src-pipeline-providers-rs"></a>

```rust
//! RO:WHAT — Providers pipeline: cid -> ranked provider list (MVP).
//! RO:WHY  Validate CID, pull from DHT, filter synthetic stubs, rank, clamp, cache.
//! RO:INVARIANTS Do not synthesize providers; never cache stub entries.

use crate::{error::SvcError, types::ProvidersResponse, AppState};
use std::sync::Arc;

#[inline]
fn is_b3(s: &str) -> bool {
    let s = s.strip_prefix("b3:").unwrap_or("");
    s.len() == 64 && s.bytes().all(|b| matches!(b, b'0'..=b'9' | b'a'..=b'f'))
}

pub async fn run(
    state: Arc<AppState>,
    cid: &str,
    limit: usize,
) -> Result<ProvidersResponse, SvcError> {
    // 1) Validate input (malformed -> 400)
    if !is_b3(cid) {
        return Err(SvcError::BadRequest("invalid cid".into()));
    }

    // 2) Cache fast-path (already a cleaned object)
    if let Some(cached) = state.cache.get_providers(cid) {
        return Ok(cached);
    }

    // 3) Query DHT (upper-bound to avoid large allocations)
    let lim = limit.clamp(1, 32);
    let mut providers = state.dht.providers_for(cid, lim).await;

    // 4) Remove any synthetic stub providers
    providers.retain(|p| p.id != "local://stub");

    // 5) Rank descending by score
    providers.sort_by(|a, b| b.score.total_cmp(&a.score));

    // 6) Truncate after filtering; mark truncated truthfully
    let truncated = providers.len() > lim;
    if truncated {
        providers.truncate(lim);
    }

    // 7) Build response (no synthesis)
    let resp = ProvidersResponse {
        cid: cid.to_string(),
        providers,
        truncated,
        etag: None,
    };

    // 8) Cache cleaned response
    state.cache.put_providers(cid.to_string(), resp.clone());

    Ok(resp)
}

```

### crates/svc-index/src/pipeline/resolve.rs
<a id="crates-svc-index-src-pipeline-resolve-rs"></a>

```rust
//! RO:WHAT — Resolve pipeline: key (name|b3) -> manifest + providers (MVP).
//! RO:WHY  — Encapsulate read-optimized logic with cache & store.

use crate::{
    error::SvcError,
    types::{ProviderEntry, ResolveResponse},
    AppState,
};
use std::sync::Arc;

#[inline]
fn is_b3(s: &str) -> bool {
    let s = s.strip_prefix("b3:").unwrap_or("");
    s.len() == 64 && s.bytes().all(|b| matches!(b, b'0'..=b'9'|b'a'..=b'f'))
}

pub async fn run(
    state: Arc<AppState>,
    key: &str,
    fresh: bool,
) -> Result<ResolveResponse, SvcError> {
    if !is_b3(key) && !key.starts_with("name:") {
        return Err(SvcError::BadRequest("invalid key".into()));
    }
    if !fresh {
        if let Some(cached) = state.cache.get_resolve(key) {
            return Ok(cached);
        }
    }

    // Manifest lookup (store is authority for names; b3 maps to itself in MVP)
    let manifest = if is_b3(key) {
        Some(key.to_string())
    } else {
        state.store.get_manifest(key)
    };

    // Provider set (stubbed to DHT client)
    let providers = if let Some(cid) = manifest.as_ref() {
        state.dht.providers_for(cid, 5).await
    } else {
        Vec::<ProviderEntry>::new()
    };

    let resp = ResolveResponse {
        key: key.to_string(),
        manifest,
        providers,
        etag: None,
        cached: false,
    };
    state.cache.put_resolve(key.to_string(), resp.clone());
    Ok(resp)
}

```

### crates/svc-index/src/router.rs
<a id="crates-svc-index-src-router-rs"></a>

```rust
//! RO:WHAT — HTTP router (routes + middleware).
//! RO:WHY  — Keep as Router<Arc<AppState>>; main.rs injects state via .with_state(...).
//! RO:INVARIANTS — Handlers use State<Arc<AppState>>.

use std::sync::Arc;

use axum::{routing::get, Router};

use crate::{
    constants::MAX_BODY_BYTES,
    http::{middleware, routes},
    state::AppState,
};

pub fn build_router() -> Router<Arc<AppState>> {
    let api = Router::new()
        .route("/healthz", get(routes::health::healthz))
        .route("/readyz", get(routes::health::readyz))
        .route("/version", get(routes::version::version))
        .route("/metrics", get(routes::metrics::metrics))
        // Generic key resolver: supports "name:*" or "b3:*"
        .route("/resolve/:key", get(routes::resolve::resolve))
        .route("/providers/:cid", get(routes::providers::providers));

    Router::new()
        .nest("/", api)
        .layer(middleware::trace_layer::layer())
        .layer(middleware::body_limits::layer(MAX_BODY_BYTES))
}

```

### crates/svc-index/src/state/metrics.rs
<a id="crates-svc-index-src-state-metrics-rs"></a>

```rust
//! RO:WHAT — Prometheus metrics registry and golden histograms.
//! RO:WHY  — Observability; consistent metric names.

use prometheus::{Encoder, Histogram, HistogramOpts, IntCounterVec, Opts, Registry, TextEncoder};

pub struct Metrics {
    pub registry: Registry,
    pub http_requests_total: IntCounterVec,
    pub request_latency_seconds: Histogram,
    pub rejected_total: IntCounterVec,
}

impl Metrics {
    pub fn new() -> anyhow::Result<Self> {
        let registry = Registry::new();
        let http_requests_total = IntCounterVec::new(
            Opts::new("http_requests_total", "HTTP request count"),
            &["route", "method", "status"],
        )?;
        let request_latency_seconds = Histogram::with_opts(HistogramOpts::new(
            "request_latency_seconds",
            "Request latency",
        ))?;
        let rejected_total = IntCounterVec::new(
            Opts::new("rejected_total", "Rejected requests by reason"),
            &["reason"],
        )?;
        registry.register(Box::new(http_requests_total.clone()))?;
        registry.register(Box::new(request_latency_seconds.clone()))?;
        registry.register(Box::new(rejected_total.clone()))?;
        Ok(Self {
            registry,
            http_requests_total,
            request_latency_seconds,
            rejected_total,
        })
    }

    pub fn render(&self) -> anyhow::Result<String> {
        let mut buf = Vec::new();
        let enc = TextEncoder::new();
        enc.encode(&self.registry.gather(), &mut buf)?;
        Ok(String::from_utf8(buf).unwrap_or_default())
    }
}

```

### crates/svc-index/src/state/mod.rs
<a id="crates-svc-index-src-state-mod-rs"></a>

```rust
//! RO:WHAT — AppState: health, metrics, cfg, cache, store, dht client.
//! RO:WHY  — Centralized handles; ready/health truth.
//! RO:INVARIANTS — set ready last; clone handles; register metrics once.

pub mod metrics;
pub mod readiness;
pub mod shutdown;

use crate::{cache, config::Config, dht::client::DhtClient, store::Store};

pub struct AppState {
    pub cfg: Config,
    pub health: readiness::HealthState,
    pub metrics: metrics::Metrics,
    pub cache: cache::IndexCache,
    pub store: Store,
    pub dht: DhtClient,
}

impl AppState {
    pub async fn new(cfg: Config) -> anyhow::Result<Self> {
        let metrics = metrics::Metrics::new()?;
        let health = readiness::HealthState::new();
        let cache = cache::IndexCache::new(cfg.cache_ttl_secs);
        let store = Store::new(cfg.enable_sled)?;
        let dht = DhtClient::new();

        Ok(Self {
            cfg,
            health,
            metrics,
            cache,
            store,
            dht,
        })
    }
}

```

### crates/svc-index/src/state/readiness.rs
<a id="crates-svc-index-src-state-readiness-rs"></a>

```rust
//! RO:WHAT — Health/Readiness gate with truthful signals.

use std::sync::atomic::{AtomicBool, Ordering};

#[derive(Clone)]
pub struct HealthState {
    ready: std::sync::Arc<AtomicBool>,
}

impl Default for HealthState {
    fn default() -> Self {
        Self {
            ready: std::sync::Arc::new(AtomicBool::new(false)),
        }
    }
}

impl HealthState {
    pub fn new() -> Self {
        Self::default()
    }
    pub fn mark_ready(&self) {
        self.ready.store(true, Ordering::SeqCst);
    }
    pub fn mark_not_ready(&self) {
        self.ready.store(false, Ordering::SeqCst);
    }
    pub fn all_ready(&self) -> bool {
        self.ready.load(std::sync::atomic::Ordering::SeqCst)
    }
}

```

### crates/svc-index/src/state/shutdown.rs
<a id="crates-svc-index-src-state-shutdown-rs"></a>

```rust
// graceful shutdown placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/store/keys.rs
<a id="crates-svc-index-src-store-keys-rs"></a>

```rust
// keyspace layout placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/store/mod.rs
<a id="crates-svc-index-src-store-mod-rs"></a>

```rust
//! Store abstraction; sled-backed (feature) or in-memory.

mod sled_store; // declare the sibling module within `store/`

#[derive(Clone)]
pub enum Store {
    #[cfg(feature = "sled-store")]
    Sled(self::sled_store::SledStore),
    Memory(self::sled_store::MemStore),
}

impl Store {
    pub fn new(enable_sled: bool) -> anyhow::Result<Self> {
        if cfg!(feature = "sled-store") && enable_sled {
            Ok(Self::Sled(self::sled_store::SledStore::open()?))
        } else {
            Ok(Self::Memory(self::sled_store::MemStore::default()))
        }
    }

    pub fn get_manifest(&self, key: &str) -> Option<String> {
        match self {
            #[cfg(feature = "sled-store")]
            Store::Sled(s) => s.get_manifest(key),
            Store::Memory(m) => m.get_manifest(key),
        }
    }

    pub fn put_manifest(&self, key: &str, cid: &str) {
        match self {
            #[cfg(feature = "sled-store")]
            Store::Sled(s) => s.put_manifest(key, cid),
            Store::Memory(m) => m.put_manifest(key, cid),
        }
    }
}

```

### crates/svc-index/src/store/schema.rs
<a id="crates-svc-index-src-store-schema-rs"></a>

```rust
// schema versions & migrations placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)

```

### crates/svc-index/src/store/sled_store.rs
<a id="crates-svc-index-src-store-sledstore-rs"></a>

```rust
//! Sled-backed (or in-memory) key→manifest store (MVP).
//! Changes: honor RON_INDEX_DB env; flush after writes for durability.

#[cfg(feature = "sled-store")]
#[derive(Clone)]
pub struct SledStore {
    /// Tree that holds key → manifest CID
    man: sled::Tree,
    _db: sled::Db,
}

#[cfg(feature = "sled-store")]
impl SledStore {
    pub fn open() -> anyhow::Result<Self> {
        let path = std::env::var("RON_INDEX_DB").unwrap_or_else(|_| "svc-index.db".into());
        let db = sled::open(path)?;
        let man = db.open_tree("manifest")?;
        Ok(Self { man, _db: db })
    }
    pub fn get_manifest(&self, key: &str) -> Option<String> {
        self.man
            .get(key.as_bytes())
            .ok()
            .flatten()
            .and_then(|ivec| String::from_utf8(ivec.to_vec()).ok())
    }
    pub fn put_manifest(&self, key: &str, cid: &str) {
        let _ = self.man.insert(key.as_bytes(), cid.as_bytes());
        let _ = self.man.flush(); // ensure durability for beta MVP
    }
}

#[derive(Clone, Default)]
pub struct MemStore {
    map: std::sync::Arc<parking_lot::RwLock<std::collections::HashMap<String, String>>>,
}

impl MemStore {
    pub fn get_manifest(&self, key: &str) -> Option<String> {
        self.map.read().get(key).cloned()
    }
    pub fn put_manifest(&self, key: &str, cid: &str) {
        self.map.write().insert(key.to_string(), cid.to_string());
    }
}

```

### crates/svc-index/src/telemetry.rs
<a id="crates-svc-index-src-telemetry-rs"></a>

```rust
//! RO:WHAT — OpenTelemetry glue (optional feature).
//! RO:WHY  — Trace export to OTLP if enabled.
//! RO:CONFIG — OTEL_EXPORTER_OTLP_ENDPOINT, etc.
//! RO:TEST — manual in perf/chaos workflows.

#[cfg(feature = "otel")]
pub mod otel {
    use opentelemetry::sdk::trace as sdktrace;
    use opentelemetry::KeyValue;
    use tracing_subscriber::layer::SubscriberExt;
    use tracing_subscriber::Registry;

    pub fn init(service_name: &str) {
        let tracer = opentelemetry_otlp::new_pipeline()
            .tracing()
            .with_trace_config(
                sdktrace::config().with_resource(opentelemetry::sdk::Resource::new(vec![
                    KeyValue::new("service.name", service_name.to_string()),
                ])),
            )
            .install_batch(opentelemetry::runtime::Tokio)
            .expect("install otlp");

        let telem = tracing_opentelemetry::layer().with_tracer(tracer);
        let subscriber = Registry::default().with(telem);
        tracing::subscriber::set_global_default(subscriber).ok();
    }
}

```

### crates/svc-index/src/types.rs
<a id="crates-svc-index-src-types-rs"></a>

```rust
//! RO:WHAT — DTOs for HTTP responses/requests.
//! RO:WHY  — Interop hygiene; `#[serde(deny_unknown_fields)]`.
//! RO:INVARIANTS — b3: hex shape; stable error taxonomy.
//! RO:SECURITY — no secrets in payloads.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct ResolveResponse {
    pub key: String,              // name:* or b3:<hex>
    pub manifest: Option<String>, // usually a CID of a manifest
    pub providers: Vec<ProviderEntry>,
    pub etag: Option<String>, // "b3:<hex>" when applicable
    pub cached: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct ProviderEntry {
    pub id: String, // provider id (e.g., node addr)
    pub region: Option<String>,
    pub score: f32, // ranking hint
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct ProvidersResponse {
    pub cid: String, // b3:<hex>
    pub providers: Vec<ProviderEntry>,
    pub truncated: bool,
    pub etag: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct ErrorResponse {
    pub code: String, // "not_found" | "over_capacity" | ...
    pub message: String,
}

```

### crates/svc-index/src/utils/mod.rs
<a id="crates-svc-index-src-utils-mod-rs"></a>

```rust
//! RO:WHAT — utils module root.
//! RO:WHY  — Houses common helpers (timeouts, etc).

pub mod timeouts;

```

### crates/svc-index/src/utils/timeouts.rs
<a id="crates-svc-index-src-utils-timeouts-rs"></a>

```rust
//! RO:WHAT — Common timeout helpers.
//! RO:WHY  — Keep await-time discipline explicit.

use tokio::time::{timeout, Duration};

pub async fn with_timeout<F, T>(ms: u64, fut: F) -> Result<T, ()>
where
    F: std::future::Future<Output = T>,
{
    timeout(Duration::from_millis(ms), fut)
        .await
        .map_err(|_| ())
}

```

### crates/svc-index/tests/chaos.rs
<a id="crates-svc-index-tests-chaos-rs"></a>

```rust
// chaos tests placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)
#[test]
fn chaos_placeholder() {
    assert!(true);
}

```

### crates/svc-index/tests/golden/resolve/not_found.json
<a id="crates-svc-index-tests-golden-resolve-notfound-json"></a>

```json
{ "case": "not_found", "expect": 404 }\n
```

### crates/svc-index/tests/golden/resolve/ok_basic.json
<a id="crates-svc-index-tests-golden-resolve-okbasic-json"></a>

```json
{ "case": "ok_basic", "expect": "Resolved" }\n
```

### crates/svc-index/tests/golden/resolve/over_capacity.json
<a id="crates-svc-index-tests-golden-resolve-overcapacity-json"></a>

```json
{ "case": "over_capacity", "expect": 429 }\n
```

### crates/svc-index/tests/golden/resolve/providers_ranked.json
<a id="crates-svc-index-tests-golden-resolve-providersranked-json"></a>

```json
{ "case": "providers_ranked", "expect": ["p1","p2"] }\n
```

### crates/svc-index/tests/http_contract.rs
<a id="crates-svc-index-tests-httpcontract-rs"></a>

```rust
// http contract tests placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)
#[test]
fn http_contract_placeholder() {
    assert!(true);
}

```

### crates/svc-index/tests/integration.rs
<a id="crates-svc-index-tests-integration-rs"></a>

```rust
// integration tests placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)
#[test]
fn integration_placeholder() {
    assert!(true);
}

```

### crates/svc-index/tests/loom_index.rs
<a id="crates-svc-index-tests-loomindex-rs"></a>

```rust
// loom tests placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)
#[test]
fn loom_placeholder() {
    assert!(true);
}

```

### crates/svc-index/tests/prop_index.rs
<a id="crates-svc-index-tests-propindex-rs"></a>

```rust
// property tests placeholder — (auto-generated by scaffold_svc_index2.sh; replace with real content later)
#[test]
fn prop_placeholder() {
    assert!(true);
}

```



---



# ron-policy

_Source: crates/ron-policy/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-10-30T21:44:52Z -->
# Code Bundle — `ron-policy`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-policy/.cargo/config.toml](#crates-ron-policy--cargo-config-toml)
- [crates/ron-policy/.github/workflows/policy.yml](#crates-ron-policy--github-workflows-policy-yml)
- [crates/ron-policy/Cargo.toml](#crates-ron-policy-Cargo-toml)
- [crates/ron-policy/benches/eval_throughput.rs](#crates-ron-policy-benches-evalthroughput-rs)
- [crates/ron-policy/deny.toml](#crates-ron-policy-deny-toml)
- [crates/ron-policy/examples/minimal_allow_deny.rs](#crates-ron-policy-examples-minimalallowdeny-rs)
- [crates/ron-policy/examples/ron_policy_cli.rs](#crates-ron-policy-examples-ronpolicycli-rs)
- [crates/ron-policy/fuzz/Cargo.toml](#crates-ron-policy-fuzz-Cargo-toml)
- [crates/ron-policy/fuzz/fuzz_targets/fuzz_bundle_parse.rs](#crates-ron-policy-fuzz-fuzztargets-fuzzbundleparse-rs)
- [crates/ron-policy/fuzz/fuzz_targets/fuzz_eval.rs](#crates-ron-policy-fuzz-fuzztargets-fuzzeval-rs)
- [crates/ron-policy/rust-toolchain.toml](#crates-ron-policy-rust-toolchain-toml)
- [crates/ron-policy/schema/policybundle.schema.json](#crates-ron-policy-schema-policybundle-schema-json)
- [crates/ron-policy/scripts/ci_invariants.sh](#crates-ron-policy-scripts-ciinvariants-sh)
- [crates/ron-policy/src/ctx/clock.rs](#crates-ron-policy-src-ctx-clock-rs)
- [crates/ron-policy/src/ctx/mod.rs](#crates-ron-policy-src-ctx-mod-rs)
- [crates/ron-policy/src/ctx/normalize.rs](#crates-ron-policy-src-ctx-normalize-rs)
- [crates/ron-policy/src/engine/eval.rs](#crates-ron-policy-src-engine-eval-rs)
- [crates/ron-policy/src/engine/index.rs](#crates-ron-policy-src-engine-index-rs)
- [crates/ron-policy/src/engine/metrics.rs](#crates-ron-policy-src-engine-metrics-rs)
- [crates/ron-policy/src/engine/mod.rs](#crates-ron-policy-src-engine-mod-rs)
- [crates/ron-policy/src/engine/obligations.rs](#crates-ron-policy-src-engine-obligations-rs)
- [crates/ron-policy/src/engine/reason.rs](#crates-ron-policy-src-engine-reason-rs)
- [crates/ron-policy/src/errors.rs](#crates-ron-policy-src-errors-rs)
- [crates/ron-policy/src/explain/mod.rs](#crates-ron-policy-src-explain-mod-rs)
- [crates/ron-policy/src/explain/trace.rs](#crates-ron-policy-src-explain-trace-rs)
- [crates/ron-policy/src/features.rs](#crates-ron-policy-src-features-rs)
- [crates/ron-policy/src/lib.rs](#crates-ron-policy-src-lib-rs)
- [crates/ron-policy/src/model.rs](#crates-ron-policy-src-model-rs)
- [crates/ron-policy/src/parse/json.rs](#crates-ron-policy-src-parse-json-rs)
- [crates/ron-policy/src/parse/mod.rs](#crates-ron-policy-src-parse-mod-rs)
- [crates/ron-policy/src/parse/toml.rs](#crates-ron-policy-src-parse-toml-rs)
- [crates/ron-policy/src/parse/validate.rs](#crates-ron-policy-src-parse-validate-rs)
- [crates/ron-policy/tests/golden_reasons.rs](#crates-ron-policy-tests-goldenreasons-rs)
- [crates/ron-policy/tests/helpers/bundle_load.rs](#crates-ron-policy-tests-helpers-bundleload-rs)
- [crates/ron-policy/tests/unit_churn_protection.rs](#crates-ron-policy-tests-unitchurnprotection-rs)
- [crates/ron-policy/tests/unit_eu_only.rs](#crates-ron-policy-tests-uniteuonly-rs)
- [crates/ron-policy/tests/unit_eval_determinism.rs](#crates-ron-policy-tests-unitevaldeterminism-rs)
- [crates/ron-policy/tests/unit_first_match_wins.rs](#crates-ron-policy-tests-unitfirstmatchwins-rs)
- [crates/ron-policy/tests/unit_large_body_default_deny.rs](#crates-ron-policy-tests-unitlargebodydefaultdeny-rs)
- [crates/ron-policy/tests/unit_method_matrix.rs](#crates-ron-policy-tests-unitmethodmatrix-rs)
- [crates/ron-policy/tests/unit_model_serde_strict.rs](#crates-ron-policy-tests-unitmodelserdestrict-rs)
- [crates/ron-policy/tests/unit_tags_all.rs](#crates-ron-policy-tests-unittagsall-rs)
- [crates/ron-policy/tests/unit_tighten_only.rs](#crates-ron-policy-tests-unittightenonly-rs)
- [crates/ron-policy/tests/vectors/body_too_large.json](#crates-ron-policy-tests-vectors-bodytoolarge-json)
- [crates/ron-policy/tests/vectors/decompress_guard.json](#crates-ron-policy-tests-vectors-decompressguard-json)
- [crates/ron-policy/tests/vectors/deny_region.json](#crates-ron-policy-tests-vectors-denyregion-json)
- [crates/ron-policy/tests/vectors/eu_only.json](#crates-ron-policy-tests-vectors-euonly-json)
- [crates/ron-policy/tests/vectors/large_body_default_deny.json](#crates-ron-policy-tests-vectors-largebodydefaultdeny-json)
- [crates/ron-policy/tests/vectors/method_matrix.json](#crates-ron-policy-tests-vectors-methodmatrix-json)
- [crates/ron-policy/tests/vectors/tags_all.json](#crates-ron-policy-tests-vectors-tagsall-json)

### crates/ron-policy/.cargo/config.toml
<a id="crates-ron-policy--cargo-config-toml"></a>

```toml
[build]
rustflags = ["-Dwarnings"]

[target.'cfg(all())']
rustdocflags = ["-Dwarnings"]

```

### crates/ron-policy/.github/workflows/policy.yml
<a id="crates-ron-policy--github-workflows-policy-yml"></a>

```yaml
name: ron-policy2
on:
  pull_request:
  push:
    branches: [ main ]
jobs:
  placeholder:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "CI placeholder for ron-policy2 (lint/tests/deny/benches/fuzz to be added)."

```

### crates/ron-policy/Cargo.toml
<a id="crates-ron-policy-Cargo-toml"></a>

```toml
[package]
name = "ron-policy"
version = "0.1.0-beta.1"
edition = "2021"
license = "MIT OR Apache-2.0"
description = "Declarative policy engine for RustyOnions (deny-by-default, quotas, geo, residency, reasons/obligations)"
repository = "https://example.invalid/RustyOnions"
authors = ["RustyOnions Contributors"]
rust-version = "1.78"

[lib]
name = "ron_policy"
path = "src/lib.rs"

[features]
# Tight JSON/TOML parsing with #[serde(deny_unknown_fields)] everywhere.
strict = []
# Avoids time dependencies in core; enables std::time-based clock by default.
default = ["strict"]

[dependencies]
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
toml = "0.8"
thiserror = "1.0"
bytes = "1.7"
prometheus = "0.14"
regex = "1.10"
# NOTE: we migrated metrics statics to std::sync::LazyLock, so once_cell is no longer needed.

[dev-dependencies]
criterion = "0.5"
insta = { version = "1.43", features = ["json"] }
rand = "0.9"
pico-args = "0.5"        # for examples/ron_policy_cli.rs

[package.metadata.cargo-udeps.ignore]
normal = ["prometheus"]

[[bench]]
name = "eval_throughput"
harness = false

# Explicitly list the CLI example so it builds with dev-deps.
[[example]]
name = "ron_policy_cli"
path = "examples/ron_policy_cli.rs"

# Minimal example runs without extra deps; auto-discovery also works,
# but we keep it explicit for clarity.
[[example]]
name = "minimal_allow_deny"
path = "examples/minimal_allow_deny.rs"

```

### crates/ron-policy/benches/eval_throughput.rs
<a id="crates-ron-policy-benches-evalthroughput-rs"></a>

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ron_policy::{ctx::clock::SystemClock, load_json, Context, Evaluator};

fn bench_eval(c: &mut Criterion) {
    let bundle = load_json(include_bytes!("../tests/vectors/deny_region.json")).unwrap();
    let ev = Evaluator::new(&bundle).unwrap();
    let clock = SystemClock::default();

    c.bench_function("eval:get/us", |b| {
        b.iter(|| {
            let ctx = Context::builder()
                .tenant("t")
                .method("GET")
                .region("US")
                .build(&clock);
            let d = ev.evaluate(&ctx).unwrap();
            black_box(d);
        })
    });
}

criterion_group!(benches, bench_eval);
criterion_main!(benches);

```

### crates/ron-policy/deny.toml
<a id="crates-ron-policy-deny-toml"></a>

```toml
# RO:WHAT — cargo-deny policy aligned to workspace gates
[advisories]
ignore = []

[bans]
multiple-versions = "deny"

[sources]
unknown-registry = "deny"
unknown-git = "deny"

[licenses]
unlicensed = "deny"
allow = [
  "MIT",
  "Apache-2.0",
  "Unicode-3.0",
  "Unicode-DFS-2016",
  "CC0-1.0",
  "CDLA-Permissive-2.0",
  "OpenSSL"
]

```

### crates/ron-policy/examples/minimal_allow_deny.rs
<a id="crates-ron-policy-examples-minimalallowdeny-rs"></a>

```rust
//! RO:WHAT — Minimal usage example: parse bundle → evaluate context → print result.
use ron_policy::{ctx::clock::SystemClock, load_json, Context, Evaluator};

fn main() {
    let bundle = load_json(
        br#"{
        "version":1,
        "rules":[
            {"id":"deny-fl","when":{"region":"US-FL"},"action":"deny","reason":"geo block"},
            {"id":"allow","when":{},"action":"allow","reason":"open"}
        ]
    }"#,
    )
    .unwrap();

    let ev = Evaluator::new(&bundle).unwrap();
    let ctx = Context::builder()
        .tenant("acme")
        .method("GET")
        .region("US")
        .build(&SystemClock);
    let d = ev.evaluate(&ctx).unwrap();
    println!("effect={:?} reason={:?}", d.effect, d.reason);
}

```

### crates/ron-policy/examples/ron_policy_cli.rs
<a id="crates-ron-policy-examples-ronpolicycli-rs"></a>

```rust
use ron_policy::ctx::clock::SystemClock;
use ron_policy::{load_json, load_toml, Context, Evaluator};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let mut args = pico_args::Arguments::from_env();

    let bundle: String = args.value_from_str("--bundle")?;
    let tenant: String = args
        .opt_value_from_str("--tenant")?
        .unwrap_or_else(|| "*".into());
    let method: String = args
        .opt_value_from_str("--method")?
        .unwrap_or_else(|| "*".into());
    let region: String = args
        .opt_value_from_str("--region")?
        .unwrap_or_else(|| "*".into());
    let body: u64 = args.opt_value_from_str("--body")?.unwrap_or(0);

    // Collect repeated flags: --tag paid --tag verified ...
    // Note: values_from_str<A, T>(...) — we specify T and let A be inferred via `_`.
    let tags: Vec<String> = args
        .values_from_str::<_, String>("--tag")
        .unwrap_or_default();

    let bytes = std::fs::read(&bundle)?;
    let bundle_val = if bundle.ends_with(".json") {
        load_json(&bytes)?
    } else if bundle.ends_with(".toml") {
        load_toml(&bytes)?
    } else {
        return Err("bundle must be .json or .toml".into());
    };

    let ev = Evaluator::new(&bundle_val)?;
    let mut b = Context::builder()
        .tenant(tenant)
        .method(method)
        .region(region)
        .body_bytes(body);
    for t in tags {
        b = b.tag(t);
    }
    let ctx = b.build(&SystemClock);

    let d = ev.evaluate(&ctx)?;
    println!("effect={:?} reason={:?}", d.effect, d.reason);
    println!("trace={:?}", d.trace.steps);
    Ok(())
}

```

### crates/ron-policy/fuzz/Cargo.toml
<a id="crates-ron-policy-fuzz-Cargo-toml"></a>

```toml
[package]
name = "ron-policy-fuzz"
version = "0.1.0"
publish = false
edition = "2021"

[package.metadata]
cargo-fuzz = true

[dependencies]
libfuzzer-sys = "0.4"
serde_json = "1.0"
toml = "0.8"
ron-policy = { path = ".." }

[[bin]]
name = "fuzz_bundle_parse"
path = "fuzz_targets/fuzz_bundle_parse.rs"

[[bin]]
name = "fuzz_eval"
path = "fuzz_targets/fuzz_eval.rs"

```

### crates/ron-policy/fuzz/fuzz_targets/fuzz_bundle_parse.rs
<a id="crates-ron-policy-fuzz-fuzztargets-fuzzbundleparse-rs"></a>

```rust
#![no_main]
use libfuzzer_sys::fuzz_target;
use ron_policy::{load_json, load_toml};

fuzz_target!(|data: &[u8]| {
    let _ = load_json(data);
    let _ = load_toml(data);
});

```

### crates/ron-policy/fuzz/fuzz_targets/fuzz_eval.rs
<a id="crates-ron-policy-fuzz-fuzztargets-fuzzeval-rs"></a>

```rust
#![no_main]
use libfuzzer_sys::fuzz_target;
use ron_policy::{load_json, Evaluator, Context, ctx::clock::SystemClock};

fuzz_target!(|data: &[u8]| {
    if let Ok(b) = load_json(data) {
        if let Ok(ev) = Evaluator::new(&b) {
            let c = Context::builder().tenant("t").method("GET").region("US").build(&SystemClock);
            let _ = ev.evaluate(&c);
        }
    }
});

```

### crates/ron-policy/rust-toolchain.toml
<a id="crates-ron-policy-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["rustfmt", "clippy"]

```

### crates/ron-policy/schema/policybundle.schema.json
<a id="crates-ron-policy-schema-policybundle-schema-json"></a>

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "PolicyBundle",
  "type": "object",
  "required": ["version", "rules"],
  "additionalProperties": false,
  "properties": {
    "version": { "type": "integer", "minimum": 1 },
    "meta": { "type": "object", "additionalProperties": { "type": "string" } },
    "defaults": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "default_action": { "enum": ["allow", "deny"] },
        "max_body_bytes": { "type": "integer", "minimum": 0, "maximum": 1048576 }
      }
    },
    "rules": {
      "type": "array",
      "items": { "$ref": "#/definitions/rule" }
    }
  },
  "definitions": {
    "rule": {
      "type": "object",
      "required": ["id", "when", "action"],
      "additionalProperties": false,
      "properties": {
        "id": { "type": "string", "minLength": 1 },
        "when": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "tenant": { "type": "string" },
            "method": { "type": "string" },
            "region": { "type": "string" },
            "max_body_bytes": { "type": "integer", "minimum": 0, "maximum": 1048576 },
            "require_tags_all": { "type": "array", "items": { "type": "string" } }
          }
        },
        "action": { "enum": ["allow", "deny"] },
        "obligations": {
          "type": "array",
          "items": { "$ref": "#/definitions/obligation" }
        },
        "reason": { "type": "string" }
      }
    },
    "obligation": {
      "type": "object",
      "required": ["kind"],
      "additionalProperties": false,
      "properties": {
        "kind": { "type": "string" },
        "params": { "type": "object", "additionalProperties": { "type": "string" } }
      }
    }
  }
}

```

### crates/ron-policy/scripts/ci_invariants.sh
<a id="crates-ron-policy-scripts-ciinvariants-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT — Fast CI invariants for ron-policy (fmt, clippy, tests)
# RO:INVARIANTS — no magic sleeps; fail fast on errors
set -euo pipefail
cargo fmt -p ron-policy -- --check
cargo clippy -p ron-policy --no-deps -- -D warnings
cargo test -p ron-policy

```

### crates/ron-policy/src/ctx/clock.rs
<a id="crates-ron-policy-src-ctx-clock-rs"></a>

```rust
//! RO:WHAT — Clock trait for deterministic tests and prod time access.
//!
//! RO:WHY  — Keep engine free of direct time deps; easy to mock.

pub trait Clock {
    fn now_ms(&self) -> u64;
}

#[derive(Default)]
pub struct SystemClock;

impl Clock for SystemClock {
    fn now_ms(&self) -> u64 {
        use std::time::{SystemTime, UNIX_EPOCH};
        let ms = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_millis();
        u64::try_from(ms).unwrap_or(u64::MAX)
    }
}

```

### crates/ron-policy/src/ctx/mod.rs
<a id="crates-ron-policy-src-ctx-mod-rs"></a>

```rust
//! RO:WHAT — Evaluation context types (normalized request facts) and clock trait.
//!
//! RO:WHY  — Deterministic, testable evaluation independent of actual services.
//!
//! RO:INTERACTS — `engine::eval` (consumes `Context`), `ctx::{normalize,clock}`

pub mod clock;
pub mod normalize;

use std::collections::BTreeSet;

/// Minimal context the engine needs to decide.
#[derive(Debug, Clone)]
pub struct Context {
    pub tenant: String,
    pub method: String,
    pub region: String,
    pub body_bytes: u64,
    pub tags: BTreeSet<String>,
    pub now_ms: u64,
}

impl Context {
    #[must_use]
    pub fn builder() -> normalize::ContextBuilder {
        normalize::ContextBuilder::default()
    }
}

```

### crates/ron-policy/src/ctx/normalize.rs
<a id="crates-ron-policy-src-ctx-normalize-rs"></a>

```rust
//! RO:WHAT — Builders and normalizers to construct a `Context` safely.
//!
//! RO:WHY  — Avoid ad-hoc normalization in callers; ensure consistent casing and defaults.

use super::clock::Clock;
use super::Context;
use std::collections::BTreeSet;

#[derive(Default)]
pub struct ContextBuilder {
    tenant: Option<String>,
    method: Option<String>,
    region: Option<String>,
    body_bytes: Option<u64>,
    tags: BTreeSet<String>,
}

impl ContextBuilder {
    #[must_use]
    pub fn tenant(mut self, t: impl Into<String>) -> Self {
        self.tenant = Some(t.into());
        self
    }

    #[must_use]
    pub fn method(mut self, m: impl Into<String>) -> Self {
        self.method = Some(m.into());
        self
    }

    #[must_use]
    pub fn region(mut self, r: impl Into<String>) -> Self {
        self.region = Some(r.into());
        self
    }

    #[must_use]
    pub const fn body_bytes(mut self, n: u64) -> Self {
        self.body_bytes = Some(n);
        self
    }

    #[must_use]
    pub fn tag(mut self, t: impl Into<String>) -> Self {
        self.tags.insert(t.into().to_ascii_lowercase());
        self
    }

    pub fn build<C: Clock>(self, clock: &C) -> Context {
        Context {
            tenant: self.tenant.unwrap_or_else(|| "*".to_string()),
            method: self
                .method
                .map_or_else(|| "*".to_string(), |s| s.to_ascii_uppercase()),
            region: self.region.unwrap_or_else(|| "*".to_string()),
            body_bytes: self.body_bytes.unwrap_or(0),
            tags: self.tags,
            now_ms: clock.now_ms(),
        }
    }
}

```

### crates/ron-policy/src/engine/eval.rs
<a id="crates-ron-policy-src-engine-eval-rs"></a>

```rust
//! RO:WHAT — Core evaluation logic producing a Decision + Trace.
//!
//! RO:WHY  — Deterministic, explainable allow/deny with reasons and obligations.

use super::{index::RuleIndex, metrics, obligations::ObligationSet};
use crate::{
    errors::Error,
    explain::trace::{DecisionTrace, TraceStep},
    model::{Action, PolicyBundle, Rule},
    Context,
};
use std::time::Instant;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum DecisionEffect {
    Allow,
    Deny,
}

#[derive(Debug, Clone)]
pub struct Decision {
    pub effect: DecisionEffect,
    pub obligations: ObligationSet,
    pub reason: Option<String>,
    pub trace: DecisionTrace,
}

pub struct Evaluator<'a> {
    bundle: &'a PolicyBundle,
    index: RuleIndex<'a>,
}

impl<'a> Evaluator<'a> {
    /// Construct an evaluator over a validated bundle.
    ///
    /// # Errors
    ///
    /// Currently infallible; reserved for future index build errors.
    pub fn new(bundle: &'a PolicyBundle) -> Result<Self, Error> {
        Ok(Self {
            index: RuleIndex::build(bundle),
            bundle,
        })
    }

    /// Evaluate a decision for `ctx`.
    ///
    /// # Errors
    ///
    /// Returns `Error::Eval` if evaluation cannot complete (reserved; not used today).
    pub fn evaluate(&self, ctx: &Context) -> Result<Decision, Error> {
        metrics::REQUESTS_TOTAL.inc();
        let t0 = Instant::now();

        let mut trace = DecisionTrace::default();
        let mut obligations = ObligationSet::default();

        // Hard guard: body cap from defaults first.
        if let Some(max) = self.bundle.defaults.max_body_bytes {
            if ctx.body_bytes > max {
                metrics::REJECTED_TOTAL
                    .with_label_values(&["body_too_large"])
                    .inc();
                trace
                    .steps
                    .push(TraceStep::note("defaults.max_body_bytes", "exceeded"));
                metrics::EVAL_LATENCY_SECONDS.observe(t0.elapsed().as_secs_f64());
                return Ok(Decision {
                    effect: DecisionEffect::Deny,
                    obligations,
                    reason: Some("body too large (defaults)".into()),
                    trace,
                });
            }
        }

        // Candidate rules restricted by method (and then checked fully).
        // `ctx.method` is already uppercased by the builder; reuse it to avoid alloc.
        let method: &str = &ctx.method;
        for r in self.index.candidates(method) {
            if rule_matches(r, ctx) {
                if matches!(r.action, Action::Deny) {
                    metrics::REJECTED_TOTAL
                        .with_label_values(&["rule_deny"])
                        .inc();
                }
                obligations.extend(&r.obligations);
                trace.steps.push(TraceStep::rule_hit(
                    &r.id,
                    r.reason.as_deref().unwrap_or(""),
                ));
                metrics::EVAL_LATENCY_SECONDS.observe(t0.elapsed().as_secs_f64());
                return Ok(Decision {
                    effect: match r.action {
                        Action::Allow => DecisionEffect::Allow,
                        Action::Deny => DecisionEffect::Deny,
                    },
                    obligations,
                    reason: r.reason.clone(),
                    trace,
                });
            }
            // Miss path (the `if` branch returns on hit).
            trace.steps.push(TraceStep::rule_miss(&r.id));
        }

        // No matches → default action (deny-by-default if unspecified)
        let effect = self.bundle.defaults.default_action.unwrap_or(Action::Deny);

        if matches!(effect, Action::Deny) {
            metrics::REJECTED_TOTAL
                .with_label_values(&["default_deny"])
                .inc();
        }

        metrics::EVAL_LATENCY_SECONDS.observe(t0.elapsed().as_secs_f64());
        Ok(Decision {
            effect: match effect {
                Action::Allow => DecisionEffect::Allow,
                Action::Deny => DecisionEffect::Deny,
            },
            obligations,
            reason: Some("default".into()),
            trace,
        })
    }
}

fn rule_matches(r: &Rule, ctx: &Context) -> bool {
    if let Some(t) = &r.when.tenant {
        if t != "*" && t != &ctx.tenant {
            return false;
        }
    }
    if let Some(m) = &r.when.method {
        if m != "*" && m.to_ascii_uppercase() != ctx.method {
            return false;
        }
    }
    if let Some(g) = &r.when.region {
        if g != "*" && g != &ctx.region {
            return false;
        }
    }
    if let Some(n) = r.when.max_body_bytes {
        if ctx.body_bytes > n {
            return false;
        }
    }
    if !r.when.require_tags_all.is_empty() {
        for tag in &r.when.require_tags_all {
            if !ctx.tags.contains(&tag.to_ascii_lowercase()) {
                return false;
            }
        }
    }
    true
}

```

### crates/ron-policy/src/engine/index.rs
<a id="crates-ron-policy-src-engine-index-rs"></a>

```rust
//! RO:WHAT — In-memory index to accelerate rule lookup by HTTP method.
//!
//! RO:WHY  — Avoid scanning all rules; common case is method-restricted rules.
//!
//! RO:INVARIANTS — Keys are uppercased method names or "*".

use crate::model::{PolicyBundle, Rule};
use std::collections::BTreeMap;

pub struct RuleIndex<'a> {
    by_method: BTreeMap<String, Vec<&'a Rule>>,
}

impl<'a> RuleIndex<'a> {
    /// Build an index from a validated `PolicyBundle`.
    ///
    /// # Errors
    ///
    /// Currently infallible; reserved for future index-build errors.
    #[must_use]
    pub fn build(bundle: &'a PolicyBundle) -> Self {
        let mut by_method: BTreeMap<String, Vec<&'a Rule>> = BTreeMap::new();
        for r in &bundle.rules {
            // clippy(map_unwrap_or): use map_or_else
            let key = r
                .when
                .method
                .as_ref()
                .map_or_else(|| "*".to_string(), |s| s.to_ascii_uppercase());
            by_method.entry(key).or_default().push(r);
        }
        Self { by_method }
    }

    /// Return candidates for a given (already UPPERCASED) method,
    /// falling back to "*" rules as well.
    pub fn candidates(&'a self, method: &str) -> impl Iterator<Item = &'a Rule> + 'a {
        // Avoid map/unwrap and redundant closures; iterate directly.
        self.by_method
            .get(method)
            .into_iter()
            .flat_map(|v| v.iter().copied())
            .chain(
                self.by_method
                    .get("*")
                    .into_iter()
                    .flat_map(|v| v.iter().copied()),
            )
    }
}

```

### crates/ron-policy/src/engine/metrics.rs
<a id="crates-ron-policy-src-engine-metrics-rs"></a>

```rust
//! RO:WHAT — Prometheus metrics for policy evaluations.
//!
//! RO:INVARIANTS — register once; use default registry.

use prometheus::{
    register_histogram, register_int_counter, register_int_counter_vec, Histogram, HistogramOpts,
    IntCounter, IntCounterVec, Opts,
};

pub static REQUESTS_TOTAL: std::sync::LazyLock<IntCounter> = std::sync::LazyLock::new(|| {
    register_int_counter!(Opts::new("policy_requests_total", "Policy evaluations")).unwrap()
});

pub static REJECTED_TOTAL: std::sync::LazyLock<IntCounterVec> = std::sync::LazyLock::new(|| {
    register_int_counter_vec!(
        Opts::new("policy_rejected_total", "Total rejects by reason"),
        &["reason"]
    )
    .unwrap()
});

pub static EVAL_LATENCY_SECONDS: std::sync::LazyLock<Histogram> = std::sync::LazyLock::new(|| {
    register_histogram!(HistogramOpts::new(
        "policy_eval_latency_seconds",
        "Evaluation latency"
    ))
    .unwrap()
});

```

### crates/ron-policy/src/engine/mod.rs
<a id="crates-ron-policy-src-engine-mod-rs"></a>

```rust
//! RO:WHAT — Policy evaluation engine modules.
pub mod eval;
pub mod index;
pub mod metrics;
pub mod obligations;
pub mod reason;

```

### crates/ron-policy/src/engine/obligations.rs
<a id="crates-ron-policy-src-engine-obligations-rs"></a>

```rust
//! RO:WHAT — Obligation handling (logical; no side effects here).
//! RO:WHY  — Services will interpret obligations; engine just aggregates.

use crate::model::Obligation;

#[derive(Debug, Clone, Default)]
pub struct ObligationSet {
    pub items: Vec<Obligation>,
}

impl ObligationSet {
    pub fn extend(&mut self, more: &[Obligation]) {
        self.items.extend_from_slice(more);
    }
}

```

### crates/ron-policy/src/engine/reason.rs
<a id="crates-ron-policy-src-engine-reason-rs"></a>

```rust
//! RO:WHAT — Machine+human readable reasons for decisions.

#[derive(Debug, Clone)]
pub struct Reason {
    pub code: &'static str,
    pub message: String,
}

impl Reason {
    pub fn new(code: &'static str, message: impl Into<String>) -> Self {
        Self {
            code,
            message: message.into(),
        }
    }
}

```

### crates/ron-policy/src/errors.rs
<a id="crates-ron-policy-src-errors-rs"></a>

```rust
//! RO:WHAT — Error taxonomy for ron-policy.
//!
//! RO:WHY  — Stable, deterministic error envelope for services/tests.
//!
//! RO:INTERACTS — `parse::{json,toml,validate}`, `engine::eval`
//!
//! RO:INVARIANTS — human-safe messages; no leaking secrets
//!
//! RO:TEST — unit tests exercise all variants

use thiserror::Error;

#[derive(Debug, Error)]
pub enum Error {
    #[error("parse error: {0}")]
    Parse(String),
    #[error("validation error: {0}")]
    Validation(String),
    #[error("evaluation error: {0}")]
    Eval(String),
}

```

### crates/ron-policy/src/explain/mod.rs
<a id="crates-ron-policy-src-explain-mod-rs"></a>

```rust
//! RO:WHAT — Explainability surface (trace).
pub mod trace;

```

### crates/ron-policy/src/explain/trace.rs
<a id="crates-ron-policy-src-explain-trace-rs"></a>

```rust
//! RO:WHAT — Structured trace steps for explain/debug/audit.

#[derive(Debug, Clone, Default)]
pub struct DecisionTrace {
    pub steps: Vec<TraceStep>,
}

#[derive(Debug, Clone)]
pub enum TraceStep {
    Note { key: String, msg: String },
    RuleHit { id: String, reason: String },
    RuleMiss { id: String },
}

impl DecisionTrace {
    pub fn note(key: impl Into<String>, msg: impl Into<String>) -> Self {
        let mut d = Self::default();
        d.steps.push(TraceStep::Note {
            key: key.into(),
            msg: msg.into(),
        });
        d
    }
}

impl TraceStep {
    pub fn note(key: impl Into<String>, msg: impl Into<String>) -> Self {
        Self::Note {
            key: key.into(),
            msg: msg.into(),
        }
    }
    pub fn rule_hit(id: impl Into<String>, reason: impl Into<String>) -> Self {
        Self::RuleHit {
            id: id.into(),
            reason: reason.into(),
        }
    }
    pub fn rule_miss(id: impl Into<String>) -> Self {
        Self::RuleMiss { id: id.into() }
    }
}

```

### crates/ron-policy/src/features.rs
<a id="crates-ron-policy-src-features-rs"></a>

```rust
//! RO:WHAT — Feature switches (placeholder for future toggles).
//!
//! RO:WHY  — Keep public surface stable while allowing internal perf/security opts.
//!
//! RO:INTERACTS — N/A today
//!
//! RO:INVARIANTS — default = strict parsing on

#[allow(dead_code)]
pub const STRICT: bool = cfg!(feature = "strict");

```

### crates/ron-policy/src/lib.rs
<a id="crates-ron-policy-src-lib-rs"></a>

```rust
//! RO:WHAT — ron-policy public API: load/validate bundles and evaluate decisions.
//!
//! RO:WHY  — Pillar 2 (Policy & Governance); Concerns: SEC/GOV. Deny-by-default guardrail.
//!
//! RO:INTERACTS — model, `parse::{json,toml,validate}`, `engine::{eval,index,obligations,metrics}`, `explain::trace`
//!
//! RO:INVARIANTS — DTOs are strict; no locks across `.await`; OAP caps: frame=1 MiB, chunk≈64 KiB (context only)
//!
//! RO:METRICS — `requests_total`, `rejected_total{reason}`, `eval_latency_seconds`
//!
//! RO:CONFIG — none (pure library); amnesia has no persistence here
//!
//! RO:SECURITY — capability enforcement happens in services; this crate only decides allow/deny
//!
//! RO:TEST — unit tests under `tests/*.rs`; bench: `benches/eval_throughput.rs`

#![forbid(unsafe_code)]
#![deny(clippy::all, clippy::pedantic, clippy::nursery)]

pub mod errors;
pub mod features;
pub mod model;

pub mod ctx;
pub mod engine;
pub mod explain;
pub mod parse;

pub use ctx::Context;
pub use engine::eval::{Decision, DecisionEffect, Evaluator};
pub use explain::trace::{DecisionTrace, TraceStep};
pub use model::{Action, Obligation, PolicyBundle, Rule, RuleCondition};

/// Convenience: load a bundle from JSON bytes.
///
/// # Errors
///
/// Returns `Error::Parse` on malformed JSON or `Error::Validation` if the
/// resulting `PolicyBundle` violates invariants.
pub fn load_json(bytes: &[u8]) -> Result<PolicyBundle, errors::Error> {
    let bundle = parse::json::from_slice(bytes)?;
    parse::validate::validate(&bundle)?;
    Ok(bundle)
}

/// Convenience: load a bundle from TOML bytes.
///
/// # Errors
///
/// Returns `Error::Parse` on malformed TOML or `Error::Validation` if the
/// resulting `PolicyBundle` violates invariants.
pub fn load_toml(bytes: &[u8]) -> Result<PolicyBundle, errors::Error> {
    let bundle = parse::toml::from_slice(bytes)?;
    parse::validate::validate(&bundle)?;
    Ok(bundle)
}

```

### crates/ron-policy/src/model.rs
<a id="crates-ron-policy-src-model-rs"></a>

```rust
//! RO:WHAT — Policy model (DTOs): `PolicyBundle`, Rule, Conditions, Actions, Obligations.
//!
//! RO:WHY  — DTO hygiene: `#[serde(deny_unknown_fields)]` so policies are explicit and auditable.
//!
//! RO:INTERACTS — parse loaders, engine eval, explain trace
//!
//! RO:INVARIANTS — deny-by-default; stable enums; versioned bundle

use serde::{Deserialize, Serialize};
use std::collections::BTreeMap;

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct PolicyBundle {
    pub version: u32,
    /// Optional metadata bag (stringly typed, for governance/notes).
    #[serde(default)]
    pub meta: BTreeMap<String, String>,
    /// Global defaults. If `default_action` is omitted -> deny-by-default.
    #[serde(default)]
    pub defaults: Defaults,
    /// Rules are evaluated in order; first match wins (unless `strategy` overrides).
    #[serde(default)]
    pub rules: Vec<Rule>,
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
#[serde(deny_unknown_fields)]
pub struct Defaults {
    #[serde(default)]
    pub default_action: Option<Action>,
    /// Max request body the engine expects callers to allow before evaluation (bytes).
    #[serde(default)]
    pub max_body_bytes: Option<u64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct Rule {
    pub id: String,
    pub when: RuleCondition,
    pub action: Action,
    #[serde(default)]
    pub obligations: Vec<Obligation>,
    /// Optional human-readable reason to surface if this rule triggers.
    #[serde(default)]
    pub reason: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct RuleCondition {
    /// Tenant or "*" for any.
    #[serde(default)]
    pub tenant: Option<String>,
    /// Method verb (e.g., "GET", "PUT") or "*" for any.
    #[serde(default)]
    pub method: Option<String>,
    /// Region/Geo (e.g., "US", "EU", "US-CA", "US-FL") or "*" for any.
    #[serde(default)]
    pub region: Option<String>,
    /// If present, deny if `body_bytes` exceeds this.
    #[serde(default)]
    pub max_body_bytes: Option<u64>,
    /// Arbitrary tags (all must be present in context if specified).
    #[serde(default)]
    pub require_tags_all: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct Obligation {
    /// Name (e.g., "add-header", "mask-field", "log-audit")
    pub kind: String,
    /// Arbitrary parameters.
    #[serde(default)]
    pub params: BTreeMap<String, String>,
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, Default)]
#[serde(rename_all = "lowercase")]
pub enum Action {
    Allow,
    #[default]
    Deny,
}

```

### crates/ron-policy/src/parse/json.rs
<a id="crates-ron-policy-src-parse-json-rs"></a>

```rust
//! RO:WHAT — JSON loader for `PolicyBundle` (strict).
//!
//! RO:INVARIANTS — `deny_unknown_fields` enforced by DTOs.

use crate::{errors::Error, model::PolicyBundle};

/// Parse a `PolicyBundle` from JSON bytes.
///
/// # Errors
///
/// Returns `Error::Parse` if the input is not valid JSON for `PolicyBundle`.
pub fn from_slice(bytes: &[u8]) -> Result<PolicyBundle, Error> {
    serde_json::from_slice::<PolicyBundle>(bytes).map_err(|e| Error::Parse(e.to_string()))
}

```

### crates/ron-policy/src/parse/mod.rs
<a id="crates-ron-policy-src-parse-mod-rs"></a>

```rust
//! RO:WHAT — Parse entry points and validation.
pub mod json;
pub mod toml;
pub mod validate;

```

### crates/ron-policy/src/parse/toml.rs
<a id="crates-ron-policy-src-parse-toml-rs"></a>

```rust
//! RO:WHAT — TOML loader for `PolicyBundle` (strict).

use crate::{errors::Error, model::PolicyBundle};

/// Parse a `PolicyBundle` from TOML bytes.
///
/// # Errors
///
/// Returns `Error::Parse` if the input is not valid UTF-8 or not valid TOML for `PolicyBundle`.
pub fn from_slice(bytes: &[u8]) -> Result<PolicyBundle, Error> {
    let s = std::str::from_utf8(bytes).map_err(|e| Error::Parse(e.to_string()))?;
    toml::from_str::<PolicyBundle>(s).map_err(|e| Error::Parse(e.to_string()))
}

```

### crates/ron-policy/src/parse/validate.rs
<a id="crates-ron-policy-src-parse-validate-rs"></a>

```rust
//! RO:WHAT — Structural validation for `PolicyBundle`.
//!
//! Returns early with human-readable reasons on invariant violations.

use crate::{errors::Error, model::PolicyBundle};
use std::collections::BTreeSet;

/// Validate a `PolicyBundle` for basic invariants (e.g., duplicate IDs, body caps).
///
/// # Errors
///
/// Returns `Error::Validation` if the bundle violates invariants (e.g., duplicate rule IDs,
/// empty IDs, or caps exceeding 1 MiB).
pub fn validate(b: &PolicyBundle) -> Result<(), Error> {
    if b.version == 0 {
        return Err(Error::Validation("version must be ≥ 1".into()));
    }

    let mut ids = BTreeSet::<&str>::new();
    for r in &b.rules {
        if r.id.trim().is_empty() {
            return Err(Error::Validation("rule.id must be non-empty".into()));
        }
        if !ids.insert(&r.id) {
            return Err(Error::Validation(format!("duplicate rule id: {}", r.id)));
        }
        if let Some(n) = r.when.max_body_bytes {
            if n > 1_048_576 {
                // 1 MiB guard per Hardening blueprint
                return Err(Error::Validation(format!(
                    "rule {} max_body_bytes > 1MiB",
                    r.id
                )));
            }
        }
    }
    if let Some(n) = b.defaults.max_body_bytes {
        if n > 1_048_576 {
            return Err(Error::Validation("defaults.max_body_bytes > 1MiB".into()));
        }
    }
    Ok(())
}

```

### crates/ron-policy/tests/golden_reasons.rs
<a id="crates-ron-policy-tests-goldenreasons-rs"></a>

```rust
use ron_policy::engine::eval::DecisionEffect;
use ron_policy::explain::trace::TraceStep;
use ron_policy::{ctx::clock::SystemClock, load_json, Context, Evaluator};

#[test]
fn explain_trace_is_stable() {
    let b = load_json(include_bytes!("vectors/decompress_guard.json")).unwrap();
    let ev = Evaluator::new(&b).unwrap();
    let ctx = Context::builder()
        .tenant("t")
        .method("PUT")
        .region("US")
        .body_bytes(512)
        .build(&SystemClock);
    let d = ev.evaluate(&ctx).unwrap();

    assert!(matches!(d.effect, DecisionEffect::Deny));
    assert_eq!(d.reason.as_deref(), Some("per-rule cap"));
    assert_eq!(d.trace.steps.len(), 1);
    match &d.trace.steps[0] {
        TraceStep::RuleHit { id, reason } => {
            assert_eq!(id, "deny-large-put");
            assert_eq!(reason, "per-rule cap");
        }
        other => panic!("unexpected trace step: {other:?}"),
    }
}

```

### crates/ron-policy/tests/helpers/bundle_load.rs
<a id="crates-ron-policy-tests-helpers-bundleload-rs"></a>

```rust
//! Helper to load test vectors.

use ron_policy::{load_json, PolicyBundle};

pub fn load_vector(name: &str) -> PolicyBundle {
    let path = format!("tests/vectors/{}", name);
    let bytes = std::fs::read(path).expect("read vector");
    load_json(&bytes).expect("parse bundle")
}

```

### crates/ron-policy/tests/unit_churn_protection.rs
<a id="crates-ron-policy-tests-unitchurnprotection-rs"></a>

```rust
use ron_policy::{ctx::clock::SystemClock, load_json, Context, Evaluator};

#[test]
fn rule_deny_region() {
    let b = load_json(include_bytes!("vectors/deny_region.json")).unwrap();
    let ev = Evaluator::new(&b).unwrap();
    let ctx = Context::builder()
        .tenant("any")
        .method("GET")
        .region("US-FL")
        .build(&SystemClock);
    let d = ev.evaluate(&ctx).unwrap();
    assert!(matches!(
        d.effect,
        ron_policy::engine::eval::DecisionEffect::Deny
    ));
}

```

### crates/ron-policy/tests/unit_eu_only.rs
<a id="crates-ron-policy-tests-uniteuonly-rs"></a>

```rust
use ron_policy::ctx::clock::SystemClock;
use ron_policy::engine::eval::{DecisionEffect, Evaluator};
use ron_policy::{load_json, Context};

#[test]
fn eu_allows_us_denies() {
    let b = load_json(include_bytes!("vectors/eu_only.json")).unwrap();
    let ev = Evaluator::new(&b).unwrap();

    let eu = Context::builder()
        .tenant("t")
        .method("GET")
        .region("EU")
        .build(&SystemClock);
    let us = Context::builder()
        .tenant("t")
        .method("GET")
        .region("US")
        .build(&SystemClock);

    let de = ev.evaluate(&eu).unwrap();
    assert!(matches!(de.effect, DecisionEffect::Allow));
    assert_eq!(de.reason.as_deref(), Some("eu residency"));

    let du = ev.evaluate(&us).unwrap();
    assert!(matches!(du.effect, DecisionEffect::Deny));
    assert_eq!(du.reason.as_deref(), Some("default"));
}

```

### crates/ron-policy/tests/unit_eval_determinism.rs
<a id="crates-ron-policy-tests-unitevaldeterminism-rs"></a>

```rust
use ron_policy::{ctx::clock::SystemClock, load_json, Context, Evaluator};

#[test]
fn deterministic_default_deny() {
    let bundle = load_json(br#"{"version":1,"rules":[]}"#).unwrap();
    let clock = SystemClock::default();
    let ctx = Context::builder()
        .tenant("t")
        .method("GET")
        .region("US")
        .build(&clock);
    let ev = Evaluator::new(&bundle).unwrap();
    let d = ev.evaluate(&ctx).unwrap();
    assert!(matches!(
        d.effect,
        ron_policy::engine::eval::DecisionEffect::Deny
    ));
}

```

### crates/ron-policy/tests/unit_first_match_wins.rs
<a id="crates-ron-policy-tests-unitfirstmatchwins-rs"></a>

```rust
use ron_policy::{PolicyBundle, Rule, RuleCondition, Action};
use ron_policy::engine::eval::{Evaluator, DecisionEffect};
use ron_policy::{parse, Context};
use ron_policy::ctx::clock::SystemClock;

#[test]
fn first_match_wins_and_default_applies() {
    // Bundle: two overlapping allows for GET; no catch-all rule.
    // Expectations:
    //  - GET hits the *first* allow rule and returns immediately ("first").
    //  - POST has no matching rule and falls back to defaults ("default" deny).
    let b = PolicyBundle {
        version: 1,
        defaults: Default::default(), // default_action = None -> deny by default
        meta: Default::default(),
        rules: vec![
            Rule {
                id: "allow-1".into(),
                when: RuleCondition {
                    tenant: None,
                    method: Some("GET".into()),
                    region: None,
                    max_body_bytes: None,
                    require_tags_all: vec![],
                },
                action: Action::Allow,
                obligations: vec![],
                reason: Some("first".into()),
            },
            Rule {
                id: "allow-2".into(),
                when: RuleCondition {
                    tenant: None,
                    method: Some("GET".into()),
                    region: None,
                    max_body_bytes: None,
                    require_tags_all: vec![],
                },
                action: Action::Allow,
                obligations: vec![],
                reason: Some("second".into()),
            },
            // NOTE: No deny-fallback "*" rule here; we want POST to fall through to defaults.
        ],
    };

    parse::validate::validate(&b).unwrap();
    let ev = Evaluator::new(&b).unwrap();

    let getc = Context::builder().tenant("t").method("GET").region("US").build(&SystemClock);
    let postc = Context::builder().tenant("t").method("POST").region("US").build(&SystemClock);

    let d_get = ev.evaluate(&getc).unwrap();
    assert!(matches!(d_get.effect, DecisionEffect::Allow));
    assert_eq!(d_get.reason.as_deref(), Some("first"));

    let d_post = ev.evaluate(&postc).unwrap();
    assert!(matches!(d_post.effect, DecisionEffect::Deny));
    assert_eq!(d_post.reason.as_deref(), Some("default"));
}

```

### crates/ron-policy/tests/unit_large_body_default_deny.rs
<a id="crates-ron-policy-tests-unitlargebodydefaultdeny-rs"></a>

```rust
use ron_policy::ctx::clock::SystemClock;
use ron_policy::engine::eval::{DecisionEffect, Evaluator};
use ron_policy::{load_json, Context};

#[test]
fn large_body_defaults_trips_deny() {
    let b = load_json(include_bytes!("vectors/large_body_default_deny.json")).unwrap();
    let ev = Evaluator::new(&b).unwrap();
    let ctx = Context::builder()
        .tenant("t")
        .method("PUT")
        .region("US")
        .body_bytes(512 * 1024)
        .build(&SystemClock);
    let d = ev.evaluate(&ctx).unwrap();
    assert!(matches!(d.effect, DecisionEffect::Deny));
    assert_eq!(d.reason.as_deref(), Some("body too large (defaults)"));
}

```

### crates/ron-policy/tests/unit_method_matrix.rs
<a id="crates-ron-policy-tests-unitmethodmatrix-rs"></a>

```rust
use ron_policy::ctx::clock::SystemClock;
use ron_policy::engine::eval::{DecisionEffect, Evaluator};
use ron_policy::{load_json, Context};

#[test]
fn method_matrix_behaves() {
    let b = load_json(include_bytes!("vectors/method_matrix.json")).unwrap();
    let ev = Evaluator::new(&b).unwrap();

    let getc = Context::builder()
        .tenant("t")
        .method("GET")
        .region("US")
        .build(&SystemClock);
    let putc = Context::builder()
        .tenant("t")
        .method("PUT")
        .region("US")
        .build(&SystemClock);
    let postc = Context::builder()
        .tenant("t")
        .method("POST")
        .region("US")
        .build(&SystemClock);

    let d_get = ev.evaluate(&getc).unwrap();
    assert!(matches!(d_get.effect, DecisionEffect::Allow));
    assert_eq!(d_get.reason.as_deref(), Some("get ok"));

    let d_put = ev.evaluate(&putc).unwrap();
    assert!(matches!(d_put.effect, DecisionEffect::Deny));
    assert_eq!(d_put.reason.as_deref(), Some("put blocked"));

    let d_post = ev.evaluate(&postc).unwrap();
    assert!(matches!(d_post.effect, DecisionEffect::Deny));
    assert_eq!(d_post.reason.as_deref(), Some("default"));
}

```

### crates/ron-policy/tests/unit_model_serde_strict.rs
<a id="crates-ron-policy-tests-unitmodelserdestrict-rs"></a>

```rust
use ron_policy::load_json;

#[test]
fn strict_deny_unknown_fields() {
    // Unknown field "oops" should be rejected.
    let bad = br#"{"version":1,"oops":true,"rules":[]}"#;
    let err = load_json(bad).unwrap_err();
    let msg = format!("{err}");
    assert!(msg.contains("validation error") || msg.contains("parse error"));
}

#[test]
fn round_trip_minimal() {
    let good = br#"{"version":1,"rules":[]}"#;
    let b = load_json(good).unwrap();
    assert_eq!(b.version, 1);
}

```

### crates/ron-policy/tests/unit_tags_all.rs
<a id="crates-ron-policy-tests-unittagsall-rs"></a>

```rust
use ron_policy::ctx::clock::SystemClock;
use ron_policy::engine::eval::{DecisionEffect, Evaluator};
use ron_policy::{load_json, Context};

#[test]
fn all_required_tags_must_exist() {
    let b = load_json(include_bytes!("vectors/tags_all.json")).unwrap();
    let ev = Evaluator::new(&b).unwrap();

    let ok = Context::builder()
        .tenant("t")
        .method("GET")
        .region("US")
        .tag("paid")
        .tag("verified")
        .build(&SystemClock);

    let missing_one = Context::builder()
        .tenant("t")
        .method("GET")
        .region("US")
        .tag("paid")
        .build(&SystemClock);

    let d1 = ev.evaluate(&ok).unwrap();
    assert!(matches!(d1.effect, DecisionEffect::Allow));
    assert_eq!(d1.reason.as_deref(), Some("all-required-tags-present"));

    let d2 = ev.evaluate(&missing_one).unwrap();
    assert!(matches!(d2.effect, DecisionEffect::Deny));
    assert_eq!(d2.reason.as_deref(), Some("default"));
}

```

### crates/ron-policy/tests/unit_tighten_only.rs
<a id="crates-ron-policy-tests-unittightenonly-rs"></a>

```rust
use ron_policy::{ctx::clock::SystemClock, load_json, Context, Evaluator};

#[test]
fn defaults_cap_applies() {
    let b = load_json(
        br#"{
        "version":1,
        "defaults":{"max_body_bytes": 10},
        "rules":[]
    }"#,
    )
    .unwrap();
    let ev = Evaluator::new(&b).unwrap();
    let ctx = Context::builder()
        .tenant("a")
        .method("PUT")
        .region("US")
        .body_bytes(11)
        .build(&SystemClock);
    let d = ev.evaluate(&ctx).unwrap();
    assert!(matches!(
        d.effect,
        ron_policy::engine::eval::DecisionEffect::Deny
    ));
}

```

### crates/ron-policy/tests/vectors/body_too_large.json
<a id="crates-ron-policy-tests-vectors-bodytoolarge-json"></a>

```json
{
  "version": 1,
  "defaults": { "max_body_bytes": 1024 },
  "rules": [
    { "id": "allow-gets", "when": { "method": "GET" }, "action": "allow" }
  ]
}

```

### crates/ron-policy/tests/vectors/decompress_guard.json
<a id="crates-ron-policy-tests-vectors-decompressguard-json"></a>

```json
{
  "version": 1,
  "rules": [
    {
      "id": "deny-large-put",
      "when": { "method": "PUT", "max_body_bytes": 512 },
      "action": "deny",
      "reason": "per-rule cap"
    },
    { "id": "allow-others", "when": {}, "action": "allow" }
  ]
}

```

### crates/ron-policy/tests/vectors/deny_region.json
<a id="crates-ron-policy-tests-vectors-denyregion-json"></a>

```json
{
  "version": 1,
  "rules": [
    {
      "id": "deny-us-fl",
      "when": { "region": "US-FL" },
      "action": "deny",
      "reason": "region denied"
    },
    {
      "id": "allow-rest",
      "when": {},
      "action": "allow",
      "reason": "fallback allow"
    }
  ]
}

```

### crates/ron-policy/tests/vectors/eu_only.json
<a id="crates-ron-policy-tests-vectors-euonly-json"></a>

```json
{
  "version": 1,
  "defaults": { "default_action": "deny" },
  "rules": [
    { "id": "allow-eu", "when": { "region": "EU" }, "action": "allow", "reason": "eu residency" }
  ]
}

```

### crates/ron-policy/tests/vectors/large_body_default_deny.json
<a id="crates-ron-policy-tests-vectors-largebodydefaultdeny-json"></a>

```json
{
  "version": 1,
  "defaults": { "max_body_bytes": 262144 },
  "rules": []
}

```

### crates/ron-policy/tests/vectors/method_matrix.json
<a id="crates-ron-policy-tests-vectors-methodmatrix-json"></a>

```json
{
  "version": 1,
  "rules": [
    { "id": "allow-get", "when": { "method": "GET" }, "action": "allow", "reason": "get ok" },
    { "id": "deny-put",  "when": { "method": "PUT" }, "action": "deny",  "reason": "put blocked" }
  ]
}

```

### crates/ron-policy/tests/vectors/tags_all.json
<a id="crates-ron-policy-tests-vectors-tagsall-json"></a>

```json
{
  "version": 1,
  "defaults": { "default_action": "deny" },
  "rules": [
    {
      "id": "allow-paid-verified",
      "when": { "require_tags_all": ["paid", "verified"] },
      "action": "allow",
      "reason": "all-required-tags-present"
    }
  ]
}

```



---



# omnigate

_Source: crates/omnigate/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-11-03T19:28:38Z -->
# Code Bundle — `omnigate`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/omnigate/.cargo/config.toml](#crates-omnigate--cargo-config-toml)
- [crates/omnigate/.github/workflows/chaos.yml](#crates-omnigate--github-workflows-chaos-yml)
- [crates/omnigate/.github/workflows/ci.yml](#crates-omnigate--github-workflows-ci-yml)
- [crates/omnigate/.github/workflows/perf-regression.yml](#crates-omnigate--github-workflows-perf-regression-yml)
- [crates/omnigate/.github/workflows/public-api.yml](#crates-omnigate--github-workflows-public-api-yml)
- [crates/omnigate/.github/workflows/render-mermaid.yml](#crates-omnigate--github-workflows-render-mermaid-yml)
- [crates/omnigate/Cargo.toml](#crates-omnigate-Cargo-toml)
- [crates/omnigate/benches/hydration.rs](#crates-omnigate-benches-hydration-rs)
- [crates/omnigate/benches/media_range.rs](#crates-omnigate-benches-mediarange-rs)
- [crates/omnigate/benches/middleware_ping.rs](#crates-omnigate-benches-middlewareping-rs)
- [crates/omnigate/build.rs](#crates-omnigate-build-rs)
- [crates/omnigate/configs/omnigate.toml](#crates-omnigate-configs-omnigate-toml)
- [crates/omnigate/configs/policy.bundle.json](#crates-omnigate-configs-policy-bundle-json)
- [crates/omnigate/configs/staging.toml](#crates-omnigate-configs-staging-toml)
- [crates/omnigate/deny.toml](#crates-omnigate-deny-toml)
- [crates/omnigate/fuzz/Cargo.toml](#crates-omnigate-fuzz-Cargo-toml)
- [crates/omnigate/fuzz/fuzz_targets/capability.rs](#crates-omnigate-fuzz-fuzztargets-capability-rs)
- [crates/omnigate/fuzz/fuzz_targets/decompress_guard.rs](#crates-omnigate-fuzz-fuzztargets-decompressguard-rs)
- [crates/omnigate/fuzz/fuzz_targets/headers.rs](#crates-omnigate-fuzz-fuzztargets-headers-rs)
- [crates/omnigate/rust-toolchain.toml](#crates-omnigate-rust-toolchain-toml)
- [crates/omnigate/scripts/check_boundary.sh](#crates-omnigate-scripts-checkboundary-sh)
- [crates/omnigate/scripts/ci_metrics_guard.sh](#crates-omnigate-scripts-cimetricsguard-sh)
- [crates/omnigate/scripts/hnDL_sim.sh](#crates-omnigate-scripts-hnDLsim-sh)
- [crates/omnigate/scripts/inject_faults.sh](#crates-omnigate-scripts-injectfaults-sh)
- [crates/omnigate/scripts/render_mermaid.sh](#crates-omnigate-scripts-rendermermaid-sh)
- [crates/omnigate/scripts/sanity_omnigate.sh](#crates-omnigate-scripts-sanityomnigate-sh)
- [crates/omnigate/scripts/smoke_omnigate.sh](#crates-omnigate-scripts-smokeomnigate-sh)
- [crates/omnigate/scripts/smoke_policy.sh](#crates-omnigate-scripts-smokepolicy-sh)
- [crates/omnigate/scripts/smoke_readiness.sh](#crates-omnigate-scripts-smokereadiness-sh)
- [crates/omnigate/scripts/soak.sh](#crates-omnigate-scripts-soak-sh)
- [crates/omnigate/src/admission/fair_queue.rs](#crates-omnigate-src-admission-fairqueue-rs)
- [crates/omnigate/src/admission/mod.rs](#crates-omnigate-src-admission-mod-rs)
- [crates/omnigate/src/admission/quotas.rs](#crates-omnigate-src-admission-quotas-rs)
- [crates/omnigate/src/auth/capability.rs](#crates-omnigate-src-auth-capability-rs)
- [crates/omnigate/src/auth/mod.rs](#crates-omnigate-src-auth-mod-rs)
- [crates/omnigate/src/auth/passport_client.rs](#crates-omnigate-src-auth-passportclient-rs)
- [crates/omnigate/src/auth/revocation.rs](#crates-omnigate-src-auth-revocation-rs)
- [crates/omnigate/src/bootstrap/health_probe.rs](#crates-omnigate-src-bootstrap-healthprobe-rs)
- [crates/omnigate/src/bootstrap/metrics_server.rs](#crates-omnigate-src-bootstrap-metricsserver-rs)
- [crates/omnigate/src/bootstrap/mod.rs](#crates-omnigate-src-bootstrap-mod-rs)
- [crates/omnigate/src/bootstrap/server.rs](#crates-omnigate-src-bootstrap-server-rs)
- [crates/omnigate/src/config/env.rs](#crates-omnigate-src-config-env-rs)
- [crates/omnigate/src/config/file.rs](#crates-omnigate-src-config-file-rs)
- [crates/omnigate/src/config/mod.rs](#crates-omnigate-src-config-mod-rs)
- [crates/omnigate/src/config/reload.rs](#crates-omnigate-src-config-reload-rs)
- [crates/omnigate/src/config/validate.rs](#crates-omnigate-src-config-validate-rs)
- [crates/omnigate/src/downstream/dht_client.rs](#crates-omnigate-src-downstream-dhtclient-rs)
- [crates/omnigate/src/downstream/error.rs](#crates-omnigate-src-downstream-error-rs)
- [crates/omnigate/src/downstream/hedge.rs](#crates-omnigate-src-downstream-hedge-rs)
- [crates/omnigate/src/downstream/index_client.rs](#crates-omnigate-src-downstream-indexclient-rs)
- [crates/omnigate/src/downstream/latency.rs](#crates-omnigate-src-downstream-latency-rs)
- [crates/omnigate/src/downstream/mailbox_client.rs](#crates-omnigate-src-downstream-mailboxclient-rs)
- [crates/omnigate/src/downstream/mod.rs](#crates-omnigate-src-downstream-mod-rs)
- [crates/omnigate/src/downstream/registry.rs](#crates-omnigate-src-downstream-registry-rs)
- [crates/omnigate/src/downstream/retry.rs](#crates-omnigate-src-downstream-retry-rs)
- [crates/omnigate/src/downstream/storage_client.rs](#crates-omnigate-src-downstream-storageclient-rs)
- [crates/omnigate/src/downstream/types.rs](#crates-omnigate-src-downstream-types-rs)
- [crates/omnigate/src/errors/http_map.rs](#crates-omnigate-src-errors-httpmap-rs)
- [crates/omnigate/src/errors/mod.rs](#crates-omnigate-src-errors-mod-rs)
- [crates/omnigate/src/errors/reasons.rs](#crates-omnigate-src-errors-reasons-rs)
- [crates/omnigate/src/hydration/compose.rs](#crates-omnigate-src-hydration-compose-rs)
- [crates/omnigate/src/hydration/mod.rs](#crates-omnigate-src-hydration-mod-rs)
- [crates/omnigate/src/hydration/planner.rs](#crates-omnigate-src-hydration-planner-rs)
- [crates/omnigate/src/lib.rs](#crates-omnigate-src-lib-rs)
- [crates/omnigate/src/main.rs](#crates-omnigate-src-main-rs)
- [crates/omnigate/src/metrics/gates.rs](#crates-omnigate-src-metrics-gates-rs)
- [crates/omnigate/src/metrics/mod.rs](#crates-omnigate-src-metrics-mod-rs)
- [crates/omnigate/src/metrics/registry.rs](#crates-omnigate-src-metrics-registry-rs)
- [crates/omnigate/src/middleware/body_caps.rs](#crates-omnigate-src-middleware-bodycaps-rs)
- [crates/omnigate/src/middleware/classify.rs](#crates-omnigate-src-middleware-classify-rs)
- [crates/omnigate/src/middleware/corr_id.rs](#crates-omnigate-src-middleware-corrid-rs)
- [crates/omnigate/src/middleware/decompress_guard.rs](#crates-omnigate-src-middleware-decompressguard-rs)
- [crates/omnigate/src/middleware/inflight.rs](#crates-omnigate-src-middleware-inflight-rs)
- [crates/omnigate/src/middleware/mod.rs](#crates-omnigate-src-middleware-mod-rs)
- [crates/omnigate/src/middleware/policy.rs](#crates-omnigate-src-middleware-policy-rs)
- [crates/omnigate/src/middleware/slow_loris.rs](#crates-omnigate-src-middleware-slowloris-rs)
- [crates/omnigate/src/observability/logging.rs](#crates-omnigate-src-observability-logging-rs)
- [crates/omnigate/src/observability/mod.rs](#crates-omnigate-src-observability-mod-rs)
- [crates/omnigate/src/observability/tracing_spans.rs](#crates-omnigate-src-observability-tracingspans-rs)
- [crates/omnigate/src/pq/mod.rs](#crates-omnigate-src-pq-mod-rs)
- [crates/omnigate/src/pq/negotiate.rs](#crates-omnigate-src-pq-negotiate-rs)
- [crates/omnigate/src/readiness/keys.rs](#crates-omnigate-src-readiness-keys-rs)
- [crates/omnigate/src/readiness/mod.rs](#crates-omnigate-src-readiness-mod-rs)
- [crates/omnigate/src/readiness/policy.rs](#crates-omnigate-src-readiness-policy-rs)
- [crates/omnigate/src/readiness/sampler.rs](#crates-omnigate-src-readiness-sampler-rs)
- [crates/omnigate/src/readiness/state.rs](#crates-omnigate-src-readiness-state-rs)
- [crates/omnigate/src/routes/mod.rs](#crates-omnigate-src-routes-mod-rs)
- [crates/omnigate/src/routes/ops.rs](#crates-omnigate-src-routes-ops-rs)
- [crates/omnigate/src/routes/v1/dht.rs](#crates-omnigate-src-routes-v1-dht-rs)
- [crates/omnigate/src/routes/v1/facet/feed.rs](#crates-omnigate-src-routes-v1-facet-feed-rs)
- [crates/omnigate/src/routes/v1/facet/graph.rs](#crates-omnigate-src-routes-v1-facet-graph-rs)
- [crates/omnigate/src/routes/v1/facet/media.rs](#crates-omnigate-src-routes-v1-facet-media-rs)
- [crates/omnigate/src/routes/v1/facet/mod.rs](#crates-omnigate-src-routes-v1-facet-mod-rs)
- [crates/omnigate/src/routes/v1/index.rs](#crates-omnigate-src-routes-v1-index-rs)
- [crates/omnigate/src/routes/v1/mailbox.rs](#crates-omnigate-src-routes-v1-mailbox-rs)
- [crates/omnigate/src/routes/v1/mod.rs](#crates-omnigate-src-routes-v1-mod-rs)
- [crates/omnigate/src/routes/v1/objects.rs](#crates-omnigate-src-routes-v1-objects-rs)
- [crates/omnigate/src/routes/v1/ping.rs](#crates-omnigate-src-routes-v1-ping-rs)
- [crates/omnigate/src/runtime/channels.rs](#crates-omnigate-src-runtime-channels-rs)
- [crates/omnigate/src/runtime/mod.rs](#crates-omnigate-src-runtime-mod-rs)
- [crates/omnigate/src/runtime/sample.rs](#crates-omnigate-src-runtime-sample-rs)
- [crates/omnigate/src/runtime/shutdown.rs](#crates-omnigate-src-runtime-shutdown-rs)
- [crates/omnigate/src/runtime/supervisor.rs](#crates-omnigate-src-runtime-supervisor-rs)
- [crates/omnigate/src/runtime/worker.rs](#crates-omnigate-src-runtime-worker-rs)
- [crates/omnigate/src/state.rs](#crates-omnigate-src-state-rs)
- [crates/omnigate/src/types/dto.rs](#crates-omnigate-src-types-dto-rs)
- [crates/omnigate/src/types/mod.rs](#crates-omnigate-src-types-mod-rs)
- [crates/omnigate/src/zk/mod.rs](#crates-omnigate-src-zk-mod-rs)
- [crates/omnigate/src/zk/no_mutate.rs](#crates-omnigate-src-zk-nomutate-rs)
- [crates/omnigate/src/zk/receipts.rs](#crates-omnigate-src-zk-receipts-rs)
- [crates/omnigate/testing/chaos/scenario.yml](#crates-omnigate-testing-chaos-scenario-yml)
- [crates/omnigate/testing/performance/baselines/p95_hydration.json](#crates-omnigate-testing-performance-baselines-p95hydration-json)
- [crates/omnigate/testing/performance/baselines/p95_range.json](#crates-omnigate-testing-performance-baselines-p95range-json)
- [crates/omnigate/testing/performance/hydrate_mix.sh](#crates-omnigate-testing-performance-hydratemix-sh)
- [crates/omnigate/testing/vectors/omnigate/error_413.json](#crates-omnigate-testing-vectors-omnigate-error413-json)
- [crates/omnigate/testing/vectors/omnigate/range_read.json](#crates-omnigate-testing-vectors-omnigate-rangeread-json)
- [crates/omnigate/testing/vectors/omnigate/unauth_401.json](#crates-omnigate-testing-vectors-omnigate-unauth401-json)
- [crates/omnigate/tests/admission_contract.rs](#crates-omnigate-tests-admissioncontract-rs)
- [crates/omnigate/tests/dto_serialization.rs](#crates-omnigate-tests-dtoserialization-rs)
- [crates/omnigate/tests/hardening.rs](#crates-omnigate-tests-hardening-rs)
- [crates/omnigate/tests/interop_vectors.rs](#crates-omnigate-tests-interopvectors-rs)
- [crates/omnigate/tests/loom_fanout.rs](#crates-omnigate-tests-loomfanout-rs)
- [crates/omnigate/tests/metrics_contract.rs](#crates-omnigate-tests-metricscontract-rs)
- [crates/omnigate/tests/middleware_contract.rs](#crates-omnigate-tests-middlewarecontract-rs)
- [crates/omnigate/tests/oap_limits.rs](#crates-omnigate-tests-oaplimits-rs)
- [crates/omnigate/tests/policy_gate.rs](#crates-omnigate-tests-policygate-rs)
- [crates/omnigate/tests/policy_metrics.rs](#crates-omnigate-tests-policymetrics-rs)
- [crates/omnigate/tests/readiness_error_rate.rs](#crates-omnigate-tests-readinesserrorrate-rs)
- [crates/omnigate/tests/readiness_inflight.rs](#crates-omnigate-tests-readinessinflight-rs)
- [crates/omnigate/tests/ready_truth.rs](#crates-omnigate-tests-readytruth-rs)
- [crates/omnigate/tests/readyz_overload.rs](#crates-omnigate-tests-readyzoverload-rs)
- [crates/omnigate/tests/zk_read_only.rs](#crates-omnigate-tests-zkreadonly-rs)
- [crates/omnigate/tests/zk_receipts.rs](#crates-omnigate-tests-zkreceipts-rs)

### crates/omnigate/.cargo/config.toml
<a id="crates-omnigate--cargo-config-toml"></a>

```toml
[build]
rustflags = []

[term]
verbose = false

```

### crates/omnigate/.github/workflows/chaos.yml
<a id="crates-omnigate--github-workflows-chaos-yml"></a>

```yaml
name: chaos
on:
  schedule:
    - cron: "0 3 * * 0"
jobs:
  soak:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "Chaos/soak scaffold."

```

### crates/omnigate/.github/workflows/ci.yml
<a id="crates-omnigate--github-workflows-ci-yml"></a>

```yaml
name: ci
on: [push, pull_request]
jobs:
  build-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        arch: [x86_64, aarch64]
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - run: echo "Scaffold CI placeholder."

```

### crates/omnigate/.github/workflows/perf-regression.yml
<a id="crates-omnigate--github-workflows-perf-regression-yml"></a>

```yaml
name: perf-regression
on:
  workflow_dispatch:
jobs:
  perf:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "Perf regression scaffold."

```

### crates/omnigate/.github/workflows/public-api.yml
<a id="crates-omnigate--github-workflows-public-api-yml"></a>

```yaml
name: public-api
on: [pull_request]
jobs:
  guard:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "Public API guard scaffold."

```

### crates/omnigate/.github/workflows/render-mermaid.yml
<a id="crates-omnigate--github-workflows-render-mermaid-yml"></a>

```yaml
name: render-mermaid
on: [push, pull_request]
jobs:
  mmdc:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "Render mermaid placeholder."

```

### crates/omnigate/Cargo.toml
<a id="crates-omnigate-Cargo-toml"></a>

```toml
[package]
name = "omnigate"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
publish = false
build = "build.rs"

[lib]
name = "omnigate"
path = "src/lib.rs"

[[bin]]
name = "omnigate"
path = "src/main.rs"

# Criterion uses its own harness
[[bench]]
name = "middleware_ping"
harness = false

[features]
default = []
arti = []

[dependencies]
# RON workspace crates
ron-kernel = { path = "../ron-kernel" }
ron-proto  = { path = "../ron-proto" }
oap        = { path = "../oap" }
ron-policy = { path = "../ron-policy" }     # used by PolicyLayer integration

# Async/HTTP stack
tokio       = { version = "1", features = ["macros", "rt-multi-thread", "signal", "time", "io-util", "sync", "net", "fs"] }
axum        = { version = "0.7", default-features = false, features = ["tokio", "http1", "http2", "json", "query"] }
tower       = "0.5"
tower-http  = { version = "0.6.6", features = ["trace"] }
http        = "1"
tokio-util  = "0.7"

# Outbound HTTP (downstream clients)
reqwest = { version = "0.12", features = ["rustls-tls-native-roots", "json"] }

# Observability
tracing            = "0.1"
tracing-subscriber = { version = "0.3", features = ["fmt", "env-filter"] }
prometheus         = "0.14"

# Config & serde
serde           = { version = "1.0", features = ["derive"] }
serde_json      = "1"
toml            = "0.8"
humantime-serde = "1"

# Misc
thiserror    = "1"
anyhow       = "1"
bytes        = "1"
once_cell    = "1.19"
parking_lot  = "0.12"
futures      = "0.3"
futures-util = "0.3"          # used in middleware policy layer
rand         = "0.9"          # downstream retry/jitter (matches workspace pin)
tokio-rustls = "0.26.2"       # TLS (tokio_rustls::rustls types)
fastrand     = { workspace = true }  # corr_id request IDs

[dev-dependencies]
# Criterion bench harness
criterion = { version = "0.5.1", features = ["async_tokio"] }

# Tests: in-process server + clients
# We include the same tokio with multi-thread runtime + time so readiness tests work.
tokio     = { version = "1", features = ["macros", "rt-multi-thread", "time"] }

# `reqwest` is already a normal dependency, so tests can use it.
# If you ever drop it from [dependencies], uncomment this line:
# reqwest   = { version = "0.12", features = ["rustls-tls-native-roots", "json"] }

regex     = "1"

```

### crates/omnigate/benches/hydration.rs
<a id="crates-omnigate-benches-hydration-rs"></a>

```rust


```

### crates/omnigate/benches/media_range.rs
<a id="crates-omnigate-benches-mediarange-rs"></a>

```rust


```

### crates/omnigate/benches/middleware_ping.rs
<a id="crates-omnigate-benches-middlewareping-rs"></a>

```rust
//! Bench the omnigate middleware stack end-to-end (in-process, no sockets).
//! Build an axum Router, apply `omnigate::middleware::apply`, then
//! issue GET /ping requests and measure total round-trip time.
//!
//! Run: `cargo bench -p omnigate --bench middleware_ping`

use std::time::Duration;

use axum::{
    body::{self, Body},
    http::{Request, StatusCode},
    routing::get,
    Router,
};
use criterion::{black_box, criterion_group, criterion_main, BatchSize, Criterion, Throughput};
use tower::ServiceExt; // for .oneshot()

fn build_router() -> Router {
    let api = Router::new().route("/ping", get(|| async { "pong" }));
    omnigate::middleware::apply(api)
}

/// Issue a single in-process GET /ping and return (status, body_len).
async fn hit_ping(router: &Router) -> (StatusCode, usize) {
    let req = Request::builder()
        .method("GET")
        .uri("/ping")
        .body(Body::empty())
        .expect("request");

    let resp = router.clone().oneshot(req).await.expect("response");
    let status = resp.status();

    // axum 0.7: to_bytes requires an explicit limit
    let bytes = body::to_bytes(resp.into_body(), usize::MAX)
        .await
        .expect("to_bytes");

    (status, bytes.len())
}

fn bench_middleware_ping(c: &mut Criterion) {
    // Build router once; cloned per-req by ServiceExt::oneshot
    let router = build_router();

    // Current-thread Tokio runtime (cheap to drive short async ops)
    let rt = tokio::runtime::Builder::new_current_thread()
        .enable_all()
        .build()
        .expect("tokio rt");

    let mut group = c.benchmark_group("omnigate/middleware_ping");
    group.warm_up_time(Duration::from_millis(500));
    group.measurement_time(Duration::from_secs(8));
    group.sample_size(40);
    group.throughput(Throughput::Elements(1));

    group.bench_function("GET /ping (in-process)", |b| {
        b.iter_batched(
            || router.clone(),
            |svc| {
                rt.block_on(async move {
                    let (status, len) = hit_ping(&svc).await;
                    assert_eq!(status, StatusCode::OK);
                    black_box(len);
                });
            },
            BatchSize::SmallInput,
        );
    });

    group.finish();
}

criterion_group!(benches, bench_middleware_ping);
criterion_main!(benches);

```

### crates/omnigate/build.rs
<a id="crates-omnigate-build-rs"></a>

```rust
// Build script to embed a short Git commit into the binary as GIT_COMMIT_SHORT.
// Falls back cleanly if `git` is unavailable (e.g., shallow CI clones).

use std::process::Command;

fn main() {
    // Re-run if HEAD moves.
    println!("cargo:rerun-if-changed=.git/HEAD");
    println!("cargo:rerun-if-changed=.git/refs/");

    let short = Command::new("git")
        .args(["rev-parse", "--short=9", "HEAD"])
        .output()
        .ok()
        .and_then(|o| o.status.success().then_some(o))
        .and_then(|o| String::from_utf8(o.stdout).ok())
        .map(|s| s.trim().to_string());

    if let Some(s) = short {
        println!("cargo:rustc-env=GIT_COMMIT_SHORT={}", s);
    }
}

```

### crates/omnigate/configs/omnigate.toml
<a id="crates-omnigate-configs-omnigate-toml"></a>

```toml
# omnigate — default config (Beta)

[server]
bind         = "127.0.0.1:5305"
metrics_addr = "127.0.0.1:9605"
amnesia      = true

[oap]
# Keep <= 1 MiB as enforced by config validation & invariants.
max_frame_bytes    = 1048576
stream_chunk_bytes = 65536

[admission.global_quota]
# Default (sane) production-ish limits. For forcing 429s in smoke, see the
# commented dev overrides further below.
qps   = 20000
burst = 40000

[admission.ip_quota]
enabled = true
qps     = 2000
burst   = 4000
# buckets = [ { cidr="10.0.0.0/8", qps=5000, burst=10000 } ]

[admission.fair_queue]
# Hard cap. Leave roomy for prod; readiness trips use a lower threshold below.
max_inflight = 2048
# Optional interactive headroom; if omitted, computed as max_inflight/8 by code.
headroom = 256
weights = { anon = 1, auth = 5, admin = 10 }

[admission.body]
# IMPORTANT: Align with middleware guard (1 MiB) to avoid 413s before decompression budget.
# (The decompression guard also uses this as its max expanded size.)
max_content_length       = 1048576
reject_on_missing_length = true

[admission.decompression]
allow        = ["identity", "gzip"]
deny_stacked = true

[policy]
enabled     = true
bundle_path = "crates/omnigate/configs/policy.bundle.json"
fail_mode   = "deny"  # "deny" | "allow"

[readiness]
# Tune low enough for laptop smoke to trip:
# - The inflight gauge crosses this threshold under /v1/sleep load
# - Error-rate path trips if 429/503 share exceeds this %
max_inflight_threshold = 64
error_rate_429_503_pct = 1.0
window_secs            = 10
hold_for_secs          = 20

# --- Optional dev overrides for smoke tests (uncomment as needed) ---
# [admission.global_quota]
# qps   = 50
# burst = 50
#
# [admission.ip_quota]
# enabled = true
# qps     = 50
# burst   = 50
#
# [readiness]
# max_inflight_threshold = 64
# error_rate_429_503_pct = 1.0
# window_secs            = 10
# hold_for_secs          = 20

```

### crates/omnigate/configs/policy.bundle.json
<a id="crates-omnigate-configs-policy-bundle-json"></a>

```json
{
  "version": 1,
  "meta": {
    "name": "omnigate-default",
    "description": "Default Omnigate policy: allow safe reads, deny writes by default."
  },
  "defaults": {
    "default_action": "deny",
    "max_body_bytes": 262144
  },
  "rules": [
    {
      "id": "allow-gets",
      "when": { "method": "GET" },
      "action": "allow",
      "reason": "read ok"
    },
    {
      "id": "allow-heads",
      "when": { "method": "HEAD" },
      "action": "allow",
      "reason": "head ok"
    },
    {
      "id": "deny-puts",
      "when": { "method": "PUT" },
      "action": "deny",
      "reason": "put blocked"
    },
    {
      "id": "deny-deletes",
      "when": { "method": "DELETE" },
      "action": "deny",
      "reason": "delete blocked"
    }
  ]
}

```

### crates/omnigate/configs/staging.toml
<a id="crates-omnigate-configs-staging-toml"></a>

```toml

```

### crates/omnigate/deny.toml
<a id="crates-omnigate-deny-toml"></a>

```toml
[advisories]
yanked = "deny"
unmaintained = "deny"
vulnerability = "deny"

[licenses]
allow = ["MIT", "Apache-2.0"]

```

### crates/omnigate/fuzz/Cargo.toml
<a id="crates-omnigate-fuzz-Cargo-toml"></a>

```toml
[package]
name = "omnigate2-fuzz"
version = "0.0.0"
edition = "2021"
publish = false

[package.metadata]
cargo-fuzz = true

```

### crates/omnigate/fuzz/fuzz_targets/capability.rs
<a id="crates-omnigate-fuzz-fuzztargets-capability-rs"></a>

```rust

```

### crates/omnigate/fuzz/fuzz_targets/decompress_guard.rs
<a id="crates-omnigate-fuzz-fuzztargets-decompressguard-rs"></a>

```rust

```

### crates/omnigate/fuzz/fuzz_targets/headers.rs
<a id="crates-omnigate-fuzz-fuzztargets-headers-rs"></a>

```rust

```

### crates/omnigate/rust-toolchain.toml
<a id="crates-omnigate-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["rustfmt","clippy"]

```

### crates/omnigate/scripts/check_boundary.sh
<a id="crates-omnigate-scripts-checkboundary-sh"></a>

```bash
#!/usr/bin/env bash
# Scaffold: add grep/lints for forbidden deps and patterns.

```

### crates/omnigate/scripts/ci_metrics_guard.sh
<a id="crates-omnigate-scripts-cimetricsguard-sh"></a>

```bash
#!/usr/bin/env bash
# Scaffold: scrape /metrics and assert label/name contracts.

```

### crates/omnigate/scripts/hnDL_sim.sh
<a id="crates-omnigate-scripts-hnDLsim-sh"></a>

```bash
#!/usr/bin/env bash
# Scaffold: Harvest-now-decrypt-later drill placeholder.

```

### crates/omnigate/scripts/inject_faults.sh
<a id="crates-omnigate-scripts-injectfaults-sh"></a>

```bash
#!/usr/bin/env bash
# Scaffold: locally simulate latency/errors.

```

### crates/omnigate/scripts/render_mermaid.sh
<a id="crates-omnigate-scripts-rendermermaid-sh"></a>

```bash
#!/usr/bin/env bash
# Scaffold: render docs/mermaid/*.mmd to SVGs.

```

### crates/omnigate/scripts/sanity_omnigate.sh
<a id="crates-omnigate-scripts-sanityomnigate-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

API_ADDR="${API_ADDR:-127.0.0.1:5305}"
METRICS_ADDR="${METRICS_ADDR:-127.0.0.1:9605}"
BIN_PKG="omnigate"
RUST_LOG_LEVEL="${RUST_LOG_LEVEL:-info}"
TRACE_LOG_COMPONENT="${TRACE_LOG_COMPONENT:-omnigate=trace}"
CARGO="${CARGO:-cargo}"
CONFIG_PATH="${CONFIG_PATH:-crates/omnigate/configs/omnigate.toml}"   # default to repo config
SKIP_NET_BURST="${SKIP_NET_BURST:-0}"                                 # set to 1 to skip the 429 burst check

req()  { printf "[sanity] %s\n" "$*"; }
fail() { printf "[sanity][FAIL] %s\n" "$*" >&2; exit 1; }

need() { command -v "$1" >/dev/null 2>&1 || fail "missing required tool: $1"; }

# --- prerequisites ---
need curl; need awk; need jq; need dd

# --- helpers ---
CHILD_PID=""
stop_child() {
  if [[ -n "${CHILD_PID:-}" ]] && kill -0 "$CHILD_PID" 2>/dev/null; then
    # Try graceful first, then a hard kill if needed
    kill "$CHILD_PID" 2>/dev/null || true
    sleep 0.2
    kill -0 "$CHILD_PID" 2>/dev/null && kill -9 "$CHILD_PID" 2>/dev/null || true
    wait "$CHILD_PID" 2>/dev/null || true
    CHILD_PID=""
  fi
}
trap stop_child EXIT

http_code() {
  local url="$1"
  curl -s -o /dev/null -w "%{http_code}" "$url"
}

wait_200() {
  local url="$1" tries="${2:-80}" delay="${3:-0.125}"
  for ((i=1;i<=tries;i++)); do
    local code; code="$(http_code "$url" || true)"
    [[ "$code" == "200" ]] && return 0
    sleep "$delay"
  done
  return 1
}

assert_http_200() {
  local url="$1"
  local code; code="$(http_code "$url" || true)"
  [[ "$code" == "200" ]] || fail "expected 200: $url (got $code)"
}

assert_json_true() {
  local url="$1" key="$2"
  local val; val="$(curl -s "$url" | jq -r ".${key}")"
  [[ "$val" == "true" ]] || fail "expected ${key}=true at $url (got $val)"
}

metric_value() {
  local metric="$1"
  # Grab the first *unlabeled* sample line:  "<name> <value>"
  curl -s "http://${METRICS_ADDR}/metrics" \
    | awk -v m="$metric" '$1==m{print $2; exit}'
}

assert_metric_eq() {
  local metric="$1" expect="$2"
  local val; val="$(metric_value "$metric")"
  [[ "${val:-}" == "$expect" ]] || fail "metric $metric expected $expect got ${val:-<missing>}"
}

print_metric() {
  local metric="$1"
  curl -s "http://${METRICS_ADDR}/metrics" | awk -v m="$metric" '$1==m{print}'
}

# --- build & tests ---
req "fmt + clippy + build"
$CARGO fmt -p "$BIN_PKG"
$CARGO clippy -p "$BIN_PKG" --no-deps -- -D warnings
$CARGO build -p "$BIN_PKG"

req "unit/integration tests"
$CARGO test -p "$BIN_PKG" --test dto_serialization --test ready_truth --test zk_receipts

# --- run helper ---
run_omnigate() {
  local dev_ready="$1" # 0 or 1
  stop_child
  req "starting omnigate (OMNIGATE_DEV_READY=${dev_ready})"
  req "using --config $CONFIG_PATH"

  OMNIGATE_DEV_READY="$dev_ready" \
  OMNIGATE_AMNESIA=on \
  RUST_LOG="${RUST_LOG_LEVEL},${TRACE_LOG_COMPONENT}" \
  $CARGO run -p "$BIN_PKG" --quiet -- --config "$CONFIG_PATH" &

  CHILD_PID=$!

  req "waiting for /healthz 200"
  wait_200 "http://${API_ADDR}/healthz" || fail "healthz did not become 200"

  req "waiting for /readyz 200"
  wait_200 "http://${API_ADDR}/readyz" || fail "readyz did not become 200"

  req "waiting for /metrics 200"
  wait_200 "http://${METRICS_ADDR}/metrics" || req "WARN: metrics endpoint not yet 200 (continuing best-effort)"

  # small settle to avoid initial scrape races
  sleep 0.15
}

# --- Phase A: DEV override ON ---
run_omnigate 1

req "check admin plane & v1 routes"
assert_http_200 "http://${API_ADDR}/healthz"
assert_http_200 "http://${API_ADDR}/readyz"
assert_json_true "http://${API_ADDR}/v1/ping" "ok"

req "versionz contains version (git may be null)"
curl -s "http://${API_ADDR}/versionz" | jq -e '.version | length > 0' >/dev/null \
  || fail "/versionz missing 'version'"

req "assert amnesia_mode == 1"
assert_metric_eq amnesia_mode 1

stop_child

# --- Phase B: DEV override OFF (real gates) ---
run_omnigate 0

req "assert readyz payload is true"
assert_json_true "http://${API_ADDR}/readyz" "ready"

req "gate gauges (best-effort if present)"
for m in listeners_bound metrics_bound cfg_loaded ready_state; do
  val="$(metric_value "$m" || true)"
  if [[ -n "$val" && "$val" != "1" ]]; then
    req "WARN: $m present but not 1 (got $val)"
  fi
done

# --- Fair queue cap header check ---
req "fair queue cap header exposes different caps for priorities"
curl -s -i -H 'x-omnigate-priority: interactive' "http://${API_ADDR}/v1/ping" \
  | awk 'BEGIN{IGNORECASE=1}/^x-omnigate-cap:/{print}'
curl -s -i -H 'x-omnigate-priority: bulk'        "http://${API_ADDR}/v1/ping" \
  | awk 'BEGIN{IGNORECASE=1}/^x-omnigate-cap:/{print}'

# --- Global quota burst to try for 429s ---
if [[ "$SKIP_NET_BURST" != "1" ]]; then
  req "burst load to trigger some 429 (best-effort)"
  if command -v xargs >/dev/null 2>&1; then
    seq 1 1200 | xargs -n1 -P64 -I{} curl -s -o /dev/null -w "%{http_code}\n" \
      "http://${API_ADDR}/v1/ping" | sort | uniq -c || true
  else
    req "WARN: xargs not available; skipping burst"
  fi
else
  req "SKIP_NET_BURST=1 — skipping the 429 burst check"
fi

req "check quota exhaust counter (if burst produced 429s)"
print_metric admission_quota_exhausted_total || req "NOTE: admission_quota_exhausted_total not present yet"

# --- Body caps: oversize -> 413 + counter ---
req "body caps oversize 413 + metric"
TMP_BIG="/tmp/omnigate_big.bin"
dd if=/dev/urandom of="$TMP_BIG" bs=1k count=1100 status=none
code="$(curl -s -o /dev/null -w "%{http_code}" -X POST --data-binary @"$TMP_BIG" "http://${API_ADDR}/v1/ping")"
if [[ "$code" != "413" ]]; then
  req "WARN: oversize POST did not return 413 (got $code) — verify route setup for POST on /v1/ping or test an endpoint that accepts body"
fi
print_metric body_reject_total || req "NOTE: body_reject_total not present yet"

# --- Decompression guard: unknown + stacked encodings ---
req "decompress guard rejects: unknown encoding"
code="$(curl -s -o /dev/null -w "%{http_code}" -H 'Content-Encoding: compress' -X POST --data 'abc' "http://${API_ADDR}/v1/ping")" || true
if [[ "$code" != "415" ]]; then
  req "WARN: unknown encoding did not return 415 (got $code) — ensure POST route is guarded by decompress layer"
fi

req "decompress guard rejects: stacked encodings"
code="$(curl -s -o /dev/null -w "%{http_code}" -H 'Content-Encoding: gzip, deflate' -X POST --data 'abc' "http://${API_ADDR}/v1/ping")" || true
if [[ "$code" != "415" ]]; then
  req "WARN: stacked encodings did not return 415 (got $code) — ensure POST route is guarded by decompress layer"
fi
print_metric decompress_reject_total || req "NOTE: decompress_reject_total not present yet"

# --- Ready trip/recover (best-effort) ---
req "ready trip metrics snapshot"
curl -s "http://${METRICS_ADDR}/metrics" | egrep 'ready_trips_total|ready_state_changes_total|ready_error_rate_pct|ready_inflight_current' || true

# Done
stop_child
req "OK — all sanity checks finished"

```

### crates/omnigate/scripts/smoke_omnigate.sh
<a id="crates-omnigate-scripts-smokeomnigate-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Colors
G="\033[0;32m"; Y="\033[1;33m"; R="\033[0;31m"; Z="\033[0m"

echo -e "${Y}fmt + clippy + build…${Z}"
cargo fmt -p omnigate
cargo clippy -p omnigate --no-deps -- -D warnings
cargo build -p omnigate

# Defaults (API=5305, ADMIN=9605)
API_ADDR="${API_ADDR:-127.0.0.1:5305}"
ADMIN_ADDR="${ADMIN_ADDR:-127.0.0.1:9605}"
LOG="/tmp/omnigate.log"

# REQUIRED: config path (can be overridden)
CONFIG_PATH="${OMNIGATE_CONFIG:-crates/omnigate/configs/omnigate.toml}"
if [ ! -f "${CONFIG_PATH}" ]; then
  echo -e "${R}❌ Config file not found at: ${CONFIG_PATH}${Z}"
  exit 1
fi
echo -e "${Y}using config: ${CONFIG_PATH}${Z}"

# Optional dev-readiness override
export OMNIGATE_DEV_READY="${OMNIGATE_DEV_READY:-}"

echo -e "${Y}starting omnigate at ${API_ADDR} (logs: ${LOG})…${Z}"
BIN="target/debug/omnigate"
# Pass --config so the readiness 'config' gate can flip
"${BIN}" --config "${CONFIG_PATH}" > "${LOG}" 2>&1 &
PID=$!

cleanup() {
  echo -e "${Y}stopping omnigate (pid=${PID})…${Z}"
  kill "${PID}" >/dev/null 2>&1 || true
  wait "${PID}" >/dev/null 2>&1 || true
}
trap cleanup EXIT

# Wait for /healthz on the API port
echo "waiting for /healthz…"
set +e
for i in {1..100}; do
  curl -sf "http://${API_ADDR}/healthz" >/dev/null && break
  sleep 0.1
done
set -e

echo "-- /healthz (API)"
curl -sf "http://${API_ADDR}/healthz"
echo

# Metrics are on the ADMIN plane
echo "-- /metrics (ADMIN)"
if ! curl -sf "http://${ADMIN_ADDR}/metrics" | head -n 20; then
  echo -e "${R}❌ /metrics not available on ${ADMIN_ADDR}. Check ${LOG}.${Z}"
  exit 1
fi

# Root / should 404
echo "-- / (API, expect 404)"
CODE=$(curl -s -o /dev/null -w "%{http_code}" "http://${API_ADDR}/")
if [ "${CODE}" = "404" ]; then
  echo -e "✅ 404 ok"
else
  echo -e "${R}❌ expected 404, got ${CODE}${Z}"
  exit 1
fi

check_ready() {
  local path="$1"
  local status body
  status=$(curl -s -o /dev/null -w "%{http_code}" "http://${API_ADDR}${path}")
  body=$(curl -s "http://${API_ADDR}${path}" || true)
  echo "readyz status (${path} on API): ${status}"
  if [ "${status}" = "200" ]; then
    echo -e "${G}✅ ready (body: ${body})${Z}"
    return 0
  else
    echo -e "${Y}ℹ️ not ready (status ${status}, body: ${body})${Z}"
    # Show last 20 log lines to explain the gate
    echo -e "${Y}--- tail ${LOG} ---${Z}"
    tail -n 20 "${LOG}" || true
    echo -e "${Y}-------------------${Z}"
    return 1
  fi
}

echo "-- /readyz (API; truthful readiness)"
check_ready "/readyz" || true

echo "-- /ops/readyz (API alias)"
check_ready "/ops/readyz" || true

echo -e "${G}✅ smoke ok${Z}"

```

### crates/omnigate/scripts/smoke_policy.sh
<a id="crates-omnigate-scripts-smokepolicy-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

API_ADDR="${API_ADDR:-127.0.0.1:5305}"
ADMIN_ADDR="${ADMIN_ADDR:-127.0.0.1:9605}"
MAX_BODY="${OMNIGATE_MAX_BODY:-10485760}"

# We scrape the default Prom registry exposed by the API on /ops/metrics
METRICS_URL="${METRICS_URL:-http://${API_ADDR}/ops/metrics}"

say() { printf "\n\033[1m▶ %s\033[0m\n" "$*"; }
status() { curl -s -o /dev/null -w "%{http_code}" "$@"; }

metric_sum() {
  local metric="$1"
  curl -s "$METRICS_URL" \
  | awk -v re="^"$(printf "%s" "$metric" | sed 's/[].[^$*+?{}()|/\\]/\\&/g') \
      '$0 ~ re { v=$NF; if (v ~ /^[0-9]+([.][0-9]+)?$/) s+=v+0 } END { printf("%.0f\n", (s==""?0:s)) }'
}

metric_show() {
  local metric="$1"
  echo "---- ${metric} lines ----"
  curl -s "$METRICS_URL" \
  | awk -v re="^"$(printf "%s" "$metric" | sed 's/[].[^$*+?{}()|/\\]/\\&/g') '$0 ~ re { print }'
  echo "-------------------------"
}

say "Check /readyz"
[ "$(status "http://${ADMIN_ADDR}/readyz")" = "200" ] && echo "✅ /readyz: 200" || { echo "❌ /readyz not 200"; exit 1; }

say "GET /v1/ping (expect 200)"
[ "$(status -X GET "http://${API_ADDR}/v1/ping")" = "200" ] && echo "✅ GET /v1/ping: 200" || { echo "❌ ping"; exit 1; }

POLICY_METRIC="policy_middleware_shortcircuits_total"
BODY_METRIC="body_reject_total"
DECOMP_METRIC="decompress_reject_total"

P_BEFORE="$(metric_sum "$POLICY_METRIC")"
B_BEFORE="$(metric_sum "$BODY_METRIC")"
D_BEFORE="$(metric_sum "$DECOMP_METRIC")"

say "PUT /v1/ping with Content-Length: 0 (expect policy 403)"
[ "$(status -X PUT -H "Content-Length: 0" "http://${API_ADDR}/v1/ping")" = "403" ] && echo "✅ PUT /v1/ping (CL:0): 403" || { echo "❌ policy 403"; exit 1; }

say "PUT /v1/ping with stacked encodings (expect 415)"
[ "$(status -X PUT -H "Content-Encoding: gzip, br" -H "Content-Length: 0" "http://${API_ADDR}/v1/ping")" = "415" ] && echo "✅ PUT /v1/ping (stacked encodings): 415" || { echo "❌ 415"; exit 1; }

say "PUT /v1/ping oversize body (expect 413)"
TMP_BIG="$(mktemp -t omnigate-big.XXXXXX)"
if head -c "$((MAX_BODY + 1))" /dev/zero > "$TMP_BIG" 2>/dev/null; then :; else
  dd if=/dev/zero bs=1 count=$((MAX_BODY + 1)) of="$TMP_BIG" status=none
fi
[ "$(status -X PUT --data-binary @"$TMP_BIG" "http://${API_ADDR}/v1/ping")" = "413" ] && echo "✅ PUT /v1/ping (oversize): 413" || { echo "❌ 413"; rm -f "$TMP_BIG"; exit 1; }
rm -f "$TMP_BIG"

P_AFTER="$(metric_sum "$POLICY_METRIC")"
B_AFTER="$(metric_sum "$BODY_METRIC")"
D_AFTER="$(metric_sum "$DECOMP_METRIC")"

say "Metrics deltas"
printf "  %s: %s -> %s  (Δ=%s)\n" "$POLICY_METRIC" "$P_BEFORE" "$P_AFTER" "$((P_AFTER - P_BEFORE))"
printf "  %s: %s -> %s  (Δ=%s)\n" "$BODY_METRIC"    "$B_BEFORE" "$B_AFTER" "$((B_AFTER - B_BEFORE))"
printf "  %s: %s -> %s  (Δ=%s)\n" "$DECOMP_METRIC"  "$D_BEFORE" "$D_AFTER" "$((D_AFTER - D_BEFORE))"

metric_show "$POLICY_METRIC"
metric_show "$BODY_METRIC"
metric_show "$DECOMP_METRIC"

say "All checks passed."

```

### crates/omnigate/scripts/smoke_readiness.sh
<a id="crates-omnigate-scripts-smokereadiness-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# RO:WHAT   Drive inflight & error proxies, then verify /readyz degrades (503) and recovers.
# RO:USE    OMNIGATE_DEV_READY=0 cargo run -p omnigate --bin omnigate
#           chmod +x crates/omnigate/scripts/smoke_readiness.sh
#           crates/omnigate/scripts/smoke_readiness.sh
# RO:ENV    BASE=http://127.0.0.1:5305  CONCURRENCY=600  DURATION=12  MS=800  POLL_TIMEOUT=25

BASE="${BASE:-http://127.0.0.1:5305}"
CONCURRENCY="${CONCURRENCY:-600}"   # macOS-safe; bump if your box can take it
DURATION="${DURATION:-12}"          # seconds to sustain load
MS="${MS:-800}"                     # /v1/sleep duration per request
POLL_TIMEOUT="${POLL_TIMEOUT:-25}"  # seconds to wait for a 503

get() { curl -sS -o /dev/null -w "%{http_code}" "$1"; }
say() { printf "%s\n" "$*"; }
ok() { printf "✅ %s\n" "$*"; }
bad() { printf "❌ %s\n" "$*" ; }

say ""
say "▶ Check /readyz before load"
code="$(get "$BASE/readyz")"
if [[ "$code" == "200" ]]; then ok "/readyz: 200"; else bad "/readyz: $code"; exit 1; fi

say ""
say "▶ Create inflight pressure via /v1/sleep?ms=$MS (CONCURRENCY=$CONCURRENCY for ${DURATION}s)"

# Background load generator (bounded duration)
(
  end=$((SECONDS + DURATION))
  while (( SECONDS < end )); do
    # Fire CONCURRENCY requests, then wait for them to complete
    for _ in $(seq 1 "$CONCURRENCY"); do
      curl -sS -o /dev/null "$BASE/v1/sleep?ms=$MS" &
    done
    wait
  done
) & LOAD_PID=$!

say ""
say "▶ Poll /readyz for degrade (expect 503 within a few seconds)"
deadline=$((SECONDS + POLL_TIMEOUT))
tripped=0
while (( SECONDS < deadline )); do
  code="$(get "$BASE/readyz")"
  if [[ "$code" == "503" ]]; then
    ok "Observed degrade: /readyz -> 503"
    tripped=1
    break
  fi
  sleep 0.25
done

# Stop background load if it’s still running
if ps -p "$LOAD_PID" >/dev/null 2>&1; then kill "$LOAD_PID" 2>/dev/null || true; wait "$LOAD_PID" 2>/dev/null || true; fi

if [[ "$tripped" == "0" ]]; then
  bad "Did not observe degrade (still 200)"
  # Show quick gauges to help debug thresholds
  say ""
  say "---- readiness gauges ----"
  curl -sS "$BASE/ops/metrics" | grep -E 'ready_(inflight_current|error_rate_pct|queue_saturated)' || true
  exit 1
fi

say ""
say "▶ Hold window check: /readyz should remain 503 briefly, then recover"
sleep 1
code="$(get "$BASE/readyz")"
say "   now: $code (will go back to 200 after hold_for_secs)"

say ""
say "---- readiness gauges ----"
curl -sS "$BASE/ops/metrics" | grep -E 'ready_(inflight_current|error_rate_pct|queue_saturated)'

ok "All checks executed."

```

### crates/omnigate/scripts/soak.sh
<a id="crates-omnigate-scripts-soak-sh"></a>

```bash
#!/usr/bin/env bash
# Scaffold: 24h soak runner placeholder.

```

### crates/omnigate/src/admission/fair_queue.rs
<a id="crates-omnigate-src-admission-fairqueue-rs"></a>

```rust
//! RO:WHAT  Inflight cap with interactive headroom (priority via x-omnigate-priority).
//! RO:WHY   Shed overload early with stable semantics and visibility into capacity.
//! RO:INVARS Single-writer discipline for counters; label bounds on metrics.

use std::sync::{
    atomic::{AtomicUsize, Ordering},
    Arc,
};

use axum::{
    body::Body,
    extract::State,
    http::{HeaderMap, HeaderName, HeaderValue, Request, StatusCode},
    middleware::{from_fn_with_state, Next},
    response::{IntoResponse, Response},
    Router,
};
use serde::Serialize;

const HEADER_PRIORITY: &str = "x-omnigate-priority";

#[derive(Clone)]
struct Gate {
    hard: usize,
    headroom: usize,
    in_flight: Arc<AtomicUsize>,
}

impl Gate {
    fn new(hard: usize, headroom: usize) -> Self {
        Self {
            hard,
            headroom,
            in_flight: Arc::new(AtomicUsize::new(0)),
        }
    }

    fn limit_for(&self, headers: &HeaderMap) -> usize {
        match headers
            .get(HEADER_PRIORITY)
            .and_then(|v| v.to_str().ok())
            .unwrap_or("bulk")
        {
            "interactive" => self.hard + self.headroom,
            _ => self.hard,
        }
    }

    fn try_enter(&self, headers: &HeaderMap) -> bool {
        let cap = self.limit_for(headers);
        loop {
            let cur = self.in_flight.load(Ordering::Relaxed);
            if cur >= cap {
                return false;
            }
            if self
                .in_flight
                .compare_exchange(cur, cur + 1, Ordering::AcqRel, Ordering::Relaxed)
                .is_ok()
            {
                // reflect the new inflight count to readiness gauges
                crate::metrics::gates::READY_INFLIGHT_CURRENT.set((cur + 1) as i64);
                return true;
            }
        }
    }

    fn leave(&self) {
        let prev = self.in_flight.fetch_sub(1, Ordering::AcqRel);
        // saturating floor at 0 for safety
        let now = prev.saturating_sub(1);
        crate::metrics::gates::READY_INFLIGHT_CURRENT.set(now as i64);
    }
}

#[derive(Serialize)]
struct ErrorBody<'a> {
    reason: &'a str,
    message: &'a str,
}

async fn fairness_guard(State(gate): State<Arc<Gate>>, req: Request<Body>, next: Next) -> Response {
    if gate.try_enter(req.headers()) {
        // admitted: queue not saturated
        crate::metrics::gates::READY_QUEUE_SATURATED.set(0);

        struct Guard(Arc<Gate>);
        impl Drop for Guard {
            fn drop(&mut self) {
                self.0.leave();
            }
        }
        let cap = gate.limit_for(req.headers());
        let _guard = Guard(gate.clone());

        let mut resp = next.run(req).await;
        let _ = resp.headers_mut().insert(
            HeaderName::from_static("x-omnigate-cap"),
            HeaderValue::from_str(&cap.to_string()).unwrap_or(HeaderValue::from_static("0")),
        );
        resp
    } else {
        // Shed: mark queue saturation and count a drop event.
        crate::metrics::gates::READY_QUEUE_SATURATED.set(1);
        crate::metrics::FAIR_Q_EVENTS_TOTAL
            .with_label_values(&["dropped"])
            .inc();

        (
            StatusCode::SERVICE_UNAVAILABLE,
            axum::Json(ErrorBody {
                reason: "overloaded",
                message: "server is shedding load; please retry",
            }),
        )
            .into_response()
    }
}

/// Attach the fair-queue guard with the current (default) capacity.
/// NOTE: retained for tests/back-compat; prefer `attach_with_cfg`.
pub fn attach<S>(router: Router<S>) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    router.layer(from_fn_with_state(
        Arc::new(Gate::new(256, 32)),
        fairness_guard,
    ))
}

/// Attach the fair-queue guard using FairQueue from Config.
pub fn attach_with_cfg<S>(router: Router<S>, fq: &crate::config::FairQueue) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    let (hard, headroom) = fq.hard_and_headroom();
    let gate = Arc::new(Gate::new(hard, headroom));
    router.layer(from_fn_with_state(gate, fairness_guard))
}

```

### crates/omnigate/src/admission/mod.rs
<a id="crates-omnigate-src-admission-mod-rs"></a>

```rust
// crates/omnigate/src/admission/mod.rs
//! RO:WHAT   Admission composite attach point.
//! RO:WHY    Single place to enable quotas + fair-queue before handlers.
//! RO:INVARS Layers are low-cardinality; return 429/503 only.

mod fair_queue;
mod quotas;

use axum::Router;

/// Attach admission layers (quotas first, then fairness shed) using defaults.
/// Kept for tests/back-compat. Prefer `attach_with_cfg`.
pub fn attach<S>(router: Router<S>) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    // Quotas first (fast reject), then fairness gate.
    fair_queue::attach(quotas::attach(router))
}

/// Attach admission layers using values from Config.
/// Order matters: quotas first, then fair-queue.
/// NOTE: Decompression guard is layered in `middleware::apply_with_cfg`.
pub fn attach_with_cfg<S>(router: Router<S>, cfg: &crate::config::Admission) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    // Pass the whole Admission to quotas (it needs both global & ip slices)
    let r = quotas::attach_with_cfg(router, cfg);
    // Then pass just the FairQueue part to the fairness gate
    fair_queue::attach_with_cfg(r, &cfg.fair_queue)
}

```

### crates/omnigate/src/admission/quotas.rs
<a id="crates-omnigate-src-admission-quotas-rs"></a>

```rust
// crates/omnigate/src/admission/quotas.rs
//! RO:WHAT  Global + per-IP token-bucket admission guards that return 429 when over limit.
//! RO:WHY   Prevent abuse/overload by bounding request rate upfront, before heavy work.
//! RO:INVARS Constant-time hot path; no label explosion; pure edge guards; no drift in deps.

use std::{
    collections::HashMap,
    sync::{Arc, Mutex},
    time::Instant,
};

use axum::{
    body::Body,
    extract::State,
    http::{HeaderMap, Request},
    middleware::{from_fn_with_state, Next},
    response::{IntoResponse, Response},
    Router,
};

use crate::errors::GateError;

// -----------------------------
// Bucket + limiter primitives
// -----------------------------

#[derive(Debug)]
struct Bucket {
    tokens: f64,
    last: Instant,
    rate_per_sec: f64,
    burst: f64,
}

impl Bucket {
    fn new(qps: u64, burst: u64) -> Self {
        let now = Instant::now();
        Self {
            tokens: burst as f64,
            last: now,
            rate_per_sec: qps as f64,
            burst: burst as f64,
        }
    }

    #[inline]
    fn allow(&mut self) -> bool {
        let now = Instant::now();
        let dt = (now - self.last).as_secs_f64();
        self.last = now;

        // refill
        self.tokens = (self.tokens + dt * self.rate_per_sec).min(self.burst);

        if self.tokens >= 1.0 {
            self.tokens -= 1.0;
            true
        } else {
            false
        }
    }
}

// -----------------------------
// Global limiter
// -----------------------------

#[derive(Clone)]
struct GlobalLimiter {
    inner: Arc<Mutex<Bucket>>,
}

impl GlobalLimiter {
    fn new(qps: u64, burst: u64) -> Self {
        Self {
            inner: Arc::new(Mutex::new(Bucket::new(qps, burst))),
        }
    }

    #[inline]
    fn allow(&self) -> bool {
        let mut b = self.inner.lock().expect("global limiter poisoned");
        b.allow()
    }
}

async fn global_quota_guard(
    State(glob): State<GlobalLimiter>,
    req: Request<Body>,
    next: Next,
) -> Response {
    if glob.allow() {
        next.run(req).await
    } else {
        // Heuristic small backoff; refine later if needed.
        let retry_ms = 50u64;

        // Metrics bump (scope=global, reason=qps).
        crate::metrics::gates::QUOTA_REJECT_TOTAL
            .with_label_values(&["global", "qps"])
            .inc();

        GateError::RateLimitedGlobal {
            retry_after_ms: retry_ms,
        }
        .into_response()
    }
}

// -----------------------------
// Per-IP limiter (optional)
// -----------------------------

#[derive(Clone)]
struct IpLimiter {
    rate: u64,
    burst: u64,
    enabled: bool,
    by_ip: Arc<Mutex<HashMap<String, Bucket>>>,
}

impl IpLimiter {
    fn new(enabled: bool, qps: u64, burst: u64) -> Self {
        Self {
            rate: qps,
            burst,
            enabled,
            by_ip: Arc::new(Mutex::new(HashMap::new())),
        }
    }

    #[inline]
    fn allow(&self, ip: &str) -> bool {
        if !self.enabled {
            return true;
        }
        let mut map = self.by_ip.lock().expect("ip limiter poisoned");
        let b = map
            .entry(ip.to_string())
            .or_insert_with(|| Bucket::new(self.rate, self.burst));
        b.allow()
    }
}

fn ip_from_headers(headers: &HeaderMap) -> String {
    if let Some(v) = headers.get("x-forwarded-for") {
        if let Ok(s) = v.to_str() {
            if let Some(first) = s.split(',').next() {
                return first.trim().to_string();
            }
        }
    }
    if let Some(v) = headers.get("x-real-ip") {
        if let Ok(s) = v.to_str() {
            return s.trim().to_string();
        }
    }
    "local".to_string()
}

async fn ip_quota_guard(State(ipq): State<IpLimiter>, req: Request<Body>, next: Next) -> Response {
    let ip = ip_from_headers(req.headers());
    if ipq.allow(&ip) {
        next.run(req).await
    } else {
        let retry_ms = 50u64;

        // Metrics bump (scope=ip, reason=qps).
        crate::metrics::gates::QUOTA_REJECT_TOTAL
            .with_label_values(&["ip", "qps"])
            .inc();

        GateError::RateLimitedIp {
            retry_after_ms: retry_ms,
        }
        .into_response()
    }
}

// -----------------------------
// Attach points
// -----------------------------

/// Attach the quota limiter layer with **default constants** (test/back-compat).
/// Prefer `attach_with_cfg` in production paths.
pub fn attach<S>(router: Router<S>) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    router
        .layer(from_fn_with_state(
            GlobalLimiter::new(500, 1000),
            global_quota_guard,
        ))
        .layer(from_fn_with_state(
            IpLimiter::new(false, 200, 400),
            ip_quota_guard,
        ))
}

/// Attach quota limiters using values from **Admission** config.
/// Order: global first (cheap, broad), then per-IP (optional).
pub fn attach_with_cfg<S>(router: Router<S>, adm: &crate::config::Admission) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    let ip = &adm.ip_quota;

    router
        .layer(from_fn_with_state(
            GlobalLimiter::new(adm.global_quota.qps, adm.global_quota.burst),
            global_quota_guard,
        ))
        .layer(from_fn_with_state(
            IpLimiter::new(ip.enabled, ip.qps, ip.burst),
            ip_quota_guard,
        ))
}

```

### crates/omnigate/src/auth/capability.rs
<a id="crates-omnigate-src-auth-capability-rs"></a>

```rust
/// STUBBED - FINISH SVC-PASSPORT THEN COME BACK
```

### crates/omnigate/src/auth/mod.rs
<a id="crates-omnigate-src-auth-mod-rs"></a>

```rust
/// STUBBED - FINISH SVC-PASSPORT THEN COME BACK
```

### crates/omnigate/src/auth/passport_client.rs
<a id="crates-omnigate-src-auth-passportclient-rs"></a>

```rust
/// STUBBED - FINISH SVC-PASSPORT THEN COME BACK
```

### crates/omnigate/src/auth/revocation.rs
<a id="crates-omnigate-src-auth-revocation-rs"></a>

```rust
/// STUBBED - FINISH SVC-PASSPORT THEN COME BACK
```

### crates/omnigate/src/bootstrap/health_probe.rs
<a id="crates-omnigate-src-bootstrap-healthprobe-rs"></a>

```rust
//! RO:WHAT — Helpers for health/readiness wiring (stubs for future use).
//! RO:WHY  — Keep separation of concerns; Concerns: RES/GOV.
//! RO:INTERACTS — ron_kernel::metrics::{health, readiness}.

pub struct HealthProbe; // future: gates for downstream client binding, queues_ok, etc.

```

### crates/omnigate/src/bootstrap/metrics_server.rs
<a id="crates-omnigate-src-bootstrap-metricsserver-rs"></a>

```rust
//! RO:WHAT — Placeholder to document metrics server behavior (served by ron-kernel Metrics).
//! RO:WHY  — Keep parity with TODO structure; Concerns: GOV/OBS.
//! RO:INTERACTS — ron_kernel::Metrics::serve() started in App::build().
//! RO:INVARIANTS — none here; admin plane lives in kernel exporter.

/// Metrics server is started in `App::build()` via `ron_kernel::Metrics::serve`.
pub struct MetricsServer;

```

### crates/omnigate/src/bootstrap/mod.rs
<a id="crates-omnigate-src-bootstrap-mod-rs"></a>

```rust
//! RO:WHAT — Bootstrap modules: API server, metrics server (via kernel), health probe helpers.
//! RO:WHY  — Keep main.rs tiny; Concerns: RES/PERF (clean layering, quick start/stop).
//! RO:INTERACTS — server.rs (axum serve), metrics_server.rs (delegates to ron-kernel), health_probe.rs.
//! RO:INVARIANTS — single writer per listener; truthful readiness; no blocking in async.

pub mod health_probe;
pub mod metrics_server;
pub mod server;

```

### crates/omnigate/src/bootstrap/server.rs
<a id="crates-omnigate-src-bootstrap-server-rs"></a>

```rust
//! RO:WHAT — Axum HTTP server bootstrap for the API plane.
//! RO:WHY  — Separate from main; Concerns: RES/PERF; handles bind + graceful-ish shutdown.
//! RO:INTERACTS — axum::Router, crate::config::Server, ron-kernel readiness (future toggle).
//! RO:INVARIANTS — bind before marking ready; one server task, one listener; stop cleanly on Ctrl-C.

use axum::Router;
use std::net::SocketAddr;
use tokio::task::JoinHandle;
use tracing::{error, info};

pub async fn serve(
    cfg: crate::config::Server,
    router: Router,
) -> anyhow::Result<(JoinHandle<()>, SocketAddr)> {
    // Bind first to satisfy "bind before ready".
    let listener = tokio::net::TcpListener::bind(cfg.bind).await?;
    let local: SocketAddr = listener.local_addr()?;
    info!(%local, "api listener bound");

    // Axum/Hyper server with graceful shutdown on Ctrl-C.
    // (Main still holds the JoinHandle and can abort on top; this just ensures
    //  a clean drain when Ctrl-C is delivered to the process.)
    let http = axum::serve(listener, router).with_graceful_shutdown(async {
        // Best-effort: if ctrl_c fails, just keep serving.
        if let Err(e) = tokio::signal::ctrl_c().await {
            // Log once; we don't bubble this up because we want the server to continue.
            error!(error=?e, "ctrl-c listener failed in server task");
        }
    });

    let task = tokio::spawn(async move {
        if let Err(e) = http.await {
            // This fires on listener errors or if the accept loop ends unexpectedly.
            tracing::error!(error=?e, "http server stopped with error");
        } else {
            tracing::info!("http server exited");
        }
    });

    Ok((task, local))
}

```

### crates/omnigate/src/config/env.rs
<a id="crates-omnigate-src-config-env-rs"></a>

```rust
//! RO:WHAT — Apply env var overrides to Config.
//! RO:WHY  — 12 Pillars hardening: explicit/typed config; Concerns: GOV.
//! RO:INVARIANTS — Only documented keys; parse-safe; no panics.

use super::Config;
use std::env;

pub fn apply_env_overrides(cfg: &mut Config) -> anyhow::Result<()> {
    if let Ok(v) = env::var("OMNIGATE_BIND") {
        cfg.server.bind = v.parse()?;
    }
    if let Ok(v) = env::var("OMNIGATE_METRICS_ADDR") {
        cfg.server.metrics_addr = v.parse()?;
    }
    if let Ok(v) = env::var("OMNIGATE_AMNESIA") {
        cfg.server.amnesia = matches!(v.as_str(), "1" | "true" | "on" | "yes" | "TRUE");
    }
    Ok(())
}

```

### crates/omnigate/src/config/file.rs
<a id="crates-omnigate-src-config-file-rs"></a>

```rust
//! RO:WHAT — Load Config from TOML file if present (simple search).

use super::Config;
use std::{fs, path::PathBuf};

const DEFAULT_PATHS: &[&str] = &[
    "crates/omnigate/configs/omnigate.toml", // repo-relative (dev)
    "configs/omnigate.toml",                 // crate-relative (installed)
    "/etc/ron/omnigate.toml",                // system
];

pub fn load_from_default_path() -> anyhow::Result<Option<Config>> {
    for p in DEFAULT_PATHS {
        if let Some(cfg) = try_load(PathBuf::from(p))? {
            return Ok(Some(cfg));
        }
    }
    Ok(None)
}

fn try_load(path: PathBuf) -> anyhow::Result<Option<Config>> {
    if !path.exists() {
        return Ok(None);
    }
    let s = fs::read_to_string(&path)?;
    let cfg: Config = toml::from_str::<Config>(&s)?;
    Ok(Some(cfg))
}

```

### crates/omnigate/src/config/mod.rs
<a id="crates-omnigate-src-config-mod-rs"></a>

```rust
// crates/omnigate/src/config/mod.rs
//! RO:WHAT   Omnigate configuration model + loaders (env/file) + defaults.
//! RO:INVARS  oap.max_frame_bytes ≤ 1MiB; body caps aligned with middleware guards.

use serde::Deserialize;
use std::{fs, net::SocketAddr, path::Path};

mod env;
mod file;
mod validate;

#[derive(Debug, Clone, Deserialize)]
pub struct Config {
    pub server: Server,
    pub oap: Oap,
    #[serde(default)]
    pub admission: Admission,
    pub policy: Policy,
    pub readiness: Readiness,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Server {
    /// API listener bind, e.g. "127.0.0.1:5305"
    pub bind: SocketAddr,
    /// Admin/metrics bind, e.g. "127.0.0.1:9605"
    pub metrics_addr: SocketAddr,
    pub amnesia: bool,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Oap {
    pub max_frame_bytes: u64,
    pub stream_chunk_bytes: u64,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Admission {
    #[serde(default)]
    pub global_quota: GlobalQuota,
    #[serde(default)]
    pub ip_quota: IpQuota,
    #[serde(default)]
    pub fair_queue: FairQueue,
    #[serde(default)]
    pub body: BodyCaps,
    #[serde(default)]
    pub decompression: Decompress,
}

impl Default for Admission {
    fn default() -> Self {
        Self {
            global_quota: GlobalQuota {
                qps: 20_000,
                burst: 40_000,
            },
            ip_quota: IpQuota {
                enabled: true,
                qps: 2_000,
                burst: 4_000,
            },
            fair_queue: FairQueue {
                max_inflight: 2_048,
                headroom: None, // computed as 1/8th of hard cap if absent
                weights: Weights {
                    anon: 1,
                    auth: 5,
                    admin: 10,
                },
            },
            body: BodyCaps {
                max_content_length: 1_048_576 * 10,
                reject_on_missing_length: true,
            },
            decompression: Decompress {
                allow: vec!["identity".into(), "gzip".into()],
                deny_stacked: true,
            },
        }
    }
}

#[derive(Default, Debug, Clone, Deserialize)]
pub struct GlobalQuota {
    pub qps: u64,
    pub burst: u64,
}

impl GlobalQuota {
    /// Downcast to the types our limiter expects.
    #[inline]
    pub fn params_u32(&self) -> (u32, u32) {
        (self.qps as u32, self.burst as u32)
    }
}

#[derive(Default, Debug, Clone, Deserialize)]
pub struct IpQuota {
    #[serde(default)]
    pub enabled: bool,
    pub qps: u64,
    pub burst: u64,
}

#[derive(Debug, Clone, Deserialize)]
pub struct FairQueue {
    /// Maximum in-flight (the hard cap).
    pub max_inflight: u64,
    /// Optional extra headroom for interactive traffic.
    /// If None, computed as `max_inflight / 8`.
    #[serde(default)]
    pub headroom: Option<u64>,
    #[serde(default)]
    pub weights: Weights,
}

impl Default for FairQueue {
    fn default() -> Self {
        Self {
            max_inflight: 2_048,
            headroom: None,
            // Mirror the Admission::default() weights so serde(default) yields identical behavior.
            weights: Weights {
                anon: 1,
                auth: 5,
                admin: 10,
            },
        }
    }
}

impl FairQueue {
    /// Returns (hard, headroom) as `usize` for guards.
    #[inline]
    pub fn hard_and_headroom(&self) -> (usize, usize) {
        let hard = self.max_inflight as usize;
        // clippy(unnecessary_min_or_max): value is non-negative already (u64)
        let head = self.headroom.unwrap_or(self.max_inflight / 8) as usize;
        (hard, head)
    }
}

#[derive(Debug, Clone, Deserialize, Default)]
pub struct Weights {
    #[serde(default)]
    pub anon: u32,
    #[serde(default)]
    pub auth: u32,
    #[serde(default)]
    pub admin: u32,
}

#[derive(Debug, Clone, Deserialize)]
pub struct BodyCaps {
    pub max_content_length: u64,
    pub reject_on_missing_length: bool,
}

impl Default for BodyCaps {
    fn default() -> Self {
        Self {
            max_content_length: 1_048_576 * 10,
            reject_on_missing_length: true,
        }
    }
}

#[derive(Debug, Clone, Deserialize)]
pub struct Decompress {
    #[serde(default)]
    pub allow: Vec<String>,
    #[serde(default)]
    pub deny_stacked: bool,
}

impl Default for Decompress {
    fn default() -> Self {
        Self {
            allow: vec!["identity".into(), "gzip".into()],
            deny_stacked: true,
        }
    }
}

#[derive(Debug, Clone, Deserialize)]
pub struct Policy {
    pub enabled: bool,
    pub bundle_path: String,
    /// "deny" or "allow" on evaluator failure (kept for future use).
    #[serde(default = "Policy::default_fail_mode")]
    pub fail_mode: String,
}

impl Policy {
    fn default_fail_mode() -> String {
        "deny".into()
    }
    pub fn fail_deny(&self) -> bool {
        self.fail_mode.eq_ignore_ascii_case("deny")
    }
}

#[derive(Debug, Clone, Deserialize)]
pub struct Readiness {
    pub max_inflight_threshold: u64,
    pub error_rate_429_503_pct: f64,
    pub window_secs: u64,
    pub hold_for_secs: u64,
}

impl Config {
    /// Load config with precedence: CLI `--config <path>` (handled in main) → env overrides → defaults/file.
    pub fn load() -> anyhow::Result<Self> {
        // Try file from default search paths.
        if let Some(cfg) = file::load_from_default_path()? {
            let mut cfg = cfg;
            env::apply_env_overrides(&mut cfg)?;
            validate::validate(&cfg)?;
            anyhow::ensure!(
                cfg.oap.max_frame_bytes <= 1_048_576,
                "oap.max_frame_bytes > 1MiB not allowed"
            );
            return Ok(cfg);
        }

        // Fallback minimal defaults (safe localhost).
        let mut cfg = Self {
            server: Server {
                bind: "127.0.0.1:5305".parse()?,
                metrics_addr: "127.0.0.1:9605".parse()?,
                amnesia: true,
            },
            oap: Oap {
                max_frame_bytes: 1_048_576,
                stream_chunk_bytes: 65_536,
            },
            admission: Admission::default(),
            policy: Policy {
                enabled: false,
                bundle_path: "policy.bundle.json".into(),
                fail_mode: "deny".into(),
            },
            readiness: Readiness {
                max_inflight_threshold: 1_800,
                error_rate_429_503_pct: 2.0,
                window_secs: 10,
                hold_for_secs: 30,
            },
        };
        env::apply_env_overrides(&mut cfg)?;
        validate::validate(&cfg)?;
        Ok(cfg)
    }

    /// Explicit file load (used by main when `--config` is provided).
    pub fn from_toml_file<P: AsRef<Path>>(p: P) -> anyhow::Result<Self> {
        let s = fs::read_to_string(p)?;
        let mut cfg: Self = toml::from_str(&s)?;
        env::apply_env_overrides(&mut cfg)?;
        validate::validate(&cfg)?;
        anyhow::ensure!(
            cfg.oap.max_frame_bytes <= 1_048_576,
            "oap.max_frame_bytes > 1MiB not allowed"
        );
        Ok(cfg)
    }
}

```

### crates/omnigate/src/config/reload.rs
<a id="crates-omnigate-src-config-reload-rs"></a>

```rust
//! RO:WHAT — Hot-reload scaffold (listen for kernel ConfigUpdated, apply).
//! RO:WHY  — RON pattern: runtime config changes without restart; Concerns: GOV/RES.
//! RO:INTERACTS — ron-kernel bus events; to be wired in Phase 2.

pub struct Reload; // placeholder for future reload worker

```

### crates/omnigate/src/config/validate.rs
<a id="crates-omnigate-src-config-validate-rs"></a>

```rust
//! RO:WHAT — Validate Config invariants (caps, limits).
//! RO:WHY  — Prevent misconfig from violating protocol/HTTP limits; Concerns: GOV/SEC.
//! RO:INVARIANTS — OAP max_frame=1MiB; body cap ≤1MiB; decompression ≤10x (to be added when body handling lands).

use super::Config;

pub fn validate(_cfg: &Config) -> anyhow::Result<()> {
    // Add concrete checks as data-plane routes land (body caps, timeouts, inflight).
    Ok(())
}

```

### crates/omnigate/src/downstream/dht_client.rs
<a id="crates-omnigate-src-downstream-dhtclient-rs"></a>

```rust
//! RO:WHAT   DHT service client (thin).
//! RO:WHY    Encapsulate K/V provider lookups etc.

use super::{build_client, DsError};
use std::time::Duration;

#[derive(Clone)]
pub struct DhtClient {
    base_url: String,
    client: reqwest::Client,
    connect_timeout: Duration,
    req_timeout: Duration,
}

impl Default for DhtClient {
    fn default() -> Self { Self::new("http://127.0.0.1:5301") }
}

impl DhtClient {
    pub fn new(base_url: &str) -> Self {
        Self {
            base_url: base_url.to_owned(),
            client: build_client(),
            connect_timeout: Duration::from_millis(200),
            req_timeout: Duration::from_secs(2),
        }
    }

    pub async fn healthz(&self) -> Result<String, DsError> {
        let url = format!("{}/healthz", self.base_url.trim_end_matches('/'));
        let res = self.client
            .get(url)
            .connect_timeout(self.connect_timeout)
            .timeout(self.req_timeout)
            .send().await?;
        if res.status().is_success() {
            Ok(res.text().await.unwrap_or_default())
        } else {
            Ok(format!("status={}", res.status().as_u16()))
        }
    }
}

```

### crates/omnigate/src/downstream/error.rs
<a id="crates-omnigate-src-downstream-error-rs"></a>

```rust
//! RO:WHAT   Egress error taxonomy.
//! RO:WHY    Normalize reqwest errors + HTTP status into a small set.

use thiserror::Error;

#[derive(Debug, Error)]
pub enum DsError {
    #[error("http {status}: {body}")]
    Http { status: u16, body: String },
    #[error("network: {0}")]
    Net(#[from] reqwest::Error),
    #[error("serde: {0}")]
    Serde(#[from] serde_json::Error),
}

impl DsError {
    pub fn is_retryable(&self) -> bool {
        match self {
            DsError::Http { status, .. } => (500..600).contains(status),
            DsError::Net(e) => e.is_connect() || e.is_timeout() || e.is_request(),
            DsError::Serde(_) => false,
        }
    }
}

```

### crates/omnigate/src/downstream/hedge.rs
<a id="crates-omnigate-src-downstream-hedge-rs"></a>

```rust
//! RO:WHAT   Hedged requests helper: launch a second attempt after a delay, take first success.
//! RO:WHY    Reduce tail latency for p95+ under occasional stragglers.
//! RO:INVARS  Max two in-flight per call; second attempt only if first hasn't finished.

use super::{DsError, RetryPolicy};
use rand::rngs::StdRng;
use tokio::task::JoinSet;
use std::future::Future;

pub async fn hedge2<F, T>(
    make_call: impl Fn() -> F + Send + Sync + 'static + Clone,
    hedged_after_ms: u64,
) -> Result<T, DsError>
where
    F: Future<Output = Result<T, DsError>> + Send + 'static,
    T: Send + 'static,
{
    let mut js = JoinSet::new();
    js.spawn(make_call.clone()());
    tokio::time::sleep(std::time::Duration::from_millis(hedged_after_ms)).await;
    js.spawn(make_call());

    while let Some(res) = js.join_next().await {
        match res {
            Ok(Ok(v)) => return Ok(v),
            Ok(Err(_)) => continue,
            Err(_) => continue,
        }
    }
    Err(DsError::Net(reqwest::Error::new(
        reqwest::ErrorKind::Request,
        "both hedged attempts failed",
    )))
}

```

### crates/omnigate/src/downstream/index_client.rs
<a id="crates-omnigate-src-downstream-indexclient-rs"></a>

```rust
//! RO:WHAT   Index service client (thin wrapper over reqwest).
//! RO:WHY    Keep service-specific paths/types out of generic code.
//! RO:INTERACTS  GET /healthz, generic JSON GET/POST for later expansion.

use super::{build_client, DsError, RetryPolicy, full_jitter_backoff};
use rand::rngs::StdRng;
use rand::SeedableRng;
use std::time::Duration;

#[derive(Clone)]
pub struct IndexClient {
    base_url: String,
    client: reqwest::Client,
    retry: RetryPolicy,
    connect_timeout: Duration,
    req_timeout: Duration,
}

impl Default for IndexClient {
    fn default() -> Self {
        Self::new("http://127.0.0.1:5304")
    }
}

impl IndexClient {
    pub fn new(base_url: &str) -> Self {
        Self {
            base_url: base_url.to_owned(),
            client: build_client(),
            retry: RetryPolicy::default(),
            connect_timeout: Duration::from_millis(200),
            req_timeout: Duration::from_secs(2),
        }
    }

    pub fn with_retry(mut self, retry: RetryPolicy) -> Self { self.retry = retry; self }

    pub async fn healthz(&self) -> Result<String, DsError> {
        self.get_text("/healthz", None).await
    }

    pub async fn get_json<T: serde::de::DeserializeOwned>(&self, path: &str) -> Result<T, DsError> {
        self.exec::<(), T>("GET", path, None, None).await
    }

    pub async fn post_json<B: serde::Serialize, T: serde::de::DeserializeOwned>(&self, path: &str, body: &B) -> Result<T, DsError> {
        self.exec("POST", path, Some(body), None).await
    }

    pub async fn get_text(&self, path: &str, corr_id: Option<&str>) -> Result<String, DsError> {
        self.exec::<(), String>("GET", path, None, corr_id).await
    }

    async fn exec<B: serde::Serialize, T: serde::de::DeserializeOwned>(
        &self,
        method: &str,
        path: &str,
        body: Option<&B>,
        corr_id: Option<&str>,
    ) -> Result<T, DsError> {
        let url = format!("{}/{}", self.base_url.trim_end_matches('/'), path.trim_start_matches('/'));
        let mut attempt = 1u32;
        let mut rng = StdRng::from_entropy();

        loop {
            let res = {
                let mut req = self.client
                    .request(reqwest::Method::from_bytes(method.as_bytes()).unwrap(), &url)
                    .connect_timeout(self.connect_timeout)
                    .timeout(self.req_timeout);

                if let Some(id) = corr_id {
                    if let Ok(v) = reqwest::header::HeaderValue::from_str(id) {
                        let mut h = req.headers_mut();
                        h.insert("x-correlation-id", v);
                    }
                }
                if let Some(b) = body {
                    req = req.json(b);
                }
                req.send().await
            };

            match res {
                Ok(r) if r.status().is_success() => {
                    if std::any::TypeId::of::<T>() == std::any::TypeId::of::<String>() {
                        // Fast path: text
                        let txt = r.text().await.map_err(DsError::Net)?;
                        // SAFETY: we know T=String at this call site
                        let any = unsafe { std::mem::transmute::<String, T>(txt) };
                        return Ok(any);
                    } else {
                        let txt = r.text().await.map_err(DsError::Net)?;
                        let out = serde_json::from_str::<T>(&txt)?;
                        return Ok(out);
                    }
                }
                Ok(r) => {
                    let status = r.status().as_u16();
                    let body = r.text().await.unwrap_or_default();
                    let err = DsError::Http { status, body };
                    if attempt >= self.retry.max_attempts || !err.is_retryable() {
                        return Err(err);
                    }
                    let sleep = full_jitter_backoff(attempt, self.retry.base_delay, self.retry.max_delay, &mut rng);
                    tokio::time::sleep(sleep).await;
                }
                Err(e) => {
                    let err = DsError::from(e);
                    if attempt >= self.retry.max_attempts || !err.is_retryable() {
                        return Err(err);
                    }
                    let sleep = full_jitter_backoff(attempt, self.retry.base_delay, self.retry.max_delay, &mut rng);
                    tokio::time::sleep(sleep).await;
                }
            }

            attempt += 1;
        }
    }
}

```

### crates/omnigate/src/downstream/latency.rs
<a id="crates-omnigate-src-downstream-latency-rs"></a>

```rust
//! RO:WHAT   Small latency helpers for downstream timing (standalone).
//! RO:WHY    Keep measurement logic trivial to test/mock.

use std::time::{Duration, Instant};

pub struct Timer(Instant);

impl Timer {
    pub fn start() -> Self { Self(Instant::now()) }
    pub fn stop(self) -> Duration { self.0.elapsed() }
}

```

### crates/omnigate/src/downstream/mailbox_client.rs
<a id="crates-omnigate-src-downstream-mailboxclient-rs"></a>

```rust
//! RO:WHAT   Mailbox/notification client (thin).
//! RO:WHY    Keeps notify calls decoupled from core.

use super::{build_client, DsError};
use std::time::Duration;

#[derive(Clone)]
pub struct MailboxClient {
    base_url: String,
    client: reqwest::Client,
    connect_timeout: Duration,
    req_timeout: Duration,
}

impl Default for MailboxClient {
    fn default() -> Self { Self::new("http://127.0.0.1:5310") }
}

impl MailboxClient {
    pub fn new(base_url: &str) -> Self {
        Self {
            base_url: base_url.to_owned(),
            client: build_client(),
            connect_timeout: Duration::from_millis(200),
            req_timeout: Duration::from_secs(2),
        }
    }

    pub async fn healthz(&self) -> Result<String, DsError> {
        let url = format!("{}/healthz", self.base_url.trim_end_matches('/'));
        let res = self.client
            .get(url)
            .connect_timeout(self.connect_timeout)
            .timeout(self.req_timeout)
            .send().await?;
        if res.status().is_success() {
            Ok(res.text().await.unwrap_or_default())
        } else {
            Ok(format!("status={}", res.status().as_u16()))
        }
    }
}

```

### crates/omnigate/src/downstream/mod.rs
<a id="crates-omnigate-src-downstream-mod-rs"></a>

```rust
//! RO:WHAT   Downstream (egress) HTTP client stack for calling RON services.
//! RO:WHY    Centralize retries, timeouts, and error taxonomy; keep wrappers thin.
//! RO:INTERACTS reqwest (rustls), tokio, crate::observability (corr-id later).
//! RO:INVARS  Finite timeouts; 4xx never retried; retries use jitter; no panics.

mod retry;
mod error;

pub mod latency;
pub mod hedge;

pub mod index_client;
pub mod storage_client;
pub mod mailbox_client;
pub mod dht_client;

pub use error::DsError;
pub use retry::{RetryPolicy, full_jitter_backoff};

use std::time::Duration;

/// RO:WHAT Build a default reqwest client suitable for internal calls.
/// RO:WHY  Ensure consistent TLS & connection settings.
pub fn build_client() -> reqwest::Client {
    reqwest::Client::builder()
        .pool_idle_timeout(Duration::from_secs(30))
        .tcp_keepalive(Duration::from_secs(30))
        .use_rustls_tls()
        .build()
        .expect("reqwest client")
}

```

### crates/omnigate/src/downstream/registry.rs
<a id="crates-omnigate-src-downstream-registry-rs"></a>

```rust
//! RO:WHAT   In-memory registry mapping ServiceKind -> Endpoint config.
//! RO:WHY    Late-binding of base URLs and timeouts; simple and explicit.
//! RO:INVARS  Base URLs are absolute; timeouts finite; defaults are localhost dev-safe.

use crate::downstream::types::ServiceKind;
use std::collections::HashMap;
use std::time::Duration;

#[derive(Debug, Clone)]
pub struct EndpointCfg {
    pub base_url: String,          // e.g., "http://127.0.0.1:5304"
    pub connect_timeout: Duration, // TCP connect
    pub timeout: Duration,         // whole request
}

#[derive(Debug, Clone)]
pub struct DownstreamRegistry {
    map: HashMap<ServiceKind, EndpointCfg>,
}

impl DownstreamRegistry {
    pub fn get(&self, k: ServiceKind) -> Option<&EndpointCfg> {
        self.map.get(&k)
    }

    pub fn insert(&mut self, k: ServiceKind, e: EndpointCfg) {
        self.map.insert(k, e);
    }
}

impl Default for DownstreamRegistry {
    fn default() -> Self {
        use ServiceKind::*;
        let mut map = HashMap::new();
        let fast = EndpointCfg {
            base_url: "http://127.0.0.1:5300".into(),
            connect_timeout: Duration::from_millis(200),
            timeout: Duration::from_secs(2),
        };
        // Dev-safe placeholders; change per crate ports as needed.
        map.insert(Index,   EndpointCfg { base_url: "http://127.0.0.1:5304".into(), ..fast.clone() });
        map.insert(Storage, EndpointCfg { base_url: "http://127.0.0.1:5303".into(), ..fast.clone() });
        map.insert(Dht,     EndpointCfg { base_url: "http://127.0.0.1:5301".into(), ..fast.clone() });
        map.insert(Naming,  EndpointCfg { base_url: "http://127.0.0.1:5302".into(), ..fast.clone() });
        map.insert(Overlay, EndpointCfg { base_url: "http://127.0.0.1:5306".into(), ..fast.clone() });
        map.insert(Policy,  EndpointCfg { base_url: "http://127.0.0.1:9609".into(), ..fast.clone() });
        Self { map }
    }
}

```

### crates/omnigate/src/downstream/retry.rs
<a id="crates-omnigate-src-downstream-retry-rs"></a>

```rust
//! RO:WHAT   Retry policy & jittered backoff helpers for outbound HTTP.
//! RO:WHY    Make transient failures tolerable without thundering herd.
//! RO:INVARS  Budgeted attempts; exponential w/ full jitter; never retry 4xx.

use rand::{rngs::StdRng, Rng, SeedableRng};
use std::time::Duration;

#[derive(Debug, Clone)]
pub struct RetryPolicy {
    pub max_attempts: u32,   // total, including first try
    pub base_delay: Duration,
    pub max_delay: Duration,
}

impl Default for RetryPolicy {
    fn default() -> Self {
        Self {
            max_attempts: 3,
            base_delay: Duration::from_millis(50),
            max_delay: Duration::from_millis(600),
        }
    }
}

pub fn full_jitter_backoff(attempt: u32, base: Duration, max: Duration, rng: &mut StdRng) -> Duration {
    let exp = base.saturating_mul(1u32.saturating_shl(attempt.saturating_sub(1).min(10)));
    let cap = std::cmp::min(exp, max);
    let nanos = rng.gen_range(0..=cap.as_nanos() as u128);
    Duration::from_nanos(nanos as u64)
}

pub fn new_rng() -> StdRng { StdRng::from_entropy() }

```

### crates/omnigate/src/downstream/storage_client.rs
<a id="crates-omnigate-src-downstream-storageclient-rs"></a>

```rust
//! RO:WHAT   Storage service client (thin).
//! RO:WHY    Keep storage-specific calls contained here.

use super::{build_client, DsError, RetryPolicy, full_jitter_backoff};
use rand::rngs::StdRng;
use rand::SeedableRng;
use std::time::Duration;

#[derive(Clone)]
pub struct StorageClient {
    base_url: String,
    client: reqwest::Client,
    retry: RetryPolicy,
    connect_timeout: Duration,
    req_timeout: Duration,
}

impl Default for StorageClient {
    fn default() -> Self { Self::new("http://127.0.0.1:5303") }
}

impl StorageClient {
    pub fn new(base_url: &str) -> Self {
        Self {
            base_url: base_url.to_owned(),
            client: build_client(),
            retry: RetryPolicy::default(),
            connect_timeout: Duration::from_millis(200),
            req_timeout: Duration::from_secs(3),
        }
    }

    pub async fn healthz(&self) -> Result<String, DsError> {
        self.get_text("/healthz").await
    }

    pub async fn get_text(&self, path: &str) -> Result<String, DsError> {
        self.exec::<(), String>("GET", path, None).await
    }

    pub async fn post_json<B: serde::Serialize, T: serde::de::DeserializeOwned>(&self, path: &str, body: &B) -> Result<T, DsError> {
        self.exec("POST", path, Some(body)).await
    }

    async fn exec<B: serde::Serialize, T: serde::de::DeserializeOwned>(
        &self,
        method: &str,
        path: &str,
        body: Option<&B>,
    ) -> Result<T, DsError> {
        let url = format!("{}/{}", self.base_url.trim_end_matches('/'), path.trim_start_matches('/'));
        let mut attempt = 1u32;
        let mut rng = StdRng::from_entropy();

        loop {
            let res = {
                let mut req = self.client
                    .request(reqwest::Method::from_bytes(method.as_bytes()).unwrap(), &url)
                    .connect_timeout(self.connect_timeout)
                    .timeout(self.req_timeout);

                if let Some(b) = body { req = req.json(b); }
                req.send().await
            };

            match res {
                Ok(r) if r.status().is_success() => {
                    if std::any::TypeId::of::<T>() == std::any::TypeId::of::<String>() {
                        let txt = r.text().await.map_err(DsError::Net)?;
                        let any = unsafe { std::mem::transmute::<String, T>(txt) };
                        return Ok(any);
                    } else {
                        let txt = r.text().await.map_err(DsError::Net)?;
                        let out = serde_json::from_str::<T>(&txt)?;
                        return Ok(out);
                    }
                }
                Ok(r) => {
                    let status = r.status().as_u16();
                    let body = r.text().await.unwrap_or_default();
                    let err = DsError::Http { status, body };
                    if attempt >= self.retry.max_attempts || !err.is_retryable() {
                        return Err(err);
                    }
                    let sleep = full_jitter_backoff(attempt, self.retry.base_delay, self.retry.max_delay, &mut rng);
                    tokio::time::sleep(sleep).await;
                }
                Err(e) => {
                    let err = DsError::from(e);
                    if attempt >= self.retry.max_attempts || !err.is_retryable() {
                        return Err(err);
                    }
                    let sleep = full_jitter_backoff(attempt, self.retry.base_delay, self.retry.max_delay, &mut rng);
                    tokio::time::sleep(sleep).await;
                }
            }
            attempt += 1;
        }
    }
}

```

### crates/omnigate/src/downstream/types.rs
<a id="crates-omnigate-src-downstream-types-rs"></a>

```rust
//! RO:WHAT   Core enums/types for downstream services.
//! RO:WHY    Keep labels low-cardinality and stable across releases.

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum ServiceKind {
    Index,
    Storage,
    Dht,
    Naming,
    Overlay,
    Policy, // if ever queried (bundle host, etc.)
}

impl ServiceKind {
    pub fn as_str(&self) -> &'static str {
        match self {
            ServiceKind::Index => "index",
            ServiceKind::Storage => "storage",
            ServiceKind::Dht => "dht",
            ServiceKind::Naming => "naming",
            ServiceKind::Overlay => "overlay",
            ServiceKind::Policy => "policy",
        }
    }
}

```

### crates/omnigate/src/errors/http_map.rs
<a id="crates-omnigate-src-errors-httpmap-rs"></a>

```rust
// crates/omnigate/src/errors/http_map.rs
//! RO:WHAT   Map admission/policy errors to stable JSON problem docs + helpers.
//! RO:WHY    Clients/SREs need consistent, parseable error envelopes.
//! RO:INTERACTS middleware::{quotas,fair_queue,body_caps,decompress_guard,policy}, admin plane.
//! RO:INVARS  Always include x-request-id upstream; no secret leakage; status matches code.

use axum::{
    http::{header::RETRY_AFTER, HeaderMap, HeaderValue, StatusCode},
    response::{IntoResponse, Response},
    Json,
};
use serde::Serialize;

use super::reasons::Reason;

/// Stable problem envelope for client-visible errors.
#[derive(Serialize)]
pub struct Problem<'a> {
    pub code: &'a str,
    pub message: &'a str,
    pub retryable: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub retry_after_ms: Option<u64>,
    /// Optional free-form reason (e.g., policy reason like "put blocked").
    #[serde(skip_serializing_if = "Option::is_none")]
    pub reason: Option<&'a str>,
}

/// Convert a millisecond budget into a Retry-After header value in SECONDS (ceil).
#[inline]
fn retry_after_header_secs(ms: u64) -> String {
    ms.div_ceil(1000).to_string()
}

/// Tiny helper used by tests and preflight guards: returns a canonical Problem JSON with the
/// HTTP status derived from `Reason`.
pub fn to_response(reason: Reason, message: &str) -> Response {
    let body = Problem {
        code: reason.code_str(),
        message,
        retryable: reason.retryable(),
        retry_after_ms: None,
        reason: None,
    };
    (reason.status(), Json(body)).into_response()
}

/// Admission / policy / overload error space rendered as Problem JSON.
pub enum GateError<'a> {
    // Admission
    RateLimitedGlobal {
        retry_after_ms: u64,
    },
    RateLimitedIp {
        retry_after_ms: u64,
    },
    PayloadTooLarge {
        limit: u64,
    },
    UnsupportedEncoding {
        encoding: &'a str,
    },
    StackedEncodings,

    // Policy
    /// 403 default, 451 for legal blocks (status provided by caller)
    PolicyDeny {
        reason: &'a str,
        status: StatusCode,
    },
    /// 503 when evaluator fails/errors
    PolicyError,

    // Overload
    /// 503 when readiness gate is down
    Degraded,
}

impl<'a> IntoResponse for GateError<'a> {
    fn into_response(self) -> Response {
        match self {
            GateError::RateLimitedGlobal { retry_after_ms } => {
                let mut headers = HeaderMap::new();
                let hv = HeaderValue::from_str(&retry_after_header_secs(retry_after_ms))
                    .unwrap_or_else(|_| HeaderValue::from_static("1"));
                headers.insert(RETRY_AFTER, hv);
                let body = Problem {
                    code: Reason::TooManyRequests.code_str(),
                    message: "Global rate limit",
                    retryable: true,
                    retry_after_ms: Some(retry_after_ms),
                    reason: None,
                };
                (StatusCode::TOO_MANY_REQUESTS, headers, Json(body)).into_response()
            }
            GateError::RateLimitedIp { retry_after_ms } => {
                let mut headers = HeaderMap::new();
                let hv = HeaderValue::from_str(&retry_after_header_secs(retry_after_ms))
                    .unwrap_or_else(|_| HeaderValue::from_static("1"));
                headers.insert(RETRY_AFTER, hv);
                let body = Problem {
                    code: Reason::TooManyRequests.code_str(),
                    message: "IP quota exceeded",
                    retryable: true,
                    retry_after_ms: Some(retry_after_ms),
                    reason: None,
                };
                (StatusCode::TOO_MANY_REQUESTS, headers, Json(body)).into_response()
            }
            GateError::PayloadTooLarge { .. } => {
                let body = Problem {
                    code: Reason::PayloadTooLarge.code_str(),
                    message: "Body exceeds limit",
                    retryable: false,
                    retry_after_ms: None,
                    reason: None,
                };
                (StatusCode::PAYLOAD_TOO_LARGE, Json(body)).into_response()
            }
            GateError::UnsupportedEncoding { .. } | GateError::StackedEncodings => {
                let body = Problem {
                    code: Reason::UnsupportedMediaType.code_str(),
                    message: "Encoding not allowed",
                    retryable: false,
                    retry_after_ms: None,
                    reason: None,
                };
                (StatusCode::UNSUPPORTED_MEDIA_TYPE, Json(body)).into_response()
            }
            GateError::PolicyDeny { reason, status } => {
                let code = if status == StatusCode::UNAVAILABLE_FOR_LEGAL_REASONS {
                    "LEGAL_RESTRICTION"
                } else {
                    "POLICY_DENY"
                };
                let body = Problem {
                    code,
                    message: "Access denied",
                    retryable: false,
                    retry_after_ms: None,
                    reason: Some(reason),
                };
                (status, Json(body)).into_response()
            }
            GateError::PolicyError => {
                // Small backoff hint (250ms) + header
                let retry_after_ms = 250u64;
                let mut headers = HeaderMap::new();
                let hv = HeaderValue::from_str(&retry_after_header_secs(retry_after_ms))
                    .unwrap_or_else(|_| HeaderValue::from_static("1"));
                headers.insert(RETRY_AFTER, hv);
                let body = Problem {
                    code: "POLICY_ERROR",
                    message: "Policy evaluation failed",
                    retryable: true,
                    retry_after_ms: Some(retry_after_ms),
                    reason: None,
                };
                (StatusCode::SERVICE_UNAVAILABLE, headers, Json(body)).into_response()
            }
            GateError::Degraded => {
                // Backoff hint (250ms) + header
                let retry_after_ms = 250u64;
                let mut headers = HeaderMap::new();
                let hv = HeaderValue::from_str(&retry_after_header_secs(retry_after_ms))
                    .unwrap_or_else(|_| HeaderValue::from_static("1"));
                headers.insert(RETRY_AFTER, hv);
                let body = Problem {
                    code: "SERVICE_DEGRADED",
                    message: "Overload protection",
                    retryable: true,
                    retry_after_ms: Some(retry_after_ms),
                    reason: None,
                };
                (StatusCode::SERVICE_UNAVAILABLE, headers, Json(body)).into_response()
            }
        }
    }
}

/// Generic downstream error mapper used by v1 passthrough routes (no crate::downstream dependency).
pub fn map_ds_error<E: std::fmt::Display>(e: E) -> (StatusCode, String) {
    (StatusCode::BAD_GATEWAY, e.to_string())
}

```

### crates/omnigate/src/errors/mod.rs
<a id="crates-omnigate-src-errors-mod-rs"></a>

```rust
//! RO:WHAT — Error taxonomy + HTTP mapping.
//! RO:WHY  — Deterministic errors (RON invariant); Concerns: DX/GOV.
//! RO:INTERACTS — http_map.rs, reasons.rs.

pub mod http_map;
pub mod reasons;

pub use http_map::{GateError, Problem};
pub use reasons::Reason;

```

### crates/omnigate/src/errors/reasons.rs
<a id="crates-omnigate-src-errors-reasons-rs"></a>

```rust
// RO:WHAT  Canonical reason codes used by http_map to produce JSON envelopes.
// RO:INVARS Codes are stable ASCII-UPPER_SNAKE where applicable.

use axum::http::StatusCode;

#[derive(Debug, Copy, Clone)]
pub enum Reason {
    // Common
    BadRequest,
    Unauthorized,
    Forbidden,
    NotFound,
    MethodNotAllowed,
    PayloadTooLarge,
    UnsupportedMediaType,
    TooManyRequests,
    Internal,

    // Policy
    PolicyDeny,
    PolicyError,

    // New: for 411 responses when payload methods omit Content-Length
    LengthRequired,
}

impl Reason {
    pub fn status(self) -> StatusCode {
        match self {
            Reason::BadRequest => StatusCode::BAD_REQUEST,
            Reason::Unauthorized => StatusCode::UNAUTHORIZED,
            Reason::Forbidden => StatusCode::FORBIDDEN,
            Reason::NotFound => StatusCode::NOT_FOUND,
            Reason::MethodNotAllowed => StatusCode::METHOD_NOT_ALLOWED,
            Reason::PayloadTooLarge => StatusCode::PAYLOAD_TOO_LARGE,
            Reason::UnsupportedMediaType => StatusCode::UNSUPPORTED_MEDIA_TYPE,
            Reason::TooManyRequests => StatusCode::TOO_MANY_REQUESTS,
            Reason::Internal => StatusCode::INTERNAL_SERVER_ERROR,

            Reason::PolicyDeny => StatusCode::FORBIDDEN,
            Reason::PolicyError => StatusCode::SERVICE_UNAVAILABLE,

            Reason::LengthRequired => StatusCode::LENGTH_REQUIRED, // 411
        }
    }

    pub fn code_str(self) -> &'static str {
        match self {
            Reason::BadRequest => "BAD_REQUEST",
            Reason::Unauthorized => "UNAUTHORIZED",
            Reason::Forbidden => "FORBIDDEN",
            Reason::NotFound => "NOT_FOUND",
            Reason::MethodNotAllowed => "METHOD_NOT_ALLOWED",
            Reason::PayloadTooLarge => "PAYLOAD_TOO_LARGE",
            Reason::UnsupportedMediaType => "UNSUPPORTED_MEDIA_TYPE",
            Reason::TooManyRequests => "TOO_MANY_REQUESTS",
            Reason::Internal => "INTERNAL",

            Reason::PolicyDeny => "POLICY_DENY",
            Reason::PolicyError => "POLICY_ERROR",

            Reason::LengthRequired => "LENGTH_REQUIRED",
        }
    }

    pub fn retryable(self) -> bool {
        matches!(
            self,
            Reason::TooManyRequests | Reason::PolicyError | Reason::Internal
        )
    }
}

```

### crates/omnigate/src/hydration/compose.rs
<a id="crates-omnigate-src-hydration-compose-rs"></a>

```rust

```

### crates/omnigate/src/hydration/mod.rs
<a id="crates-omnigate-src-hydration-mod-rs"></a>

```rust

```

### crates/omnigate/src/hydration/planner.rs
<a id="crates-omnigate-src-hydration-planner-rs"></a>

```rust

```

### crates/omnigate/src/lib.rs
<a id="crates-omnigate-src-lib-rs"></a>

```rust
// crates/omnigate/src/lib.rs
#![allow(clippy::needless_return)]

pub mod admission;
pub mod bootstrap;
pub mod config;
pub mod errors;
pub mod metrics;
pub mod middleware;
pub mod observability;
pub mod readiness;
pub mod routes;
pub mod runtime;
pub mod types;
pub mod zk;

use axum::{extract::State, response::IntoResponse, routing::get, Extension, Router};
use ron_kernel::metrics::{health::HealthState, readiness::Readiness as KernelReadiness};
use ron_kernel::Metrics;
use std::net::SocketAddr;
use std::sync::Arc;
use tracing::{info, warn};

use ron_policy::PolicyBundle;
use serde_json::Map;

#[derive(Clone)]
pub struct App {
    pub router: Router,
    pub admin_addr: SocketAddr,
}

impl App {
    pub async fn build(cfg: config::Config) -> anyhow::Result<Self> {
        let amnesia_from_cfg = cfg.server.amnesia;
        let amnesia_from_env = matches!(
            std::env::var("OMNIGATE_AMNESIA").as_deref(),
            Ok("1") | Ok("true") | Ok("TRUE") | Ok("on") | Ok("ON")
        );
        let amnesia_on = amnesia_from_cfg || amnesia_from_env;
        info!(
            amnesia_from_cfg,
            amnesia_from_env, amnesia_on, "amnesia mode resolved"
        );

        let metrics = Metrics::new(false);
        metrics.set_amnesia(amnesia_on);

        crate::metrics::gates::init_gate_metrics();

        let health = HealthState::new();
        let kernel_ready = KernelReadiness::new(health.clone());

        let (_admin_task, admin_addr) = metrics
            .clone()
            .serve(
                cfg.server.metrics_addr,
                health.clone(),
                kernel_ready.clone(),
            )
            .await
            .map_err(|e| anyhow::anyhow!("{}", e))?;

        health.set("omnigate", true);
        health.set("config", true);
        kernel_ready.set_config_loaded(true);

        let dev_ready = matches!(
            std::env::var("OMNIGATE_DEV_READY").as_deref(),
            Ok("1") | Ok("true") | Ok("TRUE") | Ok("on") | Ok("ON")
        );
        if dev_ready {
            info!("OMNIGATE_DEV_READY=on — /readyz will report 200 (dev override)");
        }

        // Local readiness policy + admin state
        let rp = Arc::new(readiness::policy::ReadyPolicy::new());
        let admin_state = readiness::state::AdminState::new(
            health.clone(),
            kernel_ready.clone(),
            dev_ready,
            &cfg.readiness,
            rp.clone(),
        );

        // -------------------- ROUTES --------------------
        let api_v1 = crate::routes::v1::index::router();

        async fn healthz(State(st): State<readiness::state::AdminState>) -> impl IntoResponse {
            ron_kernel::metrics::health::healthz_handler(st.health.clone()).await
        }

        let ops = Router::new()
            .route("/ops/version", get(crate::routes::ops::version))
            .route("/ops/readyz", get(readiness::readyz))
            .route("/ops/healthz", get(healthz))
            .route(
                "/ops/metrics",
                get(|| async {
                    use prometheus::TextEncoder;
                    let encoder = TextEncoder::new();
                    let mfs = prometheus::gather();
                    encoder.encode_to_string(&mfs).unwrap_or_default()
                }),
            )
            .with_state(admin_state.clone());

        let roots = Router::new()
            .route("/versionz", get(crate::routes::ops::versionz))
            .route("/readyz", get(readiness::readyz))
            .route("/healthz", get(healthz))
            .with_state(admin_state);

        // Base router (no layers yet)
        let mut app_router = Router::new().merge(roots).merge(ops).nest("/v1", api_v1);

        // -------------------- HTTP MIDDLEWARE + ADMISSION (INNER) --------------------
        // Apply the HTTP middleware stack first (includes PolicyLayer),
        // then admission (quotas/fair-queue) — these are INNER layers.
        app_router = middleware::apply_with_cfg(app_router, &cfg.admission)
            .layer(observability::http_trace_layer());
        app_router = crate::admission::attach_with_cfg(app_router, &cfg.admission);

        // -------------------- POLICY BUNDLE (OUTERMOST so inner policy layer can see it) --------------------
        // In Axum, the last .layer(...) is the outermost and runs first. We want the Extension
        // to run BEFORE the PolicyLayer (which we already added inside apply_with_cfg), so it must
        // be layered AFTER apply_with_cfg/admission.
        let mut have_bundle = false;
        if cfg.policy.enabled {
            match std::fs::read_to_string(&cfg.policy.bundle_path) {
                Ok(json) => match serde_json::from_str::<PolicyBundle>(&json) {
                    Ok(bundle) => {
                        crate::metrics::registry::POLICY_BUNDLE_LOADED_TOTAL.inc();
                        info!(path=%cfg.policy.bundle_path, "policy bundle loaded and inserted");
                        app_router = app_router.layer(Extension(Arc::new(bundle)));
                        have_bundle = true;
                    }
                    Err(e1) => {
                        let top_keys = serde_json::from_str::<serde_json::Value>(&json)
                            .ok()
                            .and_then(|v| {
                                v.as_object().map(|o| o.keys().cloned().collect::<Vec<_>>())
                            });
                        warn!(error=?e1, ?top_keys, path=%cfg.policy.bundle_path, "failed to parse policy bundle (strict)");
                        match serde_json::from_str::<serde_json::Value>(&json)
                            .ok()
                            .and_then(|mut v| {
                                normalize_policy_value(&mut v);
                                serde_json::from_value::<PolicyBundle>(v).ok()
                            }) {
                            Some(bundle) => {
                                crate::metrics::registry::POLICY_BUNDLE_LOADED_TOTAL.inc();
                                info!(path=%cfg.policy.bundle_path, "policy bundle loaded via normalized schema");
                                app_router = app_router.layer(Extension(Arc::new(bundle)));
                                have_bundle = true;
                            }
                            None => {
                                warn!(path=%cfg.policy.bundle_path, "policy bundle still failed after normalization; PolicyLayer will pass-through");
                            }
                        }
                    }
                },
                Err(e) => {
                    warn!(error=?e, path=%cfg.policy.bundle_path, "failed to read policy bundle; PolicyLayer will pass-through");
                }
            }
        } else {
            info!("policy disabled in config; PolicyLayer will no-op");
        }

        if have_bundle {
            info!("policy Extension layered outermost (visible to PolicyLayer)");
        }

        // ---- GLOBAL INFLIGHT BRIDGE (ABSOLUTE OUTERMOST) ----
        // We want this to run before everything to count every request.
        app_router = middleware::inflight::attach(app_router, rp.clone());

        // -------------------- READINESS SAMPLER --------------------
        readiness::sampler::spawn_err_rate_sampler(rp.clone(), cfg.readiness.window_secs);

        Ok(Self {
            router: app_router,
            admin_addr,
        })
    }
}

fn normalize_policy_value(root: &mut serde_json::Value) {
    let obj = match root.as_object_mut() {
        Some(m) => m,
        None => return,
    };
    if let Some(v) = obj.get_mut("version") {
        if v.is_string() {
            if let Ok(n) = v.as_str().unwrap_or_default().parse::<u32>() {
                *v = serde_json::Value::Number(serde_json::Number::from(n));
            }
        }
    } else {
        obj.insert(
            "version".to_string(),
            serde_json::Value::Number(1u32.into()),
        );
    }
    if let Some(desc) = obj.remove("description") {
        let meta = obj
            .entry("meta")
            .or_insert_with(|| serde_json::Value::Object(Map::new()));
        if let Some(mo) = meta.as_object_mut() {
            mo.entry("name".to_string()).or_insert(desc);
        }
    } else {
        obj.entry("meta")
            .or_insert_with(|| serde_json::Value::Object(Map::new()));
    }
    let mut defaults_obj = obj
        .remove("defaults")
        .and_then(|v| v.as_object().cloned())
        .unwrap_or_default();
    if let Some(def) = obj.remove("default") {
        defaults_obj
            .entry("default_action".to_string())
            .or_insert(def);
    }
    if let Some(v) = defaults_obj.remove("effect") {
        defaults_obj
            .entry("default_action".to_string())
            .or_insert(v);
    }
    defaults_obj
        .entry("default_action".to_string())
        .or_insert(serde_json::Value::String("deny".to_string()));
    obj.insert(
        "defaults".to_string(),
        serde_json::Value::Object(defaults_obj),
    );

    let mut rules = obj
        .remove("rules")
        .and_then(|v| v.as_array().cloned())
        .unwrap_or_else(Vec::new);
    for r in &mut rules {
        if let Some(ro) = r.as_object_mut() {
            if let Some(eff) = ro.remove("effect") {
                ro.entry("action".to_string()).or_insert(eff);
            }
        }
    }
    obj.insert("rules".to_string(), serde_json::Value::Array(rules));
}

```

### crates/omnigate/src/main.rs
<a id="crates-omnigate-src-main-rs"></a>

```rust
//! RO:WHAT — Omnigate binary entrypoint: loads config, boots admin plane, serves HTTP.
//! RO:WHY  — Small main to keep logic in lib; Concerns: GOV/RES (truthful health/ready, graceful shutdown).
//! RO:INTERACTS — omnigate::config, omnigate::bootstrap::server; ron-kernel surfaces.
//! RO:INVARIANTS — no locks across .await; graceful shutdown.

use omnigate::{bootstrap, config::Config};
use ron_kernel::wait_for_ctrl_c;
use tracing::{error, info};

#[tokio::main(flavor = "multi_thread")]
async fn main() -> anyhow::Result<()> {
    omnigate::observability::init_tracing();

    // Minimal arg scan so `--config path` works (used by smoke script).
    let mut args = std::env::args().skip(1);
    let mut cfg_path: Option<String> = None;
    while let Some(arg) = args.next() {
        if arg == "--config" {
            if let Some(p) = args.next() {
                cfg_path = Some(p);
            }
            break;
        }
    }

    let cfg = match cfg_path {
        Some(p) => Config::from_toml_file(p),
        None => Config::load(),
    }
    .map_err(|e| {
        error!(error=?e, "failed to load config");
        e
    })?;

    info!(amnesia = %cfg.server.amnesia, cfg=?cfg, "omnigate config");

    // Build app (starts admin plane) and serve the API listener.
    let app = omnigate::App::build(cfg.clone()).await?;

    let server_cfg = cfg.server;
    let admin_addr = server_cfg.metrics_addr;

    let (server_task, bind) = bootstrap::server::serve(server_cfg, app.router).await?;
    info!(%bind, %admin_addr, "omnigate up");

    let workers: Vec<omnigate::runtime::DynWorker> =
        vec![omnigate::runtime::sample::TickWorker::new() as _];
    let supervisor = omnigate::runtime::spawn_supervisor(workers, 128);

    wait_for_ctrl_c().await;

    let _ = supervisor
        .tx_cmd
        .send(omnigate::runtime::SupervisorMsg::Stop);
    supervisor.shutdown.cancel();
    let _ = supervisor.join.await;

    server_task.abort();
    Ok(())
}

```

### crates/omnigate/src/metrics/gates.rs
<a id="crates-omnigate-src-metrics-gates-rs"></a>

```rust
// crates/omnigate/src/metrics/gates.rs
//! RED/Readiness gate metrics (gauges + counters)
//!
//! Also hosts gate-level guard counters used by policy/body/decompress/quotas middleware
//! so everything exports from the *default* Prometheus registry. The API exposes
//! this registry via /ops/metrics.

use once_cell::sync::Lazy;
use prometheus::{
    register_gauge, register_int_counter_vec, register_int_gauge, Gauge, IntCounterVec, IntGauge,
};

// ==============================
// Readiness
// ==============================

pub static READY_INFLIGHT_CURRENT: Lazy<IntGauge> = Lazy::new(|| {
    register_int_gauge!(
        "ready_inflight_current",
        "Current in-flight requests as tracked by readiness policy"
    )
    .expect("register ready_inflight_current")
});

pub static READY_ERROR_RATE_PCT: Lazy<Gauge> = Lazy::new(|| {
    register_gauge!(
        "ready_error_rate_pct",
        "Rolling 429/503 error rate percentage over the readiness window"
    )
    .expect("register ready_error_rate_pct")
});

pub static READY_QUEUE_SATURATED: Lazy<IntGauge> = Lazy::new(|| {
    register_int_gauge!("ready_queue_saturated", "Queue saturation flag (0/1)")
        .expect("register ready_queue_saturated")
});

pub static READY_TRIPS_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "ready_trips_total",
        "Count of readiness trips to degraded by reason",
        &["reason"] // inflight | err_rate | queue
    )
    .expect("register ready_trips_total")
});

pub static READY_STATE_CHANGES_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "ready_state_changes_total",
        "Readiness state changes",
        &["to"] // ready | degraded
    )
    .expect("register ready_state_changes_total")
});

// ==============================
// Gate guards (counters)
// ==============================

/// Policy middleware short-circuits (deny/legal/error).
/// Label `code`: "403" | "451" | "503".
pub static POLICY_MIDDLEWARE_SHORTCIRCUITS_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "policy_middleware_shortcircuits_total",
        "Policy middleware short-circuited the request",
        &["code"]
    )
    .expect("register policy_middleware_shortcircuits_total")
});

/// Body admission rejections. reason: "oversize" | "missing_length".
pub static BODY_REJECT_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "body_reject_total",
        "Body preflight or body-limit rejected the request",
        &["reason"]
    )
    .expect("register body_reject_total")
});

/// Decompression guard rejections. reason: "stacked" | "unknown" | "over_budget".
pub static DECOMPRESS_REJECT_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "decompress_reject_total",
        "Decompression guard rejected the request",
        &["reason"]
    )
    .expect("register decompress_reject_total")
});

/// Quota rejections (global or per-IP).
/// Labels:
///   - scope: "global" | "ip"
///   - reason: "qps" (MVP; future may distinguish "burst" etc.)
pub static QUOTA_REJECT_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "quota_reject_total",
        "Quota guard rejected the request",
        &["scope", "reason"]
    )
    .expect("register quota_reject_total")
});

/// Force-initialize so the series exist before the first scrape.
pub fn init_gate_metrics() {
    let _ = &*POLICY_MIDDLEWARE_SHORTCIRCUITS_TOTAL;
    let _ = &*BODY_REJECT_TOTAL;
    let _ = &*DECOMPRESS_REJECT_TOTAL;
    let _ = &*QUOTA_REJECT_TOTAL;

    let _ = &*READY_INFLIGHT_CURRENT;
    let _ = &*READY_ERROR_RATE_PCT;
    let _ = &*READY_QUEUE_SATURATED;
    let _ = &*READY_TRIPS_TOTAL;
    let _ = &*READY_STATE_CHANGES_TOTAL;
}

```

### crates/omnigate/src/metrics/mod.rs
<a id="crates-omnigate-src-metrics-mod-rs"></a>

```rust
//! RO:WHAT   Prometheus registry & handles for Omnigate.
//! RO:WHY    Stable counters/histograms backing the metrics contract test.
//! RO:INTERACTS middleware::{quotas,fair_queue,body_caps,decompress_guard,policy}, admin/handlers.
pub mod gates;
pub mod registry;

use once_cell::sync::Lazy;
use prometheus::{register_histogram_vec, register_int_counter_vec, HistogramVec, IntCounterVec};

pub static HTTP_REQS_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "http_requests_total",
        "Requests by route/method/status",
        &["route", "method", "status"]
    )
    .expect("register http_requests_total")
});

pub static REQUEST_LATENCY_SECONDS: Lazy<HistogramVec> = Lazy::new(|| {
    register_histogram_vec!(
        "request_latency_seconds",
        "Request latency by route/method",
        &["route", "method"]
    )
    .expect("register request_latency_seconds")
});

pub static ADMISSION_QUOTA_EXHAUSTED_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "admission_quota_exhausted_total",
        "Quota rejections by scope",
        &["scope"] // global|ip|token
    )
    .expect("register admission_quota_exhausted_total")
});

pub static FAIR_Q_EVENTS_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "admission_fair_queue_events_total",
        "Fair queue events by type",
        &["event"] // enqueued|dropped
    )
    .expect("register admission_fair_queue_events_total")
});

pub static BODY_REJECT_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "body_reject_total",
        "Body rejections by reason",
        &["reason"] // oversize|missing_len
    )
    .expect("register body_reject_total")
});

pub static DECOMPRESS_REJECT_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "decompress_reject_total",
        "Decompression guard rejections",
        &["reason"] // unknown|stacked
    )
    .expect("register decompress_reject_total")
});

pub static POLICY_SHORTCIRCUITS_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "policy_middleware_shortcircuits_total",
        "Requests denied by policy middleware",
        &["status"] // 403|451|503
    )
    .expect("register policy_middleware_shortcircuits_total")
});

```

### crates/omnigate/src/metrics/registry.rs
<a id="crates-omnigate-src-metrics-registry-rs"></a>

```rust
//! RO:WHAT   Prometheus registry & handles for Omnigate.
//! RO:WHY    Stable counters/histograms backing the metrics contract test.
//! RO:INTERACTS middleware::{quotas,fair_queue,body_caps,decompress_guard,policy}, http routes, admin plane.
//! RO:INVARS  Base labels elsewhere should include {service,instance,build_version,amnesia}.

use once_cell::sync::Lazy;
use prometheus::{
    register_histogram_vec, register_int_counter, register_int_counter_vec, register_int_gauge,
    HistogramVec, IntCounter, IntCounterVec, IntGauge,
};

/// Gauge reflecting whether we’re running in “amnesia mode” (Micronode/dev style).
/// Convention: 1 = amnesia ON, 0 = OFF. Wire this in App::build from cfg.server.amnesia.
pub static AMNESIA_MODE: Lazy<IntGauge> = Lazy::new(|| {
    register_int_gauge!(
        "amnesia_mode",
        "Amnesia (stateless) mode flag: 1 when enabled, else 0"
    )
    .expect("register amnesia_mode")
});

/// Count of times a policy bundle has been successfully loaded (startup/reload).
/// Increment once after policy init so sanity scripts can assert it happened.
pub static POLICY_BUNDLE_LOADED_TOTAL: Lazy<IntCounter> = Lazy::new(|| {
    register_int_counter!(
        "policy_bundle_loaded_total",
        "Policy bundles successfully loaded (startup/reload)"
    )
    .expect("register policy_bundle_loaded_total")
});

pub static HTTP_REQS_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "http_requests_total",
        "Requests by route/method/status",
        &["route", "method", "status"]
    )
    .expect("register http_requests_total")
});

pub static REQUEST_LATENCY_SECONDS: Lazy<HistogramVec> = Lazy::new(|| {
    register_histogram_vec!(
        "request_latency_seconds",
        "Request latency by route/method",
        &["route", "method"]
    )
    .expect("register request_latency_seconds")
});

pub static ADMISSION_QUOTA_EXHAUSTED_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "admission_quota_exhausted_total",
        "Quota rejections by scope",
        &["scope"] // global|ip|token
    )
    .expect("register admission_quota_exhausted_total")
});

pub static FAIR_Q_EVENTS_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "admission_fair_queue_events_total",
        "Fair queue events by type",
        &["event"] // enqueued|dropped
    )
    .expect("register admission_fair_queue_events_total")
});

pub static BODY_REJECT_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "body_reject_total",
        "Body rejections by reason",
        &["reason"] // oversize|missing_len
    )
    .expect("register body_reject_total")
});

pub static DECOMPRESS_REJECT_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "decompress_reject_total",
        "Decompression guard rejections",
        &["reason"] // unknown|stacked
    )
    .expect("register decompress_reject_total")
});

pub static POLICY_SHORTCIRCUITS_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        "policy_middleware_shortcircuits_total",
        "Requests denied by policy middleware",
        &["status"] // 403|451|503
    )
    .expect("register policy_middleware_shortcircuits_total")
});

```

### crates/omnigate/src/middleware/body_caps.rs
<a id="crates-omnigate-src-middleware-bodycaps-rs"></a>

```rust
//! RO:WHAT — Request body size caps.
//! RO:WHY  — Prevent DoS and enforce hard limits early.
//! RO:BEHAVIOR —
//!   * If `Content-Length` is present and > MAX, short-circuit with 413 JSON using our error map.
//!   * For payload-carrying methods (POST/PUT/PATCH) when `Content-Length` is missing, short-circuit
//!     with 411 JSON via our error map.
//!   * Otherwise, forward and rely on Axum's body limiter (`DefaultBodyLimit::max`) for streaming.
//!
//! RO:INVARIANTS — Keep MAX aligned with OAP/HTTP caps (default: 1 MiB). Emit metrics for oversize rejects.

use std::{
    future::Future,
    pin::Pin,
    task::{Context, Poll},
};

use axum::{
    extract::DefaultBodyLimit,
    http::{Method, Request},
    response::{IntoResponse, Response},
};
use tower::{Layer, Service};

use crate::errors::{http_map, Reason};
// IMPORTANT: use metrics from gates module so we hit the default-registry counters.
use crate::metrics::gates::BODY_REJECT_TOTAL;

/// Size constants (avoid clippy identity-op).
const KIB: usize = 1024;
const MIB: usize = KIB * KIB;
/// Default max body bytes (1 MiB). Keep in sync with service config later.
const MAX_BYTES: usize = MIB;

/// Public factory returning the composed guard as a tuple of layers,
/// which implements `Layer<Route>` (compatible with `Router::layer`).
pub fn layer() -> (PreflightContentLengthGuardLayer, DefaultBodyLimit) {
    (
        PreflightContentLengthGuardLayer { max: MAX_BYTES },
        DefaultBodyLimit::max(MAX_BYTES),
    )
}

/// Fast-path guard that inspects `Content-Length` and short-circuits with a 413/411 JSON.
#[derive(Clone, Copy)]
pub struct PreflightContentLengthGuardLayer {
    pub(crate) max: usize,
}

impl<S> Layer<S> for PreflightContentLengthGuardLayer {
    type Service = PreflightContentLengthGuard<S>;
    fn layer(&self, inner: S) -> Self::Service {
        PreflightContentLengthGuard {
            inner,
            max: self.max,
        }
    }
}

#[derive(Clone)]
pub struct PreflightContentLengthGuard<S> {
    inner: S,
    max: usize,
}

impl<S, B> Service<Request<B>> for PreflightContentLengthGuard<S>
where
    S: Service<Request<B>>,
    S::Future: Send + 'static,
    S::Response: IntoResponse,
{
    type Response = Response;
    type Error = S::Error;
    type Future =
        Pin<Box<dyn Future<Output = Result<Self::Response, Self::Error>> + Send + 'static>>;

    fn poll_ready(&mut self, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {
        self.inner.poll_ready(cx)
    }

    fn call(&mut self, req: Request<B>) -> Self::Future {
        let method = req.method().clone();
        let is_payload_method = matches!(method, Method::POST | Method::PUT | Method::PATCH);

        // If Content-Length is present and too big, reject immediately with our envelope.
        if let Some(len) = req
            .headers()
            .get(axum::http::header::CONTENT_LENGTH)
            .and_then(|v| v.to_str().ok())
            .and_then(|s| s.parse::<u64>().ok())
        {
            if len as usize > self.max {
                // Metrics: body oversize reject
                BODY_REJECT_TOTAL.with_label_values(&["oversize"]).inc();

                let resp = http_map::to_response(
                    Reason::PayloadTooLarge,
                    "request body exceeds configured limit",
                );
                return Box::pin(async move { Ok(resp) });
            }
        } else if is_payload_method {
            // For payload-carrying methods, require Content-Length to avoid slow-loris/ambiguous size.
            BODY_REJECT_TOTAL
                .with_label_values(&["missing_length"])
                .inc();

            let resp =
                http_map::to_response(Reason::LengthRequired, "Content-Length required by policy");
            return Box::pin(async move { Ok(resp) });
        }

        let fut = self.inner.call(req);
        Box::pin(async move {
            let res = fut.await?.into_response();
            Ok(res)
        })
    }
}

```

### crates/omnigate/src/middleware/classify.rs
<a id="crates-omnigate-src-middleware-classify-rs"></a>

```rust
//! RO:WHAT — Response classifier (stub).
//! RO:WHY  — Future: classify errors for metrics; integrate with tower_http::classify.
//! RO:INVARIANTS — Bounded label cardinality; now identity.

use tower::layer::Layer;

/// Identity layer placeholder (no-op).
#[derive(Clone, Copy, Default)]
pub struct NopLayer;

impl<S> Layer<S> for NopLayer {
    type Service = S;
    fn layer(&self, inner: S) -> Self::Service {
        inner
    }
}

pub fn layer() -> NopLayer {
    NopLayer
}

```

### crates/omnigate/src/middleware/corr_id.rs
<a id="crates-omnigate-src-middleware-corrid-rs"></a>

```rust
//! RO:WHAT   Correlation/request IDs middleware.
//! RO:WHY    Stable per-request IDs for logs/metrics/traces.
//! RO:INVARS Low cardinality; always attach request_id; optional correlation chain.

use axum::{
    extract::Request,
    http::header::{HeaderName, HeaderValue},
    response::{IntoResponse, Response},
};
use futures_util::future::BoxFuture;
use tower::{Layer, Service};

static HDR_REQ_ID: HeaderName = HeaderName::from_static("x-request-id");
static HDR_CORR_ID: HeaderName = HeaderName::from_static("x-correlation-id");

#[allow(dead_code)] // will be consumed by logging/observe once wired
#[derive(Debug, Clone)]
pub struct CorrelationIds {
    pub request_id: String,
    pub correlation_id: String,
}

#[derive(Clone)]
pub struct CorrIdLayer;

pub fn layer() -> CorrIdLayer {
    CorrIdLayer
}

impl<S> Layer<S> for CorrIdLayer {
    type Service = CorrIdService<S>;
    fn layer(&self, inner: S) -> Self::Service {
        CorrIdService { inner }
    }
}

#[derive(Clone)]
pub struct CorrIdService<S> {
    inner: S,
}

// 128-bit random hex via fastrand 2.x (requires an explicit range).
#[inline]
fn gen_request_id() -> String {
    // full 64-bit range on each half
    let hi = fastrand::u64(0..=u64::MAX);
    let lo = fastrand::u64(0..=u64::MAX);
    format!("{:016x}{:016x}", hi, lo)
}

impl<S> Service<Request> for CorrIdService<S>
where
    S: Service<Request> + Clone + Send + 'static,
    S::Response: IntoResponse + Send + 'static,
    S::Future: Send + 'static,
    S::Error: Into<Box<dyn std::error::Error + Send + Sync>> + Send + 'static,
{
    type Response = Response;
    type Error = S::Error;
    type Future = BoxFuture<'static, Result<Self::Response, Self::Error>>;

    fn poll_ready(
        &mut self,
        cx: &mut std::task::Context<'_>,
    ) -> std::task::Poll<Result<(), Self::Error>> {
        self.inner.poll_ready(cx)
    }

    fn call(&mut self, mut req: Request) -> Self::Future {
        let mut inner = self.inner.clone();

        // Request ID (always)
        let req_id = gen_request_id();

        // Correlation ID (propagate if present, else req_id). Keep ASCII-only to ensure header validity.
        let corr_id = req
            .headers()
            .get(&HDR_CORR_ID)
            .and_then(|v| v.to_str().ok())
            .map(str::to_owned)
            .filter(|s| s.is_ascii())
            .unwrap_or_else(|| req_id.clone());

        // Stash into request headers for downstream visibility (insert only if HeaderValue parses).
        if let Ok(v) = HeaderValue::from_str(&req_id) {
            req.headers_mut().insert(HDR_REQ_ID.clone(), v);
        }
        if let Ok(v) = HeaderValue::from_str(&corr_id) {
            req.headers_mut().insert(HDR_CORR_ID.clone(), v);
        }

        Box::pin(async move {
            let mut res = inner.call(req).await?.into_response();

            // Reflect IDs back to the client (again, only if HeaderValue parses).
            if let Ok(v) = HeaderValue::from_str(&req_id) {
                res.headers_mut().insert(HDR_REQ_ID.clone(), v);
            }
            if let Ok(v) = HeaderValue::from_str(&corr_id) {
                res.headers_mut().insert(HDR_CORR_ID.clone(), v);
            }

            Ok(res)
        })
    }
}

```

### crates/omnigate/src/middleware/decompress_guard.rs
<a id="crates-omnigate-src-middleware-decompressguard-rs"></a>

```rust
//! RO:WHAT — Decompression guard for request bodies.
//! RO:WHY  — Stop risky encodings and cap potential decompression-bomb expansion at the edge.
//!
//! RO:BEHAVIOR —
//!   • Reject unsupported or (optionally) stacked encodings with 415 using our JSON envelope.
//!   • Allowed encodings come from config: `admission.decompression.allow` (e.g., ["identity","gzip"]).
//!   • If compressed (encoding != identity) and Content-Length is present, require:
//!         compressed_length * EXPANSION_CAP <= MAX_EXPANDED
//!     where MAX_EXPANDED = `admission.body.max_content_length` and EXPANSION_CAP = 10.
//!   • Streaming/unknown sizes are still protected by `DefaultBodyLimit` in `body_caps`.
//!
//! RO:INVARIANTS — Pure guard (no decompression). Budgets track body caps precisely.

use std::{
    future::Future,
    pin::Pin,
    task::{Context, Poll},
};

use axum::{
    http::{HeaderValue, Request},
    response::{IntoResponse, Response},
    Router,
};
use tower::{Layer, Service};

use crate::errors::{http_map, Reason};
// IMPORTANT: use counters from metrics/gates so we're on the default registry.
use crate::metrics::gates::DECOMPRESS_REJECT_TOTAL;

/// Worst-case expansion factor budgeted for compressed bodies.
const EXPANSION_CAP: usize = 10;

/// Config-aware attach: add the guard with values pulled from Admission.
pub fn attach_with_cfg<S>(router: Router<S>, adm: &crate::config::Admission) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    let allow = adm
        .decompression
        .allow
        .iter()
        .map(|s| s.to_ascii_lowercase())
        .collect::<Vec<_>>();
    let deny_stacked = adm.decompression.deny_stacked;
    let max_expanded = adm.body.max_content_length as usize;

    router.layer(DecompressGuardLayer {
        allow,
        deny_stacked,
        max_expanded,
    })
}

/// Layer carrying admission parameters.
#[derive(Clone)]
pub struct DecompressGuardLayer {
    allow: Vec<String>,
    deny_stacked: bool,
    max_expanded: usize,
}

impl<S> Layer<S> for DecompressGuardLayer {
    type Service = DecompressGuard<S>;
    fn layer(&self, inner: S) -> Self::Service {
        DecompressGuard {
            inner,
            allow: self.allow.clone(),
            deny_stacked: self.deny_stacked,
            max_expanded: self.max_expanded,
        }
    }
}

#[derive(Clone)]
pub struct DecompressGuard<S> {
    inner: S,
    allow: Vec<String>,
    deny_stacked: bool,
    max_expanded: usize,
}

impl<S, B> Service<Request<B>> for DecompressGuard<S>
where
    S: Service<Request<B>>,
    S::Future: Send + 'static,
    S::Response: IntoResponse,
{
    type Response = Response;
    type Error = S::Error;
    type Future =
        Pin<Box<dyn Future<Output = Result<Self::Response, Self::Error>> + Send + 'static>>;

    fn poll_ready(&mut self, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {
        self.inner.poll_ready(cx)
    }

    fn call(&mut self, req: Request<B>) -> Self::Future {
        // Parse and normalize Content-Encoding(s)
        let enc_header = req.headers().get(axum::http::header::CONTENT_ENCODING);

        let encodings = enc_header
            .and_then(|hv: &HeaderValue| hv.to_str().ok())
            .unwrap_or("")
            .split(',')
            .map(|s| s.trim())
            .filter(|s| !s.is_empty())
            .map(|s| s.to_ascii_lowercase())
            .collect::<Vec<_>>();

        // Stacked encodings?
        if self.deny_stacked && encodings.len() > 1 {
            DECOMPRESS_REJECT_TOTAL
                .with_label_values(&["stacked"])
                .inc();

            let resp = http_map::to_response(
                Reason::UnsupportedMediaType,
                "stacked Content-Encoding not allowed",
            );
            return Box::pin(async move { Ok(resp) });
        }

        // Validate the (single) encoding or absence thereof.
        let encoding_opt = encodings.first().map(|s| s.as_str());
        let is_identity_or_none = match encoding_opt {
            None => true, // no header = identity
            Some(enc) => enc == "identity",
        };

        if let Some(enc) = encoding_opt {
            if !self.allow.iter().any(|a| a == enc) {
                // Disallowed/unknown encoding.
                DECOMPRESS_REJECT_TOTAL
                    .with_label_values(&["unknown"])
                    .inc();

                let resp = http_map::to_response(
                    Reason::UnsupportedMediaType,
                    "Content-Encoding not allowed by policy",
                );
                return Box::pin(async move { Ok(resp) });
            }
        }

        // If compressed and length is known, enforce expansion budget.
        if !is_identity_or_none {
            if let Some(cl) = req
                .headers()
                .get(axum::http::header::CONTENT_LENGTH)
                .and_then(|v| v.to_str().ok())
                .and_then(|s| s.parse::<u64>().ok())
            {
                let compressed = cl as usize;
                if compressed.saturating_mul(EXPANSION_CAP) > self.max_expanded {
                    DECOMPRESS_REJECT_TOTAL
                        .with_label_values(&["over_budget"])
                        .inc();

                    let resp = http_map::to_response(
                        Reason::PayloadTooLarge,
                        "compressed body exceeds allowed expansion budget",
                    );
                    return Box::pin(async move { Ok(resp) });
                }
            }
            // No Content-Length → streaming is still guarded by DefaultBodyLimit downstream.
        }

        let fut = self.inner.call(req);
        Box::pin(async move {
            let res = fut.await?.into_response();
            Ok(res)
        })
    }
}

```

### crates/omnigate/src/middleware/inflight.rs
<a id="crates-omnigate-src-middleware-inflight-rs"></a>

```rust
//! RO:WHAT  Global inflight bridge: measure actual concurrent requests across the whole stack.
//! RO:WHY   Guarantees that /readyz sees truthful concurrency no matter which path a request takes.

use crate::readiness::policy::ReadyPolicy;
use axum::{extract::State, middleware::from_fn_with_state, Router};
use std::sync::Arc;

pub async fn inflight_bridge(
    State(rp): State<Arc<ReadyPolicy>>,
    req: axum::http::Request<axum::body::Body>,
    next: axum::middleware::Next,
) -> axum::response::Response {
    rp.inc();
    struct Guard(Arc<ReadyPolicy>);
    impl Drop for Guard {
        fn drop(&mut self) {
            self.0.dec();
        }
    }
    let _g = Guard(rp);
    next.run(req).await
}

/// Attach the inflight bridge as the outermost layer.
pub fn attach<S>(router: Router<S>, rp: Arc<ReadyPolicy>) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    router.layer(from_fn_with_state(rp, inflight_bridge))
}

```

### crates/omnigate/src/middleware/mod.rs
<a id="crates-omnigate-src-middleware-mod-rs"></a>

```rust
// crates/omnigate/src/middleware/mod.rs
//! RO:WHAT  Shared middleware stack for the app.
//! RO:WHY   Keep router layering in one place (except admission which is cfg-driven).
//! RO:INVARS Low overhead; stable label cardinality; no blocking across .await.

mod body_caps;
mod classify;
mod corr_id;
mod decompress_guard;
pub mod inflight;
mod policy;
mod slow_loris;

use crate::config::Admission;
use axum::Router;

/// Canonical middleware stack **with config** (recommended).
/// Order: classify -> corr_id -> policy -> body caps -> default body limit -> decompress guard -> slow-loris
pub fn apply_with_cfg<S>(router: Router<S>, adm: &Admission) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    // Cheap gates first (no body access)
    let router = router
        .layer(classify::layer())
        .layer(corr_id::layer())
        .layer(policy::layer());

    // Preflight length + Axum's DefaultBodyLimit pair
    let (preflight_len_guard, default_body_limit) = body_caps::layer();

    // Attach caps/limit, then cfg-driven decompression guard, then slow-loris
    let router = router.layer(preflight_len_guard).layer(default_body_limit);

    // Config-driven decompression guard; this call ensures the symbol is referenced in this module.
    let router = decompress_guard::attach_with_cfg(router, adm);

    router.layer(slow_loris::layer())
}

/// Legacy shim kept for tests/back-compat (no config at callsite).
/// Internally calls `apply_with_cfg` using `Admission::default()`.
pub fn apply<S>(router: Router<S>) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    let defaults = crate::config::Admission::default();
    apply_with_cfg(router, &defaults)
}

```

### crates/omnigate/src/middleware/policy.rs
<a id="crates-omnigate-src-middleware-policy-rs"></a>

```rust
//! RO:WHAT   Thin policy middleware that consults a ron-policy Evaluator (if provided).
//! RO:WHY    Centralize allow/deny; keep business handlers policy-agnostic.
//! RO:INVARS If no evaluator is present, act as a no-op (safe pass-through).
//!           When denying, emit stable JSON envelopes and bounded-label metrics.

use std::{
    collections::BTreeSet,
    sync::Arc,
    time::{SystemTime, UNIX_EPOCH},
};

use axum::{
    extract::Request,
    http::StatusCode,
    response::{IntoResponse, Response},
};
use futures_util::future::BoxFuture;
use tower::{Layer, Service};

use crate::errors::GateError;
// IMPORTANT: pull counters from the gates module to match registration on the default registry.
use crate::metrics::gates::POLICY_MIDDLEWARE_SHORTCIRCUITS_TOTAL;

#[derive(Clone)]
pub struct PolicyLayer;

/// Public constructor used by the top-level middleware::apply.
pub fn layer() -> PolicyLayer {
    PolicyLayer
}

impl<S> Layer<S> for PolicyLayer {
    type Service = PolicyService<S>;
    fn layer(&self, inner: S) -> Self::Service {
        PolicyService { inner }
    }
}

#[derive(Clone)]
pub struct PolicyService<S> {
    inner: S,
}

impl<S> Service<Request> for PolicyService<S>
where
    S: Service<Request> + Clone + Send + 'static,
    S::Response: IntoResponse + Send + 'static,
    S::Future: Send + 'static,
    S::Error: Into<Box<dyn std::error::Error + Send + Sync>> + Send + 'static,
{
    type Response = Response;
    type Error = S::Error;
    type Future = BoxFuture<'static, Result<Self::Response, Self::Error>>;

    fn poll_ready(
        &mut self,
        cx: &mut std::task::Context<'_>,
    ) -> std::task::Poll<Result<(), Self::Error>> {
        self.inner.poll_ready(cx)
    }

    fn call(&mut self, req: Request) -> Self::Future {
        let mut inner = self.inner.clone();

        // Pull an optional policy bundle from request extensions; build an Evaluator per request.
        let maybe_bundle = req
            .extensions()
            .get::<Arc<ron_policy::PolicyBundle>>()
            .cloned();

        Box::pin(async move {
            if let Some(bundle) = maybe_bundle {
                // Build Evaluator borrowing the bundle (lives for the request via Arc).
                match ron_policy::Evaluator::new(&bundle) {
                    Ok(eval) => {
                        // ron-policy Context (current API): populate minimally & safely.
                        let now_ms = SystemTime::now()
                            .duration_since(UNIX_EPOCH)
                            .unwrap_or_default()
                            .as_millis() as u64;

                        // Tags: keep cardinality low and deterministic.
                        let mut tags: BTreeSet<String> = BTreeSet::new();
                        tags.insert("omnigate".to_string());

                        let method = req.method().as_str().to_owned();
                        // Region/tenant may be wired later via AppState; keep safe defaults.
                        let region = String::new();
                        let tenant = "default".to_string();

                        let ctx = ron_policy::Context {
                            now_ms,
                            body_bytes: 0, // unknown at admission time
                            method,
                            region,
                            tags,
                            tenant,
                        };

                        match eval.evaluate(&ctx) {
                            Ok(dec) => {
                                // DecisionEffect doesn’t expose is_allow(); match the variant.
                                match dec.effect {
                                    ron_policy::DecisionEffect::Allow => {
                                        let res = inner.call(req).await?;
                                        return Ok(res.into_response());
                                    }
                                    _ => {
                                        let status = if dec.reason.as_deref() == Some("LEGAL") {
                                            StatusCode::UNAVAILABLE_FOR_LEGAL_REASONS
                                        } else {
                                            StatusCode::FORBIDDEN
                                        };

                                        // Metrics increment for deny/short-circuit.
                                        POLICY_MIDDLEWARE_SHORTCIRCUITS_TOTAL
                                            .with_label_values(&[status.as_str()])
                                            .inc();

                                        let resp = GateError::PolicyDeny {
                                            reason: dec.reason.as_deref().unwrap_or("DENY"),
                                            status,
                                        }
                                        .into_response();
                                        return Ok(resp);
                                    }
                                }
                            }
                            Err(_e) => {
                                // Evaluator error → 503
                                POLICY_MIDDLEWARE_SHORTCIRCUITS_TOTAL
                                    .with_label_values(&["503"])
                                    .inc();
                                let resp = GateError::PolicyError.into_response();
                                return Ok(resp);
                            }
                        }
                    }
                    Err(_e) => {
                        // If Evaluator construction fails, treat as transient policy error.
                        POLICY_MIDDLEWARE_SHORTCIRCUITS_TOTAL
                            .with_label_values(&["503"])
                            .inc();
                        let resp = GateError::PolicyError.into_response();
                        return Ok(resp);
                    }
                }
            }

            // No bundle present → no-op pass-through.
            let res = inner.call(req).await?;
            Ok(res.into_response())
        })
    }
}

```

### crates/omnigate/src/middleware/slow_loris.rs
<a id="crates-omnigate-src-middleware-slowloris-rs"></a>

```rust
//! RO:WHAT — Slow-loris protection (stub).
//! RO:WHY  — Future: per-read header/body timeouts, idle caps; now identity.
//! RO:INVARIANTS — Avoid false positives under load when enabled.

use tower::layer::Layer;

/// Identity layer placeholder (no-op).
#[derive(Clone, Copy, Default)]
pub struct NopLayer;

impl<S> Layer<S> for NopLayer {
    type Service = S;
    fn layer(&self, inner: S) -> Self::Service {
        inner
    }
}

pub fn layer() -> NopLayer {
    NopLayer
}

```

### crates/omnigate/src/observability/logging.rs
<a id="crates-omnigate-src-observability-logging-rs"></a>

```rust

```

### crates/omnigate/src/observability/mod.rs
<a id="crates-omnigate-src-observability-mod-rs"></a>

```rust
//! RO:WHAT — Tracing init + HTTP trace layer.
//! RO:WHY  — Uniform logs + RED metrics; Concerns: OBS/PERF.
//! RO:INVARIANTS — Bounded labels; no PII in logs.

use tower_http::trace::TraceLayer;
use tracing_subscriber::{fmt, EnvFilter};

pub fn init_tracing() {
    let filter = EnvFilter::try_from_default_env()
        .unwrap_or_else(|_| EnvFilter::new("info,tower_http=info,axum=info"));
    fmt().with_env_filter(filter).compact().init();
}

pub fn http_trace_layer(
) -> TraceLayer<tower_http::classify::SharedClassifier<tower_http::classify::ServerErrorsAsFailures>>
{
    TraceLayer::new_for_http()
}

```

### crates/omnigate/src/observability/tracing_spans.rs
<a id="crates-omnigate-src-observability-tracingspans-rs"></a>

```rust

```

### crates/omnigate/src/pq/mod.rs
<a id="crates-omnigate-src-pq-mod-rs"></a>

```rust

```

### crates/omnigate/src/pq/negotiate.rs
<a id="crates-omnigate-src-pq-negotiate-rs"></a>

```rust

```

### crates/omnigate/src/readiness/keys.rs
<a id="crates-omnigate-src-readiness-keys-rs"></a>

```rust

```

### crates/omnigate/src/readiness/mod.rs
<a id="crates-omnigate-src-readiness-mod-rs"></a>

```rust
//! RO:WHAT  Readiness module: policy (truth), admin state, /readyz, and samplers.
//! RO:WHY   Keep lib.rs slim; keep readiness logic cohesive and testable.

pub mod policy;
pub mod sampler;
pub mod state;

use axum::{extract::State, response::IntoResponse};
use std::time::{Duration, Instant};

use crate::errors::http_map::GateError;
use crate::metrics::gates::{READY_STATE_CHANGES_TOTAL, READY_TRIPS_TOTAL};
use state::AdminState;

/// /readyz handler: consults local ReadyPolicy + sticky hold, else delegates to kernel.
pub async fn readyz(State(st): State<AdminState>) -> impl IntoResponse {
    if st.dev_ready {
        return (axum::http::StatusCode::OK, "ready (dev override)").into_response();
    }

    // Honor the hold window if previously tripped.
    let now = Instant::now();
    {
        // Take a copy of the Option<Instant>, since Instant is Copy.
        let mut guard = st.hold_until_lock();
        if let Some(until) = *guard {
            if now < until {
                return GateError::Degraded.into_response();
            } else {
                // Hold expired — clear and mark recovery.
                *guard = None;
                READY_STATE_CHANGES_TOTAL
                    .with_label_values(&["ready"])
                    .inc();
            }
        }
    }

    // Sample current policy state.
    let inflight = st.rp.inflight();
    let err_pct_like = st.rp.err_rate_pct();

    // Trip if either threshold is exceeded.
    let trip_inflight = inflight > st.max_inflight_threshold;
    let trip_err = err_pct_like >= st.error_rate_429_503_pct;

    if trip_inflight || trip_err {
        // Start/extend hold window.
        st.set_hold_until(now + Duration::from_secs(st.hold_for_secs.max(1)));

        // Mark trip metadata.
        let reason = if trip_inflight {
            "inflight"
        } else {
            "err_rate"
        };
        READY_TRIPS_TOTAL.with_label_values(&[reason]).inc();
        READY_STATE_CHANGES_TOTAL
            .with_label_values(&["degraded"])
            .inc();

        return GateError::Degraded.into_response();
    }

    // Otherwise delegate to kernel readiness handler (200 path).
    ron_kernel::metrics::readiness::readyz_handler(st.ready.clone()).await
}

```

### crates/omnigate/src/readiness/policy.rs
<a id="crates-omnigate-src-readiness-policy-rs"></a>

```rust
//! RO:WHAT  Local readiness policy bridge with atomics (truth source for /readyz).
//! RO:WHY   /readyz must reflect *actual* concurrency/error pressure.

use std::sync::atomic::{AtomicBool, AtomicI64, AtomicU64, Ordering};

pub struct ReadyPolicy {
    inflight: AtomicI64,
    err_rate_bits: AtomicU64, // f64 stored as bits for atomicity
    queue_saturated: AtomicBool,
}

impl ReadyPolicy {
    #[inline]
    pub fn new() -> Self {
        Self {
            inflight: AtomicI64::new(0),
            err_rate_bits: AtomicU64::new(0f64.to_bits()),
            queue_saturated: AtomicBool::new(false),
        }
    }

    #[inline]
    pub fn update_inflight(&self, v: i64) {
        let val = v.max(0);
        self.inflight.store(val, Ordering::Release);
        // mirror to gauge for observability
        crate::metrics::gates::READY_INFLIGHT_CURRENT.set(val);
    }

    #[inline]
    pub fn inc(&self) {
        let v = self.inflight.fetch_add(1, Ordering::AcqRel) + 1;
        crate::metrics::gates::READY_INFLIGHT_CURRENT.set(v.max(0));
    }

    #[inline]
    pub fn dec(&self) {
        let v = self.inflight.fetch_sub(1, Ordering::AcqRel) - 1;
        crate::metrics::gates::READY_INFLIGHT_CURRENT.set(v.max(0));
    }

    #[inline]
    pub fn update_err_rate(&self, pct: f64) {
        let c = pct.clamp(0.0, 100.0);
        self.err_rate_bits.store(c.to_bits(), Ordering::Release);
        crate::metrics::gates::READY_ERROR_RATE_PCT.set(c);
    }

    #[inline]
    pub fn set_queue_saturated(&self, on: bool) {
        self.queue_saturated.store(on, Ordering::Release);
        crate::metrics::gates::READY_QUEUE_SATURATED.set(if on { 1 } else { 0 });
    }

    #[inline]
    pub fn inflight(&self) -> i64 {
        self.inflight.load(Ordering::Acquire)
    }

    #[inline]
    pub fn err_rate_pct(&self) -> f64 {
        f64::from_bits(self.err_rate_bits.load(Ordering::Acquire))
    }

    #[allow(dead_code)]
    #[inline]
    pub fn queue_saturated(&self) -> bool {
        self.queue_saturated.load(Ordering::Acquire)
    }
}

// Silence clippy::new_without_default by providing Default in terms of new()
impl Default for ReadyPolicy {
    fn default() -> Self {
        Self::new()
    }
}

```

### crates/omnigate/src/readiness/sampler.rs
<a id="crates-omnigate-src-readiness-sampler-rs"></a>

```rust
//! RO:WHAT  Rolling error-rate sampler: turns 429/503/drops into a pct-like signal.
//! RO:WHY   /readyz should trip on sustained errors even if inflight is modest.

use super::policy::ReadyPolicy;
use crate::metrics::gates::POLICY_MIDDLEWARE_SHORTCIRCUITS_TOTAL;
use crate::metrics::{ADMISSION_QUOTA_EXHAUSTED_TOTAL, FAIR_Q_EVENTS_TOTAL};
use std::sync::Arc;
use std::time::Duration;

/// Spawns a background task; safe to call once at app boot.
pub fn spawn_err_rate_sampler(rp: Arc<ReadyPolicy>, window_secs: u64) {
    let window = window_secs.max(1);
    tokio::spawn(async move {
        let mut last_quota = {
            let g = ADMISSION_QUOTA_EXHAUSTED_TOTAL
                .with_label_values(&["global"])
                .get();
            let i = ADMISSION_QUOTA_EXHAUSTED_TOTAL
                .with_label_values(&["ip"])
                .get();
            g + i
        } as f64;
        let mut last_policy_503 = POLICY_MIDDLEWARE_SHORTCIRCUITS_TOTAL
            .with_label_values(&["503"])
            .get() as f64;
        let mut last_fair_drops = FAIR_Q_EVENTS_TOTAL.with_label_values(&["dropped"]).get() as f64;

        loop {
            tokio::time::sleep(Duration::from_secs(window)).await;

            let quota_now = {
                let g = ADMISSION_QUOTA_EXHAUSTED_TOTAL
                    .with_label_values(&["global"])
                    .get();
                let i = ADMISSION_QUOTA_EXHAUSTED_TOTAL
                    .with_label_values(&["ip"])
                    .get();
                g + i
            } as f64;
            let policy_503_now = POLICY_MIDDLEWARE_SHORTCIRCUITS_TOTAL
                .with_label_values(&["503"])
                .get() as f64;
            let fair_drops_now = FAIR_Q_EVENTS_TOTAL.with_label_values(&["dropped"]).get() as f64;

            let d_quota = (quota_now - last_quota).max(0.0);
            let d_p503 = (policy_503_now - last_policy_503).max(0.0);
            let d_drops = (fair_drops_now - last_fair_drops).max(0.0);

            let err_events = d_quota + d_p503 + d_drops;
            let per_sec = err_events / (window as f64);
            let pct_like = (per_sec * 100.0).min(100.0);

            // Update the policy (truth) — it mirrors to the gauge internally.
            rp.update_err_rate(pct_like);

            last_quota = quota_now;
            last_policy_503 = policy_503_now;
            last_fair_drops = fair_drops_now;
        }
    });
}

```

### crates/omnigate/src/readiness/state.rs
<a id="crates-omnigate-src-readiness-state-rs"></a>

```rust
//! RO:WHAT  AdminState: thresholds, kernel handles, sticky hold, and ReadyPolicy handle.

use super::policy::ReadyPolicy;
use ron_kernel::metrics::{health::HealthState, readiness::Readiness as KernelReadiness};
use std::{
    sync::{Arc, Mutex},
    time::Instant,
};

#[derive(Clone)]
pub struct AdminState {
    pub health: HealthState,
    pub ready: KernelReadiness,
    pub dev_ready: bool,
    pub max_inflight_threshold: i64,
    pub error_rate_429_503_pct: f64,
    pub hold_for_secs: u64,
    pub rp: Arc<ReadyPolicy>,
    hold_until: Arc<Mutex<Option<Instant>>>,
}

impl AdminState {
    pub fn new(
        health: HealthState,
        ready: KernelReadiness,
        dev_ready: bool,
        cfg: &crate::config::Readiness,
        rp: Arc<ReadyPolicy>,
    ) -> Self {
        Self {
            health,
            ready,
            dev_ready,
            max_inflight_threshold: cfg.max_inflight_threshold as i64,
            error_rate_429_503_pct: cfg.error_rate_429_503_pct,
            hold_for_secs: cfg.hold_for_secs,
            rp,
            hold_until: Arc::new(Mutex::new(None)),
        }
    }

    #[inline]
    pub fn hold_until_lock(&self) -> std::sync::MutexGuard<'_, Option<Instant>> {
        self.hold_until.lock().expect("hold_until mutex poisoned")
    }

    #[inline]
    pub fn set_hold_until(&self, when: Instant) {
        *self.hold_until.lock().unwrap() = Some(when);
    }

    #[inline]
    pub fn clear_hold_until(&self) {
        *self.hold_until.lock().unwrap() = None;
    }
}

```

### crates/omnigate/src/routes/mod.rs
<a id="crates-omnigate-src-routes-mod-rs"></a>

```rust
//! RO:WHAT — Route modules aggregation.
//! RO:WHY  — Keep the tree organized exactly like TODO.
//! RO:INTERACTS — ops.rs, v1::*, future middleware/auth/admission.

pub mod ops;
pub mod v1;

```

### crates/omnigate/src/routes/ops.rs
<a id="crates-omnigate-src-routes-ops-rs"></a>

```rust
//! RO:WHAT — Ops/administration endpoints (version, health, ready).
//! RO:WHY  — Keep admin plane consistent and DTO-stable.
//! RO:INVARIANTS — Shapes match types::dto; no secret/PII in responses.

use crate::types::VersionResponse;
use axum::{response::IntoResponse, Json};

/// GET /versionz (or /ops/version if routed) — returns service version and optional git short hash.
/// Wire shape: VersionResponse { version: String, git: Option<String> }.
pub async fn versionz() -> impl IntoResponse {
    // Prefer compile-time embed from build.rs; fall back to runtime env (CI can export it).
    let git = option_env!("GIT_COMMIT_SHORT")
        .map(|s| s.to_string())
        .or_else(|| std::env::var("GIT_COMMIT_SHORT").ok());

    Json(VersionResponse {
        version: env!("CARGO_PKG_VERSION").to_string(),
        git,
    })
}

/// Back-compat shim so existing router entries calling `routes::ops::version` still work.
pub async fn version() -> impl IntoResponse {
    versionz().await
}

```

### crates/omnigate/src/routes/v1/dht.rs
<a id="crates-omnigate-src-routes-v1-dht-rs"></a>

```rust
//! RO:WHAT   v1: /dht health stub (client passthrough soon).
//! RO:INVARS 200/JSON only.

use axum::{routing::get, Json, Router};
use serde::Serialize;

#[derive(Serialize)]
pub struct HealthReply {
    pub ok: bool,
}

pub fn router<S>() -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    Router::new().route("/healthz", get(healthz))
}

pub async fn healthz() -> Json<HealthReply> {
    Json(HealthReply { ok: true })
}

```

### crates/omnigate/src/routes/v1/facet/feed.rs
<a id="crates-omnigate-src-routes-v1-facet-feed-rs"></a>

```rust

```

### crates/omnigate/src/routes/v1/facet/graph.rs
<a id="crates-omnigate-src-routes-v1-facet-graph-rs"></a>

```rust

```

### crates/omnigate/src/routes/v1/facet/media.rs
<a id="crates-omnigate-src-routes-v1-facet-media-rs"></a>

```rust

```

### crates/omnigate/src/routes/v1/facet/mod.rs
<a id="crates-omnigate-src-routes-v1-facet-mod-rs"></a>

```rust
//! RO:WHAT   v1: /facet/{feed,media,graph} read-only stubs.
//! RO:WHY    Policy/capability probing + skeleton for hydration later.
//! RO:INVARS 200/JSON `{ ok: true }`, no leakage.

use axum::{routing::get, Json, Router};
use serde::Serialize;

#[derive(Serialize)]
pub struct FacetOk {
    pub ok: bool,
}

pub fn router<S>() -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    Router::new()
        .route("/feed", get(feed))
        .route("/media", get(media))
        .route("/graph", get(graph))
}

pub async fn feed() -> Json<FacetOk> {
    Json(FacetOk { ok: true })
}

pub async fn media() -> Json<FacetOk> {
    Json(FacetOk { ok: true })
}

pub async fn graph() -> Json<FacetOk> {
    Json(FacetOk { ok: true })
}

```

### crates/omnigate/src/routes/v1/index.rs
<a id="crates-omnigate-src-routes-v1-index-rs"></a>

```rust
//! RO:WHAT   v1: /ping + /index/healthz + /index/search + /sleep (bounded).
//! RO:WHY    Fast client confidence checks and a simple load helper for readiness smoke.
//! RO:INVARS JSON DTOs are stable and tiny; 200 on success. /sleep clamps ms ≤ 1000.

use axum::{
    extract::Query,
    routing::{get, post},
    Json, Router,
};
use serde::{Deserialize, Serialize};
use std::time::Duration;

#[derive(Serialize)]
pub struct PingResponse {
    pub ok: bool,
}

#[derive(Serialize)]
pub struct HealthReply {
    pub ok: bool,
}

#[derive(Deserialize, Serialize)]
pub struct SearchRequest {
    pub q: String,
}

#[derive(Serialize)]
pub struct SearchReply {
    pub ok: bool,
    pub echoed: String,
}

#[derive(Deserialize)]
pub struct SleepQ {
    /// Milliseconds to sleep; clamped to ≤ 1000. Default: 500.
    pub ms: Option<u64>,
}

#[derive(Serialize)]
pub struct SleepReply {
    pub ok: bool,
    pub slept_ms: u64,
}

pub fn router<S>() -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    Router::new()
        .route("/ping", get(ping))
        .route("/index/healthz", get(healthz))
        .route("/index/search", post(search_echo))
        .route("/sleep", get(sleep_ms))
}

pub async fn ping() -> Json<PingResponse> {
    Json(PingResponse { ok: true })
}

pub async fn healthz() -> Json<HealthReply> {
    Json(HealthReply { ok: true })
}

pub async fn search_echo(Json(body): Json<SearchRequest>) -> Json<SearchReply> {
    Json(SearchReply {
        ok: true,
        echoed: body.q,
    })
}

/// Bounded sleep helper for readiness/inflight smoke tests.
pub async fn sleep_ms(Query(q): Query<SleepQ>) -> Json<SleepReply> {
    let ms = q.ms.unwrap_or(500).min(1_000);
    tokio::time::sleep(Duration::from_millis(ms)).await;
    Json(SleepReply {
        ok: true,
        slept_ms: ms,
    })
}

```

### crates/omnigate/src/routes/v1/mailbox.rs
<a id="crates-omnigate-src-routes-v1-mailbox-rs"></a>

```rust
//! RO:WHAT   v1/mailbox surface (health stub now; real ops later).
//! RO:INVARS Stable JSON shapes for health; S must be Send+Sync for layering.

use axum::{routing::get, Json, Router};
use serde::Serialize;

#[derive(Serialize)]
pub struct HealthReply {
    pub ok: bool,
}

pub async fn healthz() -> Json<HealthReply> {
    Json(HealthReply { ok: true })
}

/// Minimal router for /v1/mailbox/*
pub fn router<S>() -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    Router::new().route("/healthz", get(healthz))
}

```

### crates/omnigate/src/routes/v1/mod.rs
<a id="crates-omnigate-src-routes-v1-mod-rs"></a>

```rust
//! RO:WHAT   v1 API surface aggregator (health/ping + facet stubs).
//! RO:WHY    Keep top-level router slim; v1 evolves independently.
//! RO:INVARS Only DTO-stable shapes; never leak internals.

pub mod dht;
pub mod facet;
pub mod index;
pub mod mailbox;
pub mod objects;

use axum::Router;

/// Compose the whole v1 subtree.
///
/// Mount with:
/// ```ignore
/// .nest("/v1", routes::v1::router())
/// ```
pub fn router<S>() -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    Router::new()
        .merge(index::router()) // includes /ping and /index/healthz
        .nest("/objects", objects::router())
        .nest("/mailbox", mailbox::router())
        .nest("/dht", dht::router())
        .nest("/facet", facet::router())
}

```

### crates/omnigate/src/routes/v1/objects.rs
<a id="crates-omnigate-src-routes-v1-objects-rs"></a>

```rust
//! RO:WHAT   v1: /objects health stub (ready to swap to StorageClient).
//! RO:INVARS 200/JSON only; no internal details.

use axum::{routing::get, Json, Router};
use serde::Serialize;

#[derive(Serialize)]
pub struct HealthReply {
    pub ok: bool,
}

pub fn router<S>() -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    Router::new().route("/healthz", get(healthz))
}

pub async fn healthz() -> Json<HealthReply> {
    Json(HealthReply { ok: true })
}

```

### crates/omnigate/src/routes/v1/ping.rs
<a id="crates-omnigate-src-routes-v1-ping-rs"></a>

```rust
//! RO:WHAT   GET /v1/ping handler
//! RO:WHY    Minimal health style endpoint used by benches and smoke tests.

use axum::{response::IntoResponse, Json};
use serde::Serialize;

#[derive(Serialize)]
pub struct PingResponse {
    pub ok: bool,
}

pub async fn handler() -> impl IntoResponse {
    Json(PingResponse { ok: true })
}

```

### crates/omnigate/src/runtime/channels.rs
<a id="crates-omnigate-src-runtime-channels-rs"></a>

```rust
//! RO:WHAT — Message channels between supervisor and workers.
//! RO:WHY  — Broadcast down (supervisor→workers), MPSC up (workers→supervisor).

use tokio::sync::{broadcast, mpsc};

#[derive(Debug, Clone)]
pub enum SupervisorMsg {
    /// Ask all workers to stop gracefully.
    Stop,
    /// Future: reload config, etc.
    Nop,
}

#[derive(Debug)]
pub enum WorkerMsg {
    Started(&'static str),
    Stopped(&'static str),
}

pub use broadcast::{Receiver as BcastRx, Sender as BcastTx};
pub use mpsc::{Receiver as MpscRx, Sender as MpscTx};

/// Build the control plane channels.
/// - `worker_backlog`: size of the per-worker upstream MPSC buffer.
pub fn mk_supervisor_bus(
    worker_backlog: usize,
) -> (
    BcastTx<SupervisorMsg>,
    BcastRx<SupervisorMsg>,
    MpscTx<WorkerMsg>,
    MpscRx<WorkerMsg>,
) {
    let (tx_cmd, rx_cmd) = broadcast::channel(16);
    let (up_tx, up_rx) = mpsc::channel(worker_backlog);
    (tx_cmd, rx_cmd, up_tx, up_rx)
}

```

### crates/omnigate/src/runtime/mod.rs
<a id="crates-omnigate-src-runtime-mod-rs"></a>

```rust
//! RO:WHAT — Lightweight runtime layer: supervised background workers + cooperative shutdown.
//! RO:WHY  — Keep App/router lean; side-loops (samplers, refreshers, warmers) live here.
//! RO:INTERACTS — ron-kernel (Bus/Events), Metrics (recorders), admission, policy.
//! RO:INVARIANTS — Single owner per worker task; graceful stop within timeout; no locks across .await.

mod channels;
mod shutdown;
mod supervisor;
mod worker;

pub mod sample;

pub use channels::{mk_supervisor_bus, SupervisorMsg, WorkerMsg};
pub use shutdown::{pair as shutdown_pair, Shutdown, ShutdownTrigger};
pub use supervisor::{spawn_supervisor, SupervisorHandle};
pub use worker::{spawn_worker, DynWorker, Worker};

```

### crates/omnigate/src/runtime/sample.rs
<a id="crates-omnigate-src-runtime-sample-rs"></a>

```rust
//! RO:WHAT — Example worker used by tests and as a template.
//! RO:WHY  — Minimal worker that exits on shutdown or Stop.

use std::{future::Future, pin::Pin, sync::Arc};
use tokio::sync::{broadcast, mpsc};
use tracing::info;

use super::channels::{SupervisorMsg, WorkerMsg};
use super::shutdown::Shutdown;
use super::worker::Worker;

#[derive(Default)]
pub struct TickWorker;

impl TickWorker {
    pub fn new() -> Arc<Self> {
        Arc::new(Self)
    }
}

impl Worker for TickWorker {
    fn name(&self) -> &'static str {
        "tick"
    }

    fn run(
        &self,
        shutdown: Shutdown,
        mut commands: broadcast::Receiver<SupervisorMsg>,
        up_tx: mpsc::Sender<WorkerMsg>,
    ) -> Pin<Box<dyn Future<Output = ()> + Send>> {
        Box::pin(async move {
            loop {
                tokio::select! {
                    _ = shutdown.cancelled() => {
                        break;
                    }
                    Ok(msg) = commands.recv() => {
                        if let SupervisorMsg::Stop = msg {
                            break;
                        }
                    }
                }
            }
            let _ = up_tx.send(WorkerMsg::Stopped("tick")).await;
            info!("tick worker exiting");
        })
    }
}

```

### crates/omnigate/src/runtime/shutdown.rs
<a id="crates-omnigate-src-runtime-shutdown-rs"></a>

```rust
//! RO:WHAT — Cooperative shutdown primitives.
//! RO:WHY  — A tiny CancellationToken wrapper so workers/supervisor can agree on quit.
//! RO:INVARIANTS — Non-blocking; clone is cheap; `cancelled()` is awaitable.

use tokio_util::sync::CancellationToken;

/// Handle that tasks can hold/clone to observe shutdown.
#[derive(Clone)]
pub struct Shutdown {
    token: CancellationToken,
}

/// Trigger used by the supervisor to request shutdown.
#[derive(Clone)]
pub struct ShutdownTrigger {
    token: CancellationToken,
}

/// Construct a (Shutdown, ShutdownTrigger) pair.
pub fn pair() -> (Shutdown, ShutdownTrigger) {
    let token = CancellationToken::new();
    (
        Shutdown {
            token: token.clone(),
        },
        ShutdownTrigger { token },
    )
}

impl Shutdown {
    /// Wait until shutdown is requested.
    pub async fn cancelled(&self) {
        self.token.cancelled().await;
    }
}

impl ShutdownTrigger {
    /// Request shutdown for all holders of the paired `Shutdown`.
    pub fn cancel(&self) {
        self.token.cancel();
    }
}

```

### crates/omnigate/src/runtime/supervisor.rs
<a id="crates-omnigate-src-runtime-supervisor-rs"></a>

```rust
//! RO:WHAT — Spawns and coordinates all workers.
//! RO:WHY  — Single place that can trigger graceful shutdown and fan-out commands.

use tokio::{sync::broadcast, task::JoinHandle};
use tracing::info;

use super::channels::{mk_supervisor_bus, MpscRx, SupervisorMsg};
use super::shutdown::{pair as shutdown_pair, ShutdownTrigger};
use super::worker::{spawn_worker, DynWorker};

pub struct SupervisorHandle {
    pub join: JoinHandle<()>,
    pub tx_cmd: broadcast::Sender<SupervisorMsg>,
    pub shutdown: ShutdownTrigger,
    pub up_rx: MpscRx<super::channels::WorkerMsg>,
}

pub fn spawn_supervisor(workers: Vec<DynWorker>, worker_backlog: usize) -> SupervisorHandle {
    let (tx_cmd, _rx_cmd, up_tx, up_rx) = mk_supervisor_bus(worker_backlog);
    let tx_cmd_for_task = tx_cmd.clone();

    let (shutdown, trigger) = shutdown_pair();

    let join = tokio::spawn(async move {
        // spawn all workers
        let mut joins: Vec<JoinHandle<()>> = Vec::with_capacity(workers.len());
        for w in workers {
            let rx = tx_cmd_for_task.subscribe();
            let j = spawn_worker(w, shutdown.clone(), rx, up_tx.clone());
            joins.push(j);
        }

        // Wait for shutdown, then ask everyone to stop.
        shutdown.cancelled().await;
        let _ = tx_cmd_for_task.send(SupervisorMsg::Stop);

        // Drain joins.
        for j in joins {
            let _ = j.await;
        }
        info!("supervisor exited");
    });

    SupervisorHandle {
        join,
        tx_cmd,
        shutdown: trigger,
        up_rx,
    }
}

```

### crates/omnigate/src/runtime/worker.rs
<a id="crates-omnigate-src-runtime-worker-rs"></a>

```rust
//! RO:WHAT — Worker trait + spawner glue.
//! RO:WHY  — Lets us run heterogeneous background tasks under a supervisor.

use std::{future::Future, pin::Pin, sync::Arc};
use tokio::{
    sync::{broadcast, mpsc},
    task::JoinHandle,
};
use tracing::info;

use super::channels::{SupervisorMsg, WorkerMsg};
use super::shutdown::Shutdown;

/// Vtable for a managed worker.
pub trait Worker: Send + Sync + 'static {
    fn name(&self) -> &'static str;

    fn run(
        &self,
        shutdown: Shutdown,
        commands: broadcast::Receiver<SupervisorMsg>,
        up_tx: mpsc::Sender<WorkerMsg>,
    ) -> Pin<Box<dyn Future<Output = ()> + Send>>;
}

pub type DynWorker = Arc<dyn Worker>;

pub fn spawn_worker(
    w: DynWorker,
    shutdown: Shutdown,
    commands: broadcast::Receiver<SupervisorMsg>,
    up_tx: mpsc::Sender<WorkerMsg>,
) -> JoinHandle<()> {
    let name = w.name();
    tokio::spawn(async move {
        // Let the supervisor know we’re starting.
        let _ = up_tx.send(WorkerMsg::Started(name)).await;

        // Run the worker future to completion.
        let fut = (*w).run(shutdown, commands, up_tx.clone());
        fut.await;

        info!(worker = name, "worker exited");
        // Best-effort notify stop.
        let _ = up_tx.send(WorkerMsg::Stopped(name)).await;
    })
}

```

### crates/omnigate/src/state.rs
<a id="crates-omnigate-src-state-rs"></a>

```rust
//! RO:WHAT   Shared application state container.
//! RO:WHY    Centralize config, policy evaluator, readiness policy, and helpers.

use std::sync::Arc;
use crate::readiness::policy::ReadyPolicy;

#[derive(Clone)]
pub struct AppState {
    pub config: Arc<crate::config::Config>,
    pub ready: ReadyPolicy,
    pub policy: Option<ron_policy::Evaluator>,
    pub tenant: Option<String>,
    pub region: Option<String>,
}

impl AppState {
    pub fn new(config: Arc<crate::config::Config>, ready: ReadyPolicy, policy: Option<ron_policy::Evaluator>) -> Arc<Self> {
        Arc::new(Self { config, ready, policy, tenant: None, region: None })
    }

    pub fn tags_for<B>(&self, _req: &axum::http::Request<B>) -> Vec<String> {
        // Future: pull auth claims or route-classifier tags.
        Vec::new()
    }
}

```

### crates/omnigate/src/types/dto.rs
<a id="crates-omnigate-src-types-dto-rs"></a>

```rust
//! RO:WHAT — Public response DTOs the API returns.
//! RO:WHY  — Tests serialize/deserialize these; keep stable wire shape.

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct VersionResponse {
    pub version: String,
    /// Optional short git hash if available.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub git: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct PingResponse {
    pub ok: bool,
}

```

### crates/omnigate/src/types/mod.rs
<a id="crates-omnigate-src-types-mod-rs"></a>

```rust
pub mod dto;

pub use dto::{PingResponse, VersionResponse};

```

### crates/omnigate/src/zk/mod.rs
<a id="crates-omnigate-src-zk-mod-rs"></a>

```rust
//! RO:WHAT — Zero-knowledge–ready envelope surface.
//! RO:WHY  — Carve clean seams (read-only vs mutate) + receipts without committing to a prover.
//! RO:INVARIANTS — No proof code here; only types and gating logic surfaces.

pub mod no_mutate;
pub mod receipts;

pub use no_mutate::{OpClass, OpGuard};
pub use receipts::{Receipt, ReceiptId, ReceiptStatus};

```

### crates/omnigate/src/zk/no_mutate.rs
<a id="crates-omnigate-src-zk-nomutate-rs"></a>

```rust
//! RO:WHAT — Read-only vs Mutate operation gating.
//! RO:WHY  — Allow policy/rate-limit paths to key off operation class.
//! RO:INVARIANTS — Pure classification; no IO; easy to unit test.

/// Operation class used by admissions/policy.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum OpClass {
    ReadOnly,
    Mutate,
}

/// Guard object carried in request extensions to mark op class.
#[derive(Debug, Clone, Copy)]
pub struct OpGuard {
    class: OpClass,
}

impl OpGuard {
    pub fn new(class: OpClass) -> Self {
        Self { class }
    }
    pub fn class(&self) -> OpClass {
        self.class
    }
}

```

### crates/omnigate/src/zk/receipts.rs
<a id="crates-omnigate-src-zk-receipts-rs"></a>

```rust
//! RO:WHAT — Generic receipt type for mutating operations.
//! RO:WHY  — Provide durable handle for async/queued mutations without picking a backend yet.
//! RO:INVARIANTS — Opaque ids; monotonic timestamps; status is conservative.

use serde::{Deserialize, Serialize};
use std::time::{SystemTime, UNIX_EPOCH};

pub type ReceiptId = String;

#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]
pub enum ReceiptStatus {
    Accepted,
    Processing,
    Completed,
    Failed,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Receipt {
    pub id: ReceiptId,
    pub status: ReceiptStatus,
    pub created_ms: u128,
    pub last_update_ms: u128,
}

impl Receipt {
    pub fn new(id: ReceiptId) -> Self {
        let now = now_ms();
        Self {
            id,
            status: ReceiptStatus::Accepted,
            created_ms: now,
            last_update_ms: now,
        }
    }
    pub fn set_status(&mut self, s: ReceiptStatus) {
        self.status = s;
        self.last_update_ms = now_ms();
    }
}

fn now_ms() -> u128 {
    SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_default()
        .as_millis()
}

```

### crates/omnigate/testing/chaos/scenario.yml
<a id="crates-omnigate-testing-chaos-scenario-yml"></a>

```yaml
# Scaffold example for chaos; fill with providers and injections.
injections: []

```

### crates/omnigate/testing/performance/baselines/p95_hydration.json
<a id="crates-omnigate-testing-performance-baselines-p95hydration-json"></a>

```json
{"p95_ms":150}

```

### crates/omnigate/testing/performance/baselines/p95_range.json
<a id="crates-omnigate-testing-performance-baselines-p95range-json"></a>

```json
{"p95_ms":100}

```

### crates/omnigate/testing/performance/hydrate_mix.sh
<a id="crates-omnigate-testing-performance-hydratemix-sh"></a>

```bash
#!/usr/bin/env bash
# Scaffold: put your loadgen here and assert p95 targets.

```

### crates/omnigate/testing/vectors/omnigate/error_413.json
<a id="crates-omnigate-testing-vectors-omnigate-error413-json"></a>

```json

```

### crates/omnigate/testing/vectors/omnigate/range_read.json
<a id="crates-omnigate-testing-vectors-omnigate-rangeread-json"></a>

```json

```

### crates/omnigate/testing/vectors/omnigate/unauth_401.json
<a id="crates-omnigate-testing-vectors-omnigate-unauth401-json"></a>

```json

```

### crates/omnigate/tests/admission_contract.rs
<a id="crates-omnigate-tests-admissioncontract-rs"></a>

```rust
// RO:WHAT
// Contract checks for simple "admission-style" guards wired via `from_fn_with_state`.
// These are *test-only* helpers to make sure our layering semantics and extractor
// signatures are correct under Axum 0.7.

use axum::{
    body::Body,
    extract::State,
    http::{Request, StatusCode},
    middleware::{from_fn_with_state, Next},
    response::{IntoResponse, Response},
    routing::get,
    Router,
};
use std::sync::{
    atomic::{AtomicUsize, Ordering},
    Arc,
};
use tower::ServiceExt;

// ----- Tiny quota guard -------------------------------------------------------

#[derive(Debug, Default)]
struct Tiny {
    // "hard" is a max-requests-left style counter.
    hard: AtomicUsize,
    // "soft" unused in these tiny tests but parked here for parity with previous shape.
    #[allow(dead_code)]
    soft: AtomicUsize,
}

async fn tiny_guard(State(state): State<Arc<Tiny>>, req: Request<Body>, next: Next) -> Response {
    // If no budget left, 429 immediately (cheap shed).
    if state.hard.load(Ordering::Relaxed) == 0 {
        return StatusCode::TOO_MANY_REQUESTS.into_response();
    }
    // Decrement and pass through.
    state.hard.fetch_sub(1, Ordering::Relaxed);
    next.run(req).await
}

// ----- "Once" guard (allow exactly one) --------------------------------------

#[derive(Debug)]
struct Once(AtomicUsize);

async fn once_guard(State(state): State<Arc<Once>>, req: Request<Body>, next: Next) -> Response {
    // First request allowed (counter set to 1), subsequent ones 429.
    if state.0.fetch_sub(1, Ordering::Relaxed) == 0 {
        return StatusCode::TOO_MANY_REQUESTS.into_response();
    }
    next.run(req).await
}

// ----- Tests -----------------------------------------------------------------

#[tokio::test]
async fn tiny_quota_allows_then_429s() {
    // Start with budget=2.
    let tiny = Arc::new(Tiny {
        hard: AtomicUsize::new(2),
        soft: AtomicUsize::new(0),
    });

    let app = Router::new()
        .route("/", get(|| async { "ok" }))
        .layer(from_fn_with_state(tiny.clone(), tiny_guard));

    // First two requests ok…
    let res = app
        .clone()
        .oneshot(Request::get("/").body(Body::empty()).unwrap())
        .await
        .unwrap();
    assert_eq!(res.status(), StatusCode::OK);

    let res = app
        .clone()
        .oneshot(Request::get("/").body(Body::empty()).unwrap())
        .await
        .unwrap();
    assert_eq!(res.status(), StatusCode::OK);

    // …third should be shed.
    let res = app
        .oneshot(Request::get("/").body(Body::empty()).unwrap())
        .await
        .unwrap();
    assert_eq!(res.status(), StatusCode::TOO_MANY_REQUESTS);
}

#[tokio::test]
async fn quota_when_exhausted_429() {
    // Allow exactly one request.
    let once = Arc::new(Once(AtomicUsize::new(1)));

    let app = Router::new()
        .route("/", get(|| async { "ok" }))
        .layer(from_fn_with_state(once.clone(), once_guard));

    // First request OK…
    let res = app
        .clone()
        .oneshot(Request::get("/").body(Body::empty()).unwrap())
        .await
        .unwrap();
    assert_eq!(res.status(), StatusCode::OK);

    // …second is 429.
    let res = app
        .oneshot(Request::get("/").body(Body::empty()).unwrap())
        .await
        .unwrap();
    assert_eq!(res.status(), StatusCode::TOO_MANY_REQUESTS);
}

```

### crates/omnigate/tests/dto_serialization.rs
<a id="crates-omnigate-tests-dtoserialization-rs"></a>

```rust
use omnigate::types::dto::{PingResponse, VersionResponse};

#[test]
fn dto_roundtrips() {
    // VersionResponse now: { version, git }
    let v = VersionResponse {
        version: "0.0.0".to_string(),
        git: Some("deadbeef".to_string()),
    };
    let s = serde_json::to_string(&v).unwrap();
    let _: VersionResponse = serde_json::from_str(&s).unwrap();

    // PingResponse now: { ok }
    let p = PingResponse { ok: true };
    let s = serde_json::to_string(&p).unwrap();
    let _: PingResponse = serde_json::from_str(&s).unwrap();
}

```

### crates/omnigate/tests/hardening.rs
<a id="crates-omnigate-tests-hardening-rs"></a>

```rust


```

### crates/omnigate/tests/interop_vectors.rs
<a id="crates-omnigate-tests-interopvectors-rs"></a>

```rust


```

### crates/omnigate/tests/loom_fanout.rs
<a id="crates-omnigate-tests-loomfanout-rs"></a>

```rust


```

### crates/omnigate/tests/metrics_contract.rs
<a id="crates-omnigate-tests-metricscontract-rs"></a>

```rust
//! Ensures /metrics exports required series & labels.
//! Run: cargo test -p omnigate --test metrics_contract

use regex::Regex;

#[test]
fn metrics_shape_is_present() {
    // For CI stability you can replace this with a boot-and-fetch helper.
    let metrics = include_str!("../testing/fixtures/metrics.sample.txt");

    for name in &[
        "http_requests_total",
        "request_latency_seconds",
        "admission_quota_exhausted_total",
        "admission_fair_queue_events_total",
        "body_reject_total",
        "decompress_reject_total",
        "policy_middleware_shortcircuits_total",
    ] {
        assert!(metrics.contains(name), "missing series: {name}");
    }

    let re = Regex::new(
        r#"http_requests_total\{route="[^"]+",method="(GET|POST|PUT|DELETE)",status="\d{3}"\}"#,
    )
    .unwrap();
    assert!(
        re.is_match(metrics),
        "labels missing on http_requests_total"
    );
}

```

### crates/omnigate/tests/middleware_contract.rs
<a id="crates-omnigate-tests-middlewarecontract-rs"></a>

```rust
// RO:WHAT — Contract tests for edge guards (decompress + body caps).
// RO:WHY  — Prevent regressions: unknown/stacked encodings => 415; over-budget compressed => 413;
//           oversized bodies => 413; small ones pass.

use axum::{
    body::{self, Body},
    http::{Request, StatusCode},
    response::IntoResponse,
    Json,
};
use serde_json::json;
use tower::{service_fn, ServiceBuilder, ServiceExt}; // ServiceExt gives us `.oneshot`

// Keep this comfortably above any tiny JSON error envelopes these tests read.
const READ_LIMIT: usize = 256 * 1024;

#[tokio::test]
async fn decompress_guard_unknown_encoding_415() {
    let svc = ServiceBuilder::new()
        .layer(omnigate::middleware::decompress_guard::layer())
        .service(service_fn(|_req| async move {
            Ok::<_, std::convert::Infallible>(Json(json!({"ok": true})).into_response())
        }));

    let req = Request::builder()
        .uri("/test")
        .method("POST")
        .header(axum::http::header::CONTENT_ENCODING, "compress") // not allowed
        .body(Body::from("tiny"))
        .unwrap();

    let resp = svc.oneshot(req).await.unwrap().into_response();
    assert_eq!(resp.status(), StatusCode::UNSUPPORTED_MEDIA_TYPE);

    let bytes = body::to_bytes(resp.into_body(), READ_LIMIT).await.unwrap();
    let v: serde_json::Value = serde_json::from_slice(&bytes).unwrap();
    assert_eq!(v["reason"], "unsupported_media_type");
}

#[tokio::test]
async fn decompress_guard_stacked_encodings_415() {
    let svc = ServiceBuilder::new()
        .layer(omnigate::middleware::decompress_guard::layer())
        .service(service_fn(|_req| async move {
            Ok::<_, std::convert::Infallible>(Json(json!({"ok": true})).into_response())
        }));

    let req = Request::builder()
        .uri("/test")
        .method("POST")
        .header(axum::http::header::CONTENT_ENCODING, "gzip, br")
        .body(Body::from("tiny"))
        .unwrap();

    let resp = svc.oneshot(req).await.unwrap().into_response();
    assert_eq!(resp.status(), StatusCode::UNSUPPORTED_MEDIA_TYPE);

    let bytes = body::to_bytes(resp.into_body(), READ_LIMIT).await.unwrap();
    let v: serde_json::Value = serde_json::from_slice(&bytes).unwrap();
    assert_eq!(v["reason"], "unsupported_media_type");
}

#[tokio::test]
async fn decompress_guard_over_budget_413() {
    let svc = ServiceBuilder::new()
        .layer(omnigate::middleware::decompress_guard::layer())
        .service(service_fn(|_req| async move {
            Ok::<_, std::convert::Infallible>(Json(json!({"ok": true})).into_response())
        }));

    // With EXPANSION_CAP=10 and MAX_EXPANDED=1 MiB, any compressed length > ~104_857 bytes triggers 413.
    let declared_len = 200_000u64;

    let req = Request::builder()
        .uri("/test")
        .method("POST")
        .header(axum::http::header::CONTENT_ENCODING, "gzip")
        .header(axum::http::header::CONTENT_LENGTH, declared_len.to_string())
        .body(Body::empty())
        .unwrap();

    let resp = svc.oneshot(req).await.unwrap().into_response();
    assert_eq!(resp.status(), StatusCode::PAYLOAD_TOO_LARGE);

    let bytes = body::to_bytes(resp.into_body(), READ_LIMIT).await.unwrap();
    let v: serde_json::Value = serde_json::from_slice(&bytes).unwrap();
    assert_eq!(v["reason"], "payload_too_large");
}

#[tokio::test]
async fn body_caps_oversized_by_header_413() {
    let svc = ServiceBuilder::new()
        .layer(omnigate::middleware::body_caps::layer())
        .service(service_fn(|_req| async move {
            Ok::<_, std::convert::Infallible>(Json(json!({"ok": true})).into_response())
        }));

    // 2 MiB > 1 MiB limit -> reject immediately via preflight guard.
    let req = Request::builder()
        .uri("/test")
        .method("POST")
        .header(
            axum::http::header::CONTENT_LENGTH,
            (2 * 1024 * 1024).to_string(),
        )
        .body(Body::empty())
        .unwrap();

    let resp = svc.oneshot(req).await.unwrap().into_response();
    assert_eq!(resp.status(), StatusCode::PAYLOAD_TOO_LARGE);

    let bytes = body::to_bytes(resp.into_body(), READ_LIMIT).await.unwrap();
    let v: serde_json::Value = serde_json::from_slice(&bytes).unwrap();
    assert_eq!(v["reason"], "payload_too_large");
}

#[tokio::test]
async fn body_caps_small_ok_200() {
    let svc = ServiceBuilder::new()
        .layer(omnigate::middleware::body_caps::layer())
        .service(service_fn(|_req| async move {
            Ok::<_, std::convert::Infallible>(Json(json!({"ok": true})).into_response())
        }));

    let body_txt = "hello world";
    let req = Request::builder()
        .uri("/test")
        .method("POST")
        .header(
            axum::http::header::CONTENT_LENGTH,
            body_txt.len().to_string(),
        )
        .body(Body::from(body_txt.to_string()))
        .unwrap();

    let resp = svc.oneshot(req).await.unwrap().into_response();
    assert_eq!(resp.status(), StatusCode::OK);

    let bytes = body::to_bytes(resp.into_body(), READ_LIMIT).await.unwrap();
    let v: serde_json::Value = serde_json::from_slice(&bytes).unwrap();
    assert_eq!(v["ok"], true);
}

```

### crates/omnigate/tests/oap_limits.rs
<a id="crates-omnigate-tests-oaplimits-rs"></a>

```rust


```

### crates/omnigate/tests/policy_gate.rs
<a id="crates-omnigate-tests-policygate-rs"></a>

```rust
//! Verifies PolicyLayer wiring and shows the failure/success cases.
//!
//! Case A (broken): Extension<PolicyBundle> layered *before* `middleware::apply` →
//!                  PolicyLayer can’t see the bundle → PUT returns 405 (router method guard).
//! Case B (fixed):  Extension<PolicyBundle> layered *after*  `middleware::apply` →
//!                  PolicyLayer sees the bundle → PUT returns 403 (policy deny).

use std::sync::Arc;

use axum::{
    body::Body, extract::Request, http::StatusCode, response::IntoResponse, routing::get, Json,
    Router,
};
use ron_policy::PolicyBundle;
use serde_json::json;
use tower::ServiceExt;

async fn ping() -> impl IntoResponse {
    Json(json!({ "ok": true }))
}

// Minimal strict-policy bundle:
// - default deny
// - allow only GET
fn test_bundle() -> PolicyBundle {
    let json = r#"
    {
      "version": 1,
      "defaults": { "default_action": "deny" },
      "rules": [
        { "id": "allow-gets", "when": { "method": "GET" }, "action": "allow" }
      ]
    }"#;

    serde_json::from_str::<PolicyBundle>(json).expect("strict bundle should parse")
}

#[tokio::test]
async fn policy_broken_layering_yields_405_put() {
    // Router with only GET /v1/ping
    let router = Router::new().route("/v1/ping", get(ping));

    // ❌ BROKEN ORDER: layer Extension first, then apply middleware stack.
    // In this order, the PolicyLayer (added by middleware::apply) sits OUTSIDE
    // the Extension layer and thus does NOT see the bundled policy.
    let router = router.layer(axum::Extension(Arc::new(test_bundle())));
    let router = omnigate::middleware::apply(router);

    // PUT should not be allowed by the route; without policy, this becomes 405.
    let req = Request::builder()
        .method("PUT")
        .uri("/v1/ping")
        .body(Body::empty())
        .unwrap();

    let resp = router.oneshot(req).await.unwrap();
    assert_eq!(
        resp.status(),
        StatusCode::METHOD_NOT_ALLOWED,
        "broken layering should yield 405 (policy unseen)"
    );
}

#[tokio::test]
async fn policy_correct_layering_yields_403_put() {
    // Router with only GET /v1/ping
    let base = Router::new().route("/v1/ping", get(ping));

    // ✅ CORRECT ORDER: build the middleware stack first (includes PolicyLayer),
    // then layer the Extension so it runs OUTSIDE and is visible to PolicyLayer.
    let router = omnigate::middleware::apply(base).layer(axum::Extension(Arc::new(test_bundle())));

    // PUT should be denied by policy (default deny; only GET is allowed).
    let req = Request::builder()
        .method("PUT")
        .uri("/v1/ping")
        .body(Body::empty())
        .unwrap();

    let resp = router.clone().oneshot(req).await.unwrap();
    assert_eq!(
        resp.status(),
        StatusCode::FORBIDDEN,
        "correct layering should yield 403 (policy deny)"
    );

    // GET should still pass (rule allows GET)
    let req_ok = Request::builder()
        .method("GET")
        .uri("/v1/ping")
        .body(Body::empty())
        .unwrap();

    let resp_ok = router.oneshot(req_ok).await.unwrap();
    assert_eq!(
        resp_ok.status(),
        StatusCode::OK,
        "GET should be allowed by policy"
    );
}

```

### crates/omnigate/tests/policy_metrics.rs
<a id="crates-omnigate-tests-policymetrics-rs"></a>

```rust
// crates/omnigate/tests/policy_metrics.rs
// Proves policy_middleware_shortcircuits_total increments when policy denies a request.
// We scrape the text exposition to avoid private proto APIs.

use std::sync::Arc;

use axum::{body::Body, extract::Request, routing::get, Json, Router};
use prometheus::{gather, Encoder, TextEncoder};
use regex::Regex;
use ron_policy::PolicyBundle;
use serde_json::json;
use tower::ServiceExt;

async fn ping() -> Json<serde_json::Value> {
    Json(json!({ "ok": true }))
}

// Strict bundle: default deny; allow only GET.
fn strict_bundle() -> PolicyBundle {
    let json = r#"
    {
      "version": 1,
      "defaults": { "default_action": "deny" },
      "rules": [
        { "id": "allow-gets", "when": { "method": "GET" }, "action": "allow" }
      ]
    }"#;
    serde_json::from_str::<PolicyBundle>(json).unwrap()
}

// Scrape the text exposition and sum all samples for a counter (any labels).
fn scrape_counter_sum(name: &str) -> f64 {
    let mut buf = Vec::new();
    TextEncoder::new().encode(&gather(), &mut buf).ok();
    let text = String::from_utf8_lossy(&buf);

    // Matches lines like:
    // policy_middleware_shortcircuits_total 3
    // policy_middleware_shortcircuits_total{status="403"} 2
    let re = Regex::new(&format!(
        r#"(?m)^{}\s*(?:\{{[^}}]*\}})?\s+([0-9]+(?:\.[0-9]+)?)\s*$"#,
        regex::escape(name)
    ))
    .unwrap();

    let mut sum = 0.0;
    for cap in re.captures_iter(&text) {
        if let Some(m) = cap.get(1) {
            if let Ok(v) = m.as_str().parse::<f64>() {
                sum += v;
            }
        }
    }
    sum
}

#[tokio::test]
async fn policy_deny_bumps_counter() {
    // Router with GET /v1/ping
    let base = Router::new().route("/v1/ping", get(ping));

    // Correct layering: middleware first (adds PolicyLayer), then Extension(bundle)
    let router =
        omnigate::middleware::apply(base).layer(axum::Extension(Arc::new(strict_bundle())));

    // Read counter before
    let before = scrape_counter_sum("policy_middleware_shortcircuits_total");

    // Issue a denied PUT (default deny)
    let req = Request::builder()
        .method("PUT")
        .uri("/v1/ping")
        .body(Body::empty())
        .unwrap();
    let resp = router.clone().oneshot(req).await.unwrap();
    assert_eq!(resp.status().as_u16(), 403, "policy should deny PUT");

    // Counter should have increased
    let after = scrape_counter_sum("policy_middleware_shortcircuits_total");
    assert!(
        after > before,
        "expected policy_middleware_shortcircuits_total to increase; before={before}, after={after}"
    );
}

```

### crates/omnigate/tests/readiness_error_rate.rs
<a id="crates-omnigate-tests-readinesserrorrate-rs"></a>

```rust
//! Verifies that sustained 503 drop/error rate trips /readyz → 503 (error-rate branch).
//! Strategy: set *tiny* fair-queue capacity to force 503 drops, but set inflight-threshold huge
//! so we do not trip via inflight. The sampler counts fair_q drops toward error-rate.

use anyhow::Result;
use omnigate::{config, App};
use reqwest::Client;
use std::net::SocketAddr;
use tokio::{
    net::TcpListener,
    time::{sleep, Duration},
};

async fn spawn_app_with_cfg(mut cfg: config::Config) -> Result<(SocketAddr, SocketAddr)> {
    cfg.server.bind = "127.0.0.1:0".parse().unwrap();
    cfg.server.metrics_addr = "127.0.0.1:0".parse().unwrap();

    let app = App::build(cfg).await?;
    let listener = TcpListener::bind("127.0.0.1:0").await?;
    let api_addr = listener.local_addr()?;
    let admin_addr = app.admin_addr;

    let router = app.router;
    tokio::spawn(async move {
        axum::serve(listener, router).await.unwrap();
    });

    Ok((api_addr, admin_addr))
}

fn cfg_error_rate_via_fair_queue() -> config::Config {
    config::Config {
        server: config::Server {
            bind: "127.0.0.1:5305".parse().unwrap(),
            metrics_addr: "127.0.0.1:9605".parse().unwrap(),
            amnesia: true,
        },
        oap: config::Oap {
            max_frame_bytes: 1_048_576,
            stream_chunk_bytes: 65_536,
        },
        admission: config::Admission {
            // Quotas generous (we don't want 429s for this test)
            global_quota: config::GlobalQuota {
                qps: 1_000_000,
                burst: 1_000_000,
            },
            ip_quota: config::IpQuota {
                enabled: false,
                qps: 0,
                burst: 0,
            },
            // FAIR-QUEUE: extremely tiny hard limit to force 503 drops under concurrency
            fair_queue: config::FairQueue {
                max_inflight: 8,
                headroom: Some(0),
                weights: config::Weights {
                    anon: 1,
                    auth: 1,
                    admin: 1,
                },
            },
            body: config::BodyCaps {
                max_content_length: 1_048_576,
                reject_on_missing_length: true,
            },
            decompression: config::Decompress {
                allow: vec!["identity".into(), "gzip".into()],
                deny_stacked: true,
            },
        },
        policy: config::Policy {
            enabled: false, // keep policy out of the picture for this test
            bundle_path: "crates/omnigate/configs/policy.bundle.json".into(),
            fail_mode: "deny".into(),
        },
        readiness: config::Readiness {
            max_inflight_threshold: 1_000_000, // make inflight path irrelevant
            error_rate_429_503_pct: 0.1,       // very easy to trip
            window_secs: 2,                    // short window => quick sampler ticks
            hold_for_secs: 3,
        },
    }
}

#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
async fn readiness_trips_on_error_rate() -> Result<()> {
    let (api, _admin) = spawn_app_with_cfg(cfg_error_rate_via_fair_queue()).await?;
    let api_base = format!("http://{}", api);
    let client = Client::builder().build()?;

    // 1) Sanity: /readyz starts 200
    let code = client
        .get(format!("{}/readyz", api_base))
        .send()
        .await?
        .status();
    assert!(code.is_success(), "expected 200 from /readyz, got {}", code);

    // 2) Create a heavy burst against /v1/sleep that will exceed the tiny fair-queue capacity
    let concurrency = 200usize;
    let sleep_ms = 800u64;
    let mut joins = Vec::with_capacity(concurrency);
    for _ in 0..concurrency {
        let url = format!("{}/v1/sleep?ms={}", api_base, sleep_ms);
        let c = client.clone();
        joins.push(tokio::spawn(async move {
            let _ = c.get(url).send().await; // many of these will be 503 from shedding
        }));
    }

    // 3) Poll /readyz until it flips to 503 (expect via error-rate branch)
    // Give sampler windows a chance to observe drops: up to ~8s
    let deadline = tokio::time::Instant::now() + Duration::from_secs(8);
    let mut degraded = false;
    while tokio::time::Instant::now() < deadline {
        let code = client
            .get(format!("{}/readyz", api_base))
            .send()
            .await?
            .status();
        if code.as_u16() == 503 {
            degraded = true;
            break;
        }
        sleep(Duration::from_millis(150)).await;
    }

    for j in joins {
        let _ = j.await;
    }
    assert!(
        degraded,
        "expected /readyz to degrade to 503 by error-rate (fair-queue drops)"
    );
    Ok(())
}

```

### crates/omnigate/tests/readiness_inflight.rs
<a id="crates-omnigate-tests-readinessinflight-rs"></a>

```rust
//! Verifies that sustained in-flight pressure trips /readyz → 503,
//! holds for hold_for_secs, then recovers to 200.

use anyhow::Result;
use omnigate::{config, App};
use reqwest::Client;
use std::net::SocketAddr;
use tokio::{
    net::TcpListener,
    time::{sleep, Duration},
};

async fn spawn_app_with_cfg(mut cfg: config::Config) -> Result<(SocketAddr, SocketAddr)> {
    // Bind API to an ephemeral port; we’ll override at serve-time.
    cfg.server.bind = "127.0.0.1:0"
        .parse()
        .unwrap_or("127.0.0.1:0".parse().unwrap());
    // Bind metrics/admin plane to ephemeral as well; App::build will return the actual addr.
    cfg.server.metrics_addr = "127.0.0.1:0".parse().unwrap();

    let app = App::build(cfg).await?;
    // Bind listener for API
    let listener = TcpListener::bind("127.0.0.1:0").await?;
    let api_addr = listener.local_addr()?;
    let admin_addr = app.admin_addr;

    // Serve API in background
    let router = app.router;
    tokio::spawn(async move {
        axum::serve(listener, router).await.unwrap();
    });

    Ok((api_addr, admin_addr))
}

fn cfg_inflight_low_threshold() -> config::Config {
    config::Config {
        server: config::Server {
            bind: "127.0.0.1:5305".parse().unwrap(), // ignored (we bind 0)
            metrics_addr: "127.0.0.1:9605".parse().unwrap(), // ignored (we bind 0)
            amnesia: true,
        },
        oap: config::Oap {
            max_frame_bytes: 1_048_576,
            stream_chunk_bytes: 65_536,
        },
        admission: config::Admission {
            global_quota: config::GlobalQuota {
                qps: 20_000,
                burst: 40_000,
            },
            ip_quota: config::IpQuota {
                enabled: true,
                qps: 2_000,
                burst: 4_000,
            },
            fair_queue: config::FairQueue {
                max_inflight: 2048,
                headroom: Some(256),
                weights: config::Weights {
                    anon: 1,
                    auth: 5,
                    admin: 10,
                },
            },
            body: config::BodyCaps {
                max_content_length: 1_048_576,
                reject_on_missing_length: true,
            },
            decompression: config::Decompress {
                allow: vec!["identity".into(), "gzip".into()],
                deny_stacked: true,
            },
        },
        policy: config::Policy {
            enabled: true,
            bundle_path: "crates/omnigate/configs/policy.bundle.json".into(),
            fail_mode: "deny".into(),
        },
        // Low thresholds so laptops trip quickly
        readiness: config::Readiness {
            max_inflight_threshold: 64,
            error_rate_429_503_pct: 100.0, // make inflight the only trigger here
            window_secs: 5,
            hold_for_secs: 6,
        },
    }
}

#[tokio::test(flavor = "multi_thread", worker_threads = 2)]
async fn readiness_trips_on_inflight_then_recovers() -> Result<()> {
    let (api, admin) = spawn_app_with_cfg(cfg_inflight_low_threshold()).await?;
    let api_base = format!("http://{}", api);
    let ops_base = format!("http://{}", admin);
    let client = Client::builder().build()?;

    // 1) Sanity: /readyz starts 200
    let code = client
        .get(format!("{}/readyz", api_base))
        .send()
        .await?
        .status();
    assert!(code.is_success(), "expected 200 from /readyz, got {}", code);

    // 2) Create sustained in-flight using /v1/sleep
    let concurrency = 200usize;
    let sleep_ms = 800u64;

    let mut joins = Vec::with_capacity(concurrency);
    for _ in 0..concurrency {
        let url = format!("{}/v1/sleep?ms={}", api_base, sleep_ms);
        let c = client.clone();
        joins.push(tokio::spawn(async move {
            let _ = c.get(url).send().await;
        }));
    }

    // 3) Poll /readyz until it flips to 503 or timeout
    let deadline = tokio::time::Instant::now() + Duration::from_secs(10);
    let mut degraded = false;
    while tokio::time::Instant::now() < deadline {
        let code = client
            .get(format!("{}/readyz", api_base))
            .send()
            .await?
            .status();
        if code.as_u16() == 503 {
            degraded = true;
            break;
        }
        sleep(Duration::from_millis(200)).await;
    }
    assert!(degraded, "expected /readyz to degrade to 503 under load");

    // 4) During hold, /readyz should remain 503
    let code_hold = client
        .get(format!("{}/readyz", api_base))
        .send()
        .await?
        .status();
    assert_eq!(code_hold.as_u16(), 503, "expected hold window to stick");

    // 5) Wait hold_for_secs + cushion and expect recovery to 200
    sleep(Duration::from_secs(7)).await;
    let code_recover = client
        .get(format!("{}/readyz", api_base))
        .send()
        .await?
        .status();
    assert!(
        code_recover.is_success(),
        "expected /readyz to recover to 200"
    );

    // Optional: sample metrics once to ensure exporter is alive
    let _ = client.get(format!("{}/metrics", ops_base)).send().await?;

    // Ensure sleepers finish
    for j in joins {
        let _ = j.await;
    }

    Ok(())
}

```

### crates/omnigate/tests/ready_truth.rs
<a id="crates-omnigate-tests-readytruth-rs"></a>

```rust
use std::io::{Read, Write};
use std::net::TcpStream;
use std::path::PathBuf;
use std::time::Duration;

use omnigate::{bootstrap::server, config::Config};

fn http_get_status(addr: &str, path: &str) -> Option<u16> {
    let mut stream = TcpStream::connect(addr).ok()?;
    stream
        .set_read_timeout(Some(Duration::from_millis(800)))
        .ok()?;
    let req = format!(
        "GET {} HTTP/1.1\r\nHost: {}\r\nConnection: close\r\n\r\n",
        path, addr
    );
    stream.write_all(req.as_bytes()).ok()?;

    let mut buf = Vec::with_capacity(4096);
    stream.read_to_end(&mut buf).ok()?;
    let text = String::from_utf8_lossy(&buf);
    if let Some(status_line) = text.lines().next() {
        let parts: Vec<_> = status_line.split_whitespace().collect();
        if parts.len() >= 2 {
            return parts[1].parse::<u16>().ok();
        }
    }
    None
}

#[tokio::test(flavor = "multi_thread")]
async fn ready_flips_with_config() {
    // Build an absolute path to configs/omnigate.toml relative to THIS crate.
    let cfg_path: PathBuf = PathBuf::from(env!("CARGO_MANIFEST_DIR"))
        .join("configs")
        .join("omnigate.toml");

    let cfg = Config::from_toml_file(cfg_path.to_string_lossy().as_ref()).expect("load config");

    // Build the app (admin plane + readiness config gate flip happens in lib.rs).
    let app = omnigate::App::build(cfg.clone()).await.expect("build app");

    // Start the API server; keep the JoinHandle alive for the test lifetime.
    let server_cfg = cfg.server; // move once
    let api_addr = server_cfg.bind;
    let (_task, _bound) = server::serve(server_cfg, app.router).await.expect("serve");

    // Probe /healthz until it is up.
    let api = api_addr.to_string();
    let mut ok = false;
    for _ in 0..100 {
        if let Some(code) = http_get_status(&api, "/healthz") {
            if code == 200 {
                ok = true;
                break;
            }
        }
        tokio::time::sleep(Duration::from_millis(50)).await;
    }
    assert!(ok, "healthz did not come up on {}", api);

    // Truthful readiness should be 200 after config gate flips.
    let mut ready_ok = false;
    for _ in 0..100 {
        if let Some(code) = http_get_status(&api, "/readyz") {
            if code == 200 {
                ready_ok = true;
                break;
            }
        }
        tokio::time::sleep(Duration::from_millis(50)).await;
    }
    assert!(ready_ok, "readyz did not return 200");
}

```

### crates/omnigate/tests/readyz_overload.rs
<a id="crates-omnigate-tests-readyzoverload-rs"></a>

```rust


```

### crates/omnigate/tests/zk_read_only.rs
<a id="crates-omnigate-tests-zkreadonly-rs"></a>

```rust


```

### crates/omnigate/tests/zk_receipts.rs
<a id="crates-omnigate-tests-zkreceipts-rs"></a>

```rust
use omnigate::zk::{OpClass, OpGuard, Receipt, ReceiptStatus};

#[test]
fn receipt_status_transitions_update_time() {
    let mut r = Receipt::new("r1".into());
    let t0 = r.last_update_ms;
    r.set_status(ReceiptStatus::Processing);
    assert!(r.last_update_ms >= t0);
    let t1 = r.last_update_ms;
    r.set_status(ReceiptStatus::Completed);
    assert!(r.last_update_ms >= t1);
}

#[test]
fn opguard_marks_class() {
    let g = OpGuard::new(OpClass::ReadOnly);
    assert_eq!(g.class(), OpClass::ReadOnly);
    let g2 = OpGuard::new(OpClass::Mutate);
    assert_eq!(g2.class(), OpClass::Mutate);
}

```



---



# svc-gateway

_Source: crates/svc-gateway/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-11-05T15:42:57Z -->
# Code Bundle — `svc-gateway`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/svc-gateway/.github/workflows/api-stability.yml](#crates-svc-gateway--github-workflows-api-stability-yml)
- [crates/svc-gateway/.github/workflows/ci.yml](#crates-svc-gateway--github-workflows-ci-yml)
- [crates/svc-gateway/.github/workflows/fuzz-nightly.yml](#crates-svc-gateway--github-workflows-fuzz-nightly-yml)
- [crates/svc-gateway/.github/workflows/perf-guard.yml](#crates-svc-gateway--github-workflows-perf-guard-yml)
- [crates/svc-gateway/Cargo.toml](#crates-svc-gateway-Cargo-toml)
- [crates/svc-gateway/benches/baseline.json](#crates-svc-gateway-benches-baseline-json)
- [crates/svc-gateway/benches/bench_gateway.sh](#crates-svc-gateway-benches-benchgateway-sh)
- [crates/svc-gateway/build.rs](#crates-svc-gateway-build-rs)
- [crates/svc-gateway/configs/svc-gateway.sample.toml](#crates-svc-gateway-configs-svc-gateway-sample-toml)
- [crates/svc-gateway/fuzz/targets/oap_frame.rs](#crates-svc-gateway-fuzz-targets-oapframe-rs)
- [crates/svc-gateway/fuzz/targets/taxonomy_mapper.rs](#crates-svc-gateway-fuzz-targets-taxonomymapper-rs)
- [crates/svc-gateway/scripts/chaos_burst.sh](#crates-svc-gateway-scripts-chaosburst-sh)
- [crates/svc-gateway/scripts/dev_run.sh](#crates-svc-gateway-scripts-devrun-sh)
- [crates/svc-gateway/scripts/export_metrics.sh](#crates-svc-gateway-scripts-exportmetrics-sh)
- [crates/svc-gateway/scripts/run_gateway.sh](#crates-svc-gateway-scripts-rungateway-sh)
- [crates/svc-gateway/scripts/sanity_rate_limit.sh](#crates-svc-gateway-scripts-sanityratelimit-sh)
- [crates/svc-gateway/scripts/smoke_gateway.sh](#crates-svc-gateway-scripts-smokegateway-sh)
- [crates/svc-gateway/scripts/soak_test.sh](#crates-svc-gateway-scripts-soaktest-sh)
- [crates/svc-gateway/scripts/test_body_cap.sh](#crates-svc-gateway-scripts-testbodycap-sh)
- [crates/svc-gateway/scripts/test_rate_limit.sh](#crates-svc-gateway-scripts-testratelimit-sh)
- [crates/svc-gateway/src/admission/capabilities.rs](#crates-svc-gateway-src-admission-capabilities-rs)
- [crates/svc-gateway/src/admission/classifier.rs](#crates-svc-gateway-src-admission-classifier-rs)
- [crates/svc-gateway/src/admission/mod.rs](#crates-svc-gateway-src-admission-mod-rs)
- [crates/svc-gateway/src/admission/payments.rs](#crates-svc-gateway-src-admission-payments-rs)
- [crates/svc-gateway/src/admission/quotas.rs](#crates-svc-gateway-src-admission-quotas-rs)
- [crates/svc-gateway/src/admission/residency.rs](#crates-svc-gateway-src-admission-residency-rs)
- [crates/svc-gateway/src/admission/taxonomy.rs](#crates-svc-gateway-src-admission-taxonomy-rs)
- [crates/svc-gateway/src/cli/mod.rs](#crates-svc-gateway-src-cli-mod-rs)
- [crates/svc-gateway/src/config/amnesia.rs](#crates-svc-gateway-src-config-amnesia-rs)
- [crates/svc-gateway/src/config/env.rs](#crates-svc-gateway-src-config-env-rs)
- [crates/svc-gateway/src/config/mod.rs](#crates-svc-gateway-src-config-mod-rs)
- [crates/svc-gateway/src/config/safety.rs](#crates-svc-gateway-src-config-safety-rs)
- [crates/svc-gateway/src/consts.rs](#crates-svc-gateway-src-consts-rs)
- [crates/svc-gateway/src/errors.rs](#crates-svc-gateway-src-errors-rs)
- [crates/svc-gateway/src/forward/index_client.rs](#crates-svc-gateway-src-forward-indexclient-rs)
- [crates/svc-gateway/src/forward/mod.rs](#crates-svc-gateway-src-forward-mod-rs)
- [crates/svc-gateway/src/forward/overlay_client.rs](#crates-svc-gateway-src-forward-overlayclient-rs)
- [crates/svc-gateway/src/forward/storage_client.rs](#crates-svc-gateway-src-forward-storageclient-rs)
- [crates/svc-gateway/src/headers/etag.rs](#crates-svc-gateway-src-headers-etag-rs)
- [crates/svc-gateway/src/headers/mod.rs](#crates-svc-gateway-src-headers-mod-rs)
- [crates/svc-gateway/src/layers/auth.rs](#crates-svc-gateway-src-layers-auth-rs)
- [crates/svc-gateway/src/layers/body_caps.rs](#crates-svc-gateway-src-layers-bodycaps-rs)
- [crates/svc-gateway/src/layers/concurrency.rs](#crates-svc-gateway-src-layers-concurrency-rs)
- [crates/svc-gateway/src/layers/corr.rs](#crates-svc-gateway-src-layers-corr-rs)
- [crates/svc-gateway/src/layers/decode_guard.rs](#crates-svc-gateway-src-layers-decodeguard-rs)
- [crates/svc-gateway/src/layers/drr.rs](#crates-svc-gateway-src-layers-drr-rs)
- [crates/svc-gateway/src/layers/mod.rs](#crates-svc-gateway-src-layers-mod-rs)
- [crates/svc-gateway/src/layers/rate_limit.rs](#crates-svc-gateway-src-layers-ratelimit-rs)
- [crates/svc-gateway/src/layers/tarpit.rs](#crates-svc-gateway-src-layers-tarpit-rs)
- [crates/svc-gateway/src/layers/timeouts.rs](#crates-svc-gateway-src-layers-timeouts-rs)
- [crates/svc-gateway/src/lib.rs](#crates-svc-gateway-src-lib-rs)
- [crates/svc-gateway/src/main.rs](#crates-svc-gateway-src-main-rs)
- [crates/svc-gateway/src/observability/http_metrics.rs](#crates-svc-gateway-src-observability-httpmetrics-rs)
- [crates/svc-gateway/src/observability/logging.rs](#crates-svc-gateway-src-observability-logging-rs)
- [crates/svc-gateway/src/observability/metrics.rs](#crates-svc-gateway-src-observability-metrics-rs)
- [crates/svc-gateway/src/observability/metrics_boot.rs](#crates-svc-gateway-src-observability-metricsboot-rs)
- [crates/svc-gateway/src/observability/mod.rs](#crates-svc-gateway-src-observability-mod-rs)
- [crates/svc-gateway/src/observability/readiness.rs](#crates-svc-gateway-src-observability-readiness-rs)
- [crates/svc-gateway/src/observability/ready_metrics.rs](#crates-svc-gateway-src-observability-readymetrics-rs)
- [crates/svc-gateway/src/observability/rejects.rs](#crates-svc-gateway-src-observability-rejects-rs)
- [crates/svc-gateway/src/observability/tracing.rs](#crates-svc-gateway-src-observability-tracing-rs)
- [crates/svc-gateway/src/policy/abuse.rs](#crates-svc-gateway-src-policy-abuse-rs)
- [crates/svc-gateway/src/policy/mod.rs](#crates-svc-gateway-src-policy-mod-rs)
- [crates/svc-gateway/src/policy/residency.rs](#crates-svc-gateway-src-policy-residency-rs)
- [crates/svc-gateway/src/pq/mod.rs](#crates-svc-gateway-src-pq-mod-rs)
- [crates/svc-gateway/src/pq/policy.rs](#crates-svc-gateway-src-pq-policy-rs)
- [crates/svc-gateway/src/readiness/keys.rs](#crates-svc-gateway-src-readiness-keys-rs)
- [crates/svc-gateway/src/readiness/mod.rs](#crates-svc-gateway-src-readiness-mod-rs)
- [crates/svc-gateway/src/result.rs](#crates-svc-gateway-src-result-rs)
- [crates/svc-gateway/src/routes/dev.rs](#crates-svc-gateway-src-routes-dev-rs)
- [crates/svc-gateway/src/routes/health.rs](#crates-svc-gateway-src-routes-health-rs)
- [crates/svc-gateway/src/routes/metrics.rs](#crates-svc-gateway-src-routes-metrics-rs)
- [crates/svc-gateway/src/routes/mod.rs](#crates-svc-gateway-src-routes-mod-rs)
- [crates/svc-gateway/src/routes/objects.rs](#crates-svc-gateway-src-routes-objects-rs)
- [crates/svc-gateway/src/routes/objects_range.rs](#crates-svc-gateway-src-routes-objectsrange-rs)
- [crates/svc-gateway/src/routes/ready.rs](#crates-svc-gateway-src-routes-ready-rs)
- [crates/svc-gateway/src/routes/version.rs](#crates-svc-gateway-src-routes-version-rs)
- [crates/svc-gateway/src/state.rs](#crates-svc-gateway-src-state-rs)
- [crates/svc-gateway/src/tls/mod.rs](#crates-svc-gateway-src-tls-mod-rs)
- [crates/svc-gateway/tests/integration/caps_limits.rs](#crates-svc-gateway-tests-integration-capslimits-rs)
- [crates/svc-gateway/tests/integration/interop_vectors.rs](#crates-svc-gateway-tests-integration-interopvectors-rs)
- [crates/svc-gateway/tests/integration/loom_readiness.rs](#crates-svc-gateway-tests-integration-loomreadiness-rs)
- [crates/svc-gateway/tests/integration/readyz_degrade.rs](#crates-svc-gateway-tests-integration-readyzdegrade-rs)
- [crates/svc-gateway/tests/integration/taxonomy_stability.rs](#crates-svc-gateway-tests-integration-taxonomystability-rs)
- [crates/svc-gateway/tests/vectors/error_taxonomy.json](#crates-svc-gateway-tests-vectors-errortaxonomy-json)
- [crates/svc-gateway/tests/vectors/manifest_digest.json](#crates-svc-gateway-tests-vectors-manifestdigest-json)
- [crates/svc-gateway/tests/vectors/oap1_frame_roundtrip.json](#crates-svc-gateway-tests-vectors-oap1frameroundtrip-json)

### crates/svc-gateway/.github/workflows/api-stability.yml
<a id="crates-svc-gateway--github-workflows-api-stability-yml"></a>

```yaml
name: api-stability
on:
  pull_request:
    paths:
      - "src/**"
      - "Cargo.toml"
jobs:
  api:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - name: public api (placeholder)
        run: echo "wire cargo-public-api / semver-checks here"

```

### crates/svc-gateway/.github/workflows/ci.yml
<a id="crates-svc-gateway--github-workflows-ci-yml"></a>

```yaml
name: ci
on: [push, pull_request]
jobs:
  ci:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - name: fmt
        run: cargo fmt --all -- --check
      - name: clippy
        run: cargo clippy --all-targets --all-features -- -D warnings
      - name: test
        run: cargo test --all-features
      - name: deny (licenses/advisories)
        run: echo "placeholder — add cargo-deny later"

```

### crates/svc-gateway/.github/workflows/fuzz-nightly.yml
<a id="crates-svc-gateway--github-workflows-fuzz-nightly-yml"></a>

```yaml
name: fuzz-nightly
on:
  schedule:
    - cron: "0 3 * * *"
jobs:
  fuzz:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - name: fuzz (placeholder)
        run: echo "wire cargo-fuzz here"

```

### crates/svc-gateway/.github/workflows/perf-guard.yml
<a id="crates-svc-gateway--github-workflows-perf-guard-yml"></a>

```yaml
name: perf-guard
on:
  pull_request:
    paths:
      - "benches/**"
jobs:
  perf:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - name: benches (placeholder)
        run: echo "run benches, compare benches/baseline.json"

```

### crates/svc-gateway/Cargo.toml
<a id="crates-svc-gateway-Cargo-toml"></a>

```toml
[package]
name = "svc-gateway"
version = "0.1.0"
edition = "2021"
rust-version = "1.78"
license = "MIT OR Apache-2.0"
publish = false
resolver = "2"

[features]
default = []
tls = ["tokio-rustls"]        # enable TLS server via rustls
pq = []                       # reserved for post-quantum toggles
cli = []                      # reserved for a future CLI surface

# --- Crate targets -----------------------------------------------------------

[lib]
name = "svc_gateway"          # underscores for the lib crate name
path = "src/lib.rs"

[[bin]]
name = "svc-gateway"          # hyphen ok for the binary name
path = "src/main.rs"

# --- Dependencies ------------------------------------------------------------

[dependencies]
anyhow = "1"
thiserror = "1"

# Axum stack (minimal features; stays on Tower 0.5)
axum = { version = "0.7", default-features = false, features = ["http1", "http2", "json", "tokio"] }
http = "1"
hyper = { version = "1", features = ["http1", "http2", "server"] }

# Ensure Tower 0.5 only (matches axum 0.7 and tower-http 0.6)
tower = { version = "0.5", features = ["util","timeout"] }
tower-http = { version = "0.6", features = [
  "trace",
  "request-id",
  "util",
  "cors",
  "limit",
  "timeout",
  "compression-full",
  "decompression-full",
  "set-header",
  "catch-panic"
] }

tokio = { version = "1", features = ["rt-multi-thread", "macros", "signal", "io-util", "time"] }
tokio-util = "0.7"
tokio-rustls = { version = "0.26", optional = true }

prometheus = "0.14"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
once_cell = "1"
bytes = "1"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["fmt", "env-filter", "json"] }
humantime = "2"
byte-unit = { version = "5", default-features = false, features = ["byte"] }
percent-encoding = "2"
uuid = { version = "1", features = ["v4"] }
headers = "0.4"
mime = "0.3"
futures-util = "0.3"

# Internal workspace crates
ron-kernel  = { path = "../ron-kernel" }
ron-metrics = { path = "../ron-metrics" }
ron-bus     = { path = "../ron-bus" }
ron-proto   = { path = "../ron-proto" }

[dev-dependencies]
reqwest = { version = "0.12", default-features = false, features = ["rustls-tls-native-roots", "json"] }
tokio   = { version = "1", features = ["rt-multi-thread", "macros", "time"] }

```

### crates/svc-gateway/benches/baseline.json
<a id="crates-svc-gateway-benches-baseline-json"></a>

```json
{
  "_comment": "Performance baseline placeholder. Fill with real numbers after first bench run."
}

```

### crates/svc-gateway/benches/bench_gateway.sh
<a id="crates-svc-gateway-benches-benchgateway-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

: "${BIND_ADDR:=127.0.0.1:5304}"
: "${HEALTH_PATH:=/healthz}"
: "${READY_PATH:=/readyz}"
: "${DEV_RL_PATH:=/dev/rl}"
: "${DEV_ECHO_PATH:=/dev/echo}"

# Load gen knobs
: "${DUR:=30s}"
: "${THREADS:=4}"
: "${CONNS:=128}"
: "${QPS:=0}"           # 0 = unlimited for hey; ignored by wrk

# Gateway knobs (explicit to make runs reproducible)
: "${SVC_GATEWAY_DEV_ROUTES:=${SVC_GATEWAY_DEV:-1}}"
: "${SVC_GATEWAY_READY_TIMEOUT_MS:=1000}"
: "${SVC_GATEWAY_READY_MAX_INFLIGHT:=1024}"
: "${SVC_GATEWAY_RL_RPS:=3}"
: "${SVC_GATEWAY_RL_BURST:=5}"
: "${SVC_GATEWAY_RL_TARPIT_MS:=0}"    # 0 = no tarpit (keeps /dev/rl bench fast)
: "${SVC_GATEWAY_MAX_BODY_BYTES:=1048576}" # 1 MiB
: "${SVC_GATEWAY_DEV_READY:=1}"            # force ready during health/ready bench
: "${SVC_GATEWAY_READY_SLEEP_MS:=0}"

LOG_DIR="${LOG_DIR:-./target/bench-logs}"
mkdir -p "$LOG_DIR"

echo "killing any existing svc-gateway…"
pkill -f svc-gateway || true
sleep 0.2

echo "starting gateway…"
GLOG="$LOG_DIR/gateway.log"
BIND_ADDR="$BIND_ADDR" \
SVC_GATEWAY_DEV_ROUTES="$SVC_GATEWAY_DEV_ROUTES" \
SVC_GATEWAY_READY_TIMEOUT_MS="$SVC_GATEWAY_READY_TIMEOUT_MS" \
SVC_GATEWAY_READY_MAX_INFLIGHT="$SVC_GATEWAY_READY_MAX_INFLIGHT" \
SVC_GATEWAY_RL_RPS="$SVC_GATEWAY_RL_RPS" \
SVC_GATEWAY_RL_BURST="$SVC_GATEWAY_RL_BURST" \
SVC_GATEWAY_RL_TARPIT_MS="$SVC_GATEWAY_RL_TARPIT_MS" \
SVC_GATEWAY_MAX_BODY_BYTES="$SVC_GATEWAY_MAX_BODY_BYTES" \
SVC_GATEWAY_DEV_READY="$SVC_GATEWAY_DEV_READY" \
SVC_GATEWAY_READY_SLEEP_MS="$SVC_GATEWAY_READY_SLEEP_MS" \
RUST_LOG="${RUST_LOG:-info,svc_gateway=debug}" \
cargo run -p svc-gateway >"$GLOG" 2>&1 &

PID=$!
trap 'kill "$PID" 2>/dev/null || true' EXIT
echo "PID: $PID (logs -> $GLOG)"

# wait for health
att=0
until [ $att -ge 100 ]; do
  code="$(curl -s -o /dev/null -w "%{http_code}" "http://${BIND_ADDR}${HEALTH_PATH}" || true)"
  [ "$code" = "200" ] && break
  att=$((att+1)); sleep 0.1
done
[ "$code" = "200" ] || { echo "gateway not ready"; tail -n 120 "$GLOG" || true; exit 1; }

have_hey=0; have_wrk=0
command -v hey >/dev/null && have_hey=1
command -v wrk >/dev/null && have_wrk=1
[ "$have_hey" = 0 ] && [ "$have_wrk" = 0 ] && { echo "install hey or wrk"; exit 1; }

bench_hey() {
  local name="$1" url="$2"
  local out="$LOG_DIR/${name}_hey.txt"
  local q=()
  [ "$QPS" != "0" ] && q=(-q "$QPS")
  echo "== hey: $name -> $url"
  hey -z "$DUR" -c "$CONNS" "${q[@]}" "$url" | tee "$out"
}

bench_wrk() {
  local name="$1" url="$2"
  local out="$LOG_DIR/${name}_wrk.txt"
  echo "== wrk: $name -> $url"
  wrk -t"$THREADS" -c"$CONNS" -d"$DUR" "$url" | tee "$out"
}

bench() {
  local name="$1" path="$2"
  local url="http://${BIND_ADDR}${path}"
  if [ "$have_hey" = 1 ]; then bench_hey "$name" "$url"; else bench_wrk "$name" "$url"; fi
}

echo
echo "===== 1) Fast path: ${HEALTH_PATH} ====="
bench "healthz" "$HEALTH_PATH"

echo
echo "===== 2) Guarded path: ${READY_PATH} (no sleep, forced ready) ====="
bench "readyz" "$READY_PATH"

echo
echo "===== 3) Rejection hot path: ${DEV_RL_PATH} (will produce 429s) ====="
bench "dev_rl" "$DEV_RL_PATH"

echo
echo "===== 4) Rejection hot path: ${DEV_ECHO_PATH} (413 via body cap) ====="
bigfile="$(mktemp)"; head -c $((SVC_GATEWAY_MAX_BODY_BYTES+1024)) </dev/zero | tr '\0' 'A' > "$bigfile"
for i in $(seq 1 10); do
  curl -s -o /dev/null -w "%{http_code}\n" -X POST --data-binary @"$bigfile" "http://${BIND_ADDR}${DEV_ECHO_PATH}"
done | tee "$LOG_DIR/dev_echo_413.txt"
rm -f "$bigfile"

echo
echo "===== 5) Metrics snapshot ====="
curl -s "http://${BIND_ADDR}/metrics" \
 | grep -E 'gateway_http_requests_total|gateway_request_latency_seconds|gateway_rejections_total' \
 | sed -n '1,200p' > "$LOG_DIR/metrics.txt"
sed -n '1,200p' "$LOG_DIR/metrics.txt"

echo "Done. To stop: kill $PID"

```

### crates/svc-gateway/build.rs
<a id="crates-svc-gateway-build-rs"></a>

```rust
use std::time::{SystemTime, UNIX_EPOCH};

fn main() {
    let ts = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map(|d| d.as_secs())
        .unwrap_or(0);
    println!("cargo:rustc-env=SVC_GATEWAY_BUILD_TS={}", ts);
}

```

### crates/svc-gateway/configs/svc-gateway.sample.toml
<a id="crates-svc-gateway-configs-svc-gateway-sample-toml"></a>

```toml
# Sample config — svc-gateway2
# Role: Declarative knobs (timeouts, caps, quotas, amnesia, PQ/TLS policy).
[server]
bind = "127.0.0.1:9300"
metrics_bind = "127.0.0.1:9301"

[caps]
body_max_bytes = 1048576      # 1 MiB
decoded_max_bytes = 8388608   # 8 MiB
decoded_ratio_max = 10.0

[limits]
global_rps = 500

[amnesia]
enabled = true

[pq]
hybrid_enabled = false

```

### crates/svc-gateway/fuzz/targets/oap_frame.rs
<a id="crates-svc-gateway-fuzz-targets-oapframe-rs"></a>

```rust
//! oap_frame.rs — fuzz target placeholder.
//! Role: enforce 1 MiB frame invariants in OAP/1 envelope parsing.

```

### crates/svc-gateway/fuzz/targets/taxonomy_mapper.rs
<a id="crates-svc-gateway-fuzz-targets-taxonomymapper-rs"></a>

```rust
//! taxonomy_mapper.rs — fuzz target placeholder.
//! Role: guarantee deterministic, bounded error mapping.

```

### crates/svc-gateway/scripts/chaos_burst.sh
<a id="crates-svc-gateway-scripts-chaosburst-sh"></a>

```bash
#!/usr/bin/env bash
# Burst traffic and simulate downstream slowness (placeholder).
set -euo pipefail
echo "chaos_burst placeholder — add chaos injection once routes exist"

```

### crates/svc-gateway/scripts/dev_run.sh
<a id="crates-svc-gateway-scripts-devrun-sh"></a>

```bash
#!/usr/bin/env bash
# Starts svc-gateway2 with local env/config (placeholder runtime).
set -euo pipefail
echo "dev_run placeholder — wire up cargo run once implemented"

```

### crates/svc-gateway/scripts/export_metrics.sh
<a id="crates-svc-gateway-scripts-exportmetrics-sh"></a>

```bash
#!/usr/bin/env bash
# Quick metrics scrape (placeholder).
set -euo pipefail
curl -s http://127.0.0.1:9301/metrics || echo "metrics endpoint not yet implemented"

```

### crates/svc-gateway/scripts/run_gateway.sh
<a id="crates-svc-gateway-scripts-rungateway-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Config knobs (override when calling the script)
: "${BIND_ADDR:=127.0.0.1:5304}"
: "${SVC_GATEWAY_DEV_READY:=1}"
: "${SVC_GATEWAY_READY_TIMEOUT_MS:=200}"
: "${RUST_LOG:=info,svc_gateway=debug}"

echo "fmt + clippy + build…"
cargo fmt -p svc-gateway
cargo clippy -p svc-gateway --no-deps -- -D warnings
cargo build -p svc-gateway

echo "killing old svc-gateway (if any)…"
pkill -f svc-gateway || true

echo "starting svc-gateway…"
BIND_ADDR="$BIND_ADDR" \
SVC_GATEWAY_DEV_READY="$SVC_GATEWAY_DEV_READY" \
SVC_GATEWAY_READY_TIMEOUT_MS="$SVC_GATEWAY_READY_TIMEOUT_MS" \
RUST_LOG="$RUST_LOG" \
cargo run -p svc-gateway >/dev/null 2>&1 &

PID=$!
echo "PID: $PID"

# --- wait until /healthz returns 200 (up to ~10s) ---
echo -n "waiting for /healthz… "
att=0
until [ $att -ge 100 ]; do
  code="$(curl -s -o /dev/null -w "%{http_code}" "http://${BIND_ADDR}/healthz" || true)"
  if [ "$code" = "200" ]; then
    echo "ready."
    break
  fi
  att=$((att+1))
  sleep 0.1
done
if [ "$code" != "200" ]; then
  echo "timeout waiting for gateway to start (last code: ${code:-none})"
  echo "tip: check 'cargo run' logs without redirect if debugging startup."
  # Don't kill the process here; it may still be starting. Exit non-zero for CI clarity.
  exit 1
fi

echo "healthz:"
curl -si "http://${BIND_ADDR}/healthz" | head -n 5

echo "readyz:"
curl -si "http://${BIND_ADDR}/readyz" | head -n 5

echo "metrics (first lines):"
curl -s "http://${BIND_ADDR}/metrics" | head -n 10

echo "Done. Gateway is running (PID $PID). To stop: kill $PID"

```

### crates/svc-gateway/scripts/sanity_rate_limit.sh
<a id="crates-svc-gateway-scripts-sanityratelimit-sh"></a>

```bash
#!/usr/bin/env bash
# Deterministic sanity for rate_limit: expect 200 then 429s.
set -euo pipefail

# -------- Knobs (override via env) --------
: "${BIND_ADDR:=127.0.0.1:5304}"
: "${SVC_GATEWAY_DEV_ROUTES:=1}"   # enable /dev/*
: "${SVC_GATEWAY_RL_RPS:=1}"       # 1 token/sec
: "${SVC_GATEWAY_RL_BURST:=1}"     # burst = 1 token
: "${SVC_GATEWAY_RL_TARPIT_MS:=0}" # no tarpit to keep it snappy
: "${RUST_LOG:=info,svc_gateway=debug}"
: "${WAIT_MS:=10000}"              # up to 10s for /healthz

log="$(mktemp -t svc-gateway-sanity.XXXXXX.log)"
pids=()

cleanup() {
  set +e
  if [ "${#pids[@]}" -gt 0 ]; then
    for p in "${pids[@]}"; do kill "$p" 2>/dev/null || true; done
  fi
}
trap cleanup EXIT

echo "killing any prior gateway…"
pkill -f svc-gateway || true
sleep 0.2

echo "priming build…"
cargo build -p svc-gateway >/dev/null

echo "starting gateway (RPS=$SVC_GATEWAY_RL_RPS BURST=$SVC_GATEWAY_RL_BURST TARPIT=${SVC_GATEWAY_RL_TARPIT_MS}ms)…"
BIND_ADDR="$BIND_ADDR" \
SVC_GATEWAY_DEV_ROUTES="$SVC_GATEWAY_DEV_ROUTES" \
SVC_GATEWAY_RL_RPS="$SVC_GATEWAY_RL_RPS" \
SVC_GATEWAY_RL_BURST="$SVC_GATEWAY_RL_BURST" \
SVC_GATEWAY_RL_TARPIT_MS="$SVC_GATEWAY_RL_TARPIT_MS" \
RUST_LOG="$RUST_LOG" \
cargo run -p svc-gateway >"$log" 2>&1 &

PID=$!
pids+=("$PID")
echo "PID: $PID (logs: $log)"

# -------- Wait for /healthz (portable: attempts * 100ms) --------
attempts=$(( (WAIT_MS + 99) / 100 ))  # ceil(WAIT_MS/100)
code=""
for _ in $(seq 1 "$attempts"); do
  if ! kill -0 "$PID" 2>/dev/null; then
    echo "gateway exited early"; tail -n 120 "$log" || true; exit 1
  fi
  code="$(curl -s -o /dev/null -w '%{http_code}' "http://${BIND_ADDR}/healthz" || true)"
  [ "$code" = "200" ] && break
  sleep 0.1
done
[ "$code" = "200" ] || { echo "gateway not healthy in ${WAIT_MS}ms"; tail -n 200 "$log" || true; exit 1; }
echo "gateway healthy."

# -------- Deterministic 3-hit probe --------
hit() { curl -s -o /dev/null -w '%{http_code}' "http://${BIND_ADDR}/dev/rl" || echo "ERR"; }

echo "probing /dev/rl (3 rapid hits; expect 200 then 429/429)…"
c1="$(hit)"; echo "hit 1 -> $c1"
c2="$(hit)"; echo "hit 2 -> $c2"
c3="$(hit)"; echo "hit 3 -> $c3"

# -------- Validate expectation --------
errs=0; [ "$c1" = "ERR" ] && errs=$((errs+1)); [ "$c2" = "ERR" ] && errs=$((errs+1)); [ "$c3" = "ERR" ] && errs=$((errs+1))

if [ "$c1" != "200" ] || [ $errs -gt 0 ]; then
  echo "FAIL: expected hit1=200 and no curl errors; saw: $c1 $c2 $c3 (ERRS=$errs)"
  echo "--- tail logs ($log) ---"; tail -n 200 "$log" || true
  echo "--- metrics (snippet) ---"
  curl -s "http://${BIND_ADDR}/metrics" | grep -E 'gateway_rejections_total\{reason="rate_limit"\}|gateway_http_requests_total\{.*dev_rl' || true
  exit 2
fi

count_429=0
[ "$c2" = "429" ] && count_429=$((count_429+1))
[ "$c3" = "429" ] && count_429=$((count_429+1))

if [ $count_429 -lt 1 ]; then
  echo "FAIL: expected at least one 429 under RPS=1,BURST=1 but saw: $c1 $c2 $c3"
  echo "--- tail logs ---"; tail -n 200 "$log" || true
  echo "--- metrics (snippet) ---"
  curl -s "http://${BIND_ADDR}/metrics" | grep -E 'gateway_rejections_total\{reason="rate_limit"\}|gateway_http_requests_total\{.*dev_rl' || true
  exit 3
fi

echo "OK: observed $count_429 x 429 (as expected)."
echo "metrics (rate_limit counters):"
curl -s "http://${BIND_ADDR}/metrics" | grep -E 'gateway_rejections_total\{reason="rate_limit"\}|gateway_http_requests_total\{.*dev_rl' || true

echo "Done. To stop: kill $PID (or Ctrl-C to trigger trap)."

```

### crates/svc-gateway/scripts/smoke_gateway.sh
<a id="crates-svc-gateway-scripts-smokegateway-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

echo "fmt+clippy+build…"
cargo fmt -p svc-gateway
cargo clippy -p svc-gateway --no-deps -- -D warnings
cargo build -p svc-gateway

pkill -f svc-gateway || true
RUST_LOG=info,target=svc_gateway=debug cargo run -p svc-gateway &

sleep 0.5
echo "healthz:";  curl -si http://127.0.0.1:5304/healthz | head -n 1
echo "readyz:";   curl -si http://127.0.0.1:5304/readyz  | head -n 1
echo "metrics:";  curl -s  http://127.0.0.1:5304/metrics | head -n 10

```

### crates/svc-gateway/scripts/soak_test.sh
<a id="crates-svc-gateway-scripts-soaktest-sh"></a>

```bash
#!/usr/bin/env bash
# Long-running load to validate SLOs (placeholder).
set -euo pipefail
echo "soak_test placeholder — integrate your load tool"

```

### crates/svc-gateway/scripts/test_body_cap.sh
<a id="crates-svc-gateway-scripts-testbodycap-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

: "${BIND_ADDR:=127.0.0.1:5304}"
: "${SVC_GATEWAY_DEV_ROUTES:=1}"          # enable /dev/echo
: "${SVC_GATEWAY_MAX_BODY_BYTES:=1024}"   # 1 KiB limit for the test
: "${RUST_LOG:=info,svc_gateway=debug}"

echo "killing old gateway (if any)…"
pkill -f svc-gateway || true
sleep 0.2

echo "start gateway with body cap..."
log="$(mktemp -t svc-gateway-test.XXXXXX.log)"
BIND_ADDR="$BIND_ADDR" \
SVC_GATEWAY_DEV_ROUTES="$SVC_GATEWAY_DEV_ROUTES" \
SVC_GATEWAY_MAX_BODY_BYTES="$SVC_GATEWAY_MAX_BODY_BYTES" \
RUST_LOG="$RUST_LOG" \
cargo run -p svc-gateway >"$log" 2>&1 &
PID=$!
echo "PID: $PID (logs: $log)"

# wait for /healthz up, but also detect early process death
att=0
code=""
while [ $att -lt 100 ]; do
  if ! kill -0 "$PID" 2>/dev/null; then
    echo "gateway process exited early. recent log:"
    tail -n 80 "$log" || true
    exit 1
  fi
  code="$(curl -s -o /dev/null -w "%{http_code}" "http://${BIND_ADDR}/healthz" || true)"
  [ "$code" = "200" ] && break
  att=$((att+1))
  sleep 0.1
done
if [ "$code" != "200" ]; then
  echo "gateway not up (last code: ${code:-none}). recent log:"
  tail -n 80 "$log" || true
  exit 1
fi

echo "== small ok =="
printf 'hi' | curl -s -i -X POST --data-binary @- "http://${BIND_ADDR}/dev/echo" | sed -n '1,10p'

echo "== too big =="
bigfile="$(mktemp)"
head -c 2048 </dev/zero | tr '\0' 'A' > "$bigfile"
curl -s -i -X POST --data-binary @"$bigfile" "http://${BIND_ADDR}/dev/echo" | sed -n '1,10p'
rm -f "$bigfile"

echo "== metrics =="
curl -s "http://${BIND_ADDR}/metrics" | grep -E 'gateway_rejections_total\{reason="body_cap"\}|gateway_ready_' | sed -n '1,50p'

echo "Done. To stop: kill $PID"

```

### crates/svc-gateway/scripts/test_rate_limit.sh
<a id="crates-svc-gateway-scripts-testratelimit-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

: "${BIND_ADDR:=127.0.0.1:5304}"
: "${PAR:=20}"                 # concurrent requests
: "${REQ_TIMEOUT:=2}"          # seconds per HTTP request max
: "${CONNECT_TIMEOUT:=1}"

# Force dev routes on regardless of shell env
export SVC_GATEWAY_DEV_ROUTES=1
export SVC_GATEWAY_DEV=1

: "${SVC_GATEWAY_RL_RPS:=3}"
: "${SVC_GATEWAY_RL_BURST:=5}"
: "${SVC_GATEWAY_RL_TARPIT_MS:=0}"
: "${RUST_LOG:=info,svc_gateway=debug}"

echo "killing old gateway (if any)…"
pkill -f svc-gateway || true
sleep 0.2

echo "start gateway with RL rps=${SVC_GATEWAY_RL_RPS} burst=${SVC_GATEWAY_RL_BURST} tarpit=${SVC_GATEWAY_RL_TARPIT_MS}ms..."
log="$(mktemp -t svc-gateway-rl.XXXXXX.log)"
BIND_ADDR="$BIND_ADDR" \
SVC_GATEWAY_RL_RPS="$SVC_GATEWAY_RL_RPS" \
SVC_GATEWAY_RL_BURST="$SVC_GATEWAY_RL_BURST" \
SVC_GATEWAY_RL_TARPIT_MS="$SVC_GATEWAY_RL_TARPIT_MS" \
RUST_LOG="$RUST_LOG" \
cargo run -p svc-gateway >"$log" 2>&1 &

PID=$!
echo "PID: $PID (logs: $log)"

# Wait for health
att=0; code=""
while [ $att -lt 100 ]; do
  if ! kill -0 "$PID" 2>/dev/null; then tail -n 200 "$log" || true; exit 1; fi
  code="$(curl -s -o /dev/null -w "%{http_code}" "http://${BIND_ADDR}/healthz" || true)"
  [ "$code" = "200" ] && break
  att=$((att+1)); sleep 0.1
done
[ "$code" = "200" ] || { echo "gateway not up"; tail -n 200 "$log" || true; exit 1; }

# Global watchdog so this script can never hang
WATCHDOG_SECS=$((REQ_TIMEOUT + 8))
( sleep "$WATCHDOG_SECS"; if ps -p "$PID" >/dev/null 2>&1; then
    echo "Watchdog: requests still running after ${WATCHDOG_SECS}s; dumping logs…"
    tail -n 200 "$log" || true
  fi ) & WD=$!

echo "bursting /dev/rl… (${PAR} concurrent hits)"
tmp="$(mktemp -t rl_hits.XXXXXX)"

# IMPORTANT: temporarily relax -e/pipefail for this pipeline so any single timeout
# doesn’t kill the whole script. We restore strict mode immediately after.
set +e
( yes 1 | head -n "$PAR" | xargs -P "$PAR" -I{} \
  sh -c '
    code=$(curl -sS -o /dev/null \
      --connect-timeout '"$CONNECT_TIMEOUT"' \
      --max-time '"$REQ_TIMEOUT"' \
      -w "%{http_code}" "http://'"$BIND_ADDR"'/dev/rl" 2>/dev/null || echo 000);
    echo "$code"
  ' ) >>"$tmp"
xargs_rc=$?
set -e

# Kill watchdog (we finished requests batch, even if some errored)
kill "$WD" >/dev/null 2>&1 || true

if [ $xargs_rc -ne 0 ]; then
  echo "note: some requests failed (xargs rc=$xargs_rc); see tallies and logs below."
fi

# Tally
ok=$(grep -c '^200$' "$tmp" || true)
rl=$(grep -c '^429$' "$tmp" || true)
ot=$(grep -c '^000$' "$tmp" || true)
echo "OK: $ok  RL(429): $rl  ERR/TO: $ot"

echo "metrics:"
curl -s "http://${BIND_ADDR}/metrics" | grep -E 'gateway_rejections_total\{reason="rate_limit"\}' || true

echo "Done. To stop: kill $PID"

```

### crates/svc-gateway/src/admission/capabilities.rs
<a id="crates-svc-gateway-src-admission-capabilities-rs"></a>

```rust
#[must_use]
pub fn has_cap(_cap: &str) -> bool {
    // Stub: wire to passport/policy later.
    true
}

```

### crates/svc-gateway/src/admission/classifier.rs
<a id="crates-svc-gateway-src-admission-classifier-rs"></a>

```rust
#[must_use]
pub fn classify(_path: &str) -> &'static str {
    // Stub: return a class label that DRR/rate-limiters might key on later.
    "default"
}

```

### crates/svc-gateway/src/admission/mod.rs
<a id="crates-svc-gateway-src-admission-mod-rs"></a>

```rust
//! Admission classifiers & quotas (stubs now).
pub mod capabilities;
pub mod classifier;
pub mod payments;
pub mod quotas;
pub mod residency;
pub mod taxonomy;

```

### crates/svc-gateway/src/admission/payments.rs
<a id="crates-svc-gateway-src-admission-payments-rs"></a>

```rust
//! admission/payments.rs — (feature = "econ") enforce paid writes/prepaid quotas — placeholder.

```

### crates/svc-gateway/src/admission/quotas.rs
<a id="crates-svc-gateway-src-admission-quotas-rs"></a>

```rust
#[must_use]
pub fn allow(_tenant: &str) -> bool {
    // Stub: tie into svc-index/svc-registry later.
    true
}

```

### crates/svc-gateway/src/admission/residency.rs
<a id="crates-svc-gateway-src-admission-residency-rs"></a>

```rust
//! admission/residency.rs — Thin adapter to `policy::residency` — placeholder.

#[must_use]
pub fn region_ok(_tenant: &str, _region: &str) -> bool {
    true
}

```

### crates/svc-gateway/src/admission/taxonomy.rs
<a id="crates-svc-gateway-src-admission-taxonomy-rs"></a>

```rust
//! admission/taxonomy.rs — Deterministic reason/status mapping — placeholder.

```

### crates/svc-gateway/src/cli/mod.rs
<a id="crates-svc-gateway-src-cli-mod-rs"></a>

```rust
//! cli/mod.rs — CLI flags (binds, pq policy, econ enforcement) — placeholder.

```

### crates/svc-gateway/src/config/amnesia.rs
<a id="crates-svc-gateway-src-config-amnesia-rs"></a>

```rust
//! Amnesia-mode toggles (RAM-only, extra redaction). 
//! Operator doc references. :contentReference[oaicite:8]{index=8}
#[inline]
pub fn amnesia_enabled() -> bool { false }

```

### crates/svc-gateway/src/config/env.rs
<a id="crates-svc-gateway-src-config-env-rs"></a>

```rust
//! Placeholder: add real env mapping (SVC_GATEWAY_*).
//! Docs show examples and precedence. :contentReference[oaicite:6]{index=6}

```

### crates/svc-gateway/src/config/mod.rs
<a id="crates-svc-gateway-src-config-mod-rs"></a>

```rust
//! RO:WHAT   Config model + loaders (env/file) with hard defaults.
//! RO:WHY    Keep caps & readiness guards aligned with blueprint.
//! Env prefix `SVC_GATEWAY`_. Docs show precedence + examples. :contentReference[oaicite:5]{index=5}

use crate::consts::{
    DEFAULT_BODY_CAP_BYTES, DEFAULT_DECODE_ABS_CAP_BYTES, DEFAULT_DECODE_RATIO_MAX,
    DEFAULT_IDLE_TIMEOUT_SECS, DEFAULT_MAX_CONNS, DEFAULT_READ_TIMEOUT_SECS, DEFAULT_RPS,
    DEFAULT_WRITE_TIMEOUT_SECS,
};

use serde::Deserialize;
use std::net::SocketAddr;

#[derive(Debug, Clone, Deserialize)]
pub struct Config {
    pub server: Server,
    pub limits: Limits,
    pub drr: Drr,
    pub amnesia: Amnesia,
    pub pq: Pq,
    pub safety: Safety,
    pub log: Log,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Server {
    pub bind_addr: SocketAddr,
    pub metrics_addr: SocketAddr,
    pub max_conns: usize,
    pub read_timeout_secs: u64,
    pub write_timeout_secs: u64,
    pub idle_timeout_secs: u64,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Limits {
    pub max_body_bytes: usize,
    pub decode_abs_cap_bytes: usize,
    pub decode_ratio_max: usize,
}

#[derive(Debug, Clone, Deserialize, Default)]
pub struct Drr {
    pub default_quantum: u32,
    pub rate_limit_rps: u64,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Amnesia {
    pub enabled: bool,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Pq {
    pub mode: String,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Safety {
    pub danger_ok: bool,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Log {
    pub format: String,
    pub level: String,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            server: Server {
                bind_addr: "127.0.0.1:5304".parse().unwrap(),
                metrics_addr: "127.0.0.1:0".parse().unwrap(),
                max_conns: DEFAULT_MAX_CONNS,
                read_timeout_secs: DEFAULT_READ_TIMEOUT_SECS,
                write_timeout_secs: DEFAULT_WRITE_TIMEOUT_SECS,
                idle_timeout_secs: DEFAULT_IDLE_TIMEOUT_SECS,
            },
            limits: Limits {
                max_body_bytes: DEFAULT_BODY_CAP_BYTES,
                decode_abs_cap_bytes: DEFAULT_DECODE_ABS_CAP_BYTES,
                decode_ratio_max: DEFAULT_DECODE_RATIO_MAX,
            },
            drr: Drr {
                default_quantum: 1,
                rate_limit_rps: DEFAULT_RPS,
            },
            amnesia: Amnesia { enabled: false },
            pq: Pq { mode: "off".into() },
            safety: Safety { danger_ok: false },
            log: Log {
                format: "json".into(),
                level: "info".into(),
            },
        }
    }
}

impl Config {
    /// Load configuration.
    ///
    /// # Errors
    ///
    /// This stubbed loader cannot fail today; it will return `Ok(Self::default())`.
    /// When file/env loading is added later, this will surface parse/IO errors.
    pub fn load() -> anyhow::Result<Self> {
        Ok(Self::default())
    }
}

```

### crates/svc-gateway/src/config/safety.rs
<a id="crates-svc-gateway-src-config-safety-rs"></a>

```rust
//! Safety guard to prevent weakening defaults unless `danger_ok=true`.
//! Hardening checklist refs. :contentReference[oaicite:7]{index=7}

#[inline]
pub fn assert_safe(danger_ok: bool) {
    if !danger_ok { /* keep defaults enforced */ }
}

```

### crates/svc-gateway/src/consts.rs
<a id="crates-svc-gateway-src-consts-rs"></a>

```rust
// crates/svc-gateway/src/consts.rs
#![allow(clippy::module_name_repetitions)]

pub const DEFAULT_MAX_CONNS: usize = 2_048;

// 1 MiB (avoid `1 * 1024 * 1024` which trips clippy::identity_op)
pub const DEFAULT_BODY_CAP_BYTES: usize = 1_048_576;

// Decompression guard
pub const DEFAULT_DECODE_RATIO_MAX: usize = 10;
pub const DEFAULT_DECODE_ABS_CAP_BYTES: usize = 16 * 1_048_576; // 16 MiB

// Read timeouts
pub const DEFAULT_READ_TIMEOUT_SECS: u64 = 10;
pub const DEFAULT_WRITE_TIMEOUT_SECS: u64 = 10;
pub const DEFAULT_IDLE_TIMEOUT_SECS: u64 = 30;

// Rate limit (as u64 to match config field)
pub const DEFAULT_RPS: u64 = 500;

```

### crates/svc-gateway/src/errors.rs
<a id="crates-svc-gateway-src-errors-rs"></a>

```rust
//! Carry-over: `Problem{code,message,retryable,retry_after_ms?,reason?}`.

use axum::{
    http::{self, HeaderValue, StatusCode},
    response::{IntoResponse, Response},
    Json,
};
use serde::Serialize;

#[derive(Serialize)]
pub struct Problem<'a> {
    pub code: &'a str,
    pub message: &'a str,
    pub retryable: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub retry_after_ms: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub reason: Option<&'a str>,
}

impl Problem<'_> {
    #[must_use]
    pub fn into_response_with(self, status: StatusCode) -> Response {
        (status, Json(self)).into_response()
    }
}

/// 429 Too Many Requests with Retry-After (seconds). Never panics.
pub fn rate_limited_retry_after(ms: u64) -> Response {
    let mut resp = Problem {
        code: "rate_limited",
        message: "Too many requests",
        retryable: true,
        retry_after_ms: Some(ms),
        reason: None,
    }
    .into_response_with(StatusCode::TOO_MANY_REQUESTS);

    // Best-effort Retry-After header; if conversion fails, omit it.
    if let Ok(v) = HeaderValue::from_str(&(ms / 1000).to_string()) {
        let headers = resp.headers_mut();
        headers.insert(http::header::RETRY_AFTER, v);
    }
    resp
}

/// 503 Busy with Retry-After (seconds). Never panics.
pub fn too_busy_retry_after(ms: u64) -> Response {
    let mut resp = Problem {
        code: "too_busy",
        message: "Server busy",
        retryable: true,
        retry_after_ms: Some(ms),
        reason: None,
    }
    .into_response_with(StatusCode::SERVICE_UNAVAILABLE);

    if let Ok(v) = HeaderValue::from_str(&(ms / 1000).to_string()) {
        let headers = resp.headers_mut();
        headers.insert(http::header::RETRY_AFTER, v);
    }
    resp
}

```

### crates/svc-gateway/src/forward/index_client.rs
<a id="crates-svc-gateway-src-forward-indexclient-rs"></a>

```rust
//! Index client stub.

```

### crates/svc-gateway/src/forward/mod.rs
<a id="crates-svc-gateway-src-forward-mod-rs"></a>

```rust
//! Clients to overlay/index/storage (stubs).

pub mod index_client;
pub mod overlay_client;
pub mod storage_client;

```

### crates/svc-gateway/src/forward/overlay_client.rs
<a id="crates-svc-gateway-src-forward-overlayclient-rs"></a>

```rust
/// Fetch raw bytes from overlay given an address + relative path.
///
/// # Errors
///
/// As a stub this never errors and returns an empty vec. When implemented,
/// it will return I/O or protocol errors from the overlay client.
pub fn get_bytes(_addr: &str, _rel: &str) -> anyhow::Result<Vec<u8>> {
    Ok(Vec::new())
}

```

### crates/svc-gateway/src/forward/storage_client.rs
<a id="crates-svc-gateway-src-forward-storageclient-rs"></a>

```rust
//! `forward/storage_client.rs` — Optional: read-only media proxy; range-reads — placeholder.

/// Stubbed storage fetch.
///
/// # Errors
///
/// See `overlay_client` notes (not implemented here yet).
pub fn get_object(_key: &str) -> anyhow::Result<Vec<u8>> {
    Ok(Vec::new())
}

```

### crates/svc-gateway/src/headers/etag.rs
<a id="crates-svc-gateway-src-headers-etag-rs"></a>

```rust
//! Produce a quoted `ETag` value for a BLAKE3 address (e.g., `b3:abcd...`).

#[must_use]
pub fn etag_from_b3(addr: &str) -> String {
    // clippy(pedantic): prefer inline args over `"{}"`
    format!("\"{addr}\"")
}

```

### crates/svc-gateway/src/headers/mod.rs
<a id="crates-svc-gateway-src-headers-mod-rs"></a>

```rust
pub mod etag;

```

### crates/svc-gateway/src/layers/auth.rs
<a id="crates-svc-gateway-src-layers-auth-rs"></a>

```rust
#[must_use]
pub fn enabled() -> bool {
    false
}

```

### crates/svc-gateway/src/layers/body_caps.rs
<a id="crates-svc-gateway-src-layers-bodycaps-rs"></a>

```rust
//! Body-size cap (route-scoped).
//! RO:WHAT  Reject requests with `Content-Length` exceeding a configured cap.
//! RO:WHY   Cheap protection against oversized uploads; observable via metrics.
//! RO:CONF  `SVC_GATEWAY_MAX_BODY_BYTES` (default 1 MiB). Header-only (no streaming).
//! RO:OBS   Increments `gateway_rejections_total{reason="body_cap"}` on reject.

use axum::{
    body::Body,
    http::{Request, StatusCode},
    middleware::Next,
    response::{IntoResponse, Response},
};

/// Middleware: if `Content-Length` is present and exceeds the cap, reject with 413.
///
/// This version is header-only. If `Content-Length` is absent or invalid, we let the request
/// pass through; a streaming cap (for unknown/incorrect lengths) can be added later.
pub async fn body_cap_mw(req: Request<Body>, next: Next) -> Response {
    let cap = std::env::var("SVC_GATEWAY_MAX_BODY_BYTES")
        .ok()
        .and_then(|s| s.parse::<u64>().ok())
        .unwrap_or(1_048_576); // 1 MiB default

    if let Some(len) = req.headers().get(axum::http::header::CONTENT_LENGTH) {
        if let Ok(len_str) = len.to_str() {
            if let Ok(n) = len_str.parse::<u64>() {
                if n > cap {
                    // Reuse the shared rejects counter to avoid AlreadyReg panics.
                    crate::observability::rejects::counter()
                        .with_label_values(&["body_cap"])
                        .inc();
                    return (StatusCode::PAYLOAD_TOO_LARGE, "payload too large").into_response();
                }
            }
        }
    }

    next.run(req).await
}

```

### crates/svc-gateway/src/layers/concurrency.rs
<a id="crates-svc-gateway-src-layers-concurrency-rs"></a>

```rust
//! Concurrency guard (route-scoped).
//! RO:WHAT  Cheap backpressure using a `Semaphore` permit per in-flight request.
//! RO:WHY   Fail fast with `503 Service Unavailable` instead of tail spikes.
//! RO:NOTE  Axum 0.7 middleware shape (`Next` has no generics). Global static,
//!          but applied only to selected routes (e.g., `/readyz`).

use axum::{
    body::Body,
    http::Request,
    middleware::Next,
    response::{IntoResponse, Response},
};
use once_cell::sync::OnceCell;
use tokio::sync::{Semaphore, SemaphorePermit};

fn semaphore() -> &'static Semaphore {
    static SEM: OnceCell<Semaphore> = OnceCell::new();
    SEM.get_or_init(|| {
        // ENV knob, default small to make behavior easy to see locally.
        let max = std::env::var("SVC_GATEWAY_READY_MAX_INFLIGHT")
            .ok()
            .and_then(|s| s.parse::<usize>().ok())
            .unwrap_or(64);
        Semaphore::new(max)
    })
}

/// Acquire a single permit or return 503 when saturated.
pub async fn ready_concurrency_mw(req: Request<Body>, next: Next) -> Response {
    // Fast-fail if saturated (non-blocking).
    let permit: Option<SemaphorePermit<'_>> = semaphore().try_acquire().ok();
    if permit.is_none() {
        return (axum::http::StatusCode::SERVICE_UNAVAILABLE, "busy").into_response();
    }

    // Hold the permit for the duration of the downstream call.
    let _permit = permit;
    next.run(req).await
}

```

### crates/svc-gateway/src/layers/corr.rs
<a id="crates-svc-gateway-src-layers-corr-rs"></a>

```rust
//! Correlation ID middleware (route-scoped).
//! RO:WHAT  Ensure each request has an `x-request-id`; echo it on the response.
//! RO:WHY   Stable correlation for tracing/logs with zero deps.
//! RO:NOTE  Axum 0.7 `Next` has no generic parameter; `Request` must be `Request<Body>`.

use axum::{
    body::Body,
    http::{HeaderValue, Request},
    middleware::Next,
    response::Response,
};
use std::sync::atomic::{AtomicU64, Ordering};

static REQ_COUNTER: AtomicU64 = AtomicU64::new(1);

/// Axum 0.7 middleware entry point.
///
/// # Behavior
/// * Respects incoming `x-request-id` if present and valid UTF-8.
/// * Otherwise synthesizes `r-<hex>` from a monotonic counter (cheap, unique-enough for dev).
/// * Echoes the final id back on the response header.
///
/// # Errors
/// Never errors; always returns a `Response`.
pub async fn mw(mut req: Request<Body>, next: Next) -> Response {
    // Try to get an existing request id.
    let maybe_id = req
        .headers()
        .get("x-request-id")
        .and_then(|v| v.to_str().ok())
        .map(str::to_owned); // clippy: method reference instead of redundant closure

    let id = maybe_id.unwrap_or_else(|| {
        let n = REQ_COUNTER.fetch_add(1, Ordering::Relaxed);
        format!("r-{n:016x}")
    });

    // Ensure header is present for downstream handlers.
    if !req.headers().contains_key("x-request-id") {
        if let Ok(v) = HeaderValue::from_str(&id) {
            req.headers_mut().insert("x-request-id", v);
        }
    }

    let mut resp = next.run(req).await;

    // Always mirror the id back on the response.
    if let Ok(v) = HeaderValue::from_str(&id) {
        resp.headers_mut().insert("x-request-id", v);
    }

    resp
}

```

### crates/svc-gateway/src/layers/decode_guard.rs
<a id="crates-svc-gateway-src-layers-decodeguard-rs"></a>

```rust
//! STUB: decode guard (decompression ratio / absolute cap checks) temporarily disabled.
//! Returns an identity layer to unblock compilation; real logic will be restored later.

#![allow(clippy::unused_async)]

use tower::layer::util::Identity;

/// Stub that produces a `Layer` satisfying axum's `route_layer` bounds.
#[must_use]
pub fn layer(_ratio_max: usize, _abs_cap: usize) -> Identity {
    Identity::new()
}

```

### crates/svc-gateway/src/layers/drr.rs
<a id="crates-svc-gateway-src-layers-drr-rs"></a>

```rust
//! RO:WHAT   DRR/fair-queue placeholder layer.
//! RO:WHY    Slot-in for future dispatcher; currently pass-through.

use axum::http::Request;
use axum::response::Response;
use std::task::{Context, Poll};
use tower::{Layer, Service};

use crate::observability::metrics::MetricsHandles;

#[derive(Clone)]
pub struct DrrLayer {
    pub max_inflight: usize,
    pub metrics: MetricsHandles,
}

impl<S> Layer<S> for DrrLayer {
    type Service = Drr<S>;
    fn layer(&self, inner: S) -> Self::Service {
        Drr {
            inner,
            max_inflight: self.max_inflight,
            metrics: self.metrics.clone(),
        }
    }
}

#[derive(Clone)]
pub struct Drr<S> {
    inner: S,
    #[allow(dead_code)]
    max_inflight: usize,
    #[allow(dead_code)]
    metrics: MetricsHandles,
}

impl<S, B> Service<Request<B>> for Drr<S>
where
    S: Service<Request<B>, Response = Response> + Clone + Send + 'static,
    S::Future: Send + 'static,
    S::Error: Send + 'static,
{
    type Response = Response;
    type Error = S::Error;
    type Future = S::Future;

    fn poll_ready(&mut self, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {
        self.inner.poll_ready(cx)
    }

    fn call(&mut self, req: Request<B>) -> Self::Future {
        // TODO: implement fair queueing; for now pass-through.
        self.inner.call(req)
    }
}

```

### crates/svc-gateway/src/layers/mod.rs
<a id="crates-svc-gateway-src-layers-mod-rs"></a>

```rust
//! Order (inner→outer): timeouts → `body_caps` → `decode_guard` → `rate_limit` → drr → tarpit → auth → corr

pub mod body_caps;
pub mod concurrency;
pub mod corr;
pub mod decode_guard;
pub mod rate_limit;
pub mod timeouts;

```

### crates/svc-gateway/src/layers/rate_limit.rs
<a id="crates-svc-gateway-src-layers-ratelimit-rs"></a>

```rust
//! Global token-bucket rate limit (lock-free fast path).
//! RO:WHAT   Enforce RPS with fixed-capacity bucket; emit 429 + Retry-After.
//! RO:WHY    Cheap back-pressure/abuse damping without mutex contention.
//! RO:METRICS increments `gateway_rejections_total{reason="rate_limit"}` on reject.
//! RO:CONFIG `SVC_GATEWAY_RL_RPS` (u64), `SVC_GATEWAY_RL_BURST` (u64), `SVC_GATEWAY_RL_TARPIT_MS` (u64).

use axum::{
    body::Body,
    http::{Request, StatusCode},
    middleware::Next,
    response::{IntoResponse, Response},
};
use once_cell::sync::OnceCell;
use std::sync::atomic::{AtomicU64, Ordering};
use std::time::{Duration, SystemTime, UNIX_EPOCH};
use tokio::time::sleep;

use crate::observability::rejects::counter as rejects_counter;

#[derive(Debug)]
struct TokenBucket {
    /// steady refill rate (tokens/sec)
    rps: u64,
    /// hard cap on tokens (burst)
    capacity: u64,
    /// current tokens (0..=capacity)
    tokens: AtomicU64,
    /// last whole second we refilled (unix seconds)
    last_sec: AtomicU64,
}

impl TokenBucket {
    fn new(rps: u64, burst: u64) -> Self {
        let now = now_secs();
        // capacity must be at least 1 to avoid degenerate 0-cap bucket
        let cap = burst.max(1);
        Self {
            rps: rps.max(1),
            capacity: cap,
            tokens: AtomicU64::new(cap), // start full
            last_sec: AtomicU64::new(now),
        }
    }

    #[inline]
    fn refill_if_needed(&self) {
        let cur = now_secs();
        let last = self.last_sec.load(Ordering::Relaxed);

        if cur > last
            && self
                .last_sec
                .compare_exchange(last, cur, Ordering::Relaxed, Ordering::Relaxed)
                .is_ok()
        {
            // elapsed whole seconds since the last successful refill tick
            let elapsed = cur.saturating_sub(last);
            if elapsed > 0 {
                let add = elapsed.saturating_mul(self.rps);
                // cap at capacity; safe because both are u64
                let before = self.tokens.load(Ordering::Relaxed);
                let after = before.saturating_add(add).min(self.capacity);
                // store (not critical if we race; any winner that writes <= capacity is fine)
                self.tokens.store(after, Ordering::Relaxed);
            }
        }
    }

    /// Try to consume one token.
    /// Never panics; never underflows; wait-free fast path on success.
    #[must_use]
    #[inline]
    fn try_take(&self) -> bool {
        self.refill_if_needed();

        // lock-free decrement with CAS so we never subtract below zero
        let mut cur = self.tokens.load(Ordering::Relaxed);
        loop {
            if cur == 0 {
                return false;
            }
            // we know cur > 0, so cur - 1 is safe; CAS guards against races
            match self.tokens.compare_exchange_weak(
                cur,
                cur - 1,
                Ordering::Relaxed,
                Ordering::Relaxed,
            ) {
                Ok(_) => return true,
                Err(observed) => {
                    cur = observed;
                    // retry until we either see 0 or win the CAS
                }
            }
        }
    }
}

#[inline]
fn now_secs() -> u64 {
    SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_else(|_| Duration::from_secs(0))
        .as_secs()
}

/// Route-scoped middleware: enforce global RPS (lock-free).
///
/// # Behavior
/// - Honors env:
///   - `SVC_GATEWAY_RL_RPS` (default 5000)
///   - `SVC_GATEWAY_RL_BURST` (default = RPS)
///   - `SVC_GATEWAY_RL_TARPIT_MS` (default 0; add small sleep on reject)
/// - On reject: returns 429 and `Retry-After: 1` header, increments `gateway_rejections_total{reason="rate_limit"}`
///
/// # Errors
/// Never returns an error directly; upstream handler may.
pub async fn rate_limit_mw(req: Request<Body>, next: Next) -> Response {
    static BUCKET: OnceCell<TokenBucket> = OnceCell::new();
    static TARPIT_MS: OnceCell<u64> = OnceCell::new();

    let rps = std::env::var("SVC_GATEWAY_RL_RPS")
        .ok()
        .and_then(|s| s.parse::<u64>().ok())
        .unwrap_or(5_000);
    let burst = std::env::var("SVC_GATEWAY_RL_BURST")
        .ok()
        .and_then(|s| s.parse::<u64>().ok())
        .unwrap_or(rps);
    let tarpit_ms = *TARPIT_MS.get_or_init(|| {
        std::env::var("SVC_GATEWAY_RL_TARPIT_MS")
            .ok()
            .and_then(|s| s.parse::<u64>().ok())
            .unwrap_or(0)
    });

    let bucket = BUCKET.get_or_init(|| TokenBucket::new(rps, burst));

    if bucket.try_take() {
        next.run(req).await
    } else {
        rejects_counter().with_label_values(&["rate_limit"]).inc();
        if tarpit_ms > 0 {
            sleep(Duration::from_millis(tarpit_ms)).await;
        }
        (
            StatusCode::TOO_MANY_REQUESTS,
            [("Retry-After", "1")],
            "rate limited",
        )
            .into_response()
    }
}

```

### crates/svc-gateway/src/layers/tarpit.rs
<a id="crates-svc-gateway-src-layers-tarpit-rs"></a>

```rust
#[must_use]
pub fn enabled() -> bool {
    false
}

```

### crates/svc-gateway/src/layers/timeouts.rs
<a id="crates-svc-gateway-src-layers-timeouts-rs"></a>

```rust
//! Route-scoped timeout middleware.
//! RO:WHAT  Enforce a simple request timeout using Tokio's `timeout`.
//! RO:WHY   Prevents hung readiness checks from stalling callers.
//! RO:NOTE  Axum 0.7 middleware shape (`Next` has no generics).
//! RO:CONF  Duration via `SVC_GATEWAY_READY_TIMEOUT_MS` (default 200ms).

use axum::{
    body::Body,
    http::Request,
    middleware::Next,
    response::{IntoResponse, Response},
};
use std::time::Duration;
use tokio::time::timeout;

/// Timeout wrapper for `/readyz`.
/// - Reads `SVC_GATEWAY_READY_TIMEOUT_MS` (u64) from env (default 200ms).
/// - On timeout, returns `504 Gateway Timeout` with "timeout".
pub async fn ready_timeout_mw(req: Request<Body>, next: Next) -> Response {
    let ms = std::env::var("SVC_GATEWAY_READY_TIMEOUT_MS")
        .ok()
        .and_then(|s| s.parse::<u64>().ok())
        .unwrap_or(200);

    match timeout(Duration::from_millis(ms), next.run(req)).await {
        Ok(resp) => resp,
        Err(_) => (axum::http::StatusCode::GATEWAY_TIMEOUT, "timeout").into_response(),
    }
}

```

### crates/svc-gateway/src/lib.rs
<a id="crates-svc-gateway-src-lib-rs"></a>

```rust
#![forbid(unsafe_code)]
#![deny(clippy::all, clippy::pedantic)]
#![allow(clippy::module_name_repetitions)]

pub mod consts;
pub mod errors;
pub mod result;
pub mod state;

pub mod config;
pub mod headers;
pub mod observability;
pub mod policy;
pub mod pq;
pub mod readiness;
pub mod tls;

pub mod admission;
pub mod forward;
pub mod layers;
pub mod routes;

```

### crates/svc-gateway/src/main.rs
<a id="crates-svc-gateway-src-main-rs"></a>

```rust
//! svc-gateway binary (stub bootstrap)

use axum::Router;
use svc_gateway::{config::Config, observability::metrics, routes, state::AppState};
use tokio::net::TcpListener;
use tracing::{info, Level};
use tracing_subscriber::EnvFilter;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // Minimal tracing; respects RUST_LOG if set.
    let _ = tracing_subscriber::fmt()
        .with_env_filter(EnvFilter::from_default_env().add_directive(Level::INFO.into()))
        .with_target(false)
        .try_init();

    let cfg = Config::load()?;
    let metrics_handles = metrics::register()?;

    // App state requires both Config and MetricsHandles
    let state = AppState::new(cfg.clone(), metrics_handles.clone());

    // Build the router from crate routes
    let router: Router = routes::build_router(&state);

    // Bind and serve with graceful shutdown
    let listener = TcpListener::bind(cfg.server.bind_addr).await?;
    info!("svc-gateway listening on {}", cfg.server.bind_addr);

    axum::serve(listener, router)
        .with_graceful_shutdown(shutdown_signal())
        .await?;

    Ok(())
}

async fn shutdown_signal() {
    // CTRL+C to stop
    let _ = tokio::signal::ctrl_c().await;
}

```

### crates/svc-gateway/src/observability/http_metrics.rs
<a id="crates-svc-gateway-src-observability-httpmetrics-rs"></a>

```rust
//! HTTP metrics wiring + tiny middleware.
//! RO:WHAT   Record request totals and latency buckets with stable labels.
//! RO:WHY    Golden counters for SREs; cheap + predictable.
//! RO:LABELS route,method,status (counter) and route,method (histogram).
//! RO:SAFETY Registered once via `OnceCell`; no panics after success.
//! RO:NOTE   `prewarm()` creates child series so dashboards light up immediately.

use axum::{body::Body, http::Request, middleware::Next, response::Response};
use once_cell::sync::OnceCell;
use prometheus::{HistogramOpts, HistogramVec, IntCounterVec, Opts};
use std::time::Instant;

static HTTP_REQS: OnceCell<IntCounterVec> = OnceCell::new();
static LAT_HIST: OnceCell<HistogramVec> = OnceCell::new();

fn reqs() -> &'static IntCounterVec {
    HTTP_REQS.get_or_init(|| {
        let vec = IntCounterVec::new(
            Opts::new(
                "gateway_http_requests_total",
                "Total HTTP requests (svc-gateway middleware)",
            ),
            &["route", "method", "status"],
        )
        .expect("IntCounterVec");
        prometheus::register(Box::new(vec.clone())).expect("register gateway_http_requests_total");
        vec
    })
}

fn lats() -> &'static HistogramVec {
    LAT_HIST.get_or_init(|| {
        // Buckets chosen to match docs (ms in seconds representation).
        let buckets = vec![
            0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0,
        ];
        let opts = HistogramOpts::new(
            "gateway_request_latency_seconds",
            "Request latency in seconds (svc-gateway middleware)",
        )
        .buckets(buckets);
        let vec = HistogramVec::new(opts, &["route", "method"]).expect("HistogramVec");
        prometheus::register(Box::new(vec.clone()))
            .expect("register gateway_request_latency_seconds");
        vec
    })
}

/// Derive a compact, low-cardinality route label from the path.
/// We keep it stable for core endpoints; everything else falls back
/// to the first segment (or "root").
fn route_label(path: &str) -> &'static str {
    match path {
        "/healthz" => "healthz",
        "/readyz" => "readyz",
        "/metrics" => "metrics",
        "/version" => "version",
        "/dev/echo" => "dev_echo",
        "/dev/rl" => "dev_rl",
        _ => {
            if path == "/" {
                "root"
            } else {
                "other"
            }
        }
    }
}

/// Middleware: measure latency + count by labels.
/// Apply at route scope where appropriate.
///
/// # Errors
/// Never returns an error directly; upstream handler may.
pub async fn mw(req: Request<Body>, next: Next) -> Response {
    // Compute labels BEFORE moving `req` into `next.run(...)`.
    let route = route_label(req.uri().path());
    let method_owned = req.method().as_str().to_owned();

    let start = Instant::now();
    let response = next.run(req).await;
    let status = response.status().as_u16().to_string();
    let secs = start.elapsed().as_secs_f64();

    reqs()
        .with_label_values(&[route, method_owned.as_str(), &status])
        .inc();
    lats()
        .with_label_values(&[route, method_owned.as_str()])
        .observe(secs);

    response
}

/// Pre-create common label series so dashboards don’t start “empty”.
/// Call this once during startup before serving traffic.
pub fn prewarm() {
    // Counters (route, method, status)
    for (route, method, statuses) in [
        ("healthz", "GET", &["200"][..]),
        ("readyz", "GET", &["200", "503"][..]),
        ("metrics", "GET", &["200"][..]),
        ("version", "GET", &["200"][..]),
        ("dev_echo", "POST", &["200", "413"][..]),
        ("dev_rl", "GET", &["200", "429"][..]),
    ] {
        for &st in statuses {
            let _ = reqs().get_metric_with_label_values(&[route, method, st]);
        }
        let _ = lats().get_metric_with_label_values(&[route, method]);
    }
}

```

### crates/svc-gateway/src/observability/logging.rs
<a id="crates-svc-gateway-src-observability-logging-rs"></a>

```rust
use tracing_subscriber::{fmt::format::FmtSpan, EnvFilter};

pub fn init() {
    let filter =
        std::env::var("RUST_LOG").unwrap_or_else(|_| "info,axum=warn,tower_http=warn".into());
    tracing_subscriber::fmt()
        .with_env_filter(EnvFilter::new(filter))
        .with_span_events(FmtSpan::CLOSE)
        .json()
        .flatten_event(true)
        .init();
}

```

### crates/svc-gateway/src/observability/metrics.rs
<a id="crates-svc-gateway-src-observability-metrics-rs"></a>

```rust
//! Prometheus registry + golden metrics wiring.
//! Dashboard hints & names aligned with docs. :contentReference[oaicite:9]{index=9}

use prometheus::{
    register_histogram_vec, register_int_counter_vec, register_int_gauge, HistogramVec,
    IntCounterVec, IntGauge,
};

/// Handles to all gateway metrics registered in the global Prometheus registry.
#[derive(Clone)]
pub struct MetricsHandles {
    /// Total HTTP requests, partitioned by `route`, `method`, and `status`.
    pub http_reqs: IntCounterVec,
    /// Request latency histogram (seconds), partitioned by `route` and `method`.
    pub http_lat: HistogramVec,
    /// Current number of in-flight requests across the gateway.
    pub inflight: IntGauge,
    /// Count of rejected requests by `reason` (e.g., `rate_limit`, `body_cap`, `timeout`).
    pub rejected: IntCounterVec,

    pub ready_inflight_current: IntGauge,
    pub ready_error_rate_pct: IntGauge,
    pub ready_queue_saturated: IntGauge,
}

/// Register metrics; returns handles.
///
/// # Errors
///
/// Returns an error if metrics of the same name are already registered.
pub fn register() -> anyhow::Result<MetricsHandles> {
    let http_reqs = register_int_counter_vec!(
        "http_requests_total",
        "HTTP requests",
        &["route", "method", "status"]
    )?;
    let http_lat = register_histogram_vec!(
        "request_latency_seconds",
        "Request latencies",
        &["route", "method"]
    )?;
    let inflight = register_int_gauge!("inflight_requests", "In-flight requests")?;
    let rejected = register_int_counter_vec!(
        "rejected_total",
        "Rejected by reason (e.g., rate_limit, body_cap, timeout)",
        &["reason"]
    )?;

    // Readiness gauges (carry-over names). :contentReference[oaicite:10]{index=10}
    let ready_inflight_current =
        register_int_gauge!("ready_inflight_current", "Current inflight across gateway")?;
    let ready_error_rate_pct =
        register_int_gauge!("ready_error_rate_pct", "Observed 429/503 % over window")?;
    let ready_queue_saturated =
        register_int_gauge!("ready_queue_saturated", "Queue saturated indicator")?;

    Ok(MetricsHandles {
        http_reqs,
        http_lat,
        inflight,
        rejected,
        ready_inflight_current,
        ready_error_rate_pct,
        ready_queue_saturated,
    })
}

```

### crates/svc-gateway/src/observability/metrics_boot.rs
<a id="crates-svc-gateway-src-observability-metricsboot-rs"></a>

```rust
//! Metrics boot helpers.
//! RO:WHAT   (Placeholder) Hooks to pre-warm metric label sets at startup.
//! RO:WHY    Avoid first-hit allocations when a route is hit under burst.
//! RO:PLAN   Once `observability::http_metrics` exposes a `prewarm_labels(...)`
//!           we call it here for the known {route,method,status} tuples.
//! RO:SAFE   Currently a no-op to avoid any registration conflicts.

/// Pre-warm metric label sets (currently a no-op).
///
/// # Notes
/// - Intentionally empty until `http_metrics` exposes a safe prewarm function.
/// - Kept as a separate module so wiring it later is a one-line change.
pub fn prewarm() {
    // no-op (will call into http_metrics once the prewarm function is exposed)
}

```

### crates/svc-gateway/src/observability/mod.rs
<a id="crates-svc-gateway-src-observability-mod-rs"></a>

```rust
pub mod http_metrics;
pub mod logging;
pub mod metrics;
pub mod readiness;
pub mod ready_metrics;
pub mod rejects;
pub mod tracing;

```

### crates/svc-gateway/src/observability/readiness.rs
<a id="crates-svc-gateway-src-observability-readiness-rs"></a>

```rust
//! Readiness sampler (lightweight, no `AppState` changes).
//! RO:WHAT   Maintain a global readiness snapshot updated on a short interval.
//! RO:WHY    Let `/readyz` consult real gates instead of a hard-coded toggle.
//! RO:SHAPE  Global `OnceLock` + Atomics so we don't touch `AppState` (tiny blast radius).
//! RO:FUTURE Hook real signals (inflight, error rate, queue depth) as they land.

use std::sync::{
    atomic::{AtomicBool, AtomicU64, Ordering},
    OnceLock,
};
use std::time::Duration;
use tokio::task::JoinHandle;

#[derive(Clone, Copy, Debug)]
pub struct Snapshot {
    pub inflight_current: u64,
    pub error_rate_pct: u64,
    pub queue_saturated: bool,
}

struct ReadyState {
    inflight_current: AtomicU64,
    error_rate_pct: AtomicU64,
    queue_saturated: AtomicBool,
}

impl ReadyState {
    const fn new() -> Self {
        Self {
            inflight_current: AtomicU64::new(0),
            error_rate_pct: AtomicU64::new(0),
            queue_saturated: AtomicBool::new(false),
        }
    }

    fn snapshot(&self) -> Snapshot {
        Snapshot {
            inflight_current: self.inflight_current.load(Ordering::Relaxed),
            error_rate_pct: self.error_rate_pct.load(Ordering::Relaxed),
            queue_saturated: self.queue_saturated.load(Ordering::Relaxed),
        }
    }
}

static READY: OnceLock<ReadyState> = OnceLock::new();
static TASK: OnceLock<JoinHandle<()>> = OnceLock::new();

fn ready() -> &'static ReadyState {
    READY.get_or_init(ReadyState::new)
}

pub fn ensure_started() {
    if TASK.get().is_some() {
        return;
    }
    let handle = tokio::spawn(async move {
        let tick = Duration::from_millis(500);
        loop {
            // Take a snapshot and publish as gauges (gateway-prefixed to avoid collisions).
            let snap = ready().snapshot();
            crate::observability::ready_metrics::set_inflight(snap.inflight_current);
            crate::observability::ready_metrics::set_error_pct(snap.error_rate_pct);
            crate::observability::ready_metrics::set_queue_saturated(snap.queue_saturated);
            tokio::time::sleep(tick).await;
        }
    });
    let _ = TASK.set(handle);
}

#[must_use]
pub fn snapshot() -> Snapshot {
    ready().snapshot()
}

#[derive(Clone, Copy)]
pub struct Thresholds {
    pub max_error_pct: u64,
    pub max_inflight: u64,
    pub allow_queue_saturation: bool,
}

impl Default for Thresholds {
    fn default() -> Self {
        Self {
            max_error_pct: 5,
            max_inflight: 10_000,
            allow_queue_saturation: false,
        }
    }
}

```

### crates/svc-gateway/src/observability/ready_metrics.rs
<a id="crates-svc-gateway-src-observability-readymetrics-rs"></a>

```rust
//! Readiness metrics helpers.
//! RO:WHAT   Export gauges used by `/readyz` truth table.
//! RO:LABELS none (singletons).
//! RO:METRICS
//!   - `gateway_ready_inflight_current` (gauge, `i64`)
//!   - `gateway_ready_error_rate_pct`   (gauge, `i64`)
//!   - `gateway_ready_queue_saturated`  (gauge, `i64`: 0/1)

use once_cell::sync::OnceCell;
use prometheus::{IntGauge, Opts};

fn inflight_gauge() -> &'static IntGauge {
    static G: OnceCell<IntGauge> = OnceCell::new();
    G.get_or_init(|| {
        let g = IntGauge::with_opts(Opts::new(
            "gateway_ready_inflight_current",
            "Current inflight across gateway",
        ))
        .expect("IntGauge");
        prometheus::register(Box::new(g.clone())).expect("register gateway_ready_inflight_current");
        g
    })
}

fn error_pct_gauge() -> &'static IntGauge {
    static G: OnceCell<IntGauge> = OnceCell::new();
    G.get_or_init(|| {
        let g = IntGauge::with_opts(Opts::new(
            "gateway_ready_error_rate_pct",
            "Observed 429/503 % over window",
        ))
        .expect("IntGauge");
        prometheus::register(Box::new(g.clone())).expect("register gateway_ready_error_rate_pct");
        g
    })
}

fn queue_sat_gauge() -> &'static IntGauge {
    static G: OnceCell<IntGauge> = OnceCell::new();
    G.get_or_init(|| {
        let g = IntGauge::with_opts(Opts::new(
            "gateway_ready_queue_saturated",
            "Queue saturated indicator",
        ))
        .expect("IntGauge");
        prometheus::register(Box::new(g.clone())).expect("register gateway_ready_queue_saturated");
        g
    })
}

/// Update inflight (safe cast; saturates at `i64::MAX`).
pub fn set_inflight(v: u64) {
    let as_i64 = i64::try_from(v).unwrap_or(i64::MAX);
    inflight_gauge().set(as_i64);
}

/// Update error percentage (0..=100 expected; safe cast).
pub fn set_error_pct(v: u64) {
    let as_i64 = i64::try_from(v).unwrap_or(i64::MAX);
    error_pct_gauge().set(as_i64);
}

/// Update saturation flag.
pub fn set_queue_saturated(v: bool) {
    queue_sat_gauge().set(i64::from(v));
}

```

### crates/svc-gateway/src/observability/rejects.rs
<a id="crates-svc-gateway-src-observability-rejects-rs"></a>

```rust
//! Shared “rejections” counter handle.
//! RO:WHAT   Central place for `gateway_rejections_total{reason}`.
//! RO:WHY    Avoid double-register; give callers a tiny, stable API.

use once_cell::sync::OnceCell;
use prometheus::{IntCounterVec, Opts};

const NAME: &str = "gateway_rejections_total";

/// Get the shared rejections counter (`reason` label).
///
/// # Panics
/// Panics once at process start if Prometheus registration fails. This
/// indicates a programmer error such as attempting to re-register the
/// same metric name with a different type/help text.
pub fn counter() -> &'static IntCounterVec {
    static CTR: OnceCell<IntCounterVec> = OnceCell::new();
    CTR.get_or_init(|| {
        let vec = IntCounterVec::new(Opts::new(NAME, "Gateway rejections by reason"), &["reason"])
            .expect("IntCounterVec");
        prometheus::register(Box::new(vec.clone())).expect("register gateway_rejections_total");
        vec
    })
}

```

### crates/svc-gateway/src/observability/tracing.rs
<a id="crates-svc-gateway-src-observability-tracing-rs"></a>

```rust
//! observability/tracing.rs — Trace subscriber & context propagation — placeholder.

```

### crates/svc-gateway/src/policy/abuse.rs
<a id="crates-svc-gateway-src-policy-abuse-rs"></a>

```rust
#[derive(Clone, Default)]
pub struct AbusePolicy;

```

### crates/svc-gateway/src/policy/mod.rs
<a id="crates-svc-gateway-src-policy-mod-rs"></a>

```rust
//! Residency/abuse policy stubs; attach via Extension<> AFTER inner layers.
//! Carry-over: Extension order discipline. :contentReference[oaicite:13]{index=13}
pub mod abuse;
pub mod residency;

#[derive(Clone, Default)]
pub struct PolicyBundle;

```

### crates/svc-gateway/src/policy/residency.rs
<a id="crates-svc-gateway-src-policy-residency-rs"></a>

```rust
#[derive(Clone, Default)]
pub struct ResidencyPolicy;

```

### crates/svc-gateway/src/pq/mod.rs
<a id="crates-svc-gateway-src-pq-mod-rs"></a>

```rust
//! Post-quantum plumbing stub (hybrid later).
pub mod policy;

```

### crates/svc-gateway/src/pq/policy.rs
<a id="crates-svc-gateway-src-pq-policy-rs"></a>

```rust
//! PQ policy toggles (off|hybrid). Kept as stub for now.
#[derive(Clone, Copy, Debug)]
pub enum PqMode {
    Off,
    Hybrid,
}

```

### crates/svc-gateway/src/readiness/keys.rs
<a id="crates-svc-gateway-src-readiness-keys-rs"></a>

```rust
//! Names kept stable for dashboards/tests. :contentReference[oaicite:12]{index=12}
pub const READY_INFLIGHT_CURRENT: &str = "ready_inflight_current";
pub const READY_ERROR_RATE_PCT: &str = "ready_error_rate_pct";
pub const READY_QUEUE_SATURATED: &str = "ready_queue_saturated";

```

### crates/svc-gateway/src/readiness/mod.rs
<a id="crates-svc-gateway-src-readiness-mod-rs"></a>

```rust
//! Tiny readiness/degradation flag exposed to /readyz.

use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc,
};

#[derive(Default)]
struct ReadyStateInner {
    degraded: AtomicBool,
}

#[derive(Clone)]
pub struct ReadyState(Arc<ReadyStateInner>);

impl Default for ReadyState {
    fn default() -> Self {
        Self::new()
    }
}

impl ReadyState {
    #[must_use]
    pub fn new() -> Self {
        Self(Arc::new(ReadyStateInner::default()))
    }

    pub fn set_degraded(&self, d: bool) {
        self.0.degraded.store(d, Ordering::Relaxed);
    }

    #[must_use]
    pub fn is_degraded(&self) -> bool {
        self.0.degraded.load(Ordering::Relaxed)
    }

    /// Consider "ready" when not degraded (you can enrich later with more gates).
    #[must_use]
    pub fn ready(&self) -> bool {
        !self.is_degraded()
    }
}

```

### crates/svc-gateway/src/result.rs
<a id="crates-svc-gateway-src-result-rs"></a>

```rust
pub type Result<T, E = anyhow::Error> = std::result::Result<T, E>;

```

### crates/svc-gateway/src/routes/dev.rs
<a id="crates-svc-gateway-src-routes-dev-rs"></a>

```rust
//! Dev-only routes (opt-in via env).
//! RO:CONF  `SVC_GATEWAY_DEV_ROUTES=1` to enable.
//! RO:NOTE  Guarded by body caps / rate limit in router assembly.

use axum::{
    body::{Body, Bytes},
    http::StatusCode,
    response::{IntoResponse, Response},
    Json,
};
use serde::Serialize;

/// Toggle for mounting dev routes.
#[must_use]
pub fn enabled() -> bool {
    std::env::var("SVC_GATEWAY_DEV_ROUTES")
        .map(|v| v == "1" || v.eq_ignore_ascii_case("true") || v.eq_ignore_ascii_case("yes"))
        .unwrap_or(false)
}

#[derive(Serialize)]
struct EchoResp<'a> {
    echo: &'a str,
    len: usize,
}

/// POST /dev/echo — echoes body length; body caps enforced by middleware.
pub async fn echo_post(body: Bytes) -> impl IntoResponse {
    let resp = EchoResp {
        echo: "hi",
        len: body.len(),
    };
    (StatusCode::OK, Json(resp))
}

/// GET /dev/rl — trivial “OK” for rate-limit tests (429 comes from middleware).
pub async fn burst_ok() -> Response {
    (StatusCode::OK, Body::from("ok")).into_response()
}

```

### crates/svc-gateway/src/routes/health.rs
<a id="crates-svc-gateway-src-routes-health-rs"></a>

```rust
//! RO:WHAT  /healthz — liveness probe.
//! RO:WHY   Simple process up check. Always 200 "ok".

use axum::response::{IntoResponse, Response};

pub async fn handler() -> Response {
    "ok".into_response()
}

```

### crates/svc-gateway/src/routes/metrics.rs
<a id="crates-svc-gateway-src-routes-metrics-rs"></a>

```rust
//! Prometheus metrics endpoint (text format).
//! RO:WHAT  Expose the default registry in plain text format for Prometheus.
//! RO:WHY   Our current handler returns a JSON-escaped string; Prometheus expects text/plain.
//! RO:INVARS  No allocations beyond the encode buffer; no blocking; no SHA usage anywhere.

use axum::http::{header::CONTENT_TYPE, HeaderMap};
use axum::response::{IntoResponse, Response};
use prometheus::{Encoder, TextEncoder};

/// Return metrics in Prometheus text format (`text/plain; version=0.0.4`).
///
/// # Behavior
/// - Encodes the default registry (`prometheus::gather()`) using `TextEncoder`.
/// - Sets the canonical content type expected by Prometheus.
/// - On unexpected encode errors, emits an empty body with the same content type.
pub async fn get_metrics() -> Response {
    let metric_families = prometheus::gather();
    let encoder = TextEncoder::new();

    let mut buf = Vec::with_capacity(16 * 1024);
    let _ = encoder.encode(&metric_families, &mut buf);

    let mut headers = HeaderMap::new();
    // Prometheus canonical content type for text exposition format
    headers.insert(
        CONTENT_TYPE,
        "text/plain; version=0.0.4; charset=utf-8"
            .parse()
            .expect("static content type"),
    );

    (headers, buf).into_response()
}

```

### crates/svc-gateway/src/routes/mod.rs
<a id="crates-svc-gateway-src-routes-mod-rs"></a>

```rust
//! Router assembly + core admin plane.
//! RO:ORDER  Keep layers minimal; apply correlation + HTTP metrics to `/healthz`,
//!           request-timeout + concurrency cap to `/readyz`, and body cap / rate limit
//!           only to dev routes. Optionally add `http_metrics` to dev routes when
//!           `SVC_GATEWAY_DEV_METRICS` is truthy for benching visibility.

use crate::state::AppState;
use axum::{
    routing::{get, post},
    Router,
};

pub mod dev;
pub mod health;
mod metrics;
pub mod ready;

/// Return true if `SVC_GATEWAY_DEV_METRICS` is set to a truthy value.
/// Accepted values (case-insensitive): "1", "true", "yes", "on".
fn dev_metrics_enabled() -> bool {
    match std::env::var("SVC_GATEWAY_DEV_METRICS") {
        Ok(v) => {
            let s = v.trim().to_ascii_lowercase();
            matches!(s.as_str(), "1" | "true" | "yes" | "on")
        }
        Err(_) => false,
    }
}

pub fn build_router(state: &AppState) -> Router {
    // Ensure readiness sampler is ticking.
    crate::observability::readiness::ensure_started();

    // Prewarm metric label series so dashboards light up right away.
    crate::observability::http_metrics::prewarm();

    // --- /healthz: correlation + request metrics (outermost) ---
    let health_with_layers = Router::new()
        .route("/healthz", get(health::handler))
        .route_layer(axum::middleware::from_fn(crate::layers::corr::mw))
        .route_layer(axum::middleware::from_fn(
            crate::observability::http_metrics::mw,
        ));

    // --- /readyz: guarded with timeout + concurrency cap ---
    let ready_with_guards = Router::new()
        .route("/readyz", get(ready::handler))
        .route_layer(axum::middleware::from_fn(
            crate::layers::timeouts::ready_timeout_mw,
        ))
        .route_layer(axum::middleware::from_fn(
            crate::layers::concurrency::ready_concurrency_mw,
        ));

    // --- /dev/*: body cap + rate limit; optionally add http_metrics when benching ---
    let dev_routes = if dev::enabled() {
        let dev_base = Router::new()
            .route("/dev/echo", post(dev::echo_post))
            .route("/dev/rl", get(dev::burst_ok))
            // inner: functional guards
            .route_layer(axum::middleware::from_fn(
                crate::layers::body_caps::body_cap_mw,
            ))
            .route_layer(axum::middleware::from_fn(
                crate::layers::rate_limit::rate_limit_mw, // lock-free RL
            ));

        // If enabled, make http_metrics the outermost layer on /dev/*
        if dev_metrics_enabled() {
            dev_base.route_layer(axum::middleware::from_fn(
                crate::observability::http_metrics::mw,
            ))
        } else {
            dev_base
        }
    } else {
        Router::new()
    };

    Router::new()
        .merge(health_with_layers)
        .merge(ready_with_guards)
        .merge(dev_routes)
        .route("/metrics", get(metrics::get_metrics))
        .with_state(state.clone())
}

```

### crates/svc-gateway/src/routes/objects.rs
<a id="crates-svc-gateway-src-routes-objects-rs"></a>

```rust
//! GET /o/{addr}

use crate::headers::etag::etag_from_b3;
use axum::{extract::Path, response::IntoResponse};

pub async fn get_object(Path(addr): Path<String>) -> impl IntoResponse {
    // MVP: echo stub (no overlay forwarding yet).
    (
        [(http::header::ETAG, etag_from_b3(&addr))],
        axum::body::Body::from(format!("object stub for {}", addr)),
    )
}

```

### crates/svc-gateway/src/routes/objects_range.rs
<a id="crates-svc-gateway-src-routes-objectsrange-rs"></a>

```rust
//! GET /o/{addr} with Range (separate route for clarity)

use axum::{extract::Path, response::IntoResponse};

pub async fn get_range(Path(addr): Path<String>) -> impl IntoResponse {
    // MVP: range not implemented yet
    (
        http::StatusCode::NOT_IMPLEMENTED,
        format!("range read stub for {}", addr),
    )
}

```

### crates/svc-gateway/src/routes/ready.rs
<a id="crates-svc-gateway-src-routes-ready-rs"></a>

```rust
//! Readiness endpoint.
//! RO:WHAT   Truthful readiness gate (env override remains for dev).
//! RO:WHY    Operators need a real signal; keep override for quick local bring-up.
//! RO:TEST   Set `SVC_GATEWAY_READY_SLEEP_MS` to simulate slow work and exercise
//!           the concurrency cap + timeout layers.

use crate::state::AppState;
use axum::{
    extract::State,
    http::StatusCode,
    response::{IntoResponse, Response},
};
use std::time::Duration;
use tokio::time::sleep;

/// `/readyz` handler consulting sampler thresholds, with optional sleep to
/// simulate slow checks and exercise guards.
///
/// # Errors
/// This function does not fail; it always returns a `Response`.
pub async fn handler(State(_state): State<AppState>) -> Response {
    // Optional: simulate slow work to demonstrate concurrency/timeout guards.
    if let Ok(ms_str) = std::env::var("SVC_GATEWAY_READY_SLEEP_MS") {
        if let Ok(ms) = ms_str.parse::<u64>() {
            sleep(Duration::from_millis(ms)).await;
        }
    }

    // Dev override wins if explicitly set.
    if matches!(std::env::var("SVC_GATEWAY_DEV_READY").as_deref(), Ok("1")) {
        return (StatusCode::OK, "ready").into_response();
    }

    // Truth table based on the sampler snapshot.
    let snap = crate::observability::readiness::snapshot();
    let thr = crate::observability::readiness::Thresholds::default();

    let inflight_ok = snap.inflight_current <= thr.max_inflight;
    let error_ok = snap.error_rate_pct <= thr.max_error_pct;
    let queue_ok = thr.allow_queue_saturation || !snap.queue_saturated;

    if inflight_ok && error_ok && queue_ok {
        (StatusCode::OK, "ready").into_response()
    } else {
        (StatusCode::SERVICE_UNAVAILABLE, "not ready").into_response()
    }
}

```

### crates/svc-gateway/src/routes/version.rs
<a id="crates-svc-gateway-src-routes-version-rs"></a>

```rust
//! Build/version endpoint (no SHA; respects no-SHA policy).

use axum::{
    http::StatusCode,
    response::{IntoResponse, Response},
    Json,
};

pub async fn handler() -> Response {
    let version = env!("CARGO_PKG_VERSION");
    let built_at = option_env!("SVC_GATEWAY_BUILD_TS").unwrap_or("0");
    let obj = serde_json::json!({
        "name": "svc-gateway",
        "version": version,
        "built_at_unix": built_at,
    });
    (StatusCode::OK, Json(obj)).into_response()
}

```

### crates/svc-gateway/src/state.rs
<a id="crates-svc-gateway-src-state-rs"></a>

```rust
//! RO:WHAT   Process state container passed to handlers and layers.
//! RO:WHY    Centralizes config, metrics handles, and readiness gate.
//! RO:INVARS Send + Sync; cheap to clone via Arcs.

use std::sync::Arc;

use crate::config::Config;
use crate::observability::metrics::{self, MetricsHandles};
use crate::readiness::ReadyState;

#[derive(Clone)]
pub struct AppState {
    pub cfg: Config,
    pub metrics: MetricsHandles,
    pub readiness: Arc<ReadyState>,
}

impl AppState {
    /// Build a new state from provided parts.
    #[must_use]
    pub fn new(cfg: Config, metrics: MetricsHandles) -> Self {
        Self {
            cfg,
            metrics,
            readiness: Arc::new(ReadyState::new()),
        }
    }

    /// Convenience ctor for early bring-up until real loaders are wired.
    ///
    /// # Panics
    /// Panics if metric registration fails (should not happen under normal conditions).
    #[must_use]
    pub fn new_default() -> Self {
        let cfg = Config::default();
        let metrics = metrics::register().expect("register metrics");
        Self::new(cfg, metrics)
    }
}

```

### crates/svc-gateway/src/tls/mod.rs
<a id="crates-svc-gateway-src-tls-mod-rs"></a>

```rust
//! TLS scaffolding (tokio-rustls) — enable with `--features tls`.

```

### crates/svc-gateway/tests/integration/caps_limits.rs
<a id="crates-svc-gateway-tests-integration-capslimits-rs"></a>

```rust
//! caps_limits.rs — integration test placeholder.
//! Role: prove invariants (shed writes first, caps, interop vectors, taxonomy freeze, loom interleavings).

```

### crates/svc-gateway/tests/integration/interop_vectors.rs
<a id="crates-svc-gateway-tests-integration-interopvectors-rs"></a>

```rust
//! interop_vectors.rs — integration test placeholder.
//! Role: prove invariants (shed writes first, caps, interop vectors, taxonomy freeze, loom interleavings).

```

### crates/svc-gateway/tests/integration/loom_readiness.rs
<a id="crates-svc-gateway-tests-integration-loomreadiness-rs"></a>

```rust
//! loom_readiness.rs — integration test placeholder.
//! Role: prove invariants (shed writes first, caps, interop vectors, taxonomy freeze, loom interleavings).

```

### crates/svc-gateway/tests/integration/readyz_degrade.rs
<a id="crates-svc-gateway-tests-integration-readyzdegrade-rs"></a>

```rust
//! readyz_degrade.rs — integration test placeholder.
//! Role: prove invariants (shed writes first, caps, interop vectors, taxonomy freeze, loom interleavings).

```

### crates/svc-gateway/tests/integration/taxonomy_stability.rs
<a id="crates-svc-gateway-tests-integration-taxonomystability-rs"></a>

```rust
//! taxonomy_stability.rs — integration test placeholder.
//! Role: prove invariants (shed writes first, caps, interop vectors, taxonomy freeze, loom interleavings).

```

### crates/svc-gateway/tests/vectors/error_taxonomy.json
<a id="crates-svc-gateway-tests-vectors-errortaxonomy-json"></a>

```json
{ "_comment": "Deterministic error taxonomy mapping placeholder." }

```

### crates/svc-gateway/tests/vectors/manifest_digest.json
<a id="crates-svc-gateway-tests-vectors-manifestdigest-json"></a>

```json
{ "_comment": "BLAKE3 manifest digest vector placeholder." }

```

### crates/svc-gateway/tests/vectors/oap1_frame_roundtrip.json
<a id="crates-svc-gateway-tests-vectors-oap1frameroundtrip-json"></a>

```json
{ "_comment": "OAP/1 frame roundtrip vector placeholder." }

```



---



# ron-kms

_Source: crates/ron-kms/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-11-07T01:11:30Z -->
# Code Bundle — `ron-kms`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-kms/.cargo/config.toml](#crates-ron-kms--cargo-config-toml)
- [crates/ron-kms/Cargo.toml](#crates-ron-kms-Cargo-toml)
- [crates/ron-kms/benches/batch_verify.rs](#crates-ron-kms-benches-batchverify-rs)
- [crates/ron-kms/benches/decap_bench.rs](#crates-ron-kms-benches-decapbench-rs)
- [crates/ron-kms/benches/encap_bench.rs](#crates-ron-kms-benches-encapbench-rs)
- [crates/ron-kms/benches/parallel_throughput.rs](#crates-ron-kms-benches-parallelthroughput-rs)
- [crates/ron-kms/benches/sign_bench.rs](#crates-ron-kms-benches-signbench-rs)
- [crates/ron-kms/benches/sign_fast.rs](#crates-ron-kms-benches-signfast-rs)
- [crates/ron-kms/benches/throughput_batch.rs](#crates-ron-kms-benches-throughputbatch-rs)
- [crates/ron-kms/benches/verify_bench.rs](#crates-ron-kms-benches-verifybench-rs)
- [crates/ron-kms/benches/verify_fast.rs](#crates-ron-kms-benches-verifyfast-rs)
- [crates/ron-kms/deny.toml](#crates-ron-kms-deny-toml)
- [crates/ron-kms/examples/metrics.rs](#crates-ron-kms-examples-metrics-rs)
- [crates/ron-kms/examples/rotate.rs](#crates-ron-kms-examples-rotate-rs)
- [crates/ron-kms/examples/smoke.rs](#crates-ron-kms-examples-smoke-rs)
- [crates/ron-kms/fuzz/Cargo.toml](#crates-ron-kms-fuzz-Cargo-toml)
- [crates/ron-kms/fuzz/fuzz_targets/dto_sign.rs](#crates-ron-kms-fuzz-fuzztargets-dtosign-rs)
- [crates/ron-kms/fuzz/fuzz_targets/sealed_header.rs](#crates-ron-kms-fuzz-fuzztargets-sealedheader-rs)
- [crates/ron-kms/rust-toolchain.toml](#crates-ron-kms-rust-toolchain-toml)
- [crates/ron-kms/scripts/bench.sh](#crates-ron-kms-scripts-bench-sh)
- [crates/ron-kms/src/backends/dalek.rs](#crates-ron-kms-src-backends-dalek-rs)
- [crates/ron-kms/src/backends/fast.rs](#crates-ron-kms-src-backends-fast-rs)
- [crates/ron-kms/src/backends/fast_ring.rs](#crates-ron-kms-src-backends-fastring-rs)
- [crates/ron-kms/src/backends/file.rs](#crates-ron-kms-src-backends-file-rs)
- [crates/ron-kms/src/backends/memory.rs](#crates-ron-kms-src-backends-memory-rs)
- [crates/ron-kms/src/backends/mod.rs](#crates-ron-kms-src-backends-mod-rs)
- [crates/ron-kms/src/backends/pkcs11.rs](#crates-ron-kms-src-backends-pkcs11-rs)
- [crates/ron-kms/src/config.rs](#crates-ron-kms-src-config-rs)
- [crates/ron-kms/src/error.rs](#crates-ron-kms-src-error-rs)
- [crates/ron-kms/src/lib.rs](#crates-ron-kms-src-lib-rs)
- [crates/ron-kms/src/metrics.rs](#crates-ron-kms-src-metrics-rs)
- [crates/ron-kms/src/ops/attest.rs](#crates-ron-kms-src-ops-attest-rs)
- [crates/ron-kms/src/ops/create.rs](#crates-ron-kms-src-ops-create-rs)
- [crates/ron-kms/src/ops/mod.rs](#crates-ron-kms-src-ops-mod-rs)
- [crates/ron-kms/src/ops/rotate.rs](#crates-ron-kms-src-ops-rotate-rs)
- [crates/ron-kms/src/ops/sign.rs](#crates-ron-kms-src-ops-sign-rs)
- [crates/ron-kms/src/ops/unwrap.rs](#crates-ron-kms-src-ops-unwrap-rs)
- [crates/ron-kms/src/ops/verify.rs](#crates-ron-kms-src-ops-verify-rs)
- [crates/ron-kms/src/ops/verify_batch.rs](#crates-ron-kms-src-ops-verifybatch-rs)
- [crates/ron-kms/src/ops/wrap.rs](#crates-ron-kms-src-ops-wrap-rs)
- [crates/ron-kms/src/pq/mldsa.rs](#crates-ron-kms-src-pq-mldsa-rs)
- [crates/ron-kms/src/pq/mlkem.rs](#crates-ron-kms-src-pq-mlkem-rs)
- [crates/ron-kms/src/pq/mod.rs](#crates-ron-kms-src-pq-mod-rs)
- [crates/ron-kms/src/pq/slhdsa.rs](#crates-ron-kms-src-pq-slhdsa-rs)
- [crates/ron-kms/src/prelude.rs](#crates-ron-kms-src-prelude-rs)
- [crates/ron-kms/src/sealed/aead.rs](#crates-ron-kms-src-sealed-aead-rs)
- [crates/ron-kms/src/sealed/anti_rollback.rs](#crates-ron-kms-src-sealed-antirollback-rs)
- [crates/ron-kms/src/sealed/header.rs](#crates-ron-kms-src-sealed-header-rs)
- [crates/ron-kms/src/sealed/mod.rs](#crates-ron-kms-src-sealed-mod-rs)
- [crates/ron-kms/src/sealed/store.rs](#crates-ron-kms-src-sealed-store-rs)
- [crates/ron-kms/src/telemetry.rs](#crates-ron-kms-src-telemetry-rs)
- [crates/ron-kms/src/traits/hybrid.rs](#crates-ron-kms-src-traits-hybrid-rs)
- [crates/ron-kms/src/traits/kem.rs](#crates-ron-kms-src-traits-kem-rs)
- [crates/ron-kms/src/traits/keystore.rs](#crates-ron-kms-src-traits-keystore-rs)
- [crates/ron-kms/src/traits/mod.rs](#crates-ron-kms-src-traits-mod-rs)
- [crates/ron-kms/src/traits/pubkey.rs](#crates-ron-kms-src-traits-pubkey-rs)
- [crates/ron-kms/src/traits/signer.rs](#crates-ron-kms-src-traits-signer-rs)
- [crates/ron-kms/src/traits/verifier.rs](#crates-ron-kms-src-traits-verifier-rs)
- [crates/ron-kms/src/types.rs](#crates-ron-kms-src-types-rs)
- [crates/ron-kms/src/util/ct.rs](#crates-ron-kms-src-util-ct-rs)
- [crates/ron-kms/src/util/mod.rs](#crates-ron-kms-src-util-mod-rs)
- [crates/ron-kms/src/util/time.rs](#crates-ron-kms-src-util-time-rs)
- [crates/ron-kms/src/util/zeroize.rs](#crates-ron-kms-src-util-zeroize-rs)
- [crates/ron-kms/telemetry.rs](#crates-ron-kms-telemetry-rs)
- [crates/ron-kms/testing/kms-dev-server/Cargo.toml](#crates-ron-kms-testing-kms-dev-server-Cargo-toml)
- [crates/ron-kms/testing/kms-dev-server/src/main.rs](#crates-ron-kms-testing-kms-dev-server-src-main-rs)
- [crates/ron-kms/tests/attest.rs](#crates-ron-kms-tests-attest-rs)
- [crates/ron-kms/tests/interop_kats.rs](#crates-ron-kms-tests-interopkats-rs)
- [crates/ron-kms/tests/keyid_and_roundtrip.rs](#crates-ron-kms-tests-keyidandroundtrip-rs)
- [crates/ron-kms/tests/unit/attest_test.rs](#crates-ron-kms-tests-unit-attesttest-rs)
- [crates/ron-kms/tests/unit/rotate_test.rs](#crates-ron-kms-tests-unit-rotatetest-rs)
- [crates/ron-kms/tests/unit/sealed_header_test.rs](#crates-ron-kms-tests-unit-sealedheadertest-rs)
- [crates/ron-kms/tests/unit/zeroize_test.rs](#crates-ron-kms-tests-unit-zeroizetest-rs)
- [crates/ron-kms/tests/versioned_verify.rs](#crates-ron-kms-tests-versionedverify-rs)
- [crates/ron-kms/xtask/src/main.rs](#crates-ron-kms-xtask-src-main-rs)

### crates/ron-kms/.cargo/config.toml
<a id="crates-ron-kms--cargo-config-toml"></a>

```toml
[build]
rustflags = []

[term]
verbose = false

```

### crates/ron-kms/Cargo.toml
<a id="crates-ron-kms-Cargo-toml"></a>

```toml
[package]
name = "ron-kms"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
publish = false

[lib]
path = "src/lib.rs"

[features]
default = []
with-metrics = ["dep:prometheus", "dep:once_cell"]
# Optional backends / algorithms
fast      = ["dep:ring"]     # enables ASM-accelerated Ed25519 via ring for sign/verify
mlkem     = []
mldsa     = []
slhdsa    = []
soft-seal = []
pkcs11    = []
dalek-batch = []
parallel-batch = ["rayon", "dalek-batch"] 

[dependencies]
# Default crypto backend (audit-friendly, pure Rust)
ed25519-dalek = { version = "2", default-features = false, features = ["fast", "rand_core", "batch"] }
rayon = { version = "1.10", optional = true }


# Optional fast backend (feature-gated)
ring = { version = "0.17", optional = true }

rand        = "0.8"
rand_core   = "0.6"
zeroize     = { version = "1.7", features = ["alloc"] }
thiserror   = "1"
serde       = { version = "1", features = ["derive"] }
serde_json  = "1"
blake3      = "1"
parking_lot = "0.12"
ahash       = "0.8"
prometheus  = { version = "0.14", optional = true }
once_cell   = { version = "1", optional = true }
time        = { version = "0.3", features = ["macros"] }
uuid        = { version = "1", features = ["v4", "serde"] }
anyhow      = "1"

[dev-dependencies]
hex = "0.4"
criterion = { version = "0.5", default-features = false, features = ["cargo_bench_support","html_reports"] }

# Criterion benches need harness=false
[[bench]]
name = "sign_bench"
harness = false

[[bench]]
name = "verify_bench"
harness = false

[[bench]]
name = "batch_verify"
harness = false

[[bench]]
name = "parallel_throughput"
harness = false

[[bench]]
name = "throughput_batch"
harness = false


# Stubs for later:
# [[bench]]
# name = "encap_bench"
# harness = false
#
# [[bench]]
# name = "decap_bench"
# harness = false


```

### crates/ron-kms/benches/batch_verify.rs
<a id="crates-ron-kms-benches-batchverify-rs"></a>

```rust
use criterion::{criterion_group, criterion_main, BatchSize, BenchmarkId, Criterion};
use rand::{rngs::StdRng, RngCore, SeedableRng};
use ron_kms::backends::ed25519;

fn rand_bytes(len: usize, rng: &mut StdRng) -> Vec<u8> {
    let mut buf = vec![0u8; len];
    rng.fill_bytes(&mut buf);
    buf
}

pub fn bench_batch_verify(c: &mut Criterion) {
    let mut g = c.benchmark_group("verify_batch");

    for &n in &[8usize, 32, 64] {
        g.bench_function(BenchmarkId::from_parameter(n), |b| {
            // Setup: N keypairs, messages, sigs
            let mut rng = StdRng::seed_from_u64(99 + n as u64);

            let mut pks = Vec::with_capacity(n);
            let mut msgs = Vec::with_capacity(n);
            let mut sigs = Vec::with_capacity(n);
            for _ in 0..n {
                let (pk, sk) = ed25519::generate();
                let m = rand_bytes(128, &mut rng);
                let s = ed25519::sign(&sk, &m);
                pks.push(pk);
                msgs.push(m);
                sigs.push(s);
            }
            let msg_refs: Vec<&[u8]> = msgs.iter().map(|m| m.as_slice()).collect();

            // Measure: single call into backend batch
            b.iter_batched(
                || (),
                |_| {
                    let _ = ed25519::verify_batch(&pks, &msg_refs, &sigs);
                },
                BatchSize::LargeInput,
            );
        });
    }

    g.finish();
}

criterion_group! {
    name = benches;
    config = Criterion::default()
        .sample_size(90)
        .measurement_time(std::time::Duration::from_secs(12))
        .warm_up_time(std::time::Duration::from_secs(3));
    targets = bench_batch_verify
}
criterion_main!(benches);

```

### crates/ron-kms/benches/decap_bench.rs
<a id="crates-ron-kms-benches-decapbench-rs"></a>

```rust
// bench scaffold
fn main() {}

```

### crates/ron-kms/benches/encap_bench.rs
<a id="crates-ron-kms-benches-encapbench-rs"></a>

```rust
// bench scaffold
fn main() {}

```

### crates/ron-kms/benches/parallel_throughput.rs
<a id="crates-ron-kms-benches-parallelthroughput-rs"></a>

```rust
use criterion::{criterion_group, criterion_main, Criterion};
use rand::{rngs::StdRng, RngCore, SeedableRng};
use std::sync::Arc;
use std::thread;

use ron_kms::backends::ed25519;

fn rand_bytes(len: usize, rng: &mut StdRng) -> Vec<u8> {
    let mut buf = vec![0u8; len];
    rng.fill_bytes(&mut buf);
    buf
}

const OPS: usize = 4_000; // per run
const THREADS: usize = 4;

pub fn bench_parallel(c: &mut Criterion) {
    let mut g = c.benchmark_group("parallel");

    // --- Sign 4× ---
    g.bench_function("parallel_sign_4x", |b| {
        let mut rng = StdRng::seed_from_u64(777);
        let (_pk, sk) = ed25519::generate();
        let msg = Arc::new(rand_bytes(128, &mut rng));

        b.iter(|| {
            let mut handles = Vec::with_capacity(THREADS);
            for _ in 0..THREADS {
                let sk = sk; // copy seed
                let msg = Arc::clone(&msg);
                handles.push(thread::spawn(move || {
                    for _ in 0..(OPS / THREADS) {
                        let _ = ed25519::sign(&sk, &msg);
                    }
                }));
            }
            for h in handles {
                let _ = h.join();
            }
        });
    });

    // --- Verify 4× ---
    g.bench_function("parallel_verify_4x", |b| {
        let mut rng = StdRng::seed_from_u64(778);
        let (pk, sk) = ed25519::generate();
        let msg = Arc::new(rand_bytes(128, &mut rng));
        let sig = ed25519::sign(&sk, &msg);

        b.iter(|| {
            let mut handles = Vec::with_capacity(THREADS);
            for _ in 0..THREADS {
                let pk = pk;
                let msg = Arc::clone(&msg);
                let sig = sig;
                handles.push(thread::spawn(move || {
                    for _ in 0..(OPS / THREADS) {
                        let _ = ed25519::verify(&pk, &msg, &sig);
                    }
                }));
            }
            for h in handles {
                let _ = h.join();
            }
        });
    });

    g.finish();
}

criterion_group! {
    name = benches;
    config = Criterion::default()
        .sample_size(60)
        .measurement_time(std::time::Duration::from_secs(8))
        .warm_up_time(std::time::Duration::from_secs(2));
    targets = bench_parallel
}
criterion_main!(benches);

```

### crates/ron-kms/benches/sign_bench.rs
<a id="crates-ron-kms-benches-signbench-rs"></a>

```rust
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};
use rand::{rngs::StdRng, RngCore, SeedableRng};

use ron_kms::backends::ed25519;

#[cfg(not(feature = "fast"))]
mod native {
    pub use ed25519_dalek::{Signer as _, SigningKey};
}
#[cfg(feature = "fast")]
mod native {
    pub use ring::signature::Ed25519KeyPair;
}

fn rand_bytes(len: usize, rng: &mut StdRng) -> Vec<u8> {
    let mut buf = vec![0u8; len];
    rng.fill_bytes(&mut buf);
    buf
}

pub fn bench_sign(c: &mut Criterion) {
    let mut g = c.benchmark_group("ed25519_sign_128B");
    let mut rng = StdRng::seed_from_u64(42);

    // Adapter path (seed -> sign) to reflect API
    {
        let (_pk, sk_seed) = ed25519::generate();
        let msg = rand_bytes(128, &mut rng);
        g.bench_function(BenchmarkId::new("adapter", "seed_→_sign"), |b| {
            b.iter(|| {
                let _sig = ed25519::sign(&sk_seed, &msg);
            });
        });
    }

    // Steady-state: prebuilt key, measure only .sign()
    #[cfg(not(feature = "fast"))]
    {
        use native::*;
        let sk_seed = {
            let (_, s) = ed25519::generate();
            s
        };
        let sk = SigningKey::from_bytes(&sk_seed);
        let msg = rand_bytes(128, &mut rng);

        g.bench_function(BenchmarkId::new("steady", "dalek_signingkey.sign"), |b| {
            b.iter(|| {
                let _ = sk.sign(&msg);
            })
        });
    }

    #[cfg(feature = "fast")]
    {
        use native::*;
        let sk_seed = {
            let (_, s) = ed25519::generate();
            s
        };
        let kp = Ed25519KeyPair::from_seed_unchecked(&sk_seed).expect("ring seed");
        let msg = rand_bytes(128, &mut rng);

        g.bench_function(BenchmarkId::new("steady", "ring_keypair.sign"), |b| {
            b.iter(|| {
                let _ = kp.sign(&msg);
            })
        });
    }

    g.finish();
}

criterion_group! {
    name = benches;
    config = Criterion::default()
        .sample_size(120)
        .measurement_time(std::time::Duration::from_secs(10))
        .warm_up_time(std::time::Duration::from_secs(3));
    targets = bench_sign
}
criterion_main!(benches);

```

### crates/ron-kms/benches/sign_fast.rs
<a id="crates-ron-kms-benches-signfast-rs"></a>

```rust
#![cfg(feature = "fast")]
//! RO:WHAT  A/B bench for fast (ring) sign on 128B message.
//! RO:WHY   Quantify single-op latency vs default dalek path.

use criterion::{criterion_group, criterion_main, Criterion};
use ron_kms::backends::ed25519;

fn bench_sign_fast(c: &mut Criterion) {
    let (sk_blob, _pk) = ed25519::ed25519_generate();
    let msg = vec![0u8; 128];

    c.bench_function("ed25519_sign_fast_128B", |b| {
        b.iter(|| {
            let _sig = ed25519::ed25519_sign(&sk_blob, &msg);
        })
    });
}

criterion_group!(benches, bench_sign_fast);
criterion_main!(benches);

```

### crates/ron-kms/benches/throughput_batch.rs
<a id="crates-ron-kms-benches-throughputbatch-rs"></a>

```rust
//! Throughput bench for parallel multiscalar batch verification.
//! Measures sustained verifies/sec at several batch sizes while keeping setup outside the timing.
//!
//! Run (parallel multiscalar enabled):
//! RUSTFLAGS="-C target-cpu=native" RAYON_NUM_THREADS=4 \
//!   cargo bench -p ron-kms --features "dalek-batch,parallel-batch" \
//!   --bench throughput_batch -- --measurement-time 14 --sample-size 90
//!
//! What it reports:
//! - Criterion shows time/iter, and because we set Throughput::Elements(n), it also shows
//!   "elements/s" = messages verified per second for each batch size.
//!
//! Notes:
//! - We generate valid (pk, msg, sig) tuples once per N and reuse them to isolate curve verify cost.
//! - No unsafe. No 'static lifetimes required.

use criterion::{criterion_group, criterion_main, Criterion, Throughput};
use rand::{rngs::StdRng, RngCore, SeedableRng};

use ron_kms::backends::ed25519;

/// Build a valid batch and return OWNED data so we can derive &\[u8] slices later.
fn prepare_valid_batch(n: usize) -> (Vec<[u8; 32]>, Vec<Box<[u8]>>, Vec<[u8; 64]>) {
    let mut rng = StdRng::seed_from_u64(0xDEAD_BEEF_F00D_1234);
    let mut msg_bufs: Vec<Box<[u8]>> = Vec::with_capacity(n);
    let mut pks: Vec<[u8; 32]> = Vec::with_capacity(n);
    let mut sigs: Vec<[u8; 64]> = Vec::with_capacity(n);

    for _ in 0..n {
        // Random message length in [64, 256] to add mild variance
        let mlen = 64 + (rng.next_u32() as usize % 193);
        let mut m = vec![0u8; mlen].into_boxed_slice();
        rng.fill_bytes(&mut m);

        let (pk, sk) = ed25519::generate();
        let sig = ed25519::sign(&sk, &m);

        msg_bufs.push(m);
        pks.push(pk);
        sigs.push(sig);
    }

    (pks, msg_bufs, sigs)
}

fn bench_throughput(c: &mut Criterion) {
    for &n in &[64usize, 128, 256, 512] {
        // Keep owned buffers alive for the entire group scope
        let (pks, owned_msgs, sigs) = prepare_valid_batch(n);

        // Build borrowed slice view from owned buffers
        let msgs: Vec<&[u8]> = owned_msgs.iter().map(|b| b.as_ref()).collect();

        let mut group = c.benchmark_group(format!("batch_throughput/{n}"));
        group.throughput(Throughput::Elements(n as u64));

        group.bench_function("verify_parallel_multiscalar", |b| {
            b.iter(|| {
                let ok = ed25519::verify_batch(&pks, &msgs, &sigs);
                // Keep the assert so the optimizer can't DCE the call.
                assert!(ok);
            });
        });

        group.finish();
    }
}

criterion_group!(benches, bench_throughput);
criterion_main!(benches);

```

### crates/ron-kms/benches/verify_bench.rs
<a id="crates-ron-kms-benches-verifybench-rs"></a>

```rust
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};
use rand::{rngs::StdRng, RngCore, SeedableRng};

use ron_kms::backends::ed25519;

#[cfg(not(feature = "fast"))]
mod native {
    pub use ed25519_dalek::{Signature, Verifier as _, VerifyingKey};
}
#[cfg(feature = "fast")]
mod native {
    pub use ring::signature::{UnparsedPublicKey, ED25519};
}

fn rand_bytes(len: usize, rng: &mut StdRng) -> Vec<u8> {
    let mut buf = vec![0u8; len];
    rng.fill_bytes(&mut buf);
    buf
}

pub fn bench_verify(c: &mut Criterion) {
    let mut g = c.benchmark_group("ed25519_verify_128B");
    let mut rng = StdRng::seed_from_u64(43);

    let (pk, sk_seed) = ed25519::generate();
    let msg = rand_bytes(128, &mut rng);
    let sig = ed25519::sign(&sk_seed, &msg);

    // Adapter path (bytes -> verify)
    g.bench_function(BenchmarkId::new("adapter", "bytes_verify"), |b| {
        b.iter(|| {
            let _ok = ed25519::verify(&pk, &msg, &sig);
        })
    });

    // Steady-state: preparse verifying key + signature; verify only
    #[cfg(not(feature = "fast"))]
    {
        use native::*;
        let vk = VerifyingKey::from_bytes(&pk).expect("vk");
        let sig = Signature::from_slice(&sig).expect("sig");

        g.bench_function(BenchmarkId::new("steady", "dalek_vk.verify"), |b| {
            b.iter(|| {
                let _ = vk.verify_strict(&msg, &sig);
            })
        });
    }

    #[cfg(feature = "fast")]
    {
        use native::*;
        let verifier = UnparsedPublicKey::new(&ED25519, &pk);

        g.bench_function(BenchmarkId::new("steady", "ring_unparsed.verify"), |b| {
            b.iter(|| {
                let _ = verifier.verify(&msg, &sig);
            })
        });
    }

    g.finish();
}

criterion_group! {
    name = benches;
    config = Criterion::default()
        .sample_size(120)
        .measurement_time(std::time::Duration::from_secs(10))
        .warm_up_time(std::time::Duration::from_secs(3));
    targets = bench_verify
}
criterion_main!(benches);

```

### crates/ron-kms/benches/verify_fast.rs
<a id="crates-ron-kms-benches-verifyfast-rs"></a>

```rust
#![cfg(feature = "fast")]
//! RO:WHAT  A/B bench for fast (ring) verify on 128B message.
//! RO:WHY   Quantify single-op latency vs default dalek path.

use criterion::{criterion_group, criterion_main, Criterion};
use ron_kms::backends::ed25519;

fn bench_verify_fast(c: &mut Criterion) {
    let (sk_blob, pk) = ed25519::ed25519_generate();
    let msg = vec![0u8; 128];
    let sig = ed25519::ed25519_sign(&sk_blob, &msg);

    c.bench_function("ed25519_verify_fast_128B", |b| {
        b.iter(|| {
            let _ok = ed25519::ed25519_verify(&pk, &msg, &sig);
        })
    });
}

criterion_group!(benches, bench_verify_fast);
criterion_main!(benches);

```

### crates/ron-kms/deny.toml
<a id="crates-ron-kms-deny-toml"></a>

```toml
# cargo-deny scaffold (fill with project rules later)
[advisories]
yanked = "warn"

[bans]
multiple-versions = "warn"

[sources]
unknown-registry = "deny"
unknown-git = "deny"

```

### crates/ron-kms/examples/metrics.rs
<a id="crates-ron-kms-examples-metrics-rs"></a>

```rust
// Minimal metrics demo: perform a few ops, then print Prometheus text.
use ron_kms::memory_keystore;
use ron_kms::ops::{attest::attest, create, rotate, sign, verify};

fn main() -> anyhow::Result<()> {
    // Do a few ops so counters/histogram tick.
    let kms = memory_keystore();
    let kid = create::ed25519(&kms, "auth", "signing")?;
    let msg = b"hello-metrics";
    let sig = sign::sign(&kms, &kid, msg)?;
    assert!(verify::verify(&kms, &kid, msg, &sig)?);
    let kid2 = rotate::rotate(&kms, &kid)?;
    let _ = attest(&kms, &kid2)?;

    // Print Prometheus exposition to stdout (feature `with-metrics` must be enabled).
    #[cfg(feature = "with-metrics")]
    {
        use prometheus::{gather, Encoder, TextEncoder};
        let encoder = TextEncoder::new();
        let mf = gather();
        let mut buf = Vec::new();
        encoder.encode(&mf, &mut buf).expect("encode");
        println!("{}", String::from_utf8_lossy(&buf));
    }

    Ok(())
}

```

### crates/ron-kms/examples/rotate.rs
<a id="crates-ron-kms-examples-rotate-rs"></a>

```rust
// crates/ron-kms/examples/rotate.rs
use ron_kms::{memory_keystore, Keystore, Signer, Verifier};

fn main() -> anyhow::Result<()> {
    let kms = memory_keystore();

    // v1
    let kid_v1 = kms.create_ed25519("auth", "signing")?;
    let msg_v1 = b"first signature before rotation";
    let sig_v1 = kms.sign(&kid_v1, msg_v1)?;
    assert!(kms.verify(&kid_v1, msg_v1, &sig_v1)?);

    // rotate → v2
    let kid_v2 = kms.rotate(&kid_v1)?;
    assert_eq!(kid_v2.version, kid_v1.version + 1);

    // v2 signs and verifies
    let msg_v2 = b"second signature after rotation";
    let sig_v2 = kms.sign(&kid_v2, msg_v2)?;
    assert!(kms.verify(&kid_v2, msg_v2, &sig_v2)?);

    // NOTE: In this dev backend, the latest public key replaces the old one.
    // Old signatures are not guaranteed to verify after rotation (by design here).

    Ok(())
}

```

### crates/ron-kms/examples/smoke.rs
<a id="crates-ron-kms-examples-smoke-rs"></a>

```rust
use ron_kms::{memory_keystore, Keystore, Signer, Verifier};

fn main() -> anyhow::Result<()> {
    let kms = memory_keystore();
    let kid = kms.create_ed25519("auth", "signing")?;
    let msg = b"rustyonions";
    let sig = kms.sign(&kid, msg)?;
    assert!(kms.verify(&kid, msg, &sig)?);
    Ok(())
}

```

### crates/ron-kms/fuzz/Cargo.toml
<a id="crates-ron-kms-fuzz-Cargo-toml"></a>

```toml
[package]
name = "ron-kms2-fuzz"
version = "0.0.0"
publish = false
edition = "2021"

[dependencies]
libfuzzer-sys = { version = "0.4", features = ["arbitrary-derive"] }

[package.metadata]
cargo-fuzz = true

[[bin]]
name = "sealed_header"
path = "fuzz_targets/sealed_header.rs"
test = false
doc = false

[[bin]]
name = "dto_sign"
path = "fuzz_targets/dto_sign.rs"
test = false
doc = false

```

### crates/ron-kms/fuzz/fuzz_targets/dto_sign.rs
<a id="crates-ron-kms-fuzz-fuzztargets-dtosign-rs"></a>

```rust
// fuzz target scaffold
#![no_main]
use libfuzzer_sys::fuzz_target;
fuzz_target!(|data: &[u8]| {
    let _ = data.iter().fold(0u8, |acc, b| acc ^ b);
});

```

### crates/ron-kms/fuzz/fuzz_targets/sealed_header.rs
<a id="crates-ron-kms-fuzz-fuzztargets-sealedheader-rs"></a>

```rust
// fuzz target scaffold
#![no_main]
use libfuzzer_sys::fuzz_target;
fuzz_target!(|data: &[u8]| {
    let _ = data.len();
});

```

### crates/ron-kms/rust-toolchain.toml
<a id="crates-ron-kms-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["clippy", "rustfmt"]

```

### crates/ron-kms/scripts/bench.sh
<a id="crates-ron-kms-scripts-bench-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Usage:
#   crates/ron-kms/scripts/bench.sh        # dalek lane
#   FAST=1 crates/ron-kms/scripts/bench.sh # ring lane

export RUSTFLAGS="-C target-cpu=native"

# robust under set -u: use string not array
FEATURES_ARGS=""
if [[ "${FAST:-0}" == "1" ]]; then
  FEATURES_ARGS="--features fast"
fi

cargo bench -p ron-kms $FEATURES_ARGS \
  --bench sign_bench \
  --bench verify_bench \
  --bench batch_verify \
  --bench parallel_throughput \
  -- --sample-size 120 --measurement-time 10 --warm-up-time 3

```

### crates/ron-kms/src/backends/dalek.rs
<a id="crates-ron-kms-src-backends-dalek-rs"></a>

```rust
//! Dalek (pure Rust) Ed25519 helpers.
//! Uses `ed25519-dalek` v2 types explicitly to avoid collisions with the `ed25519` trait crate.

#![allow(clippy::module_name_repetitions)]

use ed25519_dalek::Signer; // trait for `sign`
use ed25519_dalek::{Signature, SigningKey, VerifyingKey};
use rand::rngs::OsRng;

#[cfg(not(all(feature = "dalek-batch", feature = "parallel-batch")))]
use std::cell::RefCell;

#[cfg(feature = "parallel-batch")]
use rayon::prelude::*;

/// Thread-local scratch to avoid per-call Vec allocs in batch verification (serial paths).
/// Only compiled when the parallel multiscalar path is NOT active.
#[cfg(not(all(feature = "dalek-batch", feature = "parallel-batch")))]
struct BatchScratch {
    vks: Vec<VerifyingKey>,
    sigs: Vec<Signature>,
}
#[cfg(not(all(feature = "dalek-batch", feature = "parallel-batch")))]
impl BatchScratch {
    fn with_capacity(n: usize) -> Self {
        Self {
            vks: Vec::with_capacity(n),
            sigs: Vec::with_capacity(n),
        }
    }
    fn reset(&mut self, n: usize) {
        if self.vks.capacity() < n {
            self.vks.reserve(n - self.vks.capacity());
        }
        if self.sigs.capacity() < n {
            self.sigs.reserve(n - self.sigs.capacity());
        }
        self.vks.clear();
        self.sigs.clear();
    }
}

#[cfg(not(all(feature = "dalek-batch", feature = "parallel-batch")))]
thread_local! {
    static SCRATCH: RefCell<BatchScratch> = RefCell::new(BatchScratch::with_capacity(64));
}

/// Generate a new Ed25519 keypair, returning (`public_key_bytes`, `secret_key_bytes`).
#[must_use]
pub fn ed25519_generate() -> ([u8; 32], [u8; 32]) {
    let mut csprng = OsRng;
    let sk: SigningKey = SigningKey::generate(&mut csprng);
    let vk: VerifyingKey = VerifyingKey::from(&sk);
    (vk.to_bytes(), sk.to_bytes())
}

/// Sign `msg` using a 32-byte Ed25519 secret key (seed). Returns the 64-byte signature.
#[must_use]
pub fn ed25519_sign(secret_seed: &[u8; 32], msg: &[u8]) -> [u8; 64] {
    let sk: SigningKey = SigningKey::from_bytes(secret_seed);
    sk.sign(msg).to_bytes()
}

/// Verify a 64-byte signature against a 32-byte public key. Returns true if valid.
#[must_use]
pub fn ed25519_verify(pk_bytes: &[u8; 32], msg: &[u8], sig_bytes: &[u8; 64]) -> bool {
    let sig: Signature = Signature::from_bytes(sig_bytes);
    let Ok(vk) = VerifyingKey::from_bytes(pk_bytes) else {
        return false;
    };
    vk.verify_strict(msg, &sig).is_ok()
}

/// Batch verify N signatures. `pks.len() == msgs.len() == sigs.len()`.
#[must_use]
pub fn ed25519_verify_batch(pks: &[[u8; 32]], msgs: &[&[u8]], sigs: &[[u8; 64]]) -> bool {
    let n = pks.len();
    if !(n == msgs.len() && n == sigs.len()) {
        return false;
    }

    // ======== Parallel multiscalar batch ========
    #[cfg(all(feature = "dalek-batch", feature = "parallel-batch"))]
    {
        // Decode once into local vectors (no thread-local scratch in the parallel path).
        let mut vks = Vec::with_capacity(n);
        let mut sig_parsed = Vec::with_capacity(n);
        for pk in pks {
            let Ok(vk) = VerifyingKey::from_bytes(pk) else {
                return false;
            };
            vks.push(vk);
        }
        for s in sigs {
            sig_parsed.push(Signature::from_bytes(s));
        }

        // Pick a chunk count: up to 2× threads, but not more than n; ensure ≥8 items per chunk.
        let threads = rayon::current_num_threads().max(1);
        let mut chunks = (threads * 2).min(n.max(1));
        while chunks > 1 && (n / chunks) < 8 {
            chunks -= 1;
        }

        // Parallelize over 0..chunks; compute (start,end) inside the closure.
        let all_ok = (0..chunks).into_par_iter().all(|i| {
            let start = i * n / chunks;
            let end = ((i + 1) * n / chunks).min(n);
            ed25519_dalek::verify_batch(
                &msgs[start..end],
                &sig_parsed[start..end],
                &vks[start..end],
            )
            .is_ok()
        });

        return all_ok;
    }

    // ======== Serial multiscalar batch ========
    #[cfg(all(feature = "dalek-batch", not(feature = "parallel-batch")))]
    {
        return SCRATCH.with(|cell| {
            let mut scratch = cell.borrow_mut();
            scratch.reset(n);

            for pk in pks {
                let Ok(vk) = VerifyingKey::from_bytes(pk) else {
                    return false;
                };
                scratch.vks.push(vk);
            }
            for s in sigs {
                scratch.sigs.push(Signature::from_bytes(s));
            }
            ed25519_dalek::verify_batch(&msgs, &scratch.sigs, &scratch.vks).is_ok()
        });
    }

    // ======== Serial strict loop (no dalek batch available) ========
    #[cfg(not(feature = "dalek-batch"))]
    {
        SCRATCH.with(|cell| {
            let mut scratch = cell.borrow_mut();
            scratch.reset(n);

            for pk in pks {
                let Ok(vk) = VerifyingKey::from_bytes(pk) else {
                    return false;
                };
                scratch.vks.push(vk);
            }
            for s in sigs {
                scratch.sigs.push(Signature::from_bytes(s));
            }

            for ((vk, sig), msg) in scratch
                .vks
                .iter()
                .zip(scratch.sigs.iter())
                .zip(msgs.iter().copied())
            {
                if vk.verify_strict(msg, sig).is_err() {
                    return false;
                }
            }
            true
        })
    }
}

```

### crates/ron-kms/src/backends/fast.rs
<a id="crates-ron-kms-src-backends-fast-rs"></a>

```rust
//! Fast Ed25519 path using `ring`.
//!
//! Exposes the same free functions as the dalek backend so callers can feature-switch:
//! - `ed25519_generate()` -> (`public_key_bytes`, `secret_key_bytes`)
//! - `ed25519_sign(seed, msg)` -> signature bytes
//! - `ed25519_verify(pk, msg, sig)` -> bool

#![allow(clippy::module_name_repetitions)]

use ring::rand::{SecureRandom, SystemRandom};
use ring::signature::{Ed25519KeyPair, Signature, UnparsedPublicKey, ED25519};

/// Generate a new Ed25519 keypair, returning (`public_key_bytes`, `secret_key_bytes`).
/// - public key: 32 bytes
/// - secret key (seed): 32 bytes
#[must_use]
pub fn ed25519_generate() -> ([u8; 32], [u8; 32]) {
    let rng = SystemRandom::new();

    // ring's Ed25519KeyPair can be constructed from a 32-byte seed.
    let mut seed = [0u8; 32];
    rng.fill(&mut seed).expect("ring: RNG failed");

    let kp = Ed25519KeyPair::from_seed_unchecked(&seed).expect("ring: from_seed_unchecked failed");
    let pk_bytes: [u8; 32] = kp.public_key().as_ref().try_into().expect("pk size");

    (pk_bytes, seed)
}

/// Sign `msg` using a 32-byte Ed25519 secret key (seed).
/// Returns the 64-byte signature.
#[must_use]
pub fn ed25519_sign(secret_seed: &[u8; 32], msg: &[u8]) -> [u8; 64] {
    let kp = Ed25519KeyPair::from_seed_unchecked(secret_seed).expect("ring: from_seed_unchecked");
    let sig: Signature = kp.sign(msg);
    sig.as_ref().try_into().expect("sig size")
}

/// Verify a 64-byte signature against a 32-byte public key.
/// Returns true if valid.
#[must_use]
pub fn ed25519_verify(pk_bytes: &[u8; 32], msg: &[u8], sig_bytes: &[u8; 64]) -> bool {
    let verifier = UnparsedPublicKey::new(&ED25519, pk_bytes);
    verifier.verify(msg, sig_bytes).is_ok()
}

```

### crates/ron-kms/src/backends/fast_ring.rs
<a id="crates-ron-kms-src-backends-fastring-rs"></a>

```rust
//! Fast Ed25519 path using `ring`.
//!
//! Exposes the same free functions as the dalek backend so callers can feature-switch:
//! - `ed25519_generate()` -> (`public_key_bytes`, `secret_key_bytes`)
//! - `ed25519_sign(seed, msg)` -> signature bytes
//! - `ed25519_verify(pk, msg, sig)` -> bool
//! - `ed25519_verify_batch(pks, msgs, sigs)` -> bool
//!
//! Invariants:
//! - Always return fixed-size arrays ([u8; 32] pubkey/seed, [u8; 64] signature)
//! - No allocations on hot sign/verify paths.
//! - Pure `ring` API; no unsafe.

#![allow(clippy::module_name_repetitions)]

use ring::rand::{SecureRandom, SystemRandom};
use ring::signature::{Ed25519KeyPair, KeyPair, Signature, UnparsedPublicKey, ED25519};

/// Generate a new Ed25519 keypair, returning (`public_key_bytes`, `secret_key_bytes`).
/// - public key: 32 bytes
/// - secret key (seed): 32 bytes
#[must_use]
pub fn ed25519_generate() -> ([u8; 32], [u8; 32]) {
    let rng = SystemRandom::new();

    // ring’s Ed25519KeyPair can be constructed from a 32-byte seed.
    let mut seed = [0u8; 32];
    rng.fill(&mut seed).expect("ring RNG failed");

    let kp = Ed25519KeyPair::from_seed_unchecked(&seed).expect("ring from_seed_unchecked");
    let mut pk = [0u8; 32];
    pk.copy_from_slice(kp.public_key().as_ref()); // KeyPair::public_key() -> &[u8] (32)

    (pk, seed)
}

/// Sign `msg` using a 32-byte Ed25519 secret key (seed).
/// Returns the 64-byte signature.
#[must_use]
pub fn ed25519_sign(secret_seed: &[u8; 32], msg: &[u8]) -> [u8; 64] {
    let kp = Ed25519KeyPair::from_seed_unchecked(secret_seed).expect("ring from_seed_unchecked");
    let sig: Signature = kp.sign(msg);
    let mut out = [0u8; 64];
    out.copy_from_slice(sig.as_ref()); // 64 bytes
    out
}

/// Verify a 64-byte signature against a 32-byte public key.
/// Returns true if valid.
#[must_use]
pub fn ed25519_verify(pk_bytes: &[u8; 32], msg: &[u8], sig_bytes: &[u8; 64]) -> bool {
    let verifier = UnparsedPublicKey::new(&ED25519, pk_bytes);
    verifier.verify(msg, sig_bytes).is_ok()
}

/// Batch verify N signatures. Expects `pks.len() == msgs.len() == sigs.len()`.
#[must_use]
pub fn ed25519_verify_batch(pks: &[[u8; 32]], msgs: &[&[u8]], sigs: &[[u8; 64]]) -> bool {
    if !(pks.len() == msgs.len() && msgs.len() == sigs.len()) {
        return false;
    }
    // Build once; ring's UnparsedPublicKey holds a reference, so no copies.
    let verifiers: Vec<UnparsedPublicKey<&[u8; 32]>> = pks
        .iter()
        .map(|pk| UnparsedPublicKey::new(&ED25519, pk))
        .collect();
    for i in 0..pks.len() {
        if verifiers[i].verify(msgs[i], &sigs[i]).is_err() {
            return false;
        }
    }
    true
}

```

### crates/ron-kms/src/backends/file.rs
<a id="crates-ron-kms-src-backends-file-rs"></a>

```rust
// File backend scaffold

```

### crates/ron-kms/src/backends/memory.rs
<a id="crates-ron-kms-src-backends-memory-rs"></a>

```rust
// RO:WHAT  Dev in-memory KMS with version-retaining verification (contiguous VKs).
// RO:INV   Non-exportability; only the latest version can sign; any version can verify.

use crate::{
    error::KmsError,
    traits::pubkey::PubkeyProvider,
    traits::{Keystore, Signer, Verifier},
    types::{Alg, KeyId, KeyMeta},
    util::time::now_utc_ms,
};
use ahash::AHashMap as HashMap;
use ed25519_dalek::Signer as _; // bring .sign() into scope
use ed25519_dalek::{Signature, SigningKey, VerifyingKey};
use parking_lot::RwLock;
use rand::rngs::OsRng;
use std::sync::Arc;

#[derive(Clone)]
pub struct MemoryKeystore(Arc<RwLock<State>>);

#[derive(Default)]
struct State {
    // Map by "stable root" (tenant/purpose/alg/uuid → per-root record)
    roots: HashMap<String, Root>,
}

struct Root {
    alg: Alg,
    current_version: u32,
    created_ms: i128,
    // Only the latest private key is retained.
    sk: SigningKey,
    // Convenience copy of the current verifying key.
    vk: VerifyingKey,
    // Verification keys for all versions we've ever issued (including current).
    // Index = version - 1.
    vks: Vec<VerifyingKey>,
}

impl Default for MemoryKeystore {
    fn default() -> Self {
        Self(Arc::new(RwLock::new(State {
            roots: HashMap::new(),
        })))
    }
}

impl MemoryKeystore {
    fn root_id(tenant: &str, purpose: &str, alg: Alg, uuid: uuid::Uuid) -> String {
        format!("{tenant}/{purpose}/{alg}/{uuid}")
    }

    fn gen_signing_key() -> SigningKey {
        // Requires ed25519-dalek feature "rand_core".
        SigningKey::generate(&mut OsRng)
    }
}

impl Keystore for MemoryKeystore {
    fn create_ed25519(&self, tenant: &str, purpose: &str) -> Result<KeyId, KmsError> {
        let alg = Alg::Ed25519;
        let kid = KeyId::new(tenant, purpose, alg);
        let root_id = Self::root_id(&kid.tenant, &kid.purpose, kid.alg, kid.uuid);

        let sk = Self::gen_signing_key();
        let vk = VerifyingKey::from(&sk);

        let mut vks = Vec::with_capacity(4);
        vks.push(vk);

        let root = Root {
            alg,
            current_version: kid.version,
            created_ms: now_utc_ms(),
            sk,
            vk,
            vks,
        };

        let mut st = self.0.write();
        st.roots.insert(root_id, root);
        Ok(kid)
    }

    fn rotate(&self, kid: &KeyId) -> Result<KeyId, KmsError> {
        let root_id = Self::root_id(&kid.tenant, &kid.purpose, kid.alg, kid.uuid);
        let mut st = self.0.write();
        let root = st.roots.get_mut(&root_id).ok_or(KmsError::NoSuchKey)?;
        if root.alg != Alg::Ed25519 {
            return Err(KmsError::AlgUnavailable);
        }
        // New keypair → bump version → retain vk for verify
        let sk = Self::gen_signing_key();
        let vk = VerifyingKey::from(&sk);

        root.current_version = root.current_version.saturating_add(1);
        // Compare without truncation: convert len → u32 (Option) and compare to checked_sub(1).
        debug_assert_eq!(
            u32::try_from(root.vks.len()).ok(),
            root.current_version.checked_sub(1)
        );
        root.vks.push(vk);
        root.sk = sk;
        root.vk = vk;

        let mut new = kid.clone();
        new.version = root.current_version;
        Ok(new)
    }

    fn alg(&self, kid: &KeyId) -> Result<Alg, KmsError> {
        let root_id = Self::root_id(&kid.tenant, &kid.purpose, kid.alg, kid.uuid);
        let st = self.0.read();
        let root = st.roots.get(&root_id).ok_or(KmsError::NoSuchKey)?;
        Ok(root.alg)
    }

    fn meta(&self, kid: &KeyId) -> Result<KeyMeta, KmsError> {
        let root_id = Self::root_id(&kid.tenant, &kid.purpose, kid.alg, kid.uuid);
        let st = self.0.read();
        let root = st.roots.get(&root_id).ok_or(KmsError::NoSuchKey)?;
        // Versions are 1..=current_version by invariant.
        let versions: Vec<u32> = (1..=root.current_version).collect();
        Ok(KeyMeta {
            alg: root.alg,
            current_version: root.current_version,
            versions,
            created_ms: root.created_ms,
        })
    }
}

impl Signer for MemoryKeystore {
    fn sign(&self, kid: &KeyId, msg: &[u8]) -> Result<Vec<u8>, KmsError> {
        if kid.alg != Alg::Ed25519 {
            return Err(KmsError::AlgUnavailable);
        }
        let root_id = Self::root_id(&kid.tenant, &kid.purpose, kid.alg, kid.uuid);
        let st = self.0.read();
        let root = st.roots.get(&root_id).ok_or(KmsError::NoSuchKey)?;

        // Only the latest version is allowed to sign.
        if kid.version != root.current_version {
            return Err(KmsError::Busy);
        }

        let sig: Signature = root.sk.sign(msg);
        Ok(sig.to_bytes().to_vec())
    }
}

impl Verifier for MemoryKeystore {
    fn verify(&self, kid: &KeyId, msg: &[u8], sig: &[u8]) -> Result<bool, KmsError> {
        if kid.alg != Alg::Ed25519 {
            return Err(KmsError::AlgUnavailable);
        }
        let root_id = Self::root_id(&kid.tenant, &kid.purpose, kid.alg, kid.uuid);
        let st = self.0.read();
        let root = st.roots.get(&root_id).ok_or(KmsError::NoSuchKey)?;

        let idx = kid.version.checked_sub(1).ok_or(KmsError::NoSuchKey)? as usize;
        let vk = root.vks.get(idx).ok_or(KmsError::NoSuchKey)?;
        let sig = ed25519_dalek::Signature::from_slice(sig).map_err(|_| KmsError::VerifyFailed)?;
        Ok(vk.verify_strict(msg, &sig).is_ok())
    }
}

impl PubkeyProvider for MemoryKeystore {
    fn verifying_key_bytes(&self, kid: &KeyId) -> Result<[u8; 32], KmsError> {
        if kid.alg != Alg::Ed25519 {
            return Err(KmsError::AlgUnavailable);
        }
        let root_id = Self::root_id(&kid.tenant, &kid.purpose, kid.alg, kid.uuid);
        let st = self.0.read();
        let root = st.roots.get(&root_id).ok_or(KmsError::NoSuchKey)?;
        let idx = kid.version.checked_sub(1).ok_or(KmsError::NoSuchKey)? as usize;
        let vk = root.vks.get(idx).ok_or(KmsError::NoSuchKey)?;
        Ok(vk.to_bytes())
    }
}

```

### crates/ron-kms/src/backends/mod.rs
<a id="crates-ron-kms-src-backends-mod-rs"></a>

```rust
//! Backend selection and re-exports.
//! Default: dalek (pure Rust). Optional: ring via `fast` feature.

#![allow(clippy::module_name_repetitions)]

#[cfg(not(feature = "fast"))]
pub mod dalek;
#[cfg(not(feature = "fast"))]
pub use crate::backends::dalek::{
    ed25519_generate, ed25519_sign, ed25519_verify, ed25519_verify_batch,
};

#[cfg(feature = "fast")]
pub mod fast_ring;
#[cfg(feature = "fast")]
pub use crate::backends::fast_ring::{
    ed25519_generate, ed25519_sign, ed25519_verify, ed25519_verify_batch,
};

pub mod memory;
pub use memory::MemoryKeystore;

/// Stable adapter so benches/tests can `use ron_kms::backends::ed25519`.
/// It forwards to the currently selected backend (dalek or ring).
pub mod ed25519 {
    /// Generate a new Ed25519 keypair, returning (`public_key_bytes`, `secret_key_bytes`).
    #[must_use]
    pub fn generate() -> ([u8; 32], [u8; 32]) {
        super::ed25519_generate()
    }
    /// Sign `msg` using a 32-byte Ed25519 secret key (seed). Returns a 64-byte signature.
    #[must_use]
    pub fn sign(secret_seed: &[u8; 32], msg: &[u8]) -> [u8; 64] {
        super::ed25519_sign(secret_seed, msg)
    }
    /// Verify a 64-byte signature against a 32-byte public key.
    #[must_use]
    pub fn verify(pk_bytes: &[u8; 32], msg: &[u8], sig_bytes: &[u8; 64]) -> bool {
        super::ed25519_verify(pk_bytes, msg, sig_bytes)
    }
    /// Batch verify N signatures. `pks.len() == msgs.len() == sigs.len()`.
    #[must_use]
    pub fn verify_batch(pks: &[[u8; 32]], msgs: &[&[u8]], sigs: &[[u8; 64]]) -> bool {
        super::ed25519_verify_batch(pks, msgs, sigs)
    }
}

```

### crates/ron-kms/src/backends/pkcs11.rs
<a id="crates-ron-kms-src-backends-pkcs11-rs"></a>

```rust
// PKCS#11 backend scaffold (feature-gated in real impl)

```

### crates/ron-kms/src/config.rs
<a id="crates-ron-kms-src-config-rs"></a>

```rust
// Config scaffold (no IO yet)
pub struct KmsConfig;
impl KmsConfig {
    pub fn load() -> Self { Self }
}

```

### crates/ron-kms/src/error.rs
<a id="crates-ron-kms-src-error-rs"></a>

```rust
use thiserror::Error;

#[derive(Debug, Error)]
pub enum KmsError {
    #[error("no such key")]
    NoSuchKey,
    #[error("algorithm unavailable in this build")]
    AlgUnavailable,
    #[error("key expired or not valid for use")]
    Expired,
    #[error("entropy/rng error")]
    Entropy,
    #[error("verification failed")]
    VerifyFailed,
    #[error("capability required")]
    CapabilityMissing,
    #[error("rotation in progress; try again")]
    Busy,
    #[error("internal error: {0}")]
    Internal(&'static str),
}

impl KmsError {
    #[must_use]
    pub fn kind(&self) -> &'static str {
        match self {
            KmsError::NoSuchKey => "NoSuchKey",
            KmsError::AlgUnavailable => "AlgUnavailable",
            KmsError::Expired => "Expired",
            KmsError::Entropy => "Entropy",
            KmsError::VerifyFailed => "VerifyFailed",
            KmsError::CapabilityMissing => "CapabilityMissing",
            KmsError::Busy => "Busy",
            KmsError::Internal(_) => "Internal",
        }
    }
}

```

### crates/ron-kms/src/lib.rs
<a id="crates-ron-kms-src-lib-rs"></a>

```rust
#![forbid(unsafe_code)]
#![deny(rust_2018_idioms, clippy::all, clippy::pedantic)]
#![allow(clippy::missing_errors_doc, clippy::module_name_repetitions)]

pub mod backends;
pub mod error;
pub mod ops;
pub mod traits;
pub mod types;
pub mod util;

#[cfg(feature = "with-metrics")]
pub mod metrics;
#[cfg(feature = "with-metrics")]
mod telemetry;

pub mod prelude;

pub use crate::error::KmsError;
pub use crate::traits::{Keystore, Signer, Verifier};
pub use crate::types::{Alg, KeyId};

#[must_use]
pub fn memory_keystore() -> backends::memory::MemoryKeystore {
    backends::memory::MemoryKeystore::default()
}

```

### crates/ron-kms/src/metrics.rs
<a id="crates-ron-kms-src-metrics-rs"></a>

```rust
//! RO:WHAT  Prometheus metrics for ron-kms.
//! RO:INV   Small, stable label sets to avoid cardinality explosions.

#![cfg(feature = "with-metrics")]

use prometheus::{opts, register_histogram, register_int_counter_vec, Histogram, IntCounterVec};

pub struct KmsMetrics {
    /// Operation counts, labeled by operation and algorithm.
    /// op ∈ {create,rotate,sign,verify,attest}
    /// alg ∈ {"ed25519", ...}
    pub ops_total: IntCounterVec,

    /// Failure counts, labeled by operation and error kind.
    /// op ∈ {create,rotate,sign,verify,attest}
    /// kind ∈ {"NoSuchKey","AlgUnavailable","Expired","Entropy","VerifyFailed","CapabilityMissing","Busy","Internal"}
    pub failures_total: IntCounterVec,

    /// Latency histogram (seconds) across ops.
    pub op_latency_seconds: Histogram,
}

impl KmsMetrics {
    /// Registers all metrics in the default Prometheus registry.
    #[must_use]
    pub fn register() -> Self {
        let ops_total = register_int_counter_vec!(
            opts!(
                "kms_ops_total",
                "Total successful KMS operations by type and algorithm"
            ),
            &["op", "alg"]
        )
        .expect("register kms_ops_total");

        let failures_total = register_int_counter_vec!(
            opts!(
                "kms_failures_total",
                "Total failed KMS operations by type and error kind"
            ),
            &["op", "kind"]
        )
        .expect("register kms_failures_total");

        // Buckets: generic powers-of-two-ish, adequate for dev; refine later if needed.
        let op_latency_seconds = register_histogram!(
            "kms_op_latency_seconds",
            "Latency of KMS operations in seconds"
        )
        .expect("register kms_op_latency_seconds");

        Self {
            ops_total,
            failures_total,
            op_latency_seconds,
        }
    }
}

```

### crates/ron-kms/src/ops/attest.rs
<a id="crates-ron-kms-src-ops-attest-rs"></a>

```rust
use crate::{
    error::KmsError,
    traits::Keystore,
    types::{KeyId, KeyMeta},
};
#[cfg(feature = "with-metrics")]
use {crate::telemetry, std::time::Instant};

pub fn attest<K: Keystore>(ks: &K, kid: &KeyId) -> Result<KeyMeta, KmsError> {
    #[cfg(feature = "with-metrics")]
    let start = Instant::now();

    let res = ks.meta(kid);

    #[cfg(feature = "with-metrics")]
    {
        let m = telemetry::metrics();
        match &res {
            Ok(meta) => {
                m.ops_total
                    .with_label_values(&["attest", meta.alg.as_str()])
                    .inc();
                m.op_latency_seconds.observe(start.elapsed().as_secs_f64());
            }
            Err(e) => {
                m.failures_total
                    .with_label_values(&["attest", e.kind()])
                    .inc();
                m.op_latency_seconds.observe(start.elapsed().as_secs_f64());
            }
        }
    }
    res
}

```

### crates/ron-kms/src/ops/create.rs
<a id="crates-ron-kms-src-ops-create-rs"></a>

```rust
use crate::{error::KmsError, traits::Keystore, types::KeyId};
#[cfg(feature = "with-metrics")]
use {crate::telemetry, std::time::Instant};

pub fn ed25519<K: Keystore>(ks: &K, tenant: &str, purpose: &str) -> Result<KeyId, KmsError> {
    #[cfg(feature = "with-metrics")]
    let start = Instant::now();

    let res = ks.create_ed25519(tenant, purpose);

    #[cfg(feature = "with-metrics")]
    {
        let m = telemetry::metrics();
        match &res {
            Ok(kid) => {
                m.ops_total
                    .with_label_values(&["create", kid.alg.as_str()])
                    .inc();
                m.op_latency_seconds.observe(start.elapsed().as_secs_f64());
            }
            Err(e) => {
                m.failures_total
                    .with_label_values(&["create", e.kind()])
                    .inc();
                m.op_latency_seconds.observe(start.elapsed().as_secs_f64());
            }
        }
    }
    res
}

```

### crates/ron-kms/src/ops/mod.rs
<a id="crates-ron-kms-src-ops-mod-rs"></a>

```rust
pub mod attest;
pub mod create;
pub mod rotate;
pub mod sign;
pub mod verify;
pub mod verify_batch;

```

### crates/ron-kms/src/ops/rotate.rs
<a id="crates-ron-kms-src-ops-rotate-rs"></a>

```rust
use crate::{error::KmsError, traits::Keystore, types::KeyId};
#[cfg(feature = "with-metrics")]
use {crate::telemetry, std::time::Instant};

pub fn rotate<K: Keystore>(ks: &K, kid: &KeyId) -> Result<KeyId, KmsError> {
    #[cfg(feature = "with-metrics")]
    let start = Instant::now();

    let res = ks.rotate(kid);

    #[cfg(feature = "with-metrics")]
    {
        let m = telemetry::metrics();
        match &res {
            Ok(new_kid) => {
                m.ops_total
                    .with_label_values(&["rotate", new_kid.alg.as_str()])
                    .inc();
                m.op_latency_seconds.observe(start.elapsed().as_secs_f64());
            }
            Err(e) => {
                m.failures_total
                    .with_label_values(&["rotate", e.kind()])
                    .inc();
                m.op_latency_seconds.observe(start.elapsed().as_secs_f64());
            }
        }
    }
    res
}

```

### crates/ron-kms/src/ops/sign.rs
<a id="crates-ron-kms-src-ops-sign-rs"></a>

```rust
use crate::{error::KmsError, traits::Signer, types::KeyId};
#[cfg(feature = "with-metrics")]
use {crate::telemetry, std::time::Instant};

pub fn sign<K: Signer>(ks: &K, kid: &KeyId, msg: &[u8]) -> Result<Vec<u8>, KmsError> {
    #[cfg(feature = "with-metrics")]
    let start = Instant::now();

    let res = ks.sign(kid, msg);

    #[cfg(feature = "with-metrics")]
    {
        let m = telemetry::metrics();
        match &res {
            Ok(_) => {
                m.ops_total
                    .with_label_values(&["sign", kid.alg.as_str()])
                    .inc();
                m.op_latency_seconds.observe(start.elapsed().as_secs_f64());
            }
            Err(e) => {
                m.failures_total
                    .with_label_values(&["sign", e.kind()])
                    .inc();
                m.op_latency_seconds.observe(start.elapsed().as_secs_f64());
            }
        }
    }
    res
}

```

### crates/ron-kms/src/ops/unwrap.rs
<a id="crates-ron-kms-src-ops-unwrap-rs"></a>

```rust
// unwrap op scaffold

```

### crates/ron-kms/src/ops/verify.rs
<a id="crates-ron-kms-src-ops-verify-rs"></a>

```rust
use crate::{error::KmsError, traits::Verifier, types::KeyId};
#[cfg(feature = "with-metrics")]
use {crate::telemetry, std::time::Instant};

pub fn verify<K: Verifier>(ks: &K, kid: &KeyId, msg: &[u8], sig: &[u8]) -> Result<bool, KmsError> {
    #[cfg(feature = "with-metrics")]
    let start = Instant::now();

    let res = ks.verify(kid, msg, sig);

    #[cfg(feature = "with-metrics")]
    {
        let m = telemetry::metrics();
        match &res {
            Ok(_) => {
                m.ops_total
                    .with_label_values(&["verify", kid.alg.as_str()])
                    .inc();
                m.op_latency_seconds.observe(start.elapsed().as_secs_f64());
            }
            Err(e) => {
                m.failures_total
                    .with_label_values(&["verify", e.kind()])
                    .inc();
                m.op_latency_seconds.observe(start.elapsed().as_secs_f64());
            }
        }
    }
    res
}

```

### crates/ron-kms/src/ops/verify_batch.rs
<a id="crates-ron-kms-src-ops-verifybatch-rs"></a>

```rust
//! RO:WHAT  Batch verification with a fast all-or-nothing path using dalek's batch API,
//!          and a per-item fallback to produce precise booleans when a batch contains failures.
//! RO:WHY   Batch verify amortizes expensive scalar multiplications; this is our “God tier” lever.
//! RO:INV   - All items must share `Alg::Ed25519` for fast path.
//!          - If the batch fails as a whole, we fall back to per-item verify to return Vec<bool>.

use crate::{
    error::KmsError,
    traits::pubkey::PubkeyProvider,
    traits::Verifier,
    types::{Alg, KeyId},
};

/// One item to verify in a batch.
pub struct VerifyItem<'m, 's> {
    pub kid: &'m KeyId,
    pub msg: &'m [u8],
    pub sig: &'s [u8],
}

/// Verify a batch of (kid, msg, sig). Returns per-item booleans.
///
/// Fast path (all Ed25519, all pass): single dalek batch verify → Vec<true>.
/// If the batch fails, we fall back to per-item verify for correctness.
/// For mixed algorithms, we chunk by alg (currently only Ed25519 supported).
pub fn verify_batch<K>(kms: &K, items: &[VerifyItem<'_, '_>]) -> Result<Vec<bool>, KmsError>
where
    K: Verifier + PubkeyProvider,
{
    if items.is_empty() {
        return Ok(Vec::new());
    }

    // Verify all items are Ed25519 (current supported fast path).
    let all_ed25519 = items.iter().all(|it| it.kid.alg == Alg::Ed25519);
    if !all_ed25519 {
        // Fallback: per-item verify for any non-Ed25519.
        return items
            .iter()
            .map(|it| kms.verify(it.kid, it.msg, it.sig))
            .collect();
    }

    // Collect publics, messages, signatures for dalek batch.
    let mut msgs: Vec<&[u8]> = Vec::with_capacity(items.len());
    let mut sigs: Vec<ed25519_dalek::Signature> = Vec::with_capacity(items.len());
    let mut pubs: Vec<ed25519_dalek::VerifyingKey> = Vec::with_capacity(items.len());

    for it in items {
        let pk_bytes: [u8; 32] = kms.verifying_key_bytes(it.kid)?;
        let vk = ed25519_dalek::VerifyingKey::from_bytes(&pk_bytes)
            .map_err(|_| KmsError::VerifyFailed)?;
        let sig =
            ed25519_dalek::Signature::from_slice(it.sig).map_err(|_| KmsError::VerifyFailed)?;

        pubs.push(vk);
        sigs.push(sig);
        msgs.push(it.msg);
    }

    // Fast all-or-nothing batch verify (requires ed25519-dalek "batch" feature).
    let batch_ok = ed25519_dalek::verify_batch(&msgs, &sigs, &pubs).is_ok();
    if batch_ok {
        return Ok(vec![true; items.len()]);
    }

    // Fallback: precise booleans per item.
    items
        .iter()
        .map(|it| kms.verify(it.kid, it.msg, it.sig))
        .collect()
}

```

### crates/ron-kms/src/ops/wrap.rs
<a id="crates-ron-kms-src-ops-wrap-rs"></a>

```rust
// wrap op scaffold

```

### crates/ron-kms/src/pq/mldsa.rs
<a id="crates-ron-kms-src-pq-mldsa-rs"></a>

```rust
// ML-DSA scaffold (feature: mldsa)

```

### crates/ron-kms/src/pq/mlkem.rs
<a id="crates-ron-kms-src-pq-mlkem-rs"></a>

```rust
// ML-KEM scaffold (feature: mlkem)

```

### crates/ron-kms/src/pq/mod.rs
<a id="crates-ron-kms-src-pq-mod-rs"></a>

```rust
// PQ adapters scaffold
pub mod mlkem;
pub mod mldsa;
pub mod slhdsa;

```

### crates/ron-kms/src/pq/slhdsa.rs
<a id="crates-ron-kms-src-pq-slhdsa-rs"></a>

```rust
// SLH-DSA scaffold (feature: slhdsa)

```

### crates/ron-kms/src/prelude.rs
<a id="crates-ron-kms-src-prelude-rs"></a>

```rust
// Tiny prelude for callers.
pub use crate::{
    error::KmsError,
    traits::{Keystore, Signer, Verifier},
    types::{Alg, KeyId},
};

```

### crates/ron-kms/src/sealed/aead.rs
<a id="crates-ron-kms-src-sealed-aead-rs"></a>

```rust
// AEAD scaffold (no crypto)

```

### crates/ron-kms/src/sealed/anti_rollback.rs
<a id="crates-ron-kms-src-sealed-antirollback-rs"></a>

```rust
// Anti-rollback scaffold

```

### crates/ron-kms/src/sealed/header.rs
<a id="crates-ron-kms-src-sealed-header-rs"></a>

```rust
// Sealed header scaffold
#[allow(dead_code)]
pub struct SealedHeader {
    pub version: u8,
}

```

### crates/ron-kms/src/sealed/mod.rs
<a id="crates-ron-kms-src-sealed-mod-rs"></a>

```rust
// Sealed primitives scaffold
pub mod header;
pub mod aead;
pub mod anti_rollback;
pub mod store;

```

### crates/ron-kms/src/sealed/store.rs
<a id="crates-ron-kms-src-sealed-store-rs"></a>

```rust
// Sealed store trait scaffold
use crate::error::KmResult;

pub trait SealedStore {
    fn put(&self, _blob: &[u8]) -> KmResult<()>;
}

```

### crates/ron-kms/src/telemetry.rs
<a id="crates-ron-kms-src-telemetry-rs"></a>

```rust
//! RO:WHAT  Lazy, single global access to KMS Prometheus metrics.
//! RO:WHY   Avoid passing metrics handles everywhere; keep it opt-in via the `with-metrics` feature.

#![cfg(feature = "with-metrics")]

use crate::metrics::KmsMetrics;
use once_cell::sync::OnceCell;

static METRICS: OnceCell<KmsMetrics> = OnceCell::new();

/// Get the process-global metrics set (registers on first use).
#[must_use]
pub fn metrics() -> &'static KmsMetrics {
    METRICS.get_or_init(KmsMetrics::register)
}

```

### crates/ron-kms/src/traits/hybrid.rs
<a id="crates-ron-kms-src-traits-hybrid-rs"></a>

```rust
// Hybrid trait scaffold
use crate::error::KmResult;

pub trait Hybrid {
    fn wrap(&self, _pt: &[u8]) -> KmResult<Vec<u8>>;
    fn unwrap_(&self, _ct: &[u8]) -> KmResult<Vec<u8>>;
}

```

### crates/ron-kms/src/traits/kem.rs
<a id="crates-ron-kms-src-traits-kem-rs"></a>

```rust
// KEM trait scaffold
use crate::error::KmResult;

pub trait Kem {
    fn encap(&self, _peer_pub: &[u8]) -> KmResult<(Vec<u8>, Vec<u8>)>;
    fn decap(&self, _ct: &[u8]) -> KmResult<Vec<u8>>;
}

```

### crates/ron-kms/src/traits/keystore.rs
<a id="crates-ron-kms-src-traits-keystore-rs"></a>

```rust
use crate::{
    error::KmsError,
    types::{Alg, KeyId, KeyMeta},
};

/// Custody lifecycle — create/rotate/get metadata/attest (subset for core boot).
pub trait Keystore: Send + Sync {
    fn create_ed25519(&self, tenant: &str, purpose: &str) -> Result<KeyId, KmsError>;
    fn rotate(&self, kid: &KeyId) -> Result<KeyId, KmsError>;
    fn alg(&self, kid: &KeyId) -> Result<Alg, KmsError>;
    /// Public metadata about a key root.
    fn meta(&self, kid: &KeyId) -> Result<KeyMeta, KmsError>;
}

```

### crates/ron-kms/src/traits/mod.rs
<a id="crates-ron-kms-src-traits-mod-rs"></a>

```rust
//! KMS trait surfaces

pub mod keystore;
pub mod signer;
pub mod verifier;

// Internal-only helper for batch verify fast path.
pub(crate) mod pubkey;

pub use keystore::Keystore;
pub use signer::Signer;
pub use verifier::Verifier;

```

### crates/ron-kms/src/traits/pubkey.rs
<a id="crates-ron-kms-src-traits-pubkey-rs"></a>

```rust
//! RO:WHAT  Internal trait to expose verifying keys for batch verify fast paths.
//! RO:WHY   Our public Verifier trait only exposes boolean checks; batch verify
//!          needs access to the raw verifying keys to use dalek's batch API.

use crate::{error::KmsError, types::KeyId};

/// Internal-only surface to fetch verifying key bytes for a given `KeyId` version.
/// Implemented by in-crate backends (memory, file, pkcs11) as needed.
pub trait PubkeyProvider {
    /// Returns the raw verifying key bytes (Ed25519, 32 bytes) for this `KeyId`/version.
    fn verifying_key_bytes(&self, kid: &KeyId) -> Result<[u8; 32], KmsError>;
}

```

### crates/ron-kms/src/traits/signer.rs
<a id="crates-ron-kms-src-traits-signer-rs"></a>

```rust
use crate::{error::KmsError, types::KeyId};

pub trait Signer: Send + Sync {
    /// Sign message bytes with the private key designated by `kid`.
    fn sign(&self, kid: &KeyId, msg: &[u8]) -> Result<Vec<u8>, KmsError>;
}

```

### crates/ron-kms/src/traits/verifier.rs
<a id="crates-ron-kms-src-traits-verifier-rs"></a>

```rust
use crate::{error::KmsError, types::KeyId};

pub trait Verifier: Send + Sync {
    /// Verify the signature for `msg` under `kid`'s public key.
    fn verify(&self, kid: &KeyId, msg: &[u8], sig: &[u8]) -> Result<bool, KmsError>;
}

```

### crates/ron-kms/src/types.rs
<a id="crates-ron-kms-src-types-rs"></a>

```rust
use serde::{Deserialize, Serialize};
use std::{fmt, str::FromStr};
use time::OffsetDateTime;
use uuid::Uuid;

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum Alg {
    Ed25519,
    // Future: MlDsa, SlhDsa, X25519, MlKem...
}

impl Alg {
    #[must_use]
    pub const fn as_str(self) -> &'static str {
        match self {
            Alg::Ed25519 => "ed25519",
        }
    }
}

impl fmt::Display for Alg {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Alg::Ed25519 => write!(f, "Ed25519"),
        }
    }
}

impl FromStr for Alg {
    type Err = &'static str;
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s {
            "Ed25519" | "ed25519" => Ok(Self::Ed25519),
            _ => Err("unknown alg"),
        }
    }
}

/// Versioned key identifier: `<tenant>/<purpose>/<alg>/<uuid>#vN`
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct KeyId {
    pub tenant: String,
    pub purpose: String,
    pub alg: Alg,
    pub uuid: Uuid,
    pub version: u32,
}

impl KeyId {
    #[must_use]
    pub fn new(tenant: impl Into<String>, purpose: impl Into<String>, alg: Alg) -> Self {
        Self {
            tenant: tenant.into(),
            purpose: purpose.into(),
            alg,
            uuid: Uuid::new_v4(),
            version: 1,
        }
    }

    #[must_use]
    pub fn bump(&self) -> Self {
        let mut k = self.clone();
        k.version += 1;
        k
    }

    #[must_use]
    pub fn now_utc_ms() -> i128 {
        OffsetDateTime::now_utc().unix_timestamp_nanos() / 1_000_000
    }
}

impl fmt::Display for KeyId {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(
            f,
            "{}/{}/{}/{}#v{}",
            self.tenant, self.purpose, self.alg, self.uuid, self.version
        )
    }
}

impl FromStr for KeyId {
    type Err = &'static str;
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        let (left, vpart) = s.rsplit_once("#v").ok_or("missing version")?;
        let version: u32 = vpart.parse().map_err(|_| "bad version")?;
        let mut it = left.split('/');
        let tenant = it.next().ok_or("missing tenant")?;
        let purpose = it.next().ok_or("missing purpose")?;
        let alg = it.next().ok_or("missing alg")?.parse().map_err(|_| "alg")?;
        let uuid_s = it.next().ok_or("missing uuid")?;
        if it.next().is_some() {
            return Err("too many parts");
        }
        let uuid = uuid::Uuid::parse_str(uuid_s).map_err(|_| "uuid")?;
        Ok(Self {
            tenant: tenant.to_string(),
            purpose: purpose.to_string(),
            alg,
            uuid,
            version,
        })
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct KeyMeta {
    pub alg: Alg,
    pub current_version: u32,
    pub versions: Vec<u32>,
    pub created_ms: i128,
}

```

### crates/ron-kms/src/util/ct.rs
<a id="crates-ron-kms-src-util-ct-rs"></a>

```rust
// RO:WHAT Constant-time helpers (tiny, just equality for now).
#[must_use]
pub fn ct_eq(a: &[u8], b: &[u8]) -> bool {
    if a.len() != b.len() {
        return false;
    }
    let mut acc = 0u8;
    for (&x, &y) in a.iter().zip(b.iter()) {
        acc |= x ^ y;
    }
    acc == 0
}

```

### crates/ron-kms/src/util/mod.rs
<a id="crates-ron-kms-src-util-mod-rs"></a>

```rust
// Module glue for util/ submodules.
pub mod ct;
pub mod time;
pub mod zeroize;

pub use ct::*;
pub use time::*;
pub use zeroize::*;

```

### crates/ron-kms/src/util/time.rs
<a id="crates-ron-kms-src-util-time-rs"></a>

```rust
use time::OffsetDateTime;

#[must_use]
pub fn now_utc_ms() -> i128 {
    OffsetDateTime::now_utc().unix_timestamp_nanos() / 1_000_000
}

```

### crates/ron-kms/src/util/zeroize.rs
<a id="crates-ron-kms-src-util-zeroize-rs"></a>

```rust
// RO:WHAT Helpers to wipe secrets explicitly when using Vec/Box.
use zeroize::Zeroize;

pub fn wipe_vec(v: &mut Vec<u8>) {
    v.zeroize();
}

```

### crates/ron-kms/telemetry.rs
<a id="crates-ron-kms-telemetry-rs"></a>

```rust
#![cfg(feature = "with-metrics")]

use once_cell::sync::OnceCell;
use crate::metrics::KmsMetrics;

static METRICS: OnceCell<KmsMetrics> = OnceCell::new();

#[must_use]
pub fn metrics() -> &'static KmsMetrics {
    METRICS.get_or_init(KmsMetrics::register)
}

```

### crates/ron-kms/testing/kms-dev-server/Cargo.toml
<a id="crates-ron-kms-testing-kms-dev-server-Cargo-toml"></a>

```toml
[package]
name = "kms-dev-server"
version = "0.0.0"
edition = "2021"
publish = false

[dependencies]
# Intentionally empty; fill when building the dev server harness.

```

### crates/ron-kms/testing/kms-dev-server/src/main.rs
<a id="crates-ron-kms-testing-kms-dev-server-src-main-rs"></a>

```rust
// Dev server harness scaffold (keep separate from library)
fn main() {
    println!("kms-dev-server scaffold (no HTTP yet)");
}

```

### crates/ron-kms/tests/attest.rs
<a id="crates-ron-kms-tests-attest-rs"></a>

```rust
use ron_kms::ops::attest::attest;
use ron_kms::{memory_keystore, Keystore}; // <-- import the function, not the module

#[test]
fn attest_reports_versions_and_current() {
    let kms = memory_keystore();
    let kid_v1 = kms.create_ed25519("auth", "signing").expect("create");

    let meta1 = attest(&kms, &kid_v1).expect("attest v1");
    assert_eq!(meta1.current_version, 1);
    assert_eq!(meta1.versions, vec![1]);
    assert!(meta1.created_ms > 0);

    let kid_v2 = kms.rotate(&kid_v1).expect("rotate");
    let meta2 = attest(&kms, &kid_v2).expect("attest v2");
    assert_eq!(meta2.current_version, 2);
    assert_eq!(meta2.versions, vec![1, 2]);
    assert_eq!(meta2.created_ms, meta1.created_ms);
}

```

### crates/ron-kms/tests/interop_kats.rs
<a id="crates-ron-kms-tests-interopkats-rs"></a>

```rust
// interop KATs scaffold

```

### crates/ron-kms/tests/keyid_and_roundtrip.rs
<a id="crates-ron-kms-tests-keyidandroundtrip-rs"></a>

```rust
use ron_kms::{memory_keystore, Alg, KeyId, Keystore, Signer, Verifier};
use std::str::FromStr;

#[test]
fn keyid_format_parse_roundtrip() {
    let kid = KeyId::new("tenantA", "purposeX", Alg::Ed25519);
    let s = kid.to_string();
    let parsed = KeyId::from_str(&s).expect("parse");
    assert_eq!(kid.tenant, parsed.tenant);
    assert_eq!(kid.purpose, parsed.purpose);
    assert_eq!(kid.alg, parsed.alg);
    assert_eq!(kid.uuid, parsed.uuid);
    assert_eq!(kid.version, parsed.version);
}

#[test]
fn sign_verify_roundtrip() {
    let kms = memory_keystore();
    let kid = kms.create_ed25519("auth", "signing").expect("create");
    let msg = b"roundtrip";
    let sig = kms.sign(&kid, msg).expect("sign");
    let ok = kms.verify(&kid, msg, &sig).expect("verify");
    assert!(ok);
}

#[test]
fn rotate_bumps_version_and_still_works() {
    let kms = memory_keystore();
    let kid_v1 = kms.create_ed25519("auth", "signing").expect("create");

    // v1 sign/verify
    let msg1 = b"before rotate";
    let sig1 = kms.sign(&kid_v1, msg1).expect("sign v1");
    assert!(kms.verify(&kid_v1, msg1, &sig1).expect("verify v1"));

    // rotate → v2
    let kid_v2 = kms.rotate(&kid_v1).expect("rotate");
    assert_eq!(kid_v2.version, kid_v1.version + 1);

    // v2 sign/verify
    let msg2 = b"after rotate";
    let sig2 = kms.sign(&kid_v2, msg2).expect("sign v2");
    assert!(kms.verify(&kid_v2, msg2, &sig2).expect("verify v2"));

    // NOTE: In the current dev backend, rotating replaces the stored public key.
    // Old signatures are not guaranteed to verify after rotation (by design here).
}

```

### crates/ron-kms/tests/unit/attest_test.rs
<a id="crates-ron-kms-tests-unit-attesttest-rs"></a>

```rust
// scaffold test placeholder

```

### crates/ron-kms/tests/unit/rotate_test.rs
<a id="crates-ron-kms-tests-unit-rotatetest-rs"></a>

```rust
// scaffold test placeholder

```

### crates/ron-kms/tests/unit/sealed_header_test.rs
<a id="crates-ron-kms-tests-unit-sealedheadertest-rs"></a>

```rust
// scaffold test placeholder

```

### crates/ron-kms/tests/unit/zeroize_test.rs
<a id="crates-ron-kms-tests-unit-zeroizetest-rs"></a>

```rust
// scaffold test placeholder

```

### crates/ron-kms/tests/versioned_verify.rs
<a id="crates-ron-kms-tests-versionedverify-rs"></a>

```rust
use ron_kms::{memory_keystore, Keystore, Signer, Verifier};

#[test]
fn old_signatures_verify_after_rotate() {
    let kms = memory_keystore();

    // Create v1 and sign a message.
    let kid_v1 = kms.create_ed25519("auth", "signing").expect("create");
    let msg_v1 = b"old message";
    let sig_v1 = kms.sign(&kid_v1, msg_v1).expect("sign v1");
    assert!(kms.verify(&kid_v1, msg_v1, &sig_v1).expect("verify v1"));

    // Rotate to v2.
    let kid_v2 = kms.rotate(&kid_v1).expect("rotate");
    assert_eq!(kid_v2.version, kid_v1.version + 1);

    // Old v1 signature should still verify using the v1 KeyId.
    assert!(kms
        .verify(&kid_v1, msg_v1, &sig_v1)
        .expect("verify v1 after rotate"));

    // New v2 signing works; verifying with v2 KeyId works.
    let msg_v2 = b"new message";
    let sig_v2 = kms.sign(&kid_v2, msg_v2).expect("sign v2");
    assert!(kms.verify(&kid_v2, msg_v2, &sig_v2).expect("verify v2"));

    // Attempting to sign with stale v1 should fail (only latest may sign).
    let stale_sign = kms.sign(&kid_v1, b"should fail");
    assert!(stale_sign.is_err(), "stale KeyId should not sign");
}

```

### crates/ron-kms/xtask/src/main.rs
<a id="crates-ron-kms-xtask-src-main-rs"></a>

```rust
// xtask scaffold (placeholder CLI)
fn main() {
    println!("xtask: ron-kms2 scaffold");
}

```



---



# svc-passport

_Source: crates/svc-passport/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-11-08T15:20:29Z -->
# Code Bundle — `svc-passport`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/svc-passport/.github/workflows/ci.yml](#crates-svc-passport--github-workflows-ci-yml)
- [crates/svc-passport/.github/workflows/obs.yml](#crates-svc-passport--github-workflows-obs-yml)
- [crates/svc-passport/.github/workflows/render-mermaid.yml](#crates-svc-passport--github-workflows-render-mermaid-yml)
- [crates/svc-passport/Cargo.toml](#crates-svc-passport-Cargo-toml)
- [crates/svc-passport/benches/issue_bench.rs](#crates-svc-passport-benches-issuebench-rs)
- [crates/svc-passport/benches/verify.rs](#crates-svc-passport-benches-verify-rs)
- [crates/svc-passport/config/default.toml](#crates-svc-passport-config-default-toml)
- [crates/svc-passport/docker/docker-compose.yml](#crates-svc-passport-docker-docker-compose-yml)
- [crates/svc-passport/examples/issue_cli.rs](#crates-svc-passport-examples-issuecli-rs)
- [crates/svc-passport/fuzz/fuzz_targets/caveat_mutation.rs](#crates-svc-passport-fuzz-fuzztargets-caveatmutation-rs)
- [crates/svc-passport/fuzz/fuzz_targets/envelope_parse.rs](#crates-svc-passport-fuzz-fuzztargets-envelopeparse-rs)
- [crates/svc-passport/loom/rotation_loom.rs](#crates-svc-passport-loom-rotationloom-rs)
- [crates/svc-passport/rust-toolchain.toml](#crates-svc-passport-rust-toolchain-toml)
- [crates/svc-passport/scripts/inject_kms_latency.sh](#crates-svc-passport-scripts-injectkmslatency-sh)
- [crates/svc-passport/scripts/load_issue_profile.sh](#crates-svc-passport-scripts-loadissueprofile-sh)
- [crates/svc-passport/scripts/rotate_under_load.sh](#crates-svc-passport-scripts-rotateunderload-sh)
- [crates/svc-passport/scripts/smoke_passport.sh](#crates-svc-passport-scripts-smokepassport-sh)
- [crates/svc-passport/src/bootstrap.rs](#crates-svc-passport-src-bootstrap-rs)
- [crates/svc-passport/src/bus/mod.rs](#crates-svc-passport-src-bus-mod-rs)
- [crates/svc-passport/src/bus/rpc.rs](#crates-svc-passport-src-bus-rpc-rs)
- [crates/svc-passport/src/config.rs](#crates-svc-passport-src-config-rs)
- [crates/svc-passport/src/dto/issue.rs](#crates-svc-passport-src-dto-issue-rs)
- [crates/svc-passport/src/dto/mod.rs](#crates-svc-passport-src-dto-mod-rs)
- [crates/svc-passport/src/dto/revoke.rs](#crates-svc-passport-src-dto-revoke-rs)
- [crates/svc-passport/src/dto/verify.rs](#crates-svc-passport-src-dto-verify-rs)
- [crates/svc-passport/src/error.rs](#crates-svc-passport-src-error-rs)
- [crates/svc-passport/src/health.rs](#crates-svc-passport-src-health-rs)
- [crates/svc-passport/src/http/handlers/healthz.rs](#crates-svc-passport-src-http-handlers-healthz-rs)
- [crates/svc-passport/src/http/handlers/issue.rs](#crates-svc-passport-src-http-handlers-issue-rs)
- [crates/svc-passport/src/http/handlers/mod.rs](#crates-svc-passport-src-http-handlers-mod-rs)
- [crates/svc-passport/src/http/handlers/readyz.rs](#crates-svc-passport-src-http-handlers-readyz-rs)
- [crates/svc-passport/src/http/handlers/revoke.rs](#crates-svc-passport-src-http-handlers-revoke-rs)
- [crates/svc-passport/src/http/handlers/verify.rs](#crates-svc-passport-src-http-handlers-verify-rs)
- [crates/svc-passport/src/http/middleware.rs](#crates-svc-passport-src-http-middleware-rs)
- [crates/svc-passport/src/http/mod.rs](#crates-svc-passport-src-http-mod-rs)
- [crates/svc-passport/src/http/router.rs](#crates-svc-passport-src-http-router-rs)
- [crates/svc-passport/src/kms/client.rs](#crates-svc-passport-src-kms-client-rs)
- [crates/svc-passport/src/kms/keyslot.rs](#crates-svc-passport-src-kms-keyslot-rs)
- [crates/svc-passport/src/kms/mod.rs](#crates-svc-passport-src-kms-mod-rs)
- [crates/svc-passport/src/kms/rotation.rs](#crates-svc-passport-src-kms-rotation-rs)
- [crates/svc-passport/src/lib.rs](#crates-svc-passport-src-lib-rs)
- [crates/svc-passport/src/main.rs](#crates-svc-passport-src-main-rs)
- [crates/svc-passport/src/metrics.rs](#crates-svc-passport-src-metrics-rs)
- [crates/svc-passport/src/policy/eval.rs](#crates-svc-passport-src-policy-eval-rs)
- [crates/svc-passport/src/policy/mod.rs](#crates-svc-passport-src-policy-mod-rs)
- [crates/svc-passport/src/state/audit.rs](#crates-svc-passport-src-state-audit-rs)
- [crates/svc-passport/src/state/issuer.rs](#crates-svc-passport-src-state-issuer-rs)
- [crates/svc-passport/src/state/mod.rs](#crates-svc-passport-src-state-mod-rs)
- [crates/svc-passport/src/telemetry/mod.rs](#crates-svc-passport-src-telemetry-mod-rs)
- [crates/svc-passport/src/telemetry/prometheus.rs](#crates-svc-passport-src-telemetry-prometheus-rs)
- [crates/svc-passport/src/telemetry/tracing_init.rs](#crates-svc-passport-src-telemetry-tracinginit-rs)
- [crates/svc-passport/src/test_support.rs](#crates-svc-passport-src-testsupport-rs)
- [crates/svc-passport/src/token/attenuate.rs](#crates-svc-passport-src-token-attenuate-rs)
- [crates/svc-passport/src/token/caveat.rs](#crates-svc-passport-src-token-caveat-rs)
- [crates/svc-passport/src/token/encode.rs](#crates-svc-passport-src-token-encode-rs)
- [crates/svc-passport/src/token/macaroon.rs](#crates-svc-passport-src-token-macaroon-rs)
- [crates/svc-passport/src/token/mod.rs](#crates-svc-passport-src-token-mod-rs)
- [crates/svc-passport/src/util/hashing.rs](#crates-svc-passport-src-util-hashing-rs)
- [crates/svc-passport/src/util/id.rs](#crates-svc-passport-src-util-id-rs)
- [crates/svc-passport/src/util/mod.rs](#crates-svc-passport-src-util-mod-rs)
- [crates/svc-passport/src/util/time.rs](#crates-svc-passport-src-util-time-rs)
- [crates/svc-passport/src/verify/mod.rs](#crates-svc-passport-src-verify-mod-rs)
- [crates/svc-passport/src/verify/preflight.rs](#crates-svc-passport-src-verify-preflight-rs)
- [crates/svc-passport/testing/profiles/issue_80_20_local.json](#crates-svc-passport-testing-profiles-issue8020local-json)
- [crates/svc-passport/tests/api_issue.rs](#crates-svc-passport-tests-apiissue-rs)
- [crates/svc-passport/tests/api_revoke.rs](#crates-svc-passport-tests-apirevoke-rs)
- [crates/svc-passport/tests/api_verify.rs](#crates-svc-passport-tests-apiverify-rs)
- [crates/svc-passport/tests/handlers.rs](#crates-svc-passport-tests-handlers-rs)
- [crates/svc-passport/tests/invariants.rs](#crates-svc-passport-tests-invariants-rs)
- [crates/svc-passport/tests/issuer.rs](#crates-svc-passport-tests-issuer-rs)
- [crates/svc-passport/tests/readiness.rs](#crates-svc-passport-tests-readiness-rs)

### crates/svc-passport/.github/workflows/ci.yml
<a id="crates-svc-passport--github-workflows-ci-yml"></a>

```yaml
name: ci-scaffold
on: [push, pull_request]
jobs:
  noop:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "ci scaffold"

```

### crates/svc-passport/.github/workflows/obs.yml
<a id="crates-svc-passport--github-workflows-obs-yml"></a>

```yaml
name: obs-scaffold
on: [push, pull_request]
jobs:
  noop:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "obs scaffold"

```

### crates/svc-passport/.github/workflows/render-mermaid.yml
<a id="crates-svc-passport--github-workflows-render-mermaid-yml"></a>

```yaml
name: render-mermaid-scaffold
on: [push, pull_request]
jobs:
  noop:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "render scaffold"

```

### crates/svc-passport/Cargo.toml
<a id="crates-svc-passport-Cargo-toml"></a>

```toml
[package]
name = "svc-passport"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
publish = false

[lib]
name = "svc_passport"
path = "src/lib.rs"
bench = false          # avoid running the lib test harness as a bench

[[bin]]
name = "svc-passport"
path = "src/main.rs"

[features]
# Enable dev-kms by default so the crate runs out-of-the-box.
default = ["with-metrics", "dev-kms"]
dalek-batch = []
parallel-batch = []
with-metrics = []
bus-rpc = []
dev-kms = ["dep:ed25519-dalek", "dep:rand_core"]

[dependencies]
# RON workspace crates
ron-kernel = { path = "../ron-kernel" }
ron-policy = { path = "../ron-policy" }

# Async/HTTP stack (match workspace pins explicitly)
tokio = { workspace = true, features = ["macros","rt-multi-thread","signal","time","io-util","sync","net","fs"] }
axum  = { workspace = true, default-features = false, features = ["tokio","http1","http2","json"] }
# IMPORTANT: explicitly mirror workspace tower settings to avoid 0.4/0.5 splits
tower = { workspace = true, default-features = false, features = ["util","limit"] }
tower-http = { workspace = true, features = ["trace"] }
http  = { workspace = true }
# hyper/hyper-util local
hyper = { version = "1", features = ["http1","http2","server"] }
hyper-util = "0.1"

# Metrics/obs
prometheus = { workspace = true }
tracing = { workspace = true }
tracing-subscriber = { workspace = true, features = ["fmt","env-filter"] }

# Serde / JSON / config / time
serde      = { workspace = true, features = ["derive"] }
serde_json = { workspace = true }
toml       = { workspace = true }
time       = { version = "0.3", features = ["formatting","parsing","macros"] }
uuid       = { version = "1", features = ["v4"] }
base64     = "0.22"

# Concurrency / utils
parking_lot = { workspace = true }
once_cell   = { workspace = true }

# Errors
thiserror = { workspace = true }   # aligns to workspace (v1) to avoid dupes
anyhow    = { workspace = true }

# Async trait for dyn-safe async methods
async-trait = "0.1"

# Zeroization
zeroize = "1"

# Dev KMS (optional; enabled by dev-kms feature)
ed25519-dalek = { version = "2", features = ["rand_core","serde"], optional = true }
rand_core     = { version = "0.6", features = ["getrandom"], optional = true }

[dev-dependencies]
# HTTP client for any future integration tests (we already have a Router-based test path)
reqwest  = { workspace = true, features = ["rustls-tls-native-roots","json"] }
tokio    = { workspace = true, features = ["macros","rt-multi-thread","time"] }
# Benches + helpers (Criterion enables --save-baseline)
criterion = "0.5"
futures   = "0.3"

[[bench]]
name = "verify"
harness = false

[profile.bench]
opt-level = 3
codegen-units = 1
lto = "thin"        # thin-LTO avoids the embed-bitcode=no conflict
panic = "abort"

[profile.release]
opt-level = 3
codegen-units = 1
lto = "thin"
panic = "abort"


```

### crates/svc-passport/benches/issue_bench.rs
<a id="crates-svc-passport-benches-issuebench-rs"></a>

```rust
// Criterion bench scaffold: /issue path
fn main() { /* bench placeholder */
}

```

### crates/svc-passport/benches/verify.rs
<a id="crates-svc-passport-benches-verify-rs"></a>

```rust
// crates/svc-passport/benches/verify.rs
use std::sync::Arc;

use base64::{engine::general_purpose::STANDARD, Engine as _};
use criterion::{black_box, criterion_group, criterion_main, BatchSize, Criterion};
use futures::executor;
use svc_passport::{
    config::Config,
    kms::client::{DevKms, KmsClient},
    state::issuer::IssuerState,
};

// Embed default config so benches don't rely on filesystem layout.
const EMBEDDED_DEFAULT_TOML: &str = include_str!("../config/default.toml");

fn ensure_bench_config() {
    // Only set if caller didn't provide something explicit.
    if std::env::var("PASSPORT_CONFIG").is_err() && std::env::var("PASSPORT_CONFIG_FILE").is_err() {
        std::env::set_var("PASSPORT_CONFIG", EMBEDDED_DEFAULT_TOML);
    }
}

fn make_issuer() -> IssuerState {
    ensure_bench_config();
    let kms: Arc<dyn KmsClient> = Arc::new(DevKms::new());
    let cfg = Config::load().expect("Config::load() in benches");
    IssuerState::new(cfg, kms)
}

pub fn bench_verify_single(c: &mut Criterion) {
    c.bench_function("verify_single", |b| {
        b.iter_batched(
            || {
                let issuer = make_issuer();
                let msg = br#"{"hello":"world"}"#.to_vec();
                let (kid, sig) = executor::block_on(issuer.sign(&msg)).unwrap();
                (issuer, kid, msg, sig)
            },
            |(issuer, kid, msg, sig)| {
                let ok = executor::block_on(issuer.verify(&kid, &msg, &sig)).unwrap();
                black_box(ok);
            },
            BatchSize::SmallInput,
        )
    });
}

pub fn bench_verify_batch_64(c: &mut Criterion) {
    c.bench_function("verify_batch_64", |b| {
        b.iter_batched(
            || {
                let issuer = make_issuer();
                let msg = br#"{"hello":"world"}"#.to_vec();
                let mut envs = Vec::with_capacity(64);
                for _ in 0..64 {
                    let (kid, sig) = executor::block_on(issuer.sign(&msg)).unwrap();
                    let env = serde_json::json!({
                        "kid": kid,
                        "msg_b64": STANDARD.encode(&msg),
                        "sig_b64": STANDARD.encode(&sig),
                        "alg": "Ed25519"
                    });
                    envs.push(env);
                }
                (issuer, envs)
            },
            |(issuer, envs)| {
                for env in &envs {
                    let kid = env["kid"].as_str().unwrap();
                    let msg = STANDARD.decode(env["msg_b64"].as_str().unwrap()).unwrap();
                    let sig = STANDARD.decode(env["sig_b64"].as_str().unwrap()).unwrap();
                    let ok = futures::executor::block_on(issuer.verify(kid, &msg, &sig)).unwrap();
                    black_box(ok);
                }
            },
            BatchSize::SmallInput,
        )
    });
}

criterion_group!(benches, bench_verify_single, bench_verify_batch_64);
criterion_main!(benches);

```

### crates/svc-passport/config/default.toml
<a id="crates-svc-passport-config-default-toml"></a>

```toml
# RO:WHAT — Default config for svc-passport (dev-friendly)
[server]
bind = "127.0.0.1:5307"
admin_bind = "127.0.0.1:5308"

[passport]
issuer = "svc-passport"
default_ttl_s = 3600
max_ttl_s = 86400
clock_skew_s = 120

[verify]
target_batch = 64
max_batch = 256
max_wait_us = 500

[cache]
vk_ttl_s = 60
jwks_ttl_s = 60

[limits]
max_msg_bytes = 4096
max_batch = 512

[security]
require_aud = true

```

### crates/svc-passport/docker/docker-compose.yml
<a id="crates-svc-passport-docker-docker-compose-yml"></a>

```yaml
version: "3.9"
services:
  svc-passport2:
    image: svcpassport2:scaffold
    build:
      context: ..
      dockerfile: docker/Dockerfile

```

### crates/svc-passport/examples/issue_cli.rs
<a id="crates-svc-passport-examples-issuecli-rs"></a>

```rust
// Minimal example scaffold: issues a passport via HTTP (to be implemented)
fn main() {
    println!("issue_cli scaffold");
}

```

### crates/svc-passport/fuzz/fuzz_targets/caveat_mutation.rs
<a id="crates-svc-passport-fuzz-fuzztargets-caveatmutation-rs"></a>

```rust
#![no_main]
// Fuzz target scaffold: caveat_mutation
use libfuzzer_sys::fuzz_target;
fuzz_target!(|_data: &[u8]| {
    // TODO
});

```

### crates/svc-passport/fuzz/fuzz_targets/envelope_parse.rs
<a id="crates-svc-passport-fuzz-fuzztargets-envelopeparse-rs"></a>

```rust
#![no_main]
// Fuzz target scaffold: envelope_parse
use libfuzzer_sys::fuzz_target;
fuzz_target!(|_data: &[u8]| {
    // TODO
});

```

### crates/svc-passport/loom/rotation_loom.rs
<a id="crates-svc-passport-loom-rotationloom-rs"></a>

```rust
// Loom model scaffold for rotation/mint interleavings
#[test] fn loom_rotation_scaffold() { assert!(true); }

```

### crates/svc-passport/rust-toolchain.toml
<a id="crates-svc-passport-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["rustfmt", "clippy"]

```

### crates/svc-passport/scripts/inject_kms_latency.sh
<a id="crates-svc-passport-scripts-injectkmslatency-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "[scaffold] inject_kms_latency.sh <latency>" >&2

```

### crates/svc-passport/scripts/load_issue_profile.sh
<a id="crates-svc-passport-scripts-loadissueprofile-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "[scaffold] load_issue_profile.sh <profile.json>" >&2

```

### crates/svc-passport/scripts/rotate_under_load.sh
<a id="crates-svc-passport-scripts-rotateunderload-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "[scaffold] rotate_under_load.sh" >&2

```

### crates/svc-passport/scripts/smoke_passport.sh
<a id="crates-svc-passport-scripts-smokepassport-sh"></a>

```bash
#!/usr/bin/env bash
# Smoke test for svc-passport (portable, macOS-safe, self-tracing)
# - Auto-spawns server if not healthy; reuses existing
# - Discovers actual bound URL from logs; falls back to host:port if absent
# - Checks aligned with current router: /healthz, /metrics, issue/verify/verify_batch
# - TRACE=1 enables bash -x and error context dump
# - All logs go to stderr so stdout is reserved for function returns (e.g., URL)

set -euo pipefail

# -------------------- knobs --------------------
PASSPORT_HOST="${PASSPORT_HOST:-127.0.0.1}"
PASSPORT_PORT="${PASSPORT_PORT:-5307}"             # fallback only; discovery preferred
STARTUP_TIMEOUT_SECS="${STARTUP_TIMEOUT_SECS:-25}"
DISABLE_AUTO_SPAWN="${DISABLE_AUTO_SPAWN:-0}"
LOGFILE="${LOGFILE:-/tmp/svc-passport.log}"
RUST_LOG="${RUST_LOG:-info}"
TRACE="${TRACE:-0}"
# ------------------------------------------------

ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"   # -> crates/svc-passport
CFG_FILE_DEFAULT="$ROOT/config/default.toml"

SERVER_PID=""
: > "$LOGFILE"

# ---- tracing helpers ----
if [[ "$TRACE" == "1" ]]; then
  set -x
fi
on_err() {
  local code=$?
  echo "=== ERROR: script aborted (exit=$code) at line ${BASH_LINENO[0]} in ${BASH_SOURCE[1]-main} ===" >&2
  echo "--- Last 60 lines of ${LOGFILE} ---" >&2
  tail -n 60 "$LOGFILE" 2>/dev/null || true
  exit "$code"
}
trap on_err ERR

# log helpers -> stderr (so stdout can carry function return values)
log()  { printf "\033[1;34m[INFO]\033[0m %s\n" "$*" >&2; }
ok()   { printf "\033[1;32m[ OK ]\033[0m %s\n" "$*" >&2; }
warn() { printf "\033[1;33m[WARN]\033[0m %s\n" "$*" >&2; }
err()  { printf "\033[1;31m[FAIL]\033[0m %s\n" "$*" >&2; }

need() { command -v "$1" >/dev/null 2>&1 || { err "Missing tool: $1"; exit 1; }; }
need curl
need jq
need awk
need grep
need sed
command -v lsof >/dev/null 2>&1 || warn "lsof not found; port freeing limited"

cleanup() {
  if [[ -n "${SERVER_PID}" ]]; then
    log "Stopping spawned svc-passport (pid=${SERVER_PID})"
    kill "${SERVER_PID}" 2>/dev/null || true
    wait "${SERVER_PID}" 2>/dev/null || true
  fi
}
trap cleanup EXIT INT TERM

# -------------------- config --------------------
prepare_config_env() {
  # Respect caller-supplied config if present
  if [[ -n "${PASSPORT_CONFIG_FILE:-}" || -n "${PASSPORT_CONFIG:-}" ]]; then
    return
  fi
  if [[ -f "$CFG_FILE_DEFAULT" ]]; then
    export PASSPORT_CONFIG_FILE="$CFG_FILE_DEFAULT"
    return
  fi
  err "No config provided and default missing: $CFG_FILE_DEFAULT"
  exit 1
}

# -------------------- ports --------------------
port_bound() {
  local port="$1"
  if command -v lsof >/dev/null 2>&1; then
    lsof -iTCP:"$port" -sTCP:LISTEN -n -P >/dev/null 2>&1
  else
    (exec 3<>/dev/tcp/"$PASSPORT_HOST"/"$port") >/dev/null 2>&1 || return 1
    exec 3>&- || true
    return 0
  fi
}

free_fixed_ports_if_needed() {
  # Best-effort only; defensive for macOS (no xargs -r)
  for PORT in "$PASSPORT_PORT" 5308; do
    if port_bound "$PORT"; then
      warn "Port $PORT busy. Killing holder(s)…"
      if command -v lsof >/dev/null 2>&1; then
        PIDS="$(lsof -tiTCP:"$PORT" -sTCP:LISTEN -n -P 2>/dev/null || true)"
        if [[ -n "${PIDS:-}" ]]; then
          # shellcheck disable=SC2086
          kill -9 $PIDS 2>/dev/null || true
        fi
      fi
      sleep 0.2
    fi
  done
}

# -------------------- URL discovery --------------------
discover_url_from_logs() {
  # Expect startup to log e.g. "svc-passport: listening on http://127.0.0.1:5307"
  # Extract the last http://IP:PORT seen
  local found
  found="$(grep -Eo 'http://[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+:[0-9]+' "$LOGFILE" | tail -n1 || true)"
  printf "%s" "${found}"
}
fallback_url() { echo "http://${PASSPORT_HOST}:${PASSPORT_PORT}"; }

is_healthy() {
  local base="$1"
  [[ -z "$base" ]] && return 1
  curl -sSf "$base/healthz" >/dev/null 2>&1
}

# -------------------- spawn & wait --------------------
spawn() {
  log "Spawning svc-passport (cargo run -p svc-passport)"
  : > "$LOGFILE"

  # If PASSPORT_CONFIG exists but is empty, unset it so file mode is used.
  if [[ "${PASSPORT_CONFIG+x}" == "x" && -z "${PASSPORT_CONFIG:-}" ]]; then
    unset PASSPORT_CONFIG
  fi

  # Build an env block that only includes non-empty config vars
  (
    export RUST_LOG="$RUST_LOG"
    if [[ -n "${PASSPORT_CONFIG_FILE:-}" ]]; then
      export PASSPORT_CONFIG_FILE
    fi
    if [[ -n "${PASSPORT_CONFIG:-}" ]]; then
      export PASSPORT_CONFIG
    fi
    cargo run -p svc-passport --quiet
  ) >"$LOGFILE" 2>&1 &
  SERVER_PID=$!
  log "svc-passport spawned (pid=${SERVER_PID}); logs at ${LOGFILE}"
}

maybe_spawn() {
  if [[ "${DISABLE_AUTO_SPAWN}" == "1" ]]; then
    warn "Auto-spawn disabled; expecting service to be up."
    return 1
  fi
  local try_url; try_url="$(fallback_url)"
  if is_healthy "$try_url"; then
    log "Target already healthy at ${try_url}; not spawning."
    return 1
  fi
  if port_bound "${PASSPORT_PORT}"; then
    log "Port ${PASSPORT_PORT} bound; reusing existing process (will wait for health)."
    return 1
  fi
  spawn
  return 0
}

wait_for_up() {
  log "Waiting for service…"
  local url=""
  local deadline=$((SECONDS + STARTUP_TIMEOUT_SECS))
  while [[ $SECONDS -lt $deadline ]]; do
    url="$(discover_url_from_logs || true)"
    if [[ -z "$url" ]]; then
      url="$(fallback_url)"
    fi
    if is_healthy "$url"; then
      ok "Service is up at ${url}"
      # IMPORTANT: stdout returns ONLY the URL
      echo "$url"
      return 0
    fi
    if [[ -n "$SERVER_PID" ]] && ! kill -0 "$SERVER_PID" 2>/dev/null; then
      err "Process exited before becoming healthy. Last 200 log lines:"
      tail -n 200 "$LOGFILE" >&2 || true
      exit 1
    fi
    sleep 0.2
  done
  err "Timed out waiting for /healthz"
  warn "Last 200 lines of ${LOGFILE}:"
  tail -n 200 "$LOGFILE" >&2 || true
  exit 1
}

# -------------------- HTTP helpers --------------------
curl_save() {
  local url="$1" method="$2" path="$3" body="${4:-}" out="${5:-/dev/null}"
  if [[ -n "$body" ]]; then
    curl -sS -X "$method" -H 'content-type: application/json' -d "$body" -o "$out" -w '%{http_code}' "${url}${path}"
  else
    curl -sS -X "$method" -o "$out" -w '%{http_code}' "${url}${path}"
  fi
}

run_checks() {
  local url="$1" spawned="$2"
  local code failures=0 tmp body ENV ENV_FILE

  # Basics (aligned with current router)
  code=$(curl -s -o /dev/null -w '%{http_code}' "${url}/healthz") && [[ "$code" == "200" ]] \
    && ok "/healthz" || { err "/healthz (code=$code)"; failures=$((failures+1)); }

  if curl -sSf "${url}/metrics" >/dev/null 2>&1; then ok "/metrics"; else warn "/metrics (not present)"; fi

  # Issue
  ENV_FILE="$(mktemp)"
  code=$(curl_save "$url" POST "/v1/passport/issue" '{"hello":"world"}' "$ENV_FILE")
  [[ "$code" == "200" ]] && ok "issue → envelope" || { err "issue (code=$code)"; failures=$((failures+1)); }
  ENV="$(cat "$ENV_FILE")"; rm -f "$ENV_FILE"

  # Verify single
  tmp="$(mktemp)"
  code=$(curl_save "$url" POST "/v1/passport/verify" "$ENV" "$tmp"); body="$(cat "$tmp")"; rm -f "$tmp"
  [[ "$code" == "200" ]] && jq -e '. == true' >/dev/null 2>&1 <<<"$body" \
    && ok "verify (single)" || { err "verify single (code=$code body=$body)"; failures=$((failures+1)); }

  # Verify batch
  tmp="$(mktemp)"
  code=$(curl_save "$url" POST "/v1/passport/verify_batch" "[$ENV,$ENV]" "$tmp"); body="$(cat "$tmp")"; rm -f "$tmp"
  [[ "$code" == "200" ]] && jq -e '. == [true,true]' >/dev/null 2>&1 <<<"$body" \
    && ok "verify (batch)" || { err "verify batch (code=$code body=$body)"; failures=$((failures+1)); }

  # Negative: tamper → 200:false or 400
  local ENV_TAMPER code_tamper BODY_TAMPER body_tamper_file
  ENV_TAMPER="$(echo "$ENV" | jq '.msg_b64="e30"')" || ENV_TAMPER=''
  if [[ -n "$ENV_TAMPER" ]]; then
    body_tamper_file="$(mktemp)"
    code_tamper=$(curl_save "$url" POST "/v1/passport/verify" "$ENV_TAMPER" "$body_tamper_file")
    BODY_TAMPER="$(cat "$body_tamper_file" || true)"; rm -f "$body_tamper_file"
    if [[ "$code_tamper" == "200" ]] && echo "$BODY_TAMPER" | jq -e '. == false' >/dev/null 2>&1; then
      ok "negative: tampered → 200 false"
    elif [[ "$code_tamper" == "400" ]] ; then
      ok "negative: tampered → 400"
    else
      err "negative: tampered expected 200:false or 400; got ${code_tamper:-<none>}"
      failures=$((failures+1))
    fi
  fi

  (( failures == 0 )) && { ok "All checks passed"; return 0; }
  err "Smoke FAILED (${failures} failing check(s))"; return 1
}

# -------------------- main --------------------
{ set +e; echo "--- TRACE: env ---" >&2; env | grep -E '^PASSPORT_|^RUST_LOG' >&2 || true; echo "--------------" >&2; set -e; }

prepare_config_env
free_fixed_ports_if_needed

spawned=0
if maybe_spawn; then spawned=1; fi

log "--- REACHED: before wait_for_up (spawned=${spawned}) ---"

URL="$(wait_for_up)"
run_checks "$URL" "$spawned"

```

### crates/svc-passport/src/bootstrap.rs
<a id="crates-svc-passport-src-bootstrap-rs"></a>

```rust
// crates/svc-passport/src/bootstrap.rs
//! RO:WHAT   TCP listener + Axum server bootstrap.
//! RO:WHY    Keep signature expected by main.rs (bind, admin, cfg) -> (JoinHandle, addr).
//!           Print the *actual* bound addr so curl targets the right port.
//!           Router is unit-state so `axum::serve(listener, app)` compiles cleanly.

use crate::{config::Config, health::Health, http::router::build_router};
use anyhow::Result;
use std::net::SocketAddr;
use tokio::{net::TcpListener, task::JoinHandle};

pub async fn run(
    bind: SocketAddr,
    _admin: SocketAddr,
    cfg: Config,
) -> Result<(JoinHandle<()>, SocketAddr)> {
    // 1) Bind TCP listener (explicit address from main.rs)
    let listener = TcpListener::bind(bind).await?;
    let addr = listener.local_addr()?; // in case port=0, this tells you what you actually got

    // 2) Loud startup so you can't miss it (works even if tracing isn't configured)
    println!("svc-passport: listening on http://{addr}");
    eprintln!("svc-passport: listening on http://{addr}");

    // 3) Health (Default ok)
    let health: Health = Default::default();

    // 4) Build Router<()> (IssuerState is carried via Extension inside build_router)
    let app = build_router(cfg.clone(), health);

    // 5) Serve (await inside a task so main can hold the JoinHandle)
    let task = tokio::spawn(async move {
        if let Err(e) = axum::serve(listener, app).await {
            eprintln!("svc-passport server error: {e}");
        }
    });

    Ok((task, addr))
}

```

### crates/svc-passport/src/bus/mod.rs
<a id="crates-svc-passport-src-bus-mod-rs"></a>

```rust
//! Experimental Bus RPC surface (scaffold). HTTP remains canonical.
pub mod rpc;

```

### crates/svc-passport/src/bus/rpc.rs
<a id="crates-svc-passport-src-bus-rpc-rs"></a>

```rust
//! mint_cap RPC handler stubs (scaffold).

```

### crates/svc-passport/src/config.rs
<a id="crates-svc-passport-src-config-rs"></a>

```rust
//! RO:WHAT — Service configuration model + loader (env/file), with sane defaults.

use serde::Deserialize;
use std::{env, fs, path::Path};

#[derive(Debug, Clone, Deserialize)]
pub struct Config {
    pub server: Server,
    pub passport: Passport,
    pub verify: VerifyPolicy,
    pub cache: Cache,
    pub limits: Limits,
    pub security: Security,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Server {
    pub bind: String,
    pub admin_bind: String,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Passport {
    pub issuer: String,
    pub default_ttl_s: u64,
    pub max_ttl_s: u64,
    pub clock_skew_s: i64,
}

#[derive(Debug, Clone, Deserialize)]
pub struct VerifyPolicy {
    pub target_batch: usize,
    pub max_batch: usize,
    pub max_wait_us: u64,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Cache {
    pub vk_ttl_s: u64,
    pub jwks_ttl_s: u64,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Limits {
    pub max_msg_bytes: usize,
    pub max_batch: usize,
}

#[derive(Debug, Clone, Deserialize)]
pub struct Security {
    pub require_aud: bool,
}

impl Config {
    pub fn load() -> anyhow::Result<Self> {
        if let Ok(s) = env::var("PASSPORT_CONFIG") {
            return Ok(toml::from_str(&s)?);
        }
        let path = env::var("PASSPORT_CONFIG_FILE")
            .unwrap_or_else(|_| "crates/svc-passport/config/default.toml".to_string());
        let text = fs::read_to_string(Path::new(&path))?;
        Ok(toml::from_str(&text)?)
    }
}

```

### crates/svc-passport/src/dto/issue.rs
<a id="crates-svc-passport-src-dto-issue-rs"></a>

```rust
use serde::{Deserialize, Serialize};
use serde_json::Value;

#[derive(Debug, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct IssueRequest {
    pub sub: String,
    pub aud: Vec<String>,
    pub scopes: Vec<String>,
    #[serde(default)]
    pub ctx: Option<Value>,
    #[serde(default)]
    pub ttl_s: Option<u64>,
    #[serde(default)]
    pub nbf: Option<i64>,
    #[serde(default)]
    pub nonce: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct IssueResponse {
    pub envelope: super::verify::Envelope,
}

```

### crates/svc-passport/src/dto/mod.rs
<a id="crates-svc-passport-src-dto-mod-rs"></a>

```rust
//! RO:WHAT — Stable JSON DTOs for issue/verify/revoke (deny unknown fields).
pub mod issue;
pub mod revoke;
pub mod verify;

```

### crates/svc-passport/src/dto/revoke.rs
<a id="crates-svc-passport-src-dto-revoke-rs"></a>

```rust
#![allow(dead_code)]
use serde::Deserialize;

#[derive(Debug, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct RevokeRequest {
    pub jti: String,
}

```

### crates/svc-passport/src/dto/verify.rs
<a id="crates-svc-passport-src-dto-verify-rs"></a>

```rust
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Envelope {
    pub alg: String,
    pub kid: String,
    pub sig_b64: String,
    pub msg_b64: String,
}

#[derive(Debug, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct VerifyRequest {
    pub envelope: Envelope,
}

#[derive(Debug, Serialize)]
pub struct VerifyResponse {
    pub ok: bool,
    pub reason: Option<String>,
}

#[derive(Debug, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct VerifyBatchRequest {
    pub envelopes: Vec<Envelope>,
}

#[derive(Debug, Serialize)]
pub struct VerifyBatchResponse {
    pub results: Vec<VerifyResult>,
}

#[derive(Debug, Serialize)]
pub struct VerifyResult {
    pub ok: bool,
    pub reason: Option<String>,
}

```

### crates/svc-passport/src/error.rs
<a id="crates-svc-passport-src-error-rs"></a>

```rust
//! RO:WHAT — Error taxonomy (stable, machine-parseable) and IntoResponse mapping.
//! RO:WHY  — Deterministic client behavior, SDK-friendly.
//! RO:INVARIANTS — No secrets in messages; stable codes.

use axum::{
    http::StatusCode,
    response::{IntoResponse, Response},
    Json,
};
use serde::Serialize;
use thiserror::Error;

#[derive(Debug, Error)]
pub enum Error {
    #[error("malformed")]
    Malformed,
    #[error("verify_failed")]
    VerifyFailed,
    #[error("expired")]
    Expired,
    #[error("nbf")]
    NotBefore,
    #[error("bad_aud")]
    BadAudience,
    #[error("unknown_kid")]
    UnknownKid,
    #[error("scope_denied")]
    ScopeDenied,
    #[error("internal")]
    Internal(anyhow::Error),
}

#[derive(Serialize)]
pub struct Problem<'a> {
    code: &'a str,
    message: &'a str,
    retryable: bool,
}

impl IntoResponse for Error {
    fn into_response(self) -> Response {
        let (code, msg, status, retryable) = match &self {
            Error::Malformed => (
                "malformed",
                "bad request body",
                StatusCode::BAD_REQUEST,
                false,
            ),
            Error::VerifyFailed => (
                "verify_failed",
                "signature did not verify",
                StatusCode::UNAUTHORIZED,
                false,
            ),
            Error::Expired => ("expired", "token expired", StatusCode::UNAUTHORIZED, false),
            Error::NotBefore => ("nbf", "token not valid yet", StatusCode::UNAUTHORIZED, true),
            Error::BadAudience => ("bad_aud", "audience denied", StatusCode::FORBIDDEN, false),
            Error::UnknownKid => (
                "unknown_kid",
                "unknown verifying key",
                StatusCode::UNAUTHORIZED,
                true,
            ),
            Error::ScopeDenied => (
                "scope_denied",
                "capability denied",
                StatusCode::FORBIDDEN,
                false,
            ),
            Error::Internal(_) => (
                "internal",
                "internal error",
                StatusCode::INTERNAL_SERVER_ERROR,
                true,
            ),
        };
        let body = Json(Problem {
            code,
            message: msg,
            retryable,
        });
        (status, body).into_response()
    }
}

impl From<anyhow::Error> for Error {
    fn from(e: anyhow::Error) -> Self {
        Error::Internal(e)
    }
}

```

### crates/svc-passport/src/health.rs
<a id="crates-svc-passport-src-health-rs"></a>

```rust
//! Health/Readiness wrappers.

use ron_kernel::metrics::{health::HealthState, readiness::Readiness};

#[derive(Clone)]
pub struct Health {
    pub health: HealthState,
    pub ready: Readiness,
}

impl Health {
    pub fn new() -> Self {
        let health = HealthState::new();
        let ready = Readiness::new(health.clone());
        Self { health, ready }
    }
}

// Clippy asked for this; also makes it easy to construct.
impl Default for Health {
    fn default() -> Self {
        Self::new()
    }
}

```

### crates/svc-passport/src/http/handlers/healthz.rs
<a id="crates-svc-passport-src-http-handlers-healthz-rs"></a>

```rust
//! RO:WHAT — GET /healthz (passthrough to ron-kernel health).
use axum::response::IntoResponse;
use ron_kernel::metrics::health::HealthState;

pub async fn healthz(h: HealthState) -> impl IntoResponse {
    if h.all_ready() {
        "ok"
    } else {
        "degraded"
    }
}

```

### crates/svc-passport/src/http/handlers/issue.rs
<a id="crates-svc-passport-src-http-handlers-issue-rs"></a>

```rust
//! RO:WHAT   Issue + admin plane + JWKS export.
//! RO:WHY    Unit-state Router: state via Extension(Arc<_>); metrics intact.

use axum::{response::IntoResponse, Extension, Json};
use serde_json::{json, Value};
use std::sync::Arc;

use crate::{
    error::Error,
    metrics::{OPS_TOTAL, OP_LATENCY},
    state::issuer::IssuerState,
};

/// Minimal health probe keeps behavior stable even if other parts evolve.
pub async fn healthz() -> impl IntoResponse {
    Json(json!({ "ok": true }))
}

/// GET /v1/keys  -> JWKS (OKP/Ed25519)
pub async fn keys(
    Extension(issuer): Extension<Arc<IssuerState>>,
) -> Result<impl IntoResponse, Error> {
    let jwks = issuer.jwks().await?;
    Ok(Json(jwks))
}

/// POST /v1/passport/issue
/// Body: arbitrary JSON payload to be signed
/// Returns: Envelope { alg, kid, msg_b64, sig_b64 }
pub async fn issue(
    Extension(issuer): Extension<Arc<IssuerState>>,
    Json(payload): Json<Value>,
) -> Result<impl IntoResponse, Error> {
    let _timer = OP_LATENCY.start_timer();

    let bytes = serde_json::to_vec(&payload).map_err(|_| Error::Malformed)?;
    let (kid, sig) = issuer.sign(&bytes).await?;
    let env = issuer.build_envelope(kid, bytes, sig);

    OPS_TOTAL
        .with_label_values(&["issue", "ok", "Ed25519"])
        .inc();

    Ok(Json(json!({
        "alg": env.alg,
        "kid": env.kid,
        "sig_b64": env.sig_b64,
        "msg_b64": env.msg_b64
    })))
}

/// POST /admin/rotate  -> { current_kid }
pub async fn rotate(
    Extension(issuer): Extension<Arc<IssuerState>>,
) -> Result<impl IntoResponse, Error> {
    let kid = issuer.kms.rotate().await.map_err(Error::Internal)?;
    Ok(Json(json!({ "current_kid": kid })))
}

/// GET /admin/attest  -> attestation doc
pub async fn attest(
    Extension(issuer): Extension<Arc<IssuerState>>,
) -> Result<impl IntoResponse, Error> {
    let view = issuer.kms.attest().await.map_err(Error::Internal)?;
    Ok(Json(view))
}

```

### crates/svc-passport/src/http/handlers/mod.rs
<a id="crates-svc-passport-src-http-handlers-mod-rs"></a>

```rust
pub mod healthz;
pub mod issue;
pub mod readyz;
pub mod revoke;
pub mod verify;

```

### crates/svc-passport/src/http/handlers/readyz.rs
<a id="crates-svc-passport-src-http-handlers-readyz-rs"></a>

```rust
//! RO:WHAT — GET /readyz handled in bootstrap via ron-kernel readiness handler.
//! RO:WHY  — Keep handler here for symmetry if needed later.
#![allow(dead_code)]

```

### crates/svc-passport/src/http/handlers/revoke.rs
<a id="crates-svc-passport-src-http-handlers-revoke-rs"></a>

```rust
//! RO:WHAT — (stub) Revocation endpoint; Bronze stores nonce/jti in-memory with TTL.
//! RO:WHY  — Demonstrate shape; Silver will back by CAS/index if needed.
#![allow(dead_code)]

```

### crates/svc-passport/src/http/handlers/verify.rs
<a id="crates-svc-passport-src-http-handlers-verify-rs"></a>

```rust
//! RO:WHAT   Verify endpoints: single and batch (Envelope-based).
//! RO:WHY    Unit-state Router: pull IssuerState via Extension(Arc<_>); keep metrics.
//! RO:INVARS No secret leakage; errors mapped by Error; low-cardinality labels.

use axum::{http::StatusCode, Extension, Json};
use base64::{engine::general_purpose::STANDARD, Engine as _};
use std::sync::Arc;

use crate::{
    dto::verify::Envelope,
    error::Error,
    metrics::{BATCH_LEN, OPS_TOTAL, OP_LATENCY},
    state::issuer::IssuerState,
};

/// POST /v1/passport/verify  Envelope -> bool
pub async fn verify_one(
    Extension(issuer): Extension<Arc<IssuerState>>,
    Json(env): Json<Envelope>,
) -> Result<(StatusCode, Json<bool>), Error> {
    let _t = OP_LATENCY.start_timer();

    let msg = STANDARD
        .decode(&env.msg_b64)
        .map_err(|_| Error::Malformed)?;
    let sig = STANDARD
        .decode(&env.sig_b64)
        .map_err(|_| Error::Malformed)?;
    let ok = issuer.verify(&env.kid, &msg, &sig).await?;

    OPS_TOTAL
        .with_label_values(&["verify", if ok { "ok" } else { "bad_sig" }, "Ed25519"])
        .inc();

    Ok((StatusCode::OK, Json(ok)))
}

/// POST /v1/passport/verify_batch  [Envelope] -> [bool]
pub async fn verify_batch(
    Extension(issuer): Extension<Arc<IssuerState>>,
    Json(envs): Json<Vec<Envelope>>,
) -> Result<(StatusCode, Json<Vec<bool>>), Error> {
    let _t = OP_LATENCY.start_timer();
    BATCH_LEN.observe(envs.len() as f64);

    let mut out = Vec::with_capacity(envs.len());
    for env in &envs {
        let msg = STANDARD
            .decode(&env.msg_b64)
            .map_err(|_| Error::Malformed)?;
        let sig = STANDARD
            .decode(&env.sig_b64)
            .map_err(|_| Error::Malformed)?;
        let ok = issuer.verify(&env.kid, &msg, &sig).await?;
        out.push(ok);
    }

    OPS_TOTAL
        .with_label_values(&["verify_batch", "ok", "Ed25519"])
        .inc();

    Ok((StatusCode::OK, Json(out)))
}

```

### crates/svc-passport/src/http/middleware.rs
<a id="crates-svc-passport-src-http-middleware-rs"></a>

```rust
//! RO:WHAT — (stub) room for quotas/fair-queue/body caps if we front-door here.
//! RO:WHY  — Hardening blueprint hooks.
//! RO:INVARIANTS — keep simple for Bronze; svc-gateway can apply global guards.

#![allow(dead_code)]

```

### crates/svc-passport/src/http/mod.rs
<a id="crates-svc-passport-src-http-mod-rs"></a>

```rust
//! RO:WHAT — HTTP layer: router, middleware, and handlers.
//! RO:WHY  — Surface area kept small/boring; DTO hygiene.
//! RO:INVARIANTS — body caps, timeouts, deterministic errors.

pub mod handlers;
pub mod middleware;
pub mod router;

```

### crates/svc-passport/src/http/router.rs
<a id="crates-svc-passport-src-http-router-rs"></a>

```rust
// crates/svc-passport/src/http/router.rs
//! RO:WHAT   HTTP router assembly (unit-state Router<()>).
//! RO:WHY    Axum 0.7 serve() accepts Router<()> directly; state via Extension(Arc<_>).
//! RO:PLUS   /metrics + per-route body caps + concurrency guards for verify hotpaths.

use crate::{
    config::Config,
    health::Health,
    kms::client::{DevKms, KmsClient},
    metrics, // /metrics exporter
    state::issuer::IssuerState,
};
use axum::{
    extract::DefaultBodyLimit,
    response::IntoResponse,
    routing::{get, post},
    Extension, Json, Router,
};
use std::sync::Arc;
use tower::limit::ConcurrencyLimitLayer;

// Handlers
use crate::http::handlers::{issue, verify};

pub fn build_router(cfg: Config, _health: Health) -> Router {
    // KMS client (dev) and IssuerState as shared Arc
    let kms: Arc<dyn KmsClient> = Arc::new(DevKms::new());
    let issuer = Arc::new(IssuerState::new(cfg.clone(), kms));

    // Tunables (env-first; conservative defaults)
    let max_body_bytes: usize = std::env::var("PASSPORT_MAX_MSG_BYTES")
        .ok()
        .and_then(|s| s.parse().ok())
        .unwrap_or(1_048_576); // 1 MiB

    let verify_conc: usize = std::env::var("PASSPORT_VERIFY_CONCURRENCY")
        .ok()
        .and_then(|s| s.parse().ok())
        .unwrap_or(64);

    let verify_batch_conc: usize = std::env::var("PASSPORT_VERIFY_BATCH_CONCURRENCY")
        .ok()
        .and_then(|s| s.parse().ok())
        .unwrap_or(16);

    // Minimal /healthz so we can always probe quickly
    async fn healthz() -> impl IntoResponse {
        Json(serde_json::json!({ "ok": true }))
    }

    Router::new()
        // Admin/ops plane basics
        .route("/healthz", get(healthz))
        .route("/metrics", get(metrics::export))
        // v1 API
        .route(
            "/v1/passport/issue",
            post(issue::issue).route_layer(DefaultBodyLimit::max(max_body_bytes)),
        )
        .route(
            "/v1/passport/verify",
            post(verify::verify_one)
                .route_layer(DefaultBodyLimit::max(max_body_bytes))
                .route_layer(ConcurrencyLimitLayer::new(verify_conc)),
        )
        .route(
            "/v1/passport/verify_batch",
            post(verify::verify_batch)
                .route_layer(DefaultBodyLimit::max(max_body_bytes))
                .route_layer(ConcurrencyLimitLayer::new(verify_batch_conc)),
        )
        .route("/v1/keys", get(issue::keys))
        .route("/admin/rotate", post(issue::rotate))
        .route("/admin/attest", get(issue::attest))
        // Carry IssuerState via Extension so the Router stays unit-state
        .layer(Extension(issuer))
}

```

### crates/svc-passport/src/kms/client.rs
<a id="crates-svc-passport-src-kms-client-rs"></a>

```rust
//! RO:WHAT — KmsClient trait; DevKms (ed25519-dalek) for dev/tests.
//! RO:INVARIANTS — versioned KID "ed25519/default/v{n}"
//! RO:NOTES — DevKms is feature-gated behind `dev-kms` and uses rand_core::OsRng.

use async_trait::async_trait;

#[async_trait]
pub trait KmsClient: Send + Sync {
    async fn sign(&self, msg: &[u8]) -> anyhow::Result<(String, Vec<u8>)>;
    async fn verify(&self, kid: &str, msg: &[u8], sig: &[u8]) -> anyhow::Result<bool>;
    async fn public_keys(&self) -> anyhow::Result<serde_json::Value>;
    async fn rotate(&self) -> anyhow::Result<String>;
    async fn attest(&self) -> anyhow::Result<serde_json::Value>;
}

#[cfg(feature = "dev-kms")]
mod dev {
    use super::*;
    use base64::engine::general_purpose::URL_SAFE_NO_PAD;
    use base64::Engine;
    use ed25519_dalek::{Signer, SigningKey, VerifyingKey};
    use parking_lot::RwLock;
    use rand_core::OsRng; // rand_core 0.6 — CSPRNG compatible with dalek v2
    use serde_json::json;
    use std::sync::atomic::{AtomicU64, Ordering};

    /// Simple in-proc KMS for dev/tests.
    pub struct DevKms {
        version: AtomicU64,
        head: RwLock<(SigningKey, VerifyingKey)>,
        history: RwLock<Vec<(String, VerifyingKey)>>, // (kid, vk)
    }

    impl Default for DevKms {
        fn default() -> Self {
            Self::new()
        }
    }

    impl DevKms {
        pub fn new() -> Self {
            // Use OsRng (rand_core 0.6) to satisfy dalek's CryptoRngCore bound.
            let mut csprng = OsRng;
            let sk = SigningKey::generate(&mut csprng);
            let vk = sk.verifying_key();
            let kid = "ed25519/default/v1".to_string();
            Self {
                version: AtomicU64::new(1),
                head: RwLock::new((sk, vk)),
                history: RwLock::new(vec![(kid, vk)]),
            }
        }

        fn current_kid(&self) -> String {
            format!("ed25519/default/v{}", self.version.load(Ordering::SeqCst))
        }
    }

    #[async_trait]
    impl KmsClient for DevKms {
        async fn sign(&self, msg: &[u8]) -> anyhow::Result<(String, Vec<u8>)> {
            let (sk, _vk) = &*self.head.read();
            let sig = sk.sign(msg).to_bytes().to_vec();
            Ok((self.current_kid(), sig))
        }

        async fn verify(&self, kid: &str, msg: &[u8], sig: &[u8]) -> anyhow::Result<bool> {
            // find vk by kid
            let vk = {
                let hist = self.history.read();
                hist.iter().find(|(k, _)| k == kid).map(|(_, v)| *v)
            }
            .ok_or_else(|| anyhow::anyhow!("unknown kid"))?;

            let Ok(sig) = ed25519_dalek::Signature::from_slice(sig) else {
                return Ok(false);
            };
            Ok(vk.verify_strict(msg, &sig).is_ok())
        }

        async fn public_keys(&self) -> anyhow::Result<serde_json::Value> {
            let keys: Vec<_> = {
                let hist = self.history.read();
                hist.iter()
                    .map(|(kid, vk)| {
                        json!({"kid": kid, "vk_b64": URL_SAFE_NO_PAD.encode(vk.to_bytes()), "alg":"Ed25519"})
                    })
                    .collect()
            };
            Ok(json!({"alg":"Ed25519","current": self.current_kid(), "keys": keys }))
        }

        async fn rotate(&self) -> anyhow::Result<String> {
            // Bump to a new key/version using OsRng again.
            let mut csprng = OsRng;
            let sk = SigningKey::generate(&mut csprng);
            let vk = sk.verifying_key();

            {
                let mut head = self.head.write();
                *head = (sk, vk);
            }
            let next = self.version.load(Ordering::SeqCst) + 1;
            self.version.store(next, Ordering::SeqCst);
            let kid = self.current_kid();
            self.history.write().push((kid.clone(), vk));
            Ok(kid)
        }

        async fn attest(&self) -> anyhow::Result<serde_json::Value> {
            self.public_keys().await
        }
    }
}

#[cfg(feature = "dev-kms")]
pub use dev::DevKms;

#[cfg(not(feature = "dev-kms"))]
compile_error!("Enable feature `dev-kms` or wire a real ron-kms client here.");

```

### crates/svc-passport/src/kms/keyslot.rs
<a id="crates-svc-passport-src-kms-keyslot-rs"></a>

```rust
//! RO:WHAT — Keyslot types (versioned KID newtype).
#[derive(Debug, Clone)]
pub struct KeyId(pub String);
impl std::fmt::Display for KeyId {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        self.0.fmt(f)
    }
}

```

### crates/svc-passport/src/kms/mod.rs
<a id="crates-svc-passport-src-kms-mod-rs"></a>

```rust
//! RO:WHAT — KMS boundary (trait) + local dev implementation.
//! RO:WHY  — Swap to ron-kms without touching service code.

pub mod client;
pub mod keyslot;
pub mod rotation;

```

### crates/svc-passport/src/kms/rotation.rs
<a id="crates-svc-passport-src-kms-rotation-rs"></a>

```rust
//! RO:WHAT — Rotation helpers (admin plane).
#![allow(dead_code)]

```

### crates/svc-passport/src/lib.rs
<a id="crates-svc-passport-src-lib-rs"></a>

```rust
//! RO:WHAT — Library root for svc-passport: issue/verify Ed25519 "passports" with versioned KID.
//! RO:WHY  — P3 Identity & Keys; Concerns: SEC/RES/PERF. Short-TTL capability tokens with batch verify.
//! RO:INTERACTS — http::handlers, token::{encode,macaroon}, kms::client, state::issuer, policy::eval
//! RO:INVARIANTS — strict Ed25519 only; deterministic envelopes; no locks across .await
//! RO:METRICS — passport_ops_total, passport_failures_total, passport_op_latency_seconds, passport_batch_len
//! RO:CONFIG — see config.rs (ttl, batch, caps); /metrics + /healthz + /readyz via ron-kernel surfaces
//! RO:SECURITY — no ambient authority; admin routes gated; zeroize ephemeral secrets
//! RO:TEST — tests/* (API smoke), fuzz/* (envelope/caveat), loom/* (rotation under races)
#![forbid(unsafe_code)]

pub mod bootstrap;
pub mod config;
pub mod dto;
pub mod error;
pub mod health;
pub mod http;
pub mod kms;
pub mod metrics;
pub mod policy;
pub mod state;
pub mod telemetry;
pub mod token;
pub mod util;
pub mod verify;

pub use crate::config::Config;

```

### crates/svc-passport/src/main.rs
<a id="crates-svc-passport-src-main-rs"></a>

```rust
//! RO:WHAT — Binary entrypoint: loads config, boots HTTP, exposes /metrics,/healthz,/readyz.
//! RO:WHY  — Service wrapper around library surfaces.
//! RO:INTERACTS — bootstrap::run, telemetry::tracing_init
//! RO:INVARIANTS — truthful readiness; graceful shutdown; no locks across .await

use std::net::SocketAddr;
use svc_passport::{bootstrap, telemetry::tracing_init, Config};
use tracing::info;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    tracing_init::init();
    let cfg = Config::load()?;
    let bind: SocketAddr = cfg.server.bind.parse()?;
    let admin: SocketAddr = cfg.server.admin_bind.parse()?;

    let (_http, http_addr) = bootstrap::run(bind, admin, cfg).await?;
    info!(%http_addr, "svc-passport: listening");
    // Block until Ctrl-C
    tokio::signal::ctrl_c().await?;
    Ok(())
}

```

### crates/svc-passport/src/metrics.rs
<a id="crates-svc-passport-src-metrics-rs"></a>

```rust
// crates/svc-passport/src/metrics.rs
//! RO:WHAT — Prometheus counters/histograms for passport ops + /metrics exporter.
//! RO:WHY  — Golden metrics & perf gates; scrapeable by Prometheus.

use axum::{http::StatusCode, response::IntoResponse};
use once_cell::sync::Lazy;
use prometheus::{
    gather, register_histogram, register_int_counter_vec, Encoder, Histogram, HistogramOpts,
    IntCounterVec, Opts, TextEncoder,
};

pub static OPS_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    let opts = Opts::new("passport_ops_total", "passport operations total")
        .const_label("service", "svc-passport");
    register_int_counter_vec!(opts, &["op", "result", "alg"]).expect("register passport_ops_total")
});

pub static FAILURES_TOTAL: Lazy<IntCounterVec> = Lazy::new(|| {
    let opts = Opts::new("passport_failures_total", "passport failures by reason")
        .const_label("service", "svc-passport");
    register_int_counter_vec!(opts, &["reason"]).expect("register passport_failures_total")
});

pub static OP_LATENCY: Lazy<Histogram> = Lazy::new(|| {
    let opts = HistogramOpts {
        common_opts: Opts::new("passport_op_latency_seconds", "op latency")
            .const_label("service", "svc-passport"),
        buckets: vec![0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1],
    };
    register_histogram!(opts).expect("register passport_op_latency_seconds")
});

pub static BATCH_LEN: Lazy<Histogram> = Lazy::new(|| {
    let opts = HistogramOpts {
        common_opts: Opts::new("passport_batch_len", "verify batch length")
            .const_label("service", "svc-passport"),
        buckets: vec![1.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0],
    };
    register_histogram!(opts).expect("register passport_batch_len")
});

pub async fn export() -> impl IntoResponse {
    let metric_families = gather();
    let mut buf = Vec::with_capacity(16 * 1024);
    let encoder = TextEncoder::new();
    if let Err(e) = encoder.encode(&metric_families, &mut buf) {
        return (
            StatusCode::INTERNAL_SERVER_ERROR,
            format!("encode metrics: {e}"),
        )
            .into_response();
    }
    (
        StatusCode::OK,
        (
            [(axum::http::header::CONTENT_TYPE, encoder.format_type())],
            buf,
        ),
    )
        .into_response()
}

```

### crates/svc-passport/src/policy/eval.rs
<a id="crates-svc-passport-src-policy-eval-rs"></a>

```rust
#![allow(dead_code)]
//! RO:WHAT — (stub) Evaluate scopes/caveats vs requested operation; default allow.
pub fn allow() -> bool {
    true
}

```

### crates/svc-passport/src/policy/mod.rs
<a id="crates-svc-passport-src-policy-mod-rs"></a>

```rust
//! RO:WHAT — Policy adapter (deny-by-default); Bronze: allow all.
pub mod eval;

```

### crates/svc-passport/src/state/audit.rs
<a id="crates-svc-passport-src-state-audit-rs"></a>

```rust
#![allow(dead_code)]
//! RO:WHAT — (stub) Audit sink for issue/verify/revoke events; Bronze: no-op.

```

### crates/svc-passport/src/state/issuer.rs
<a id="crates-svc-passport-src-state-issuer-rs"></a>

```rust
// RO:WHAT   IssuerState: thin service state around a KMS client + helpers.
// RO:WHY    Handlers expect helpers: build_envelope, jwks, rotate, attest, verify_envelope.

use crate::{config::Config, dto::verify::Envelope, error::Error, kms::client::KmsClient};
use base64::{engine::general_purpose::STANDARD, Engine as _};
use parking_lot::RwLock;
use serde_json::{json, Value};
use std::{collections::HashMap, sync::Arc};

#[derive(Clone)]
pub struct IssuerState {
    pub cfg: Config,
    pub kms: Arc<dyn KmsClient>,
    pub cache: Arc<RwLock<HashMap<String, ()>>>,
}

impl IssuerState {
    pub fn new(cfg: Config, kms: Arc<dyn KmsClient>) -> Self {
        Self {
            cfg,
            kms,
            cache: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    /// Sign raw message bytes; returns (kid, signature).
    pub async fn sign(&self, msg: &[u8]) -> Result<(String, Vec<u8>), Error> {
        self.kms.sign(msg).await.map_err(Error::Internal)
    }

    /// Verify signature with kid; returns true/false.
    pub async fn verify(&self, kid: &str, msg: &[u8], sig: &[u8]) -> Result<bool, Error> {
        self.kms
            .verify(kid, msg, sig)
            .await
            .map_err(Error::Internal)
    }

    /// Build a transport envelope from parts.
    pub fn build_envelope(&self, kid: String, msg: Vec<u8>, sig: Vec<u8>) -> Envelope {
        Envelope {
            alg: "Ed25519".to_string(),
            kid,
            msg_b64: STANDARD.encode(msg),
            sig_b64: STANDARD.encode(sig),
        }
    }

    /// Public JWKS (OKP/Ed25519). Converts KMS `public_keys()` shape -> standard JWKS.
    ///
    /// DevKms `public_keys()` returns:
    /// { "alg":"Ed25519", "current":"ed25519/default/vN",
    ///   "keys":[{"kid": "...", "vk_b64": "<urlsafe-b64>", "alg":"Ed25519"}] }
    pub async fn jwks(&self) -> Result<Value, Error> {
        let kms_view = self.kms.public_keys().await.map_err(Error::Internal)?;
        let Some(keys) = kms_view.get("keys").and_then(|v| v.as_array()) else {
            return Ok(json!({ "keys": [] }));
        };

        // Map into OKP JWKS set
        let jwk_keys: Vec<Value> = keys
            .iter()
            .filter_map(|k| {
                let kid = k.get("kid")?.as_str()?;
                let x = k.get("vk_b64")?.as_str()?; // already URL_SAFE_NO_PAD encoded
                Some(json!({
                    "kty": "OKP",
                    "crv": "Ed25519",
                    "use": "sig",
                    "key_ops": ["verify"],
                    "alg": "EdDSA",
                    "kid": kid,
                    "x": x
                }))
            })
            .collect();

        Ok(json!({ "keys": jwk_keys }))
    }
}

```

### crates/svc-passport/src/state/mod.rs
<a id="crates-svc-passport-src-state-mod-rs"></a>

```rust
//! RO:WHAT — Service state (issuer, audit).
pub mod audit;
pub mod issuer;

```

### crates/svc-passport/src/telemetry/mod.rs
<a id="crates-svc-passport-src-telemetry-mod-rs"></a>

```rust
pub mod prometheus;
pub mod tracing_init;

```

### crates/svc-passport/src/telemetry/prometheus.rs
<a id="crates-svc-passport-src-telemetry-prometheus-rs"></a>

```rust
use axum::{http::StatusCode, response::IntoResponse};
use prometheus::{Encoder, TextEncoder};
use ron_kernel::metrics::health::HealthState;

pub async fn metrics_handler() -> impl IntoResponse {
    let mf = prometheus::default_registry().gather();
    let mut buf = Vec::new();
    TextEncoder::new().encode(&mf, &mut buf).unwrap();
    (StatusCode::OK, buf)
}

pub async fn healthz_handler(h: HealthState) -> impl IntoResponse {
    if h.all_ready() {
        StatusCode::OK
    } else {
        StatusCode::SERVICE_UNAVAILABLE
    }
}

```

### crates/svc-passport/src/telemetry/tracing_init.rs
<a id="crates-svc-passport-src-telemetry-tracinginit-rs"></a>

```rust
//! RO:WHAT — Init tracing subscriber with env filter.
use tracing_subscriber::{fmt, EnvFilter};

pub fn init() {
    let _ = fmt()
        .with_env_filter(EnvFilter::from_default_env())
        .with_target(false)
        .try_init();
}

```

### crates/svc-passport/src/test_support.rs
<a id="crates-svc-passport-src-testsupport-rs"></a>

```rust
// crates/svc-passport/src/test_support.rs
// RO:WHAT  Helpers for integration tests that include this file via:
//          #[path = "../src/test_support.rs"] mod test_support;
// RO:WHY   Integration tests compile as a separate crate, so we must
//          import through the external crate name `svc_passport::…`.
// RO:INVARS Never read from disk unless PASSPORT_CONFIG(_FILE) is set;
//           otherwise embed the crate’s default TOML so tests are hermetic.

use std::{env, sync::Arc};

use svc_passport::{
    config::Config,
    kms::client::{DevKms, KmsClient},
    state::issuer::IssuerState,
};

// Embed the crate’s default config so tests don’t depend on CWD.
const DEFAULT_TOML: &str = include_str!("../config/default.toml");

fn load_cfg_for_tests() -> Config {
    // If the runner provided a config (string or file), honor it and let
    // svc_passport::config::Config::load() do the parsing.
    if env::var("PASSPORT_CONFIG").is_ok() || env::var("PASSPORT_CONFIG_FILE").is_ok() {
        return Config::load().expect("Config::load() in tests");
    }

    // Otherwise, inject the embedded TOML via PASSPORT_CONFIG so the crate’s
    // own loader will parse it (no extra dev-deps in the test crate).
    env::set_var("PASSPORT_CONFIG", DEFAULT_TOML);
    Config::load().expect("Config::load() with embedded DEFAULT_TOML")
}

pub fn issuer_state_for_tests() -> IssuerState {
    let kms: Arc<dyn KmsClient> = Arc::new(DevKms::new());
    let cfg = load_cfg_for_tests();
    IssuerState::new(cfg, kms)
}

pub fn default_config() -> Config {
    load_cfg_for_tests()
}

```

### crates/svc-passport/src/token/attenuate.rs
<a id="crates-svc-passport-src-token-attenuate-rs"></a>

```rust
#![allow(dead_code)]
//! Placeholder helpers to attenuate scopes/caveats deterministically.

```

### crates/svc-passport/src/token/caveat.rs
<a id="crates-svc-passport-src-token-caveat-rs"></a>

```rust
#![allow(dead_code)]
//! Placeholder for caveat definitions & serialization rules.

```

### crates/svc-passport/src/token/encode.rs
<a id="crates-svc-passport-src-token-encode-rs"></a>

```rust
//! RO:WHAT — Canonical JSON payload + envelope (base64url, no pad).
//! RO:INVARIANTS — sorted keys; UTF-8 bytes; stable across languages.

use crate::{
    dto::{issue::IssueRequest, verify::Envelope},
    Config,
};
use base64::engine::general_purpose::URL_SAFE_NO_PAD;
use base64::Engine;
use serde_json::{json, Value};
use time::OffsetDateTime;

pub fn canonical_payload(cfg: &Config, req: &IssueRequest) -> anyhow::Result<Value> {
    let now = OffsetDateTime::now_utc().unix_timestamp();
    let ttl = req
        .ttl_s
        .unwrap_or(cfg.passport.default_ttl_s)
        .min(cfg.passport.max_ttl_s);
    let iat = now;
    let exp = now + ttl as i64;
    let nbf = req.nbf.unwrap_or(iat);

    // Basic payload; kid is stamped after sign via IssuerState (KMS head)
    let payload = json!({
        "iss": cfg.passport.issuer,
        "sub": req.sub,
        "aud": req.aud,
        "iat": iat,
        "exp": exp,
        "nbf": nbf,
        "scopes": req.scopes,
        "nonce": req.nonce,
        "ctx": req.ctx
    });

    Ok(payload)
}

pub fn envelope(payload: &Value, kid: &str, sig: &[u8]) -> anyhow::Result<Envelope> {
    let msg = serde_json::to_vec(payload)?;
    Ok(Envelope {
        alg: "Ed25519".into(),
        kid: kid.to_string(),
        sig_b64: URL_SAFE_NO_PAD.encode(sig),
        msg_b64: URL_SAFE_NO_PAD.encode(&msg),
    })
}

pub fn decode_envelope(env: &Envelope) -> anyhow::Result<(Vec<u8>, Vec<u8>)> {
    let msg = URL_SAFE_NO_PAD.decode(&env.msg_b64)?;
    let sig = URL_SAFE_NO_PAD.decode(&env.sig_b64)?;
    Ok((msg, sig))
}

```

### crates/svc-passport/src/token/macaroon.rs
<a id="crates-svc-passport-src-token-macaroon-rs"></a>

```rust
//! RO:WHAT — (stub) Macaroon-like caveats; keep deterministic JSON for signing.
//! RO:NOTE — Silver+: add first-class caveat evaluation and attenuation.

#![allow(dead_code)]
#[derive(Debug, Clone)]
pub struct Caveat {
    pub kind: String,
    pub value: String,
}

```

### crates/svc-passport/src/token/mod.rs
<a id="crates-svc-passport-src-token-mod-rs"></a>

```rust
//! RO:WHAT — Token primitives: canonical payload + envelope helpers.
pub mod attenuate;
pub mod caveat;
pub mod encode;
pub mod macaroon;

```

### crates/svc-passport/src/util/hashing.rs
<a id="crates-svc-passport-src-util-hashing-rs"></a>

```rust
//! RO:WHAT — (stub) Hash helpers if needed later.
#![allow(dead_code)]

```

### crates/svc-passport/src/util/id.rs
<a id="crates-svc-passport-src-util-id-rs"></a>

```rust
//! RO:WHAT — ID helpers (nonce/jti).
pub fn rand_nonce() -> String {
    uuid::Uuid::new_v4().to_string()
}

```

### crates/svc-passport/src/util/mod.rs
<a id="crates-svc-passport-src-util-mod-rs"></a>

```rust
pub mod hashing;
pub mod id;
pub mod time;

```

### crates/svc-passport/src/util/time.rs
<a id="crates-svc-passport-src-util-time-rs"></a>

```rust
//! RO:WHAT — Time helpers (UTC seconds).
pub fn now_s() -> i64 {
    time::OffsetDateTime::now_utc().unix_timestamp()
}

```

### crates/svc-passport/src/verify/mod.rs
<a id="crates-svc-passport-src-verify-mod-rs"></a>

```rust
//! RO:WHAT — Verify pipeline: preflight + crypto calls.
pub mod preflight;

```

### crates/svc-passport/src/verify/preflight.rs
<a id="crates-svc-passport-src-verify-preflight-rs"></a>

```rust
//! RO:WHAT — Cheap checks (iat/nbf/exp/aud size) before crypto.
//! RO:INVARIANTS — bounded skew; msg bytes parsed once.

use crate::{dto::verify::Envelope, error::Error, token::encode::decode_envelope, Config};
use serde_json::Value;
use time::OffsetDateTime;

pub fn time_window(cfg: &Config, env: &Envelope) -> Result<(), Error> {
    let (msg, _sig) = decode_envelope(env).map_err(|_| Error::Malformed)?;
    let v: Value = serde_json::from_slice(&msg).map_err(|_| Error::Malformed)?;
    let now = OffsetDateTime::now_utc().unix_timestamp();
    let skew = cfg.passport.clock_skew_s;

    let iat = v
        .get("iat")
        .and_then(|x| x.as_i64())
        .ok_or(Error::Malformed)?;
    let exp = v
        .get("exp")
        .and_then(|x| x.as_i64())
        .ok_or(Error::Malformed)?;
    let nbf = v.get("nbf").and_then(|x| x.as_i64()).unwrap_or(iat);

    if now + skew < nbf {
        return Err(Error::NotBefore);
    }
    if now - skew > exp {
        return Err(Error::Expired);
    }
    Ok(())
}

```

### crates/svc-passport/testing/profiles/issue_80_20_local.json
<a id="crates-svc-passport-testing-profiles-issue8020local-json"></a>

```json
{
  "description": "80% issue, 15% verify, 5% revoke (local)",
  "rps": 100,
  "duration_s": 60
}

```

### crates/svc-passport/tests/api_issue.rs
<a id="crates-svc-passport-tests-apiissue-rs"></a>

```rust
// Black-box test scaffold for /v1/passport/issue
#[test]
fn issue_scaffold() {
    assert!(true);
}

```

### crates/svc-passport/tests/api_revoke.rs
<a id="crates-svc-passport-tests-apirevoke-rs"></a>

```rust
// Black-box test scaffold for /v1/passport/revoke
#[test]
fn revoke_scaffold() {
    assert!(true);
}

```

### crates/svc-passport/tests/api_verify.rs
<a id="crates-svc-passport-tests-apiverify-rs"></a>

```rust
// Black-box test scaffold for /v1/passport/verify
#[test]
fn verify_scaffold() {
    assert!(true);
}

```

### crates/svc-passport/tests/handlers.rs
<a id="crates-svc-passport-tests-handlers-rs"></a>

```rust
// crates/svc-passport/tests/handlers.rs
use axum::body::to_bytes;
use axum::{body::Body, http, http::Request};
use tower::ServiceExt;

use svc_passport::{health::Health, http::router::build_router};

#[path = "../src/test_support.rs"]
mod test_support;

use base64::{engine::general_purpose::STANDARD, Engine as _};
use serde_json::json;
use test_support::default_config;

#[tokio::test]
async fn healthz_ok() {
    let app = build_router(default_config(), Health::default());
    let resp = app
        .oneshot(
            Request::builder()
                .uri("/healthz")
                .body(Body::empty())
                .unwrap(),
        )
        .await
        .unwrap();

    assert!(resp.status().is_success());
}

#[tokio::test]
async fn issue_then_verify_ok() {
    let app = build_router(default_config(), Health::default());

    // 1) issue
    let body = Body::from(serde_json::to_vec(&json!({"hello":"world"})).unwrap());
    let req = Request::builder()
        .method(http::Method::POST)
        .uri("/v1/passport/issue")
        .header(http::header::CONTENT_TYPE, "application/json")
        .body(body)
        .unwrap();

    let resp = app.clone().oneshot(req).await.unwrap();
    assert!(resp.status().is_success());

    // axum 0.7: to_bytes(body, limit)
    let bytes = to_bytes(resp.into_body(), usize::MAX).await.unwrap();
    let env: serde_json::Value = serde_json::from_slice(&bytes).unwrap();

    let kid = env["kid"].as_str().unwrap().to_string();
    let msg_b64 = env["msg_b64"].as_str().unwrap().to_string();
    let sig_b64 = env["sig_b64"].as_str().unwrap().to_string();

    // 2) verify single
    let verify_env = json!({
        "kid": kid,
        "msg_b64": msg_b64,
        "sig_b64": sig_b64,
        "alg": "Ed25519"
    });
    let req = Request::builder()
        .method(http::Method::POST)
        .uri("/v1/passport/verify")
        .header(http::header::CONTENT_TYPE, "application/json")
        .body(Body::from(serde_json::to_vec(&verify_env).unwrap()))
        .unwrap();

    let resp = app.clone().oneshot(req).await.unwrap();
    assert!(resp.status().is_success());
    let ok: bool =
        serde_json::from_slice(&to_bytes(resp.into_body(), usize::MAX).await.unwrap()).unwrap();
    assert!(ok, "verify should succeed");

    // 3) verify batch (one good, one tampered)
    let mut sig_tampered = STANDARD.decode(sig_b64.as_str()).unwrap();
    if !sig_tampered.is_empty() {
        sig_tampered[0] ^= 0x01;
    }
    let sig_tampered_b64 = STANDARD.encode(sig_tampered);

    let batch_envs = json!([
        verify_env,
        {
          "kid": env["kid"].as_str().unwrap(),
          "msg_b64": env["msg_b64"].as_str().unwrap(),
          "sig_b64": sig_tampered_b64,
          "alg": "Ed25519"
        }
    ]);
    let req = Request::builder()
        .method(http::Method::POST)
        .uri("/v1/passport/verify_batch")
        .header(http::header::CONTENT_TYPE, "application/json")
        .body(Body::from(serde_json::to_vec(&batch_envs).unwrap()))
        .unwrap();

    let resp = app.clone().oneshot(req).await.unwrap();
    assert!(resp.status().is_success());
    let results: Vec<bool> =
        serde_json::from_slice(&to_bytes(resp.into_body(), usize::MAX).await.unwrap()).unwrap();
    assert_eq!(results, vec![true, false], "batch should be [true,false]");
}

```

### crates/svc-passport/tests/invariants.rs
<a id="crates-svc-passport-tests-invariants-rs"></a>

```rust
// Property/invariant test scaffold: attenuation never widens authority.
#[test]
fn invariants_scaffold() {
    assert!(true);
}

```

### crates/svc-passport/tests/issuer.rs
<a id="crates-svc-passport-tests-issuer-rs"></a>

```rust
// crates/svc-passport/tests/issuer.rs
use svc_passport::state::issuer::IssuerState;

#[path = "../src/test_support.rs"]
mod test_support;

use test_support::issuer_state_for_tests;

#[tokio::test]
async fn sign_and_verify_round_trip_ok() {
    let issuer: IssuerState = issuer_state_for_tests();

    let msg = br#"{"hello":"world"}"#.to_vec();
    let (kid, sig) = issuer.sign(&msg).await.expect("sign");
    let ok = issuer.verify(&kid, &msg, &sig).await.expect("verify");

    assert!(ok, "signature should verify");
}

#[tokio::test]
async fn verify_fails_when_tampered() {
    let issuer: IssuerState = issuer_state_for_tests();

    let msg = br#"{"hello":"world"}"#.to_vec();
    let (kid, mut sig) = issuer.sign(&msg).await.expect("sign");

    // Tamper a single byte in the signature buffer (if long enough).
    if !sig.is_empty() {
        sig[0] ^= 0x01;
    }
    let ok = issuer
        .verify(&kid, &msg, &sig)
        .await
        .expect("verify call ok");
    assert!(!ok, "tampered signature must fail");
}

```

### crates/svc-passport/tests/readiness.rs
<a id="crates-svc-passport-tests-readiness-rs"></a>

```rust
// Readiness gate scaffold
#[test]
fn readiness_scaffold() {
    assert!(true);
}

```



---



# ron-auth

_Source: crates/ron-auth/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-11-09T18:46:47Z -->
# Code Bundle — `ron-auth`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-auth/.github/workflows/ci.yml](#crates-ron-auth--github-workflows-ci-yml)
- [crates/ron-auth/.github/workflows/pq-matrix.yml](#crates-ron-auth--github-workflows-pq-matrix-yml)
- [crates/ron-auth/Cargo.toml](#crates-ron-auth-Cargo-toml)
- [crates/ron-auth/benches/verify_bench.rs](#crates-ron-auth-benches-verifybench-rs)
- [crates/ron-auth/deny.toml](#crates-ron-auth-deny-toml)
- [crates/ron-auth/examples/verify.rs](#crates-ron-auth-examples-verify-rs)
- [crates/ron-auth/fuzz/fuzz_targets/token_parser_fuzz.rs](#crates-ron-auth-fuzz-fuzztargets-tokenparserfuzz-rs)
- [crates/ron-auth/rustfmt.toml](#crates-ron-auth-rustfmt-toml)
- [crates/ron-auth/scripts/smoke_auth.sh](#crates-ron-auth-scripts-smokeauth-sh)
- [crates/ron-auth/src/bounds.rs](#crates-ron-auth-src-bounds-rs)
- [crates/ron-auth/src/builder.rs](#crates-ron-auth-src-builder-rs)
- [crates/ron-auth/src/capability/caveat.rs](#crates-ron-auth-src-capability-caveat-rs)
- [crates/ron-auth/src/capability/encode.rs](#crates-ron-auth-src-capability-encode-rs)
- [crates/ron-auth/src/capability/mod.rs](#crates-ron-auth-src-capability-mod-rs)
- [crates/ron-auth/src/capability/scope.rs](#crates-ron-auth-src-capability-scope-rs)
- [crates/ron-auth/src/caveats/builtin.rs](#crates-ron-auth-src-caveats-builtin-rs)
- [crates/ron-auth/src/caveats/custom.rs](#crates-ron-auth-src-caveats-custom-rs)
- [crates/ron-auth/src/caveats/mod.rs](#crates-ron-auth-src-caveats-mod-rs)
- [crates/ron-auth/src/caveats/registry.rs](#crates-ron-auth-src-caveats-registry-rs)
- [crates/ron-auth/src/cbor.rs](#crates-ron-auth-src-cbor-rs)
- [crates/ron-auth/src/config/env.rs](#crates-ron-auth-src-config-env-rs)
- [crates/ron-auth/src/config/mod.rs](#crates-ron-auth-src-config-mod-rs)
- [crates/ron-auth/src/config/verifier_config.rs](#crates-ron-auth-src-config-verifierconfig-rs)
- [crates/ron-auth/src/ctx.rs](#crates-ron-auth-src-ctx-rs)
- [crates/ron-auth/src/errors.rs](#crates-ron-auth-src-errors-rs)
- [crates/ron-auth/src/keys/mac_handle.rs](#crates-ron-auth-src-keys-machandle-rs)
- [crates/ron-auth/src/keys/mod.rs](#crates-ron-auth-src-keys-mod-rs)
- [crates/ron-auth/src/keys/traits.rs](#crates-ron-auth-src-keys-traits-rs)
- [crates/ron-auth/src/lib.rs](#crates-ron-auth-src-lib-rs)
- [crates/ron-auth/src/mac.rs](#crates-ron-auth-src-mac-rs)
- [crates/ron-auth/src/metrics.rs](#crates-ron-auth-src-metrics-rs)
- [crates/ron-auth/src/pq/mod.rs](#crates-ron-auth-src-pq-mod-rs)
- [crates/ron-auth/src/pq/sig_adapter.rs](#crates-ron-auth-src-pq-sigadapter-rs)
- [crates/ron-auth/src/prelude.rs](#crates-ron-auth-src-prelude-rs)
- [crates/ron-auth/src/redact.rs](#crates-ron-auth-src-redact-rs)
- [crates/ron-auth/src/types.rs](#crates-ron-auth-src-types-rs)
- [crates/ron-auth/src/verify/checks.rs](#crates-ron-auth-src-verify-checks-rs)
- [crates/ron-auth/src/verify/decision.rs](#crates-ron-auth-src-verify-decision-rs)
- [crates/ron-auth/src/verify/error.rs](#crates-ron-auth-src-verify-error-rs)
- [crates/ron-auth/src/verify/eval.rs](#crates-ron-auth-src-verify-eval-rs)
- [crates/ron-auth/src/verify/mod.rs](#crates-ron-auth-src-verify-mod-rs)
- [crates/ron-auth/src/verify/parse.rs](#crates-ron-auth-src-verify-parse-rs)
- [crates/ron-auth/src/verify/pipeline.rs](#crates-ron-auth-src-verify-pipeline-rs)
- [crates/ron-auth/src/verify/soa.rs](#crates-ron-auth-src-verify-soa-rs)
- [crates/ron-auth/src/verify/soa_eval.rs](#crates-ron-auth-src-verify-soaeval-rs)
- [crates/ron-auth/src/verify/streaming.rs](#crates-ron-auth-src-verify-streaming-rs)
- [crates/ron-auth/src/zk/mod.rs](#crates-ron-auth-src-zk-mod-rs)
- [crates/ron-auth/testing/vectors/ron-auth/v1/allow_example.json](#crates-ron-auth-testing-vectors-ron-auth-v1-allowexample-json)
- [crates/ron-auth/testing/vectors/ron-auth/v1/custom_ns_examples.json](#crates-ron-auth-testing-vectors-ron-auth-v1-customnsexamples-json)
- [crates/ron-auth/testing/vectors/ron-auth/v1/deny_expired.json](#crates-ron-auth-testing-vectors-ron-auth-v1-denyexpired-json)
- [crates/ron-auth/testing/vectors/ron-auth/v1/deny_unknown_kid.json](#crates-ron-auth-testing-vectors-ron-auth-v1-denyunknownkid-json)
- [crates/ron-auth/testing/vectors/ron-auth/v1/pq_allow.json](#crates-ron-auth-testing-vectors-ron-auth-v1-pqallow-json)
- [crates/ron-auth/testing/vectors/ron-auth/v1/pq_deny_mismatch.json](#crates-ron-auth-testing-vectors-ron-auth-v1-pqdenymismatch-json)
- [crates/ron-auth/tests/allow_deny_vectors.rs](#crates-ron-auth-tests-allowdenyvectors-rs)
- [crates/ron-auth/tests/amnesia_mode.rs](#crates-ron-auth-tests-amnesiamode-rs)
- [crates/ron-auth/tests/attenuation_monotonicity.rs](#crates-ron-auth-tests-attenuationmonotonicity-rs)
- [crates/ron-auth/tests/compat_public_api.rs](#crates-ron-auth-tests-compatpublicapi-rs)
- [crates/ron-auth/tests/ip_cidr.rs](#crates-ron-auth-tests-ipcidr-rs)
- [crates/ron-auth/tests/loom_verify.rs](#crates-ron-auth-tests-loomverify-rs)
- [crates/ron-auth/tests/parser_fixtures.rs](#crates-ron-auth-tests-parserfixtures-rs)
- [crates/ron-auth/tests/verify_batch_order.rs](#crates-ron-auth-tests-verifybatchorder-rs)
- [crates/ron-auth/tests/verify_error_path.rs](#crates-ron-auth-tests-verifyerrorpath-rs)
- [crates/ron-auth/tests/verify_happy_path.rs](#crates-ron-auth-tests-verifyhappypath-rs)

### crates/ron-auth/.github/workflows/ci.yml
<a id="crates-ron-auth--github-workflows-ci-yml"></a>

```yaml
name: CI (ron-auth2)

on:
  push:
    paths:
      - "crates/ron-auth2/**"
  pull_request:
    paths:
      - "crates/ron-auth2/**"

jobs:
  build-test:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: crates/ron-auth2
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: 1.80.0
      - run: cargo fmt --all -- --check
      - run: cargo clippy --all-targets -- -D warnings
      - run: cargo build --features ""
      - run: cargo test --features ""
      - run: echo "placeholder: cargo-deny/public-api checks wired later"
```

### crates/ron-auth/.github/workflows/pq-matrix.yml
<a id="crates-ron-auth--github-workflows-pq-matrix-yml"></a>

```yaml
name: PQ Matrix (ron-auth2)

on:
  push:
    paths:
      - "crates/ron-auth2/**"
  pull_request:
    paths:
      - "crates/ron-auth2/**"

jobs:
  matrix:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        features: ["", "pq", "pq-hybrid", "pq-only"]
    defaults:
      run:
        working-directory: crates/ron-auth2
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: 1.80.0
      - run: cargo build --features "${{ matrix.features }}"
      - run: cargo test --features "${{ matrix.features }}"
```

### crates/ron-auth/Cargo.toml
<a id="crates-ron-auth-Cargo-toml"></a>

```toml
[package]
name = "ron-auth"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
description = "Capability-based auth for RON-CORE"
readme = "README.md"
repository = "https://github.com/your-org/rusty-onions"
keywords = ["auth", "capability", "macaroon"]
categories = ["authentication", "cryptography"]

[features]
# Keep defaults minimal. Turn knobs on in benches or services.
default = ["std"]
std = []

# Perf toggles
bench-eval-modes = []
simd-b64 = ["base64-simd"]
fast-cbor = ["ciborium"]          # keep as-is (disabled by default)
parallel = ["rayon"]

# New: zero-copy CBOR scaffold (not enabled by default).
# First iteration keeps current serde encoding on the wire; we will
# A/B a borrowed decode path in a later patch behind this flag.
minicbor-zerocopy = ["minicbor"]

[dependencies]
serde = { version = "1.0", features = ["derive"] }
serde_bytes = "0.11"
serde_cbor = "0.11"
ciborium = { version = "0.2", optional = true }
base64 = "0.22"
smallvec = "1.15"
blake3 = "1.5"
ipnet = "2.11"
thiserror = "1.0"

# Feature-gated perf deps
base64-simd = { version = "0.8", optional = true }
rayon = { version = "1.11", optional = true }
minicbor = { version = "0.25", optional = true, features = ["std", "alloc"] }

[dev-dependencies]
criterion = { version = "0.5", features = ["html_reports"] }
proptest = "1.4"
loom = "0.7"

# Tell Cargo this bench uses Criterion (not the default test harness)
[[bench]]
name = "verify_bench"
harness = false

```

### crates/ron-auth/benches/verify_bench.rs
<a id="crates-ron-auth-benches-verifybench-rs"></a>

```rust
// RO:WHAT   Criterion microbench for verify_token / verify_many (small + heavy tokens).
// RO:WHY    Show hybrid crossover; optionally compare streaming-only vs SoA-only.
// RO:INVARIANTS Pure; BLAKE3; deterministic; no I/O.

use criterion::{black_box, criterion_group, criterion_main, BatchSize, Criterion};
#[cfg(feature = "bench-eval-modes")]
use ron_auth::verify::{
    verify_many_soa_only, verify_many_streaming_only, verify_token_soa_only,
    verify_token_streaming_only,
};
use ron_auth::{
    sign_and_encode_b64url, verify_many, verify_token, CapabilityBuilder, Caveat, MacKey,
    MacKeyProvider, RequestCtx, Scope, VerifierConfig,
};
use serde_cbor::Value;
use std::net::IpAddr;
use std::str::FromStr;

#[derive(Clone)]
struct StaticKeys;
impl MacKeyProvider for StaticKeys {
    fn key_for(&self, kid: &str, tid: &str) -> Option<MacKey> {
        if kid == "k1" && tid == "test" {
            Some(MacKey(*b"0123456789abcdef0123456789abcdef"))
        } else {
            None
        }
    }
}

fn now() -> u64 {
    1_700_000_000
}
fn make_cfg() -> VerifierConfig {
    VerifierConfig {
        max_token_bytes: 4096,
        max_caveats: 128,
        clock_skew_secs: 60,
        // NEW knob in Perf Pack A (exported by ron-auth); keep default crossover.
        soa_threshold: 8,
    }
}

fn base_ctx() -> RequestCtx {
    // Method uppercased once; matches verifier’s fast path.
    RequestCtx {
        now_unix_s: now(),
        method: "GET".into(),
        path: "/index/1".into(),
        peer_ip: Some(IpAddr::from_str("127.0.0.1").unwrap()),
        object_addr: None,
        tenant: "test".into(),
        amnesia: false,
        policy_digest_hex: Some("aud-demo".into()),
        extras: Value::Null,
    }
}

fn make_token_small(keys: &impl MacKeyProvider) -> String {
    let scope = Scope {
        prefix: Some("/index/".into()),
        methods: vec!["GET".into()],
        max_bytes: None,
    };
    let cap = CapabilityBuilder::new(scope, "test", "k1")
        .caveat(Caveat::Aud("aud-demo".into()))
        .caveat(Caveat::PathPrefix("/index/".into()))
        .caveat(Caveat::Method(vec!["GET".into()]))
        .caveat(Caveat::Tenant("test".into()))
        .caveat(Caveat::Exp(now() + 600))
        .build();
    sign_and_encode_b64url(&cap, keys).unwrap()
}

// Heavier capability: multi-methods, prefixes, CIDRs, and bounds (~24–32 caveats).
fn make_token_heavy(keys: &impl MacKeyProvider) -> String {
    let methods = vec![
        "GET", "HEAD", "POST", "PUT", "PATCH", "DELETE", "OPTIONS", "TRACE", "CONNECT", "PROPFIND",
        "SEARCH", "COPY",
    ]
    .into_iter()
    .map(|s| s.to_string())
    .collect::<Vec<_>>();

    let scope = Scope {
        prefix: Some("/api/v1/tenant/test/objects/".into()),
        methods: methods.clone(),
        max_bytes: None,
    };

    let mut builder = CapabilityBuilder::new(scope, "test", "k1")
        .caveat(Caveat::Aud("aud-demo".into()))
        .caveat(Caveat::Tenant("test".into()))
        .caveat(Caveat::Exp(now() + 600))
        .caveat(Caveat::PathPrefix("/api/".into()))
        .caveat(Caveat::PathPrefix("/api/v1/".into()))
        .caveat(Caveat::PathPrefix("/api/v1/tenant/".into()))
        .caveat(Caveat::PathPrefix("/api/v1/tenant/test/".into()))
        .caveat(Caveat::Method(methods))
        .caveat(Caveat::IpCidr("127.0.0.0/8".into()))
        .caveat(Caveat::IpCidr("10.0.0.0/8".into()))
        .caveat(Caveat::IpCidr("192.168.0.0/16".into()))
        .caveat(Caveat::IpCidr("172.16.0.0/12".into()))
        .caveat(Caveat::BytesLe(1_048_576))
        .caveat(Caveat::Amnesia(false));

    // pad to ~30 caveats with no-op customs (ignored by evaluator)
    for i in 0..6 {
        builder = builder.caveat(Caveat::Custom {
            name: format!("x{}", i),
            ns: "demo".into(),
            cbor: Value::Null,
        });
    }

    let cap = builder.build();
    sign_and_encode_b64url(&cap, keys).unwrap()
}

fn benches_small(c: &mut Criterion) {
    let keys = StaticKeys;
    let token = make_token_small(&keys);
    let cfg_single = make_cfg();
    let ctx_single = base_ctx();

    c.bench_function("verify_single", |b| {
        b.iter(|| {
            let d = verify_token(&cfg_single, black_box(&token), &ctx_single, &keys).unwrap();
            black_box(d);
        })
    });

    c.bench_function("verify_batch_64_loop", |b| {
        b.iter_batched(
            || {
                let v: Vec<String> = vec![token.clone(); 64];
                (v, base_ctx(), make_cfg(), keys.clone())
            },
            |(tokens, ctx, cfg, keys)| {
                for t in tokens.iter() {
                    let d = verify_token(&cfg, t, &ctx, &keys).unwrap();
                    black_box(d);
                }
            },
            BatchSize::SmallInput,
        )
    });

    c.bench_function("verify_many_64", |b| {
        b.iter_batched(
            || {
                let v: Vec<String> = vec![token.clone(); 64];
                (v, base_ctx(), make_cfg(), keys.clone())
            },
            |(tokens, ctx, cfg, keys)| {
                let decisions = verify_many(&cfg, &tokens, &ctx, &keys).unwrap();
                black_box(decisions);
            },
            BatchSize::SmallInput,
        )
    });
}

fn benches_heavy(c: &mut Criterion) {
    let keys = StaticKeys;
    let token = make_token_heavy(&keys);

    c.bench_function("verify_single_heavy", |b| {
        b.iter(|| {
            let d = verify_token(&make_cfg(), black_box(&token), &base_ctx(), &keys).unwrap();
            black_box(d);
        })
    });

    c.bench_function("verify_many_64_heavy", |b| {
        b.iter_batched(
            || {
                let v: Vec<String> = vec![token.clone(); 64];
                (v, base_ctx(), make_cfg(), keys.clone())
            },
            |(tokens, ctx, cfg, keys)| {
                let decisions = verify_many(&cfg, &tokens, &ctx, &keys).unwrap();
                black_box(decisions);
            },
            BatchSize::SmallInput,
        )
    });

    // Optional: hard-toggle comparisons (requires `--features bench-eval-modes`)
    #[cfg(feature = "bench-eval-modes")]
    {
        c.bench_function("verify_single_heavy_streaming_only", |b| {
            b.iter(|| {
                let d =
                    verify_token_streaming_only(&make_cfg(), black_box(&token), &base_ctx(), &keys)
                        .unwrap();
                black_box(d);
            })
        });

        c.bench_function("verify_single_heavy_soa_only", |b| {
            b.iter(|| {
                let d = verify_token_soa_only(&make_cfg(), black_box(&token), &base_ctx(), &keys)
                    .unwrap();
                black_box(d);
            })
        });

        c.bench_function("verify_many_64_heavy_streaming_only", |b| {
            b.iter_batched(
                || {
                    let v: Vec<String> = vec![token.clone(); 64];
                    (v, base_ctx(), make_cfg(), keys.clone())
                },
                |(tokens, ctx, cfg, keys)| {
                    let decisions = verify_many_streaming_only(&cfg, &tokens, &ctx, &keys).unwrap();
                    black_box(decisions);
                },
                BatchSize::SmallInput,
            )
        });

        c.bench_function("verify_many_64_heavy_soa_only", |b| {
            b.iter_batched(
                || {
                    let v: Vec<String> = vec![token.clone(); 64];
                    (v, base_ctx(), make_cfg(), keys.clone())
                },
                |(tokens, ctx, cfg, keys)| {
                    let decisions = verify_many_soa_only(&cfg, &tokens, &ctx, &keys).unwrap();
                    black_box(decisions);
                },
                BatchSize::SmallInput,
            )
        });
    }
}

criterion_group!(benches, benches_small, benches_heavy);
criterion_main!(benches);

```

### crates/ron-auth/deny.toml
<a id="crates-ron-auth-deny-toml"></a>

```toml
[advisories]
yanked = "deny"
ignore = []

[bans]
multiple-versions = "warn"
wildcards = "deny"
deny = [
  { name = "tokio" },
  { name = "hyper" },
  { name = "reqwest" },
]

[sources]
unknown-registry = "deny"
unknown-git = "deny"
allow-registry = ["https://github.com/rust-lang/crates.io-index"]

[licenses]
unlicensed = "deny"
allow = [
  "MIT",
  "Apache-2.0",
  "Unicode-3.0",
  "Unicode-DFS-2016",
  "CC0-1.0",
  "CDLA-Permissive-2.0",
  "OpenSSL"
]
```

### crates/ron-auth/examples/verify.rs
<a id="crates-ron-auth-examples-verify-rs"></a>

```rust
//! Minimal end-to-end example: verify one token, then a batch.
use ron_auth::{
    verify_many, verify_token, Decision, MacKey, MacKeyProvider, RequestCtx, VerifierConfig,
};
use serde_cbor::Value;

#[derive(Clone)]
struct StaticKeys;
impl MacKeyProvider for StaticKeys {
    fn key_for(&self, kid: &str, tid: &str) -> Option<MacKey> {
        if kid == "k1" && tid == "tenant-a" {
            Some(MacKey(*b"0123456789abcdef0123456789abcdef"))
        } else {
            None
        }
    }
}

fn ctx() -> RequestCtx {
    RequestCtx {
        now_unix_s: 1_700_000_000,
        method: "GET".into(),
        path: "/index/abc".into(),
        peer_ip: None,
        object_addr: None,
        tenant: "tenant-a".into(),
        amnesia: false,
        policy_digest_hex: None,
        extras: Value::Null,
    }
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let cfg = VerifierConfig::with_defaults();

    // Single
    let token = std::env::args().nth(1).expect("pass b64 token");
    let d: Decision = verify_token(&cfg, &token, &ctx(), &StaticKeys)?;
    println!("single: {d:?}");

    // Batch
    let batch = vec![token.clone(), token.clone(), token];
    let out = verify_many(&cfg, &batch, &ctx(), &StaticKeys)?;
    println!("batch: {out:?}");

    Ok(())
}

```

### crates/ron-auth/fuzz/fuzz_targets/token_parser_fuzz.rs
<a id="crates-ron-auth-fuzz-fuzztargets-tokenparserfuzz-rs"></a>

```rust
// fuzz target: token parser placeholder
```

### crates/ron-auth/rustfmt.toml
<a id="crates-ron-auth-rustfmt-toml"></a>

```toml
max_width = 100
edition = "2021"
use_field_init_shorthand = true
newline_style = "Unix"
```

### crates/ron-auth/scripts/smoke_auth.sh
<a id="crates-ron-auth-scripts-smokeauth-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Simple smoke for ron-auth:
#  - fmt, clippy, tests
#  - builds the example
#  - runs the example with a provided or default b64url token
#
# Usage:
#   crates/ron-auth/scripts/smoke_auth.sh
#   crates/ron-auth/scripts/smoke_auth.sh "<base64url_token>"
#
# Env:
#   FEATURES   - Cargo features to use for build/test (default: "")
#   RUSTFLAGS  - Optional (e.g., -C target-cpu=native)
#   RAYON_NUM_THREADS - Optional for benches or future parallel runs

CRATE_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
cd "$CRATE_DIR"

FEATURES="${FEATURES:-}"

echo "[INFO] crate dir = $CRATE_DIR"
echo "[INFO] features  = '${FEATURES}'"

echo "[STEP] cargo fmt"
cargo fmt -p ron-auth

echo "[STEP] cargo clippy (deny warnings)"
if [[ -n "$FEATURES" ]]; then
  cargo clippy -p ron-auth --features "$FEATURES" --all-targets -- -D warnings
else
  cargo clippy -p ron-auth --all-targets -- -D warnings
fi

echo "[STEP] cargo test"
if [[ -n "$FEATURES" ]]; then
  cargo test -p ron-auth --features "$FEATURES"
else
  cargo test -p ron-auth
fi

# Build the example (exists in examples/verify.rs)
echo "[STEP] build example: verify"
if [[ -n "$FEATURES" ]]; then
  cargo build -p ron-auth --features "$FEATURES" --example verify
else
  cargo build -p ron-auth --example verify
fi

# Default demo token: valid base64url JSON-ish payload; verification will likely return Deny
# unless it matches your StaticKeys/kid/tid and caveats.
DEFAULT_TOKEN='eyJkZW1vIjoidG9rZW4tZm9yLXJvbi1hdXRoLXNtb2tlIn0'

TOKEN="${1:-$DEFAULT_TOKEN}"

echo "[STEP] run example: verify (token length: ${#TOKEN})"
set +e
if [[ -n "$FEATURES" ]]; then
  cargo run -p ron-auth --features "$FEATURES" --example verify -- "$TOKEN"
else
  cargo run -p ron-auth --example verify -- "$TOKEN"
fi
STATUS=$?
set -e

# We don't fail the smoke if the example returns Deny/Err (non-zero). The goal is “it runs”.
if [[ $STATUS -ne 0 ]]; then
  echo "[WARN] example exited with status ${STATUS} (often OK if token doesn't match keys/caveats)"
else
  echo "[OK] example ran successfully"
fi

echo "[DONE] smoke_auth complete."

```

### crates/ron-auth/src/bounds.rs
<a id="crates-ron-auth-src-bounds-rs"></a>

```rust
//! RO:WHAT  Centralized bounds helpers.
//! RO:WHY   Enforce size/complexity limits consistently.

/// Rough upper bound for Base64URL (no padding) length for a given raw size.
pub fn max_b64url_chars_for(max_bytes: usize) -> usize {
    // ceiling((max_bytes * 4) / 3) without padding; use saturating math for safety.
    max_bytes.saturating_mul(4).div_ceil(3)
}

```

### crates/ron-auth/src/builder.rs
<a id="crates-ron-auth-src-builder-rs"></a>

```rust
//! RO:WHAT  Capability attenuation builder (pure); requires caller-provided signer.
//! RO:WHY   Build stricter children; never broaden scope.
//! RO:INVARIANTS No I/O; callers inject MacKeyProvider to sign.

use crate::types::MacKey;
use crate::{
    cbor::encode_b64url_cbor_capability,
    mac::compute_mac,
    types::{Capability, Caveat, MacKeyProvider, Scope},
};

#[derive(Debug, Clone)]
pub struct CapabilityBuilder {
    tid: String,
    kid: String,
    scope: Scope,
    caveats: Vec<Caveat>,
}

impl CapabilityBuilder {
    pub fn new(scope: Scope, tid: impl Into<String>, kid: impl Into<String>) -> Self {
        Self {
            tid: tid.into(),
            kid: kid.into(),
            scope,
            caveats: Vec::new(),
        }
    }

    pub fn caveat(mut self, c: Caveat) -> Self {
        self.caveats.push(c);
        self
    }

    pub fn build(self) -> Capability {
        // Unsigned until caller signs; mac is zeroed.
        Capability {
            tid: self.tid,
            kid: self.kid,
            scope: self.scope,
            caveats: self.caveats,
            mac: vec![0u8; 32],
        }
    }
}

/// Helper for hosts/tests to sign-and-encode using their key source.
/// Note: this is referenced primarily from integration tests and host crates.
#[allow(dead_code)]
pub fn sign_and_encode_b64url(
    cap: &mut Capability,
    keys: &impl MacKeyProvider,
) -> Result<String, &'static str> {
    let MacKey(k) = keys.key_for(&cap.kid, &cap.tid).ok_or("unknown kid")?;
    let tag = compute_mac(&MacKey(k), cap);
    cap.mac.clear();
    cap.mac.extend_from_slice(&tag);
    Ok(encode_b64url_cbor_capability(cap))
}

```

### crates/ron-auth/src/capability/caveat.rs
<a id="crates-ron-auth-src-capability-caveat-rs"></a>

```rust
// capability::caveat placeholder
```

### crates/ron-auth/src/capability/encode.rs
<a id="crates-ron-auth-src-capability-encode-rs"></a>

```rust
// capability::encode placeholder
```

### crates/ron-auth/src/capability/mod.rs
<a id="crates-ron-auth-src-capability-mod-rs"></a>

```rust
// capability::mod placeholder
```

### crates/ron-auth/src/capability/scope.rs
<a id="crates-ron-auth-src-capability-scope-rs"></a>

```rust
// capability::scope placeholder
```

### crates/ron-auth/src/caveats/builtin.rs
<a id="crates-ron-auth-src-caveats-builtin-rs"></a>

```rust
// caveats::builtin placeholder
```

### crates/ron-auth/src/caveats/custom.rs
<a id="crates-ron-auth-src-caveats-custom-rs"></a>

```rust
// caveats::custom placeholder
```

### crates/ron-auth/src/caveats/mod.rs
<a id="crates-ron-auth-src-caveats-mod-rs"></a>

```rust
// caveats::mod placeholder
```

### crates/ron-auth/src/caveats/registry.rs
<a id="crates-ron-auth-src-caveats-registry-rs"></a>

```rust
// caveats::registry placeholder
```

### crates/ron-auth/src/cbor.rs
<a id="crates-ron-auth-src-cbor-rs"></a>

```rust
//! RO:WHAT  CBOR (de)serialization + Base64URL helpers (no padding).
//! RO:WHY   Keep encoding deterministic; centralized parsing; low alloc.
//! RO:INVARIANTS Deterministic CBOR; URL_SAFE_NO_PAD; strict size checks; buffer reuse.

#![allow(clippy::needless_return)]

use crate::{errors::AuthError, types::Capability};
use base64::engine::general_purpose::URL_SAFE_NO_PAD;
use base64::Engine;

#[cfg(feature = "fast-cbor")]
use ciborium::de::from_reader as cbor_from_reader;
#[cfg(not(feature = "fast-cbor"))]
use serde_cbor::from_slice as cbor_from_slice;

#[cfg(feature = "simd-b64")]
use base64_simd::URL_SAFE_NO_PAD as SIMD_URL_SAFE_NO_PAD;

/// Decode a Base64URL (no padding) CBOR-encoded Capability into `scratch` to minimize allocs.
pub fn decode_b64url_cbor_capability_with_buf(
    b64: &str,
    max_bytes: usize,
    scratch: &mut Vec<u8>,
) -> Result<Capability, AuthError> {
    // Decode Base64URL → bytes into `scratch`.
    #[cfg(feature = "simd-b64")]
    {
        // SIMD decode returns a fresh Vec; move it into `scratch` with no extra copy.
        let decoded = SIMD_URL_SAFE_NO_PAD
            .decode_to_vec(b64.as_bytes())
            .map_err(|_| AuthError::Malformed("base64url"))?;
        if decoded.len() > max_bytes {
            return Err(AuthError::Bounds);
        }
        *scratch = decoded;
    }

    #[cfg(not(feature = "simd-b64"))]
    {
        scratch.clear();
        URL_SAFE_NO_PAD
            .decode_vec(b64.as_bytes(), scratch)
            .map_err(|_| AuthError::Malformed("base64url"))?;
        if scratch.len() > max_bytes {
            return Err(AuthError::Bounds);
        }
    }

    // Decode CBOR → Capability (serde-compatible). `fast-cbor` uses a reader form.
    #[cfg(feature = "fast-cbor")]
    let cap: Capability =
        cbor_from_reader(scratch.as_slice()).map_err(|_| AuthError::Malformed("cbor"))?;

    #[cfg(not(feature = "fast-cbor"))]
    let cap: Capability = cbor_from_slice(scratch).map_err(|_| AuthError::Malformed("cbor"))?;

    // Basic MAC sanity: 32 bytes (BLAKE3 keyed).
    if cap.mac.len() != 32 {
        return Err(AuthError::Malformed("mac_len"));
    }
    Ok(cap)
}

/// Backwards-compatible wrapper (allocates) — prefer the `_with_buf` variant on hot paths.
#[allow(dead_code)]
pub fn decode_b64url_cbor_capability(b64: &str, max_bytes: usize) -> Result<Capability, AuthError> {
    let mut tmp = Vec::new();
    decode_b64url_cbor_capability_with_buf(b64, max_bytes, &mut tmp)
}

#[allow(dead_code)]
pub fn encode_b64url_cbor_capability(cap: &Capability) -> String {
    let bytes = serde_cbor::to_vec(cap).expect("capability to cbor");
    URL_SAFE_NO_PAD.encode(bytes)
}

/// Deterministic CBOR fragment encoder for MAC chaining (allocating version).
#[allow(dead_code)]
pub fn cbor_fragment<T: serde::Serialize>(t: &T) -> Vec<u8> {
    serde_cbor::to_vec(t).expect("cbor fragment")
}

/// Deterministic CBOR fragment encoder that writes into `buf` (reused across calls).
pub fn cbor_fragment_into<T: serde::Serialize>(t: &T, buf: &mut Vec<u8>) {
    buf.clear();
    // serde_cbor::to_writer keeps canonical ordering for our simple maps/seq usage.
    serde_cbor::to_writer(buf, t).expect("cbor fragment into buf");
}

```

### crates/ron-auth/src/config/env.rs
<a id="crates-ron-auth-src-config-env-rs"></a>

```rust
// config::env placeholder (feature: config-env)
```

### crates/ron-auth/src/config/mod.rs
<a id="crates-ron-auth-src-config-mod-rs"></a>

```rust
// config::mod placeholder
```

### crates/ron-auth/src/config/verifier_config.rs
<a id="crates-ron-auth-src-config-verifierconfig-rs"></a>

```rust
// config::verifier_config placeholder
```

### crates/ron-auth/src/ctx.rs
<a id="crates-ron-auth-src-ctx-rs"></a>

```rust
// ctx placeholder
```

### crates/ron-auth/src/errors.rs
<a id="crates-ron-auth-src-errors-rs"></a>

```rust
//! RO:WHAT  Public error/deny taxonomy (stable).
//! RO:WHY   Callers map to metrics and user-facing problem docs.
//! RO:INVARIANTS Codes/reasons are semver-stable.

use serde::{Deserialize, Serialize};
use thiserror::Error;

#[derive(Debug, Error)]
pub enum AuthError {
    #[error("malformed token: {0}")]
    Malformed(&'static str),
    #[error("bounds exceeded")]
    Bounds,
    #[error("unknown kid")]
    UnknownKid,
    #[error("mac mismatch")]
    MacMismatch,
    #[error("expired")]
    Expired,
    #[error("not yet valid")]
    NotYetValid,
    #[error("policy deny")]
    PolicyDeny, // Decision::Deny will contain reasons; this is for strict-mode callers.
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(tag = "reason", content = "detail")]
pub enum DenyReason {
    // Time
    Expired,
    NotYetValid,
    // Shape
    BadAudience,
    MethodNotAllowed,
    PathNotAllowed,
    IpNotAllowed,
    TenantMismatch,
    BytesExceed,
    RateExceeded, // placeholder for future rate caveat eval
    Custom(String),
}

```

### crates/ron-auth/src/keys/mac_handle.rs
<a id="crates-ron-auth-src-keys-machandle-rs"></a>

```rust
// keys::mac_handle placeholder
```

### crates/ron-auth/src/keys/mod.rs
<a id="crates-ron-auth-src-keys-mod-rs"></a>

```rust
// keys::mod placeholder
```

### crates/ron-auth/src/keys/traits.rs
<a id="crates-ron-auth-src-keys-traits-rs"></a>

```rust
// keys::traits placeholder
```

### crates/ron-auth/src/lib.rs
<a id="crates-ron-auth-src-lib-rs"></a>

```rust
//! RO:WHAT  Public crate façade for ron-auth.
//! RO:WHY   Stable, minimal surface; re-exports common types and verify APIs.
//! RO:INTERACTS  Delegates to `verify` module; no I/O or globals.
//! RO:INVARIANTS  No panics; propagate typed errors; keep generics simple and zero-IO.

pub mod cbor;
pub mod errors;
pub mod mac;
pub mod metrics;
pub mod types;
pub mod verify;

pub use errors::{AuthError, DenyReason};
pub use types::{
    Capability, Caveat, Decision, MacKey, MacKeyProvider, RequestCtx, Scope, VerifierConfig,
};

/// Verify a single Base64URL-encoded token.
#[inline]
pub fn verify_token<K: MacKeyProvider>(
    cfg: &VerifierConfig,
    token_b64url: &str,
    ctx: &RequestCtx,
    keys: &K,
) -> Result<Decision, AuthError> {
    verify::verify_token(cfg, token_b64url, ctx, keys)
}

/// Verify many tokens; amortizes internal buffers and may parallelize
/// when built with `--features parallel`.
#[inline]
pub fn verify_many<K: MacKeyProvider + Sync>(
    cfg: &VerifierConfig,
    tokens_b64url: &[String],
    ctx: &RequestCtx,
    keys: &K,
) -> Result<Vec<Decision>, AuthError> {
    verify::verify_many(cfg, tokens_b64url, ctx, keys)
}

/// Same as `verify_many` but writes into `out` (clears it first).
#[inline]
pub fn verify_many_into<K: MacKeyProvider + Sync>(
    cfg: &VerifierConfig,
    tokens_b64url: &[String],
    ctx: &RequestCtx,
    keys: &K,
    out: &mut Vec<Decision>,
) -> Result<(), AuthError> {
    verify::verify_many_into(cfg, tokens_b64url, ctx, keys, out)
}

// ===== Bench/Test-friendly helpers (stable, zero I/O) ========================

/// Builder to assemble a Capability and sign/encode it for benches/tests.
///
/// NOTE: ctor order matches the bench: `new(scope, tid, kid)`.
#[derive(Debug, Clone)]
pub struct CapabilityBuilder {
    tid: String,
    kid: String,
    scope: Scope,
    caveats: Vec<Caveat>,
}

impl CapabilityBuilder {
    /// Create a new builder.
    pub fn new<T: Into<String>, K: Into<String>>(scope: Scope, tid: T, kid: K) -> Self {
        Self {
            tid: tid.into(),
            kid: kid.into(),
            scope,
            caveats: Vec::new(),
        }
    }

    /// Add a caveat (alias for `push` to match bench naming).
    #[inline]
    pub fn caveat(self, c: Caveat) -> Self {
        self.push(c)
    }

    #[inline]
    pub fn push(mut self, c: Caveat) -> Self {
        self.caveats.push(c);
        self
    }

    #[inline]
    pub fn extend<I: IntoIterator<Item = Caveat>>(mut self, it: I) -> Self {
        self.caveats.extend(it);
        self
    }

    /// Finalize into an unsigned Capability (MAC empty).
    pub fn build_unsigned(self) -> Capability {
        Capability {
            tid: self.tid,
            kid: self.kid,
            scope: self.scope,
            caveats: self.caveats,
            mac: Vec::new(),
        }
    }

    /// Alias expected by benches.
    #[inline]
    pub fn build(self) -> Capability {
        self.build_unsigned()
    }

    /// Build, sign with `key`, and return the finalized Capability.
    pub fn build_and_sign(self, key: &MacKey) -> Capability {
        let mut cap = self.build_unsigned();
        let tag = crate::mac::compute_mac(key, &cap);
        cap.mac = tag.to_vec();
        cap
    }

    /// Build, sign, and Base64URL-encode the CBOR token.
    pub fn build_sign_encode(self, key: &MacKey) -> String {
        let cap = self.build_and_sign(key);
        crate::cbor::encode_b64url_cbor_capability(&cap)
    }
}

/// Public so it can be used in a public function bound (fixes `private_bounds` warning).
pub trait KeyLookup {
    fn key_for_cap(&self, kid: &str, tid: &str) -> Option<MacKey>;
}

impl KeyLookup for &MacKey {
    #[inline]
    fn key_for_cap(&self, _kid: &str, _tid: &str) -> Option<MacKey> {
        Some((**self).clone())
    }
}

impl<K: MacKeyProvider> KeyLookup for &K {
    #[inline]
    fn key_for_cap(&self, kid: &str, tid: &str) -> Option<MacKey> {
        MacKeyProvider::key_for(*self, kid, tid)
    }
}

/// Sign the provided `Capability` using either a `&MacKey` or a `&impl MacKeyProvider`,
/// then return the Base64URL-encoded CBOR token.
///
/// - Accepts `&Capability`.
/// - Returns `Result<String, AuthError>` so benches can `.unwrap()`.
#[inline]
pub fn sign_and_encode_b64url<L: KeyLookup>(
    cap: &Capability,
    lookup: L,
) -> Result<String, AuthError> {
    let key = lookup
        .key_for_cap(&cap.kid, &cap.tid)
        .ok_or(AuthError::UnknownKid)?;

    let mut tmp = Capability {
        tid: cap.tid.clone(),
        kid: cap.kid.clone(),
        scope: cap.scope.clone(),
        caveats: cap.caveats.clone(),
        mac: Vec::new(),
    };
    let tag = mac::compute_mac(&key, &tmp);
    tmp.mac = tag.to_vec();
    Ok(cbor::encode_b64url_cbor_capability(&tmp))
}

```

### crates/ron-auth/src/mac.rs
<a id="crates-ron-auth-src-mac-rs"></a>

```rust
//! RO:WHAT  BLAKE3 keyed MAC chaining with domain separation (low-alloc path).
//! RO:WHY   Integrity over (tenant,kid,scope,caveats...) in strict order.
//! RO:INVARIANTS No SHA; constant-time compare; buffer reuse to cut allocs.

use crate::{
    cbor,
    types::{Capability, Caveat, MacKey, Scope},
};

const DOMAIN_SEP: &[u8] = b"RON-AUTHv1\0";

#[inline]
fn init_tag(key: &MacKey, tid: &str, kid: &str, scope: &Scope, buf: &mut Vec<u8>) -> [u8; 32] {
    // tag0 = BLAKE3(key, DOMAIN || CBOR{tid,kid,scope})
    buf.clear();
    buf.extend_from_slice(DOMAIN_SEP);
    cbor::cbor_fragment_into(&(tid, kid, scope), buf);
    *blake3::keyed_hash(&key.0, buf).as_bytes()
}

#[inline]
fn fold_caveats(
    key: &MacKey,
    mut tag: [u8; 32],
    caveats: &[Caveat],
    frag: &mut Vec<u8>,
    fold: &mut Vec<u8>,
) -> [u8; 32] {
    for c in caveats {
        // Serialize caveat into frag (reused)
        cbor::cbor_fragment_into(c, frag);

        // fold = tag || frag
        fold.clear();
        fold.extend_from_slice(&tag);
        fold.extend_from_slice(frag);

        tag = *blake3::keyed_hash(&key.0, fold).as_bytes();
    }
    tag
}

/// Compute MAC with minimal transient allocations by reusing small buffers.
#[inline]
pub fn compute_mac(key: &MacKey, cap: &Capability) -> [u8; 32] {
    let mut init_buf = Vec::with_capacity(128);
    let tag0 = init_tag(key, &cap.tid, &cap.kid, &cap.scope, &mut init_buf);

    let mut frag = Vec::with_capacity(128);
    let mut fold = Vec::with_capacity(160); // 32 + typical frag
    fold_caveats(key, tag0, &cap.caveats, &mut frag, &mut fold)
}

/// Constant-time MAC comparison (works for equal-length slices).
/// Runs in time proportional to length; no early-exit and no branching on secrets.
#[inline]
pub fn macs_equal(ct_a: &[u8], ct_b: &[u8]) -> bool {
    if ct_a.len() != ct_b.len() {
        return false;
    }
    let mut diff: u8 = 0;
    // Iterate over all bytes; XOR accumulates any difference.
    for i in 0..ct_a.len() {
        // SAFETY: bounds-checked by loop condition
        diff |= ct_a[i] ^ ct_b[i];
    }
    // `diff == 0` after the loop implies equality; single comparison independent of contents.
    diff == 0
}

```

### crates/ron-auth/src/metrics.rs
<a id="crates-ron-auth-src-metrics-rs"></a>

```rust
//! Minimal, zero-IO metrics hook for ron-auth.
//!
//! - Default is NO-OP (no allocations, no locks on hot path).
//! - Hosts may register a recorder once (e.g., Prometheus in svc-passport).
//! - This crate never depends on prometheus/tokio/etc.

use crate::errors::AuthError;
use std::sync::OnceLock;

pub trait MetricsRecorder: Send + Sync + 'static {
    /// Counter add (monotonic). Example: "ron_auth_verify_allow_total"
    fn counter_add(&self, name: &'static str, by: u64);
    /// Histogram observe (nanoseconds, counts, sizes, etc.).
    fn histogram_observe(&self, name: &'static str, value: u64);
    /// Gauge set (rarely used here).
    fn gauge_set(&self, _name: &'static str, _value: i64) {
        // optional to implement
    }
}

struct Nop;
impl MetricsRecorder for Nop {
    #[inline]
    fn counter_add(&self, _name: &'static str, _by: u64) {}
    #[inline]
    fn histogram_observe(&self, _name: &'static str, _value: u64) {}
    #[inline]
    fn gauge_set(&self, _name: &'static str, _value: i64) {}
}

static REC: OnceLock<&'static dyn MetricsRecorder> = OnceLock::new();
static NOP: Nop = Nop;

/// One-time hook called by hosts (e.g., svc-passport) to install a recorder.
/// Safe to call at startup; subsequent calls are ignored.
pub fn set_recorder(rec: &'static dyn MetricsRecorder) {
    let _ = REC.set(rec);
}

#[inline]
fn rec() -> &'static dyn MetricsRecorder {
    REC.get().copied().unwrap_or(&NOP)
}

// ---------- Convenience shims used by the pipeline ----------

#[inline]
pub fn counter_inc(name: &'static str) {
    rec().counter_add(name, 1);
}
#[inline]
pub fn counter_add(name: &'static str, by: u64) {
    rec().counter_add(name, by);
}
#[inline]
pub fn hist_ns(name: &'static str, v: u64) {
    rec().histogram_observe(name, v);
}
#[inline]
pub fn gauge(name: &'static str, v: i64) {
    rec().gauge_set(name, v);
}

// Grouped helpers used at error/decision sites:

pub const C_ALLOW: &'static str = "ron_auth_verify_allow_total";
pub const C_DENY: &'static str = "ron_auth_verify_deny_total";

pub const C_ERR_MALFORMED: &'static str = "ron_auth_err_malformed_total";
pub const C_ERR_BOUNDS: &'static str = "ron_auth_err_bounds_total";
pub const C_ERR_UNKNOWN_KID: &'static str = "ron_auth_err_unknown_kid_total";
pub const C_ERR_MAC: &'static str = "ron_auth_err_mac_mismatch_total";
pub const C_ERR_EXPIRED: &'static str = "ron_auth_err_expired_total";
pub const C_ERR_NOTYET: &'static str = "ron_auth_err_not_yet_valid_total";
pub const C_ERR_POLICY: &'static str = "ron_auth_err_policy_total";

pub const H_BATCH_SIZE: &'static str = "ron_auth_verify_batch_size";
pub const H_CAVEATS_PER_CAP: &'static str = "ron_auth_caveats_per_cap";

/// Increment a counter by error type (call *before* returning the error).
#[inline]
pub fn bump_error(e: &AuthError) {
    match e {
        AuthError::Malformed(_) => counter_inc(C_ERR_MALFORMED),
        AuthError::Bounds => counter_inc(C_ERR_BOUNDS),
        AuthError::UnknownKid => counter_inc(C_ERR_UNKNOWN_KID),
        AuthError::MacMismatch => counter_inc(C_ERR_MAC),
        AuthError::Expired => counter_inc(C_ERR_EXPIRED),
        AuthError::NotYetValid => counter_inc(C_ERR_NOTYET),
        AuthError::PolicyDeny => counter_inc(C_ERR_POLICY),
    }
}

/// Record per-capacity caveat count (cheap int, helps crossover tuning).
#[inline]
pub fn observe_caveats(n: usize) {
    rec().histogram_observe(H_CAVEATS_PER_CAP, n as u64);
}

```

### crates/ron-auth/src/pq/mod.rs
<a id="crates-ron-auth-src-pq-mod-rs"></a>

```rust
// pq::mod placeholder (feature-gated)
```

### crates/ron-auth/src/pq/sig_adapter.rs
<a id="crates-ron-auth-src-pq-sigadapter-rs"></a>

```rust
// pq::sig_adapter placeholder (feature-gated)
```

### crates/ron-auth/src/prelude.rs
<a id="crates-ron-auth-src-prelude-rs"></a>

```rust
//! RO:WHAT    Shared imports/types for crate-internal modules.
//! RO:WHY     Keep lib files concise and consistent (CODECOMMENTS.MD).
//! RO:INTERACTS  Used by most modules (types, errors, tools).
//! RO:INVARIANTS No I/O, no async, no SHA; BLAKE3 only.

pub use crate::errors::AuthError;
pub use serde::{Deserialize, Serialize};

```

### crates/ron-auth/src/redact.rs
<a id="crates-ron-auth-src-redact-rs"></a>

```rust
// redact helpers placeholder
```

### crates/ron-auth/src/types.rs
<a id="crates-ron-auth-src-types-rs"></a>

```rust
//! RO:WHAT  Public types: Capability, Scope, Caveat, Decision, VerifierConfig, RequestCtx.
//! RO:WHY   Stable, boring DTOs; serde/CBOR friendly; no alloc surprises.
//! RO:INVARIANTS Deterministic encoding; strict bounds; no I/O.

use crate::errors::DenyReason;
use serde::{Deserialize, Serialize};
use std::net::IpAddr;

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct Scope {
    /// Optional resource prefix (e.g., "/index/").
    pub prefix: Option<String>,
    /// Allowed HTTP-style methods (e.g., "GET","PUT").
    pub methods: Vec<String>,
    /// Max payload bytes permitted by this capability.
    pub max_bytes: Option<u64>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(tag = "t", content = "v")]
pub enum Caveat {
    Exp(u64),
    Nbf(u64),
    Aud(String),
    Method(Vec<String>),
    PathPrefix(String),
    IpCidr(String),
    BytesLe(u64),
    Rate {
        per_s: u32,
        burst: u32,
    },
    Tenant(String),
    Amnesia(bool),
    GovPolicyDigest(String),
    Custom {
        ns: String,
        name: String,
        cbor: serde_cbor::Value,
    },
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct Capability {
    /// Tenant/domain namespace for multi-tenant safety.
    pub tid: String,
    /// Key identifier for MAC lookup.
    pub kid: String,
    pub scope: Scope,
    pub caveats: Vec<Caveat>,
    /// Final MAC (BLAKE3 keyed), 32 bytes.
    #[serde(with = "serde_bytes")]
    pub mac: Vec<u8>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct VerifierConfig {
    /// Upper bound after Base64URL decode.
    pub max_token_bytes: usize,
    /// Max allowed caveats.
    pub max_caveats: usize,
    /// Clock skew in seconds for exp/nbf.
    pub clock_skew_secs: i64,
    /// Hybrid crossover: <= threshold → streaming; > threshold → SoA.
    pub soa_threshold: usize,
}

impl VerifierConfig {
    pub fn with_defaults() -> Self {
        Self {
            max_token_bytes: 4096,
            max_caveats: 64,
            clock_skew_secs: 60,
            // Mixed workloads on your laptop benefit from a slightly higher default.
            soa_threshold: 16,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct RequestCtx {
    pub now_unix_s: u64,
    pub method: String,
    pub path: String,
    pub peer_ip: Option<IpAddr>,
    pub object_addr: Option<String>,
    pub tenant: String,
    pub amnesia: bool,
    pub policy_digest_hex: Option<String>,
    pub extras: serde_cbor::Value,
}

/// Final decision.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum Decision {
    Allow { scope: Scope },
    Deny { reasons: Vec<DenyReason> },
}

/// Opaque MAC key (32 bytes for BLAKE3 keyed mode).
#[derive(Debug, Clone)]
pub struct MacKey(pub [u8; 32]);

/// Caller-provided keys (e.g., from ron-kms). No I/O here.
pub trait MacKeyProvider {
    fn key_for(&self, kid: &str, tid: &str) -> Option<MacKey>;
}

```

### crates/ron-auth/src/verify/checks.rs
<a id="crates-ron-auth-src-verify-checks-rs"></a>

```rust
//! RO:WHAT   Fast structural/limit checks executed before MAC work.
//! RO:WHY    Shed bad requests early; keep hot path predictable.
//! RO:INVARIANTS Pure; constant-time unrelated to secrets.

use crate::types::VerifierConfig;

#[allow(dead_code)]
#[inline]
pub fn check_size_cap(cfg: &VerifierConfig, token_len: usize) -> Result<(), &'static str> {
    if token_len > cfg.max_token_bytes {
        return Err("cap: token too large");
    }
    Ok(())
}

#[allow(dead_code)]
#[inline]
pub fn check_caveat_count(cfg: &VerifierConfig, count: usize) -> Result<(), &'static str> {
    if count > cfg.max_caveats {
        return Err("cap: too many caveats");
    }
    Ok(())
}

```

### crates/ron-auth/src/verify/decision.rs
<a id="crates-ron-auth-src-verify-decision-rs"></a>

```rust
// verify::decision placeholder

```

### crates/ron-auth/src/verify/error.rs
<a id="crates-ron-auth-src-verify-error-rs"></a>

```rust
// verify::error placeholder

```

### crates/ron-auth/src/verify/eval.rs
<a id="crates-ron-auth-src-verify-eval-rs"></a>

```rust
//! RO:WHAT  Streaming caveat evaluator with early short-circuit on Exp/Nbf.
//! RO:WHY   Fast path for small caveat sets; accumulates soft mismatches.

use crate::{
    errors::{AuthError, DenyReason},
    types::{Caveat, RequestCtx, VerifierConfig},
};
use ipnet::IpNet;
use serde_cbor::Value;
use std::str::FromStr;

#[inline]
pub fn eval_caveats_streaming(
    cfg: &VerifierConfig,
    ctx: &RequestCtx,
    caveats: &[Caveat],
    out: &mut Vec<DenyReason>,
) -> Result<(), AuthError> {
    let now = ctx.now_unix_s as i64;
    let mut need_len: Option<u64> = None;

    for c in caveats {
        match c {
            Caveat::Exp(v) => {
                if now > (*v as i64) + cfg.clock_skew_secs {
                    return Err(AuthError::Expired);
                }
            }
            Caveat::Nbf(v) => {
                if now + cfg.clock_skew_secs < *v as i64 {
                    return Err(AuthError::NotYetValid);
                }
            }
            Caveat::Aud(a) => {
                if ctx.policy_digest_hex.as_deref() != Some(a.as_str()) {
                    out.push(DenyReason::BadAudience);
                }
            }
            Caveat::Method(ms) => {
                if !ms.iter().any(|m| m.eq_ignore_ascii_case(&ctx.method)) {
                    out.push(DenyReason::MethodNotAllowed);
                }
            }
            Caveat::PathPrefix(pref) => {
                if !ctx.path.starts_with(pref) {
                    out.push(DenyReason::PathNotAllowed);
                }
            }
            Caveat::IpCidr(s) => match (&ctx.peer_ip, IpNet::from_str(s)) {
                (Some(ip), Ok(net)) if net.contains(ip) => {}
                _ => out.push(DenyReason::IpNotAllowed),
            },
            Caveat::BytesLe(max) => {
                if need_len.is_none() {
                    need_len = extract_len_from_extras(&ctx.extras);
                }
                if let Some(len) = need_len {
                    if len > *max {
                        out.push(DenyReason::BytesExceed);
                    }
                }
            }
            Caveat::Rate { .. } => {
                // informational placeholder
            }
            Caveat::Tenant(t) => {
                if t != &ctx.tenant {
                    out.push(DenyReason::TenantMismatch);
                }
            }
            Caveat::Amnesia(flag) => {
                if *flag != ctx.amnesia {
                    out.push(DenyReason::Custom("amnesia_mismatch".into()));
                }
            }
            Caveat::GovPolicyDigest(d) => {
                if ctx.policy_digest_hex.as_deref() != Some(d.as_str()) {
                    out.push(DenyReason::Custom("gov_policy_digest_mismatch".into()));
                }
            }
            Caveat::Custom { .. } => {
                // host-defined; no-op
            }
        }
    }
    Ok(())
}

#[inline]
pub fn extract_len_from_extras(v: &Value) -> Option<u64> {
    match v {
        Value::Map(m) => {
            for (k, val) in m {
                if let Value::Text(s) = k {
                    if s == "len" {
                        if let Value::Integer(i) = val {
                            if *i >= 0 {
                                return Some(*i as u64);
                            }
                        } else if let Value::Float(f) = val {
                            if *f >= 0.0 {
                                return Some(*f as u64);
                            }
                        }
                    }
                }
            }
            None
        }
        _ => None,
    }
}

```

### crates/ron-auth/src/verify/mod.rs
<a id="crates-ron-auth-src-verify-mod-rs"></a>

```rust
//! RO:WHAT    Verification module split into pipeline + evaluators.
//! RO:LAYOUT  pipeline (API) | streaming (small sets) | soa (columns) | soa_eval | parse tests.

pub mod parse; // tests/utilities (kept)
pub mod soa; // CaveatsSoA columnar representation
pub mod soa_eval;
pub mod streaming; // eval for small caveat sets (early short-circuit)

mod pipeline; // main API (private module)

pub use pipeline::{verify_many, verify_many_into, verify_token};

#[cfg(feature = "bench-eval-modes")]
pub use pipeline::{
    verify_many_soa_only, verify_many_streaming_only, verify_token_soa_only,
    verify_token_streaming_only,
};

```

### crates/ron-auth/src/verify/parse.rs
<a id="crates-ron-auth-src-verify-parse-rs"></a>

```rust
//! RO:WHAT   Token parsing helpers (base64url, CBOR).
//! RO:WHY    Keep low-level parsing separate from pipeline orchestration.
//! RO:INVARIANTS No I/O; deterministic; URL-safe base64 without padding.

use base64::engine::general_purpose::URL_SAFE_NO_PAD;
use base64::Engine as _;
use serde::de::DeserializeOwned;

/// Decode URL-safe base64 (no padding) with a conservative early size cap.
/// `max_bytes` is the maximum allowed decoded length (post-base64).
#[allow(dead_code)]
#[inline]
pub fn b64url_decode(bytes_b64url: &str, max_bytes: usize) -> Result<Vec<u8>, &'static str> {
    // Early cap on input chars: ceil(max_bytes * 4 / 3)
    let max_in = max_bytes.saturating_mul(4).div_ceil(3);
    if bytes_b64url.len() > max_in {
        return Err("b64url: input too large");
    }
    URL_SAFE_NO_PAD
        .decode(bytes_b64url.as_bytes())
        .map_err(|_| "b64url: decode error")
}

/// Decode CBOR value from a slice using serde_cbor.
#[allow(dead_code)]
#[inline]
pub fn cbor_from_slice<T: DeserializeOwned>(buf: &[u8]) -> Result<T, &'static str> {
    serde_cbor::from_slice(buf).map_err(|_| "cbor: decode error")
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn decode_roundtrip() {
        let payload = b"hello";
        let enc = base64::engine::general_purpose::URL_SAFE_NO_PAD.encode(payload);
        let out = b64url_decode(&enc, 1024).unwrap();
        assert_eq!(out, payload);
    }
}

```

### crates/ron-auth/src/verify/pipeline.rs
<a id="crates-ron-auth-src-verify-pipeline-rs"></a>

```rust
//! RO:WHAT  Token verification pipeline (pure, sync) with hybrid eval + optional parallel batch.
//! RO:WHY   Keep early short-circuit cost for common tiny tokens; SoA for larger sets;
//!          add feature-gated parallelism for big batches while preserving order.
//! RO:INVARIANTS No I/O; strict bounds; constant-time MAC compare; BLAKE3 only.

use super::{soa::CaveatsSoA, soa_eval::eval_caveats_soa, streaming::eval_caveats_streaming};
use crate::cbor::decode_b64url_cbor_capability_with_buf;
use crate::errors::{AuthError, DenyReason};
use crate::mac::{compute_mac, macs_equal};
use crate::metrics as m;
use crate::types::{Decision, MacKeyProvider, RequestCtx, VerifierConfig};

use smallvec::SmallVec;

#[cfg(feature = "parallel")]
use rayon::prelude::*;

/// Parallel shard kickoff threshold (avoid thread-pool overhead on small batches).
#[cfg(feature = "parallel")]
const PAR_MIN_BATCH: usize = 64;

/// Sample size used to estimate a per-batch effective threshold.
const THRESH_SAMPLE: usize = 6;

/// Heuristic: estimate an effective crossover threshold from a tiny sample of the batch.
///
/// Optimization: if we're going to take the parallel path (large batch), we avoid
/// double-decoding a sample and simply bias strongly toward the streaming evaluator,
/// which is what heavy caveat sets prefer on this machine.
fn estimate_effective_threshold(cfg: &VerifierConfig, tokens_b64url: &[String]) -> usize {
    #[cfg(feature = "parallel")]
    {
        if tokens_b64url.len() >= PAR_MIN_BATCH {
            return usize::MAX / 2; // bias to streaming, avoids extra sample decodes
        }
    }

    let sample_n = tokens_b64url.len().min(THRESH_SAMPLE);
    if sample_n == 0 {
        return cfg.soa_threshold;
    }

    let mut scratch = Vec::with_capacity(512);
    let mut lens: SmallVec<[usize; 8]> = SmallVec::new();

    for tok in &tokens_b64url[..sample_n] {
        match decode_b64url_cbor_capability_with_buf(tok, cfg.max_token_bytes, &mut scratch) {
            Ok(cap) => lens.push(cap.caveats.len()),
            Err(_) => return cfg.soa_threshold, // fall back if malformed appears in sample
        }
    }

    if lens.is_empty() {
        return cfg.soa_threshold;
    }
    lens.sort_unstable();
    let median = lens[lens.len() / 2];

    if median > 20 {
        usize::MAX / 2 // bias strongly toward streaming for heavy caveat sets
    } else {
        cfg.soa_threshold
    }
}

/// Verify a single Base64URL token.
pub fn verify_token<K: MacKeyProvider>(
    cfg: &VerifierConfig,
    token_b64url: &str,
    ctx: &RequestCtx,
    keys: &K,
) -> Result<Decision, AuthError> {
    let mut scratch = Vec::with_capacity(1024);
    verify_one_with_buf_thresh(
        cfg,
        cfg.soa_threshold,
        token_b64url,
        ctx,
        keys,
        &mut scratch,
    )
}

/// Verify many Base64URL tokens with amortized buffer reuse; returns a Vec.
/// See `verify_many_into` to reuse the output buffer.
pub fn verify_many<K: MacKeyProvider + Sync>(
    cfg: &VerifierConfig,
    tokens_b64url: &[String],
    ctx: &RequestCtx,
    keys: &K,
) -> Result<Vec<Decision>, AuthError> {
    let mut out = Vec::with_capacity(tokens_b64url.len());
    verify_many_into(cfg, tokens_b64url, ctx, keys, &mut out)?;
    Ok(out)
}

/// Same as `verify_many` but writes decisions into `out` (clears it first).
///
/// When built with `--features parallel` and the batch size is large enough,
/// this will shard across the Rayon pool while preserving output order.
/// Otherwise it falls back to the sequential pipeline.
pub fn verify_many_into<K: MacKeyProvider + Sync>(
    cfg: &VerifierConfig,
    tokens_b64url: &[String],
    ctx: &RequestCtx,
    keys: &K,
    out: &mut Vec<Decision>,
) -> Result<(), AuthError> {
    out.clear();
    out.reserve(tokens_b64url.len());

    // empty
    if tokens_b64url.is_empty() {
        return Ok(());
    }

    // Record the batch size (cheap, one point per call).
    m::hist_ns(m::H_BATCH_SIZE, tokens_b64url.len() as u64);

    // Decide an effective threshold from a tiny sample of the batch (or skip on big batches).
    let effective_threshold = estimate_effective_threshold(cfg, tokens_b64url);

    // Parallel order-preserving path (feature-gated + threshold)
    #[cfg(feature = "parallel")]
    {
        if tokens_b64url.len() >= PAR_MIN_BATCH {
            let decisions: Result<Vec<Decision>, AuthError> = tokens_b64url
                .par_iter()
                .map(|tok| {
                    let mut scratch = Vec::with_capacity(2048);
                    verify_one_with_buf_thresh(
                        cfg,
                        effective_threshold,
                        tok,
                        ctx,
                        keys,
                        &mut scratch,
                    )
                })
                .collect();
            out.extend(decisions?);
            return Ok(());
        }
    }

    // Sequential fallback (and default when `parallel` feature is off).
    let mut scratch = Vec::with_capacity(1024);
    let mut reasons: Vec<DenyReason> = Vec::new();

    for tok in tokens_b64url {
        let cap =
            match decode_b64url_cbor_capability_with_buf(tok, cfg.max_token_bytes, &mut scratch) {
                Ok(c) => c,
                Err(e) => {
                    m::bump_error(&e);
                    return Err(e);
                }
            };

        if cap.caveats.len() > cfg.max_caveats {
            let e = AuthError::Bounds;
            m::bump_error(&e);
            return Err(e);
        }

        // tiny per-cap stat to help crossover tuning
        m::observe_caveats(cap.caveats.len());

        let key = match keys.key_for(&cap.kid, &cap.tid) {
            Some(k) => k,
            None => {
                let e = AuthError::UnknownKid;
                m::bump_error(&e);
                return Err(e);
            }
        };

        // MAC over original caveat order (domain fixed)
        let expect = compute_mac(&key, &cap);
        if !macs_equal(&expect, &cap.mac) {
            let e = AuthError::MacMismatch;
            m::bump_error(&e);
            return Err(e);
        }

        reasons.clear();

        // Evaluator may return Expired / NotYetValid (hard errors) or push soft reasons.
        let eval_res = if cap.caveats.len() <= effective_threshold {
            eval_caveats_streaming(cfg, ctx, &cap.caveats, &mut reasons)
        } else {
            eval_caveats_soa(cfg, ctx, CaveatsSoA::from_slice(&cap.caveats), &mut reasons)
        };

        if let Err(e @ (AuthError::Expired | AuthError::NotYetValid | AuthError::PolicyDeny)) =
            eval_res
        {
            m::bump_error(&e);
            return Err(e);
        }

        if reasons.is_empty() {
            m::counter_inc(m::C_ALLOW);
            out.push(Decision::Allow { scope: cap.scope });
        } else {
            m::counter_inc(m::C_DENY);
            out.push(Decision::Deny {
                reasons: core::mem::take(&mut reasons),
            });
        }
    }

    Ok(())
}

fn verify_one_with_buf_thresh<K: MacKeyProvider>(
    cfg: &VerifierConfig,
    threshold: usize,
    token_b64url: &str,
    ctx: &RequestCtx,
    keys: &K,
    scratch: &mut Vec<u8>,
) -> Result<Decision, AuthError> {
    let cap =
        match decode_b64url_cbor_capability_with_buf(token_b64url, cfg.max_token_bytes, scratch) {
            Ok(c) => c,
            Err(e) => {
                m::bump_error(&e);
                return Err(e);
            }
        };

    if cap.caveats.len() > cfg.max_caveats {
        let e = AuthError::Bounds;
        m::bump_error(&e);
        return Err(e);
    }

    m::observe_caveats(cap.caveats.len());

    let key = match keys.key_for(&cap.kid, &cap.tid) {
        Some(k) => k,
        None => {
            let e = AuthError::UnknownKid;
            m::bump_error(&e);
            return Err(e);
        }
    };

    // MAC over original caveat order
    let expect = compute_mac(&key, &cap);
    if !macs_equal(&expect, &cap.mac) {
        let e = AuthError::MacMismatch;
        m::bump_error(&e);
        return Err(e);
    }

    let mut reasons: Vec<DenyReason> = Vec::new();
    let eval_res = if cap.caveats.len() <= threshold {
        eval_caveats_streaming(cfg, ctx, &cap.caveats, &mut reasons)
    } else {
        eval_caveats_soa(cfg, ctx, CaveatsSoA::from_slice(&cap.caveats), &mut reasons)
    };

    if let Err(e @ (AuthError::Expired | AuthError::NotYetValid | AuthError::PolicyDeny)) = eval_res
    {
        m::bump_error(&e);
        return Err(e);
    }

    if reasons.is_empty() {
        m::counter_inc(m::C_ALLOW);
        Ok(Decision::Allow { scope: cap.scope })
    } else {
        m::counter_inc(m::C_DENY);
        Ok(Decision::Deny { reasons })
    }
}

#[cfg(feature = "bench-eval-modes")]
#[allow(dead_code)]
pub fn verify_token_streaming_only<K: MacKeyProvider>(
    cfg: &VerifierConfig,
    token_b64url: &str,
    ctx: &RequestCtx,
    keys: &K,
) -> Result<Decision, AuthError> {
    let mut scratch = Vec::with_capacity(1024);
    let cap =
        decode_b64url_cbor_capability_with_buf(token_b64url, cfg.max_token_bytes, &mut scratch)
            .map_err(|e| {
                m::bump_error(&e);
                e
            })?;
    if cap.caveats.len() > cfg.max_caveats {
        let e = AuthError::Bounds;
        m::bump_error(&e);
        return Err(e);
    }
    let key = keys.key_for(&cap.kid, &cap.tid).ok_or_else(|| {
        let e = AuthError::UnknownKid;
        m::bump_error(&e);
        e
    })?;
    let expect = compute_mac(&key, &cap);
    if !macs_equal(&expect, &cap.mac) {
        let e = AuthError::MacMismatch;
        m::bump_error(&e);
        return Err(e);
    }
    let mut reasons = Vec::new();
    if let Err(e @ (AuthError::Expired | AuthError::NotYetValid | AuthError::PolicyDeny)) =
        eval_caveats_streaming(cfg, ctx, &cap.caveats, &mut reasons)
    {
        m::bump_error(&e);
        return Err(e);
    }
    if reasons.is_empty() {
        m::counter_inc(m::C_ALLOW);
        Ok(Decision::Allow { scope: cap.scope })
    } else {
        m::counter_inc(m::C_DENY);
        Ok(Decision::Deny { reasons })
    }
}

#[cfg(feature = "bench-eval-modes")]
#[allow(dead_code)]
pub fn verify_token_soa_only<K: MacKeyProvider>(
    cfg: &VerifierConfig,
    token_b64url: &str,
    ctx: &RequestCtx,
    keys: &K,
) -> Result<Decision, AuthError> {
    let mut scratch = Vec::with_capacity(1024);
    let cap =
        decode_b64url_cbor_capability_with_buf(token_b64url, cfg.max_token_bytes, &mut scratch)
            .map_err(|e| {
                m::bump_error(&e);
                e
            })?;
    if cap.caveats.len() > cfg.max_caveats {
        let e = AuthError::Bounds;
        m::bump_error(&e);
        return Err(e);
    }
    let key = keys.key_for(&cap.kid, &cap.tid).ok_or_else(|| {
        let e = AuthError::UnknownKid;
        m::bump_error(&e);
        e
    })?;
    let expect = compute_mac(&key, &cap);
    if !macs_equal(&expect, &cap.mac) {
        let e = AuthError::MacMismatch;
        m::bump_error(&e);
        return Err(e);
    }
    let mut reasons = Vec::new();
    if let Err(e @ (AuthError::Expired | AuthError::NotYetValid | AuthError::PolicyDeny)) =
        eval_caveats_soa(cfg, ctx, CaveatsSoA::from_slice(&cap.caveats), &mut reasons)
    {
        m::bump_error(&e);
        return Err(e);
    }
    if reasons.is_empty() {
        m::counter_inc(m::C_ALLOW);
        Ok(Decision::Allow { scope: cap.scope })
    } else {
        m::counter_inc(m::C_DENY);
        Ok(Decision::Deny { reasons })
    }
}

#[cfg(feature = "bench-eval-modes")]
#[allow(dead_code)]
pub fn verify_many_streaming_only<K: MacKeyProvider>(
    cfg: &VerifierConfig,
    tokens_b64url: &[String],
    ctx: &RequestCtx,
    keys: &K,
) -> Result<Vec<Decision>, AuthError> {
    let mut out = Vec::with_capacity(tokens_b64url.len());
    let mut scratch = Vec::with_capacity(1024);
    let mut reasons = Vec::<DenyReason>::new();

    if !tokens_b64url.is_empty() {
        m::hist_ns(m::H_BATCH_SIZE, tokens_b64url.len() as u64);
    }

    for tok in tokens_b64url {
        let cap = decode_b64url_cbor_capability_with_buf(tok, cfg.max_token_bytes, &mut scratch)
            .map_err(|e| {
                m::bump_error(&e);
                e
            })?;
        if cap.caveats.len() > cfg.max_caveats {
            let e = AuthError::Bounds;
            m::bump_error(&e);
            return Err(e);
        }
        m::observe_caveats(cap.caveats.len());
        let key = keys.key_for(&cap.kid, &cap.tid).ok_or_else(|| {
            let e = AuthError::UnknownKid;
            m::bump_error(&e);
            e
        })?;
        let expect = compute_mac(&key, &cap);
        if !macs_equal(&expect, &cap.mac) {
            let e = AuthError::MacMismatch;
            m::bump_error(&e);
            return Err(e);
        }
        reasons.clear();
        if let Err(e @ (AuthError::Expired | AuthError::NotYetValid | AuthError::PolicyDeny)) =
            eval_caveats_streaming(cfg, ctx, &cap.caveats, &mut reasons)
        {
            m::bump_error(&e);
            return Err(e);
        }
        if reasons.is_empty() {
            m::counter_inc(m::C_ALLOW);
            out.push(Decision::Allow { scope: cap.scope });
        } else {
            m::counter_inc(m::C_DENY);
            out.push(Decision::Deny {
                reasons: core::mem::take(&mut reasons),
            });
        }
    }
    Ok(out)
}

#[cfg(feature = "bench-eval-modes")]
#[allow(dead_code)]
pub fn verify_many_soa_only<K: MacKeyProvider>(
    cfg: &VerifierConfig,
    tokens_b64url: &[String],
    ctx: &RequestCtx,
    keys: &K,
) -> Result<Vec<Decision>, AuthError> {
    let mut out = Vec::with_capacity(tokens_b64url.len());
    let mut scratch = Vec::with_capacity(1024);
    let mut reasons = Vec::<DenyReason>::new();

    if !tokens_b64url.is_empty() {
        m::hist_ns(m::H_BATCH_SIZE, tokens_b64url.len() as u64);
    }

    for tok in tokens_b64url {
        let cap = decode_b64url_cbor_capability_with_buf(tok, cfg.max_token_bytes, &mut scratch)
            .map_err(|e| {
                m::bump_error(&e);
                e
            })?;
        if cap.caveats.len() > cfg.max_caveats {
            let e = AuthError::Bounds;
            m::bump_error(&e);
            return Err(e);
        }
        m::observe_caveats(cap.caveats.len());
        let key = keys.key_for(&cap.kid, &cap.tid).ok_or_else(|| {
            let e = AuthError::UnknownKid;
            m::bump_error(&e);
            e
        })?;
        let expect = compute_mac(&key, &cap);
        if !macs_equal(&expect, &cap.mac) {
            let e = AuthError::MacMismatch;
            m::bump_error(&e);
            return Err(e);
        }
        reasons.clear();
        if let Err(e @ (AuthError::Expired | AuthError::NotYetValid | AuthError::PolicyDeny)) =
            eval_caveats_soa(cfg, ctx, CaveatsSoA::from_slice(&cap.caveats), &mut reasons)
        {
            m::bump_error(&e);
            return Err(e);
        }
        if reasons.is_empty() {
            m::counter_inc(m::C_ALLOW);
            out.push(Decision::Allow { scope: cap.scope });
        } else {
            m::counter_inc(m::C_DENY);
            out.push(Decision::Deny {
                reasons: core::mem::take(&mut reasons),
            });
        }
    }
    Ok(out)
}

```

### crates/ron-auth/src/verify/soa.rs
<a id="crates-ron-auth-src-verify-soa-rs"></a>

```rust
//! SoA (struct-of-arrays) view over a slice of Caveat.

use crate::types::Caveat;
use ipnet::IpNet;
use serde_cbor::Value;
use std::str::FromStr;

pub struct CaveatsSoA<'a> {
    pub exp: Vec<u64>,
    pub nbf: Vec<u64>,
    pub aud: Vec<&'a str>,
    pub method: Vec<&'a Vec<String>>,
    pub path_prefix: Vec<&'a str>,
    pub ip_cidr: Vec<Option<IpNet>>,
    pub bytes_le: Vec<u64>,
    pub rate: Vec<(u64, u32)>,
    pub tenant: Vec<&'a str>,
    pub amnesia: Vec<bool>,
    pub gov_policy_digest: Vec<&'a str>,
    pub custom: Vec<(&'a str, &'a str, &'a Value)>, // (ns, name, cbor)
}

impl<'a> CaveatsSoA<'a> {
    pub fn from_slice(caveats: &'a [Caveat]) -> Self {
        let mut out = Self {
            exp: Vec::new(),
            nbf: Vec::new(),
            aud: Vec::new(),
            method: Vec::new(),
            path_prefix: Vec::new(),
            ip_cidr: Vec::new(),
            bytes_le: Vec::new(),
            rate: Vec::new(),
            tenant: Vec::new(),
            amnesia: Vec::new(),
            gov_policy_digest: Vec::new(),
            custom: Vec::new(),
        };

        for c in caveats {
            match c {
                Caveat::Exp(v) => out.exp.push(*v),
                Caveat::Nbf(v) => out.nbf.push(*v),
                Caveat::Aud(a) => out.aud.push(a.as_str()),
                Caveat::Method(ms) => out.method.push(ms),
                Caveat::PathPrefix(p) => out.path_prefix.push(p.as_str()),
                Caveat::IpCidr(s) => {
                    out.ip_cidr.push(IpNet::from_str(s).ok());
                }
                Caveat::BytesLe(n) => out.bytes_le.push(*n),
                Caveat::Rate { burst, per_s } => out.rate.push((*burst as u64, *per_s)),
                Caveat::Tenant(t) => out.tenant.push(t.as_str()),
                Caveat::Amnesia(b) => out.amnesia.push(*b),
                Caveat::GovPolicyDigest(d) => out.gov_policy_digest.push(d.as_str()),
                Caveat::Custom { ns, name, cbor } => {
                    out.custom.push((ns.as_str(), name.as_str(), cbor))
                }
            }
        }

        out
    }
}

```

### crates/ron-auth/src/verify/soa_eval.rs
<a id="crates-ron-auth-src-verify-soaeval-rs"></a>

```rust
//! Evaluator over SoA columns.

use super::soa::CaveatsSoA;
use crate::errors::{AuthError, DenyReason};
use crate::types::{RequestCtx, VerifierConfig};

pub fn eval_caveats_soa<'a>(
    cfg: &VerifierConfig,
    ctx: &RequestCtx,
    soa: CaveatsSoA<'a>,
    out: &mut Vec<DenyReason>,
) -> Result<(), AuthError> {
    let now = ctx.now_unix_s as i64;

    // Hard errors first.
    for exp in soa.exp.iter() {
        if now > (*exp as i64) + cfg.clock_skew_secs {
            return Err(AuthError::Expired);
        }
    }
    for nbf in soa.nbf.iter() {
        if now + cfg.clock_skew_secs < *nbf as i64 {
            return Err(AuthError::NotYetValid);
        }
    }

    // Audience
    for a in soa.aud.iter() {
        match &ctx.policy_digest_hex {
            Some(pd) if pd == a => {}
            _ => out.push(DenyReason::BadAudience),
        }
    }

    // Method (borrowed slice of Strings; compare as &str)
    for methods in soa.method.iter() {
        if !methods
            .iter()
            .any(|m| m.as_str().eq_ignore_ascii_case(&ctx.method))
        {
            out.push(DenyReason::MethodNotAllowed);
        }
    }

    // PathPrefix
    for pref in soa.path_prefix.iter() {
        if !ctx.path.starts_with(pref) {
            out.push(DenyReason::PathNotAllowed);
        }
    }

    // IpCidr (already parsed)
    for net in soa.ip_cidr.iter() {
        match (&ctx.peer_ip, net) {
            (Some(ip), Some(n)) if n.contains(ip) => {}
            _ => out.push(DenyReason::IpNotAllowed),
        }
    }

    // BytesLe
    if let Some(len) = extract_len_from_extras_for_soa(&ctx.extras) {
        for max in soa.bytes_le.iter() {
            if len > *max {
                out.push(DenyReason::BytesExceed);
            }
        }
    }

    // Rate (placeholder)
    for (_burst, _per_s) in soa.rate.iter() {
        // host policy may enforce elsewhere
    }

    // Tenant
    for t in soa.tenant.iter() {
        if *t != ctx.tenant {
            out.push(DenyReason::TenantMismatch);
        }
    }

    // Amnesia flag
    for flag in soa.amnesia.iter() {
        if *flag != ctx.amnesia {
            out.push(DenyReason::Custom("amnesia_mismatch".into()));
        }
    }

    // Governance policy digest
    for d in soa.gov_policy_digest.iter() {
        if ctx.policy_digest_hex.as_deref() != Some(*d) {
            out.push(DenyReason::Custom("gov_policy_digest_mismatch".into()));
        }
    }

    // Custom caveats are host-defined; keep informational
    let _ = soa.custom;

    Ok(())
}

// Small helper to reuse the same len-extractor without exposing internals widely.
pub(crate) fn extract_len_from_extras_for_soa(v: &serde_cbor::Value) -> Option<u64> {
    use serde_cbor::Value;
    match v {
        Value::Map(m) => {
            for (k, val) in m {
                if let Value::Text(s) = k {
                    if s == "len" {
                        if let Value::Integer(i) = val {
                            if *i >= 0 {
                                return Some(*i as u64);
                            }
                        } else if let Value::Float(f) = val {
                            if *f >= 0.0 {
                                return Some(*f as u64);
                            }
                        }
                    }
                }
            }
            None
        }
        _ => None,
    }
}

```

### crates/ron-auth/src/verify/streaming.rs
<a id="crates-ron-auth-src-verify-streaming-rs"></a>

```rust
//! Streaming evaluator with early short-circuit for Exp/Nbf.

use crate::errors::{AuthError, DenyReason};
use crate::types::{Caveat, RequestCtx, VerifierConfig};
use ipnet::IpNet;
use serde_cbor::Value;
use std::str::FromStr;

pub fn eval_caveats_streaming(
    cfg: &VerifierConfig,
    ctx: &RequestCtx,
    caveats: &[Caveat],
    out: &mut Vec<DenyReason>,
) -> Result<(), AuthError> {
    let now = ctx.now_unix_s as i64;
    let mut need_len: Option<u64> = None;

    for c in caveats {
        match c {
            Caveat::Exp(v) => {
                if now > (*v as i64) + cfg.clock_skew_secs {
                    return Err(AuthError::Expired);
                }
            }
            Caveat::Nbf(v) => {
                if now + cfg.clock_skew_secs < *v as i64 {
                    return Err(AuthError::NotYetValid);
                }
            }
            Caveat::Aud(a) => {
                if ctx.policy_digest_hex.as_deref() != Some(a.as_str()) {
                    out.push(DenyReason::BadAudience);
                }
            }
            Caveat::Method(ms) => {
                if !ms.iter().any(|m| m.eq_ignore_ascii_case(&ctx.method)) {
                    out.push(DenyReason::MethodNotAllowed);
                }
            }
            Caveat::PathPrefix(pref) => {
                if !ctx.path.starts_with(pref) {
                    out.push(DenyReason::PathNotAllowed);
                }
            }
            Caveat::IpCidr(s) => match (&ctx.peer_ip, IpNet::from_str(s)) {
                (Some(ip), Ok(net)) if net.contains(ip) => {}
                _ => out.push(DenyReason::IpNotAllowed),
            },
            Caveat::BytesLe(max) => {
                if need_len.is_none() {
                    need_len = extract_len_from_extras(&ctx.extras);
                }
                if let Some(len) = need_len {
                    if len > *max {
                        out.push(DenyReason::BytesExceed);
                    }
                }
            }
            Caveat::Rate { .. } => {} // informational
            Caveat::Tenant(t) => {
                if t != &ctx.tenant {
                    out.push(DenyReason::TenantMismatch);
                }
            }
            Caveat::Amnesia(flag) => {
                if *flag != ctx.amnesia {
                    out.push(DenyReason::Custom("amnesia_mismatch".into()));
                }
            }
            Caveat::GovPolicyDigest(d) => {
                if ctx.policy_digest_hex.as_deref() != Some(d.as_str()) {
                    out.push(DenyReason::Custom("gov_policy_digest_mismatch".into()));
                }
            }
            Caveat::Custom { .. } => {}
        }
    }
    Ok(())
}

fn extract_len_from_extras(v: &Value) -> Option<u64> {
    match v {
        Value::Map(m) => {
            for (k, val) in m {
                if let Value::Text(s) = k {
                    if s == "len" {
                        if let Value::Integer(i) = val {
                            if *i >= 0 {
                                return Some(*i as u64);
                            }
                        } else if let Value::Float(f) = val {
                            if *f >= 0.0 {
                                return Some(*f as u64);
                            }
                        }
                    }
                }
            }
            None
        }
        _ => None,
    }
}

```

### crates/ron-auth/src/zk/mod.rs
<a id="crates-ron-auth-src-zk-mod-rs"></a>

```rust
// zk::mod placeholder (feature-gated)
```

### crates/ron-auth/testing/vectors/ron-auth/v1/allow_example.json
<a id="crates-ron-auth-testing-vectors-ron-auth-v1-allowexample-json"></a>

```json
{ "placeholder": "allow_example" }
```

### crates/ron-auth/testing/vectors/ron-auth/v1/custom_ns_examples.json
<a id="crates-ron-auth-testing-vectors-ron-auth-v1-customnsexamples-json"></a>

```json
{ "placeholder": "custom_ns_examples" }
```

### crates/ron-auth/testing/vectors/ron-auth/v1/deny_expired.json
<a id="crates-ron-auth-testing-vectors-ron-auth-v1-denyexpired-json"></a>

```json
{ "placeholder": "deny_expired" }
```

### crates/ron-auth/testing/vectors/ron-auth/v1/deny_unknown_kid.json
<a id="crates-ron-auth-testing-vectors-ron-auth-v1-denyunknownkid-json"></a>

```json
{ "placeholder": "deny_unknown_kid" }
```

### crates/ron-auth/testing/vectors/ron-auth/v1/pq_allow.json
<a id="crates-ron-auth-testing-vectors-ron-auth-v1-pqallow-json"></a>

```json
{ "placeholder": "pq_allow" }
```

### crates/ron-auth/testing/vectors/ron-auth/v1/pq_deny_mismatch.json
<a id="crates-ron-auth-testing-vectors-ron-auth-v1-pqdenymismatch-json"></a>

```json
{ "placeholder": "pq_deny_mismatch" }
```

### crates/ron-auth/tests/allow_deny_vectors.rs
<a id="crates-ron-auth-tests-allowdenyvectors-rs"></a>

```rust
// RO:WHAT   Minimal allow/deny sanity for ron-auth core.
// RO:WHY    Catch regressions fast: MAC path, bounds, caveats.
// RO:INVARIANTS BLAKE3 only; no I/O; deterministic CBOR+Base64URL.

use ron_auth::{
    sign_and_encode_b64url, verify_token, AuthError, CapabilityBuilder, Caveat, Decision,
    DenyReason, MacKey, MacKeyProvider, RequestCtx, Scope, VerifierConfig,
};
use serde_cbor::Value;
use std::net::IpAddr;
use std::str::FromStr;

#[derive(Clone)]
struct StaticKeys;
impl MacKeyProvider for StaticKeys {
    fn key_for(&self, kid: &str, tid: &str) -> Option<MacKey> {
        // One fixed 32B key for (tid="test", kid="k1")
        if kid == "k1" && tid == "test" {
            Some(MacKey(*b"0123456789abcdef0123456789abcdef"))
        } else {
            None
        }
    }
}

fn now() -> u64 {
    // Stable-ish test timestamp
    1_700_000_000
}

fn base_cfg() -> VerifierConfig {
    VerifierConfig {
        max_token_bytes: 4096,
        max_caveats: 64,
        clock_skew_secs: 60,
        soa_threshold: 8, // crossover for streaming vs SoA
    }
}

fn base_ctx() -> RequestCtx {
    RequestCtx {
        now_unix_s: now(),
        method: "GET".into(),
        path: "/index/items/42".into(),
        peer_ip: Some(IpAddr::from_str("127.0.0.1").unwrap()),
        object_addr: None,
        tenant: "test".into(),
        amnesia: false,
        policy_digest_hex: Some("aud-demo".into()),
        extras: Value::Null,
    }
}

#[test]
fn allow_happy_path() {
    // Scope allows GET under /index/
    let scope = Scope {
        prefix: Some("/index/".into()),
        methods: vec!["GET".into()],
        max_bytes: None,
    };

    // Build a capability with audience + path prefix + method + tenant + exp
    let cap = CapabilityBuilder::new(scope, "test", "k1")
        .caveat(Caveat::Aud("aud-demo".into()))
        .caveat(Caveat::PathPrefix("/index/".into()))
        .caveat(Caveat::Method(vec!["GET".into()]))
        .caveat(Caveat::Tenant("test".into()))
        .caveat(Caveat::Exp(now() + 300))
        .build();

    // Sign + encode
    let tok = sign_and_encode_b64url(&cap, &StaticKeys).expect("sign");

    // Verify
    let decision = verify_token(&base_cfg(), &tok, &base_ctx(), &StaticKeys).expect("verify ok");
    match decision {
        Decision::Allow { scope } => {
            assert_eq!(scope.prefix.as_deref(), Some("/index/"));
        }
        _ => panic!("expected Allow"),
    }
}

#[test]
fn deny_method_not_allowed() {
    // Scope allows GET under /index/
    let scope = Scope {
        prefix: Some("/index/".into()),
        methods: vec!["GET".into()],
        max_bytes: None,
    };

    let cap = CapabilityBuilder::new(scope, "test", "k1")
        .caveat(Caveat::Aud("aud-demo".into()))
        .caveat(Caveat::PathPrefix("/index/".into()))
        .caveat(Caveat::Method(vec!["GET".into()]))
        .caveat(Caveat::Tenant("test".into()))
        .caveat(Caveat::Exp(now() + 300))
        .build();

    let tok = sign_and_encode_b64url(&cap, &StaticKeys).expect("sign");

    // Change method in context to POST to trigger deny
    let mut ctx = base_ctx();
    ctx.method = "POST".into();

    let decision = verify_token(&base_cfg(), &tok, &ctx, &StaticKeys).expect("verify ok");
    match decision {
        Decision::Deny { reasons } => {
            assert!(reasons.contains(&DenyReason::MethodNotAllowed));
        }
        _ => panic!("expected Deny"),
    }
}

#[test]
fn error_mac_mismatch() {
    // Tamper with token bytes after signing to ensure MAC mismatch is caught.
    let scope = Scope {
        prefix: None,
        methods: vec!["GET".into()],
        max_bytes: None,
    };
    let cap = CapabilityBuilder::new(scope, "test", "k1")
        .caveat(Caveat::Exp(now() + 60))
        .build();
    let tok = sign_and_encode_b64url(&cap, &StaticKeys).expect("sign");

    // Flip one character safely within base64url alphabet
    let mut chars: Vec<u8> = tok.as_bytes().to_vec();
    // Find a position that is not '-' or '_' and flip it.
    let pos = chars
        .iter()
        .position(|&c| c != b'-' && c != b'_')
        .unwrap_or(0);
    chars[pos] = if chars[pos] != b'A' { b'A' } else { b'B' };
    let tampered = String::from_utf8(chars).unwrap();

    let err = verify_token(&base_cfg(), &tampered, &base_ctx(), &StaticKeys).unwrap_err();
    match err {
        AuthError::Malformed(_) | AuthError::MacMismatch => {} // either decode fails or MAC fails
        other => panic!("unexpected error: {:?}", other),
    }
}

#[test]
fn error_expired() {
    // Exp in the past triggers AuthError::Expired (hard error).
    let scope = Scope {
        prefix: None,
        methods: vec!["GET".into()],
        max_bytes: None,
    };
    let cap = CapabilityBuilder::new(scope, "test", "k1")
        .caveat(Caveat::Exp(now() - 3600))
        .build();
    let tok = sign_and_encode_b64url(&cap, &StaticKeys).expect("sign");

    let err = verify_token(&base_cfg(), &tok, &base_ctx(), &StaticKeys).unwrap_err();
    assert!(matches!(err, AuthError::Expired));
}

```

### crates/ron-auth/tests/amnesia_mode.rs
<a id="crates-ron-auth-tests-amnesiamode-rs"></a>

```rust
// test: amnesia mode placeholder

```

### crates/ron-auth/tests/attenuation_monotonicity.rs
<a id="crates-ron-auth-tests-attenuationmonotonicity-rs"></a>

```rust
//! Property: Adding extra caveats never *widens* access.
//! We approximate by holding scope fixed and adding either Exp tightening or PathPrefix tightening.
use proptest::prelude::*;
use ron_auth::{
    verify_token, CapabilityBuilder, Caveat, Decision, MacKey, MacKeyProvider, RequestCtx, Scope,
    VerifierConfig,
};
use serde_cbor::Value;

#[derive(Clone)]
struct Keys;
impl MacKeyProvider for Keys {
    fn key_for(&self, kid: &str, tid: &str) -> Option<MacKey> {
        if kid == "k1" && tid == "tenant-a" {
            Some(MacKey(*b"0123456789abcdef0123456789abcdef"))
        } else {
            None
        }
    }
}

fn ctx(now: u64, path: &str) -> RequestCtx {
    RequestCtx {
        now_unix_s: now,
        method: "GET".into(),
        path: path.into(),
        peer_ip: None,
        object_addr: None,
        tenant: "tenant-a".into(),
        amnesia: false,
        policy_digest_hex: Some("aud-demo".into()),
        extras: Value::Null,
    }
}
fn cfg() -> VerifierConfig {
    VerifierConfig {
        max_token_bytes: 4096,
        max_caveats: 128,
        clock_skew_secs: 60,
        soa_threshold: 8,
    }
}

proptest! {
    #[test]
    fn adding_stricter_caveats_does_not_turn_deny_into_allow(
        now in 1_699_999_500u64..=1_700_000_500u64,
        suffix in "[a-z]{0,8}"
    ) {
        let scope = Scope { prefix: Some("/index/".into()), methods: vec!["GET".into()], max_bytes: None };

        // Parent: exp near future; GET /index/*
        let parent = CapabilityBuilder::new(scope.clone(), "tenant-a", "k1")
            .caveat(Caveat::Aud("aud-demo".into()))
            .caveat(Caveat::Tenant("tenant-a".into()))
            .caveat(Caveat::Method(vec!["GET".into()]))
            .caveat(Caveat::PathPrefix("/index/".into()))
            .caveat(Caveat::Exp(now + 300))
            .build();
        let parent_b64 = ron_auth::sign_and_encode_b64url(&parent, &Keys).unwrap();

        // Child: add tighter expiry and tighter path
        let child = CapabilityBuilder::new(scope, "tenant-a", "k1")
            .caveat(Caveat::Aud("aud-demo".into()))
            .caveat(Caveat::Tenant("tenant-a".into()))
            .caveat(Caveat::Method(vec!["GET".into()]))
            .caveat(Caveat::PathPrefix(format!("/index/{suffix}")))
            .caveat(Caveat::Exp(now + 60))
            .build();
        let child_b64 = ron_auth::sign_and_encode_b64url(&child, &Keys).unwrap();

        // Pick a path potentially inside or outside child prefix.
        let path = format!("/index/{suffix}/item");
        let parent_dec = verify_token(&cfg(), &parent_b64, &ctx(now, &path), &Keys).unwrap();
        let child_dec = verify_token(&cfg(), &child_b64, &ctx(now, &path), &Keys).unwrap();

        // If parent denied, child must NOT become Allow.
        if matches!(parent_dec, Decision::Deny { .. }) {
            assert!(matches!(child_dec, Decision::Deny { .. }));
        }
    }
}

```

### crates/ron-auth/tests/compat_public_api.rs
<a id="crates-ron-auth-tests-compatpublicapi-rs"></a>

```rust
// test: public API stability placeholder

```

### crates/ron-auth/tests/ip_cidr.rs
<a id="crates-ron-auth-tests-ipcidr-rs"></a>

```rust
// RO:WHAT   IpCidr caveat sanity (allow/deny).
// RO:WHY    Lock CIDR parsing and membership semantics.
// RO:INVARIANTS Pure; BLAKE3; deterministic; no I/O.

use ron_auth::{
    sign_and_encode_b64url, verify_token, CapabilityBuilder, Caveat, Decision, DenyReason, MacKey,
    MacKeyProvider, RequestCtx, Scope, VerifierConfig,
};
use serde_cbor::Value;
use std::net::IpAddr;
use std::str::FromStr;

#[derive(Clone)]
struct StaticKeys;
impl MacKeyProvider for StaticKeys {
    fn key_for(&self, kid: &str, tid: &str) -> Option<MacKey> {
        if kid == "k1" && tid == "test" {
            Some(MacKey(*b"0123456789abcdef0123456789abcdef"))
        } else {
            None
        }
    }
}

fn now() -> u64 {
    1_700_000_000
}

fn cfg() -> VerifierConfig {
    VerifierConfig {
        max_token_bytes: 4096,
        max_caveats: 64,
        clock_skew_secs: 60,
        soa_threshold: 8, // crossover for streaming vs SoA
    }
}

fn ctx_with_ip(ip: &str) -> RequestCtx {
    RequestCtx {
        now_unix_s: now(),
        method: "GET".into(),
        path: "/".into(),
        peer_ip: Some(IpAddr::from_str(ip).unwrap()),
        object_addr: None,
        tenant: "test".into(),
        amnesia: false,
        policy_digest_hex: Some("aud-demo".into()),
        extras: Value::Null,
    }
}

#[test]
fn ip_cidr_allow_ipv4() {
    let scope = Scope {
        prefix: None,
        methods: vec!["GET".into()],
        max_bytes: None,
    };
    let cap = CapabilityBuilder::new(scope, "test", "k1")
        .caveat(Caveat::Aud("aud-demo".into()))
        .caveat(Caveat::IpCidr("192.168.1.0/24".into()))
        .caveat(Caveat::Exp(now() + 60))
        .build();
    let tok = sign_and_encode_b64url(&cap, &StaticKeys).unwrap();

    let dec = verify_token(&cfg(), &tok, &ctx_with_ip("192.168.1.42"), &StaticKeys).unwrap();
    assert!(matches!(dec, Decision::Allow { .. }));
}

#[test]
fn ip_cidr_deny_outside() {
    let scope = Scope {
        prefix: None,
        methods: vec!["GET".into()],
        max_bytes: None,
    };
    let cap = CapabilityBuilder::new(scope, "test", "k1")
        .caveat(Caveat::Aud("aud-demo".into()))
        .caveat(Caveat::IpCidr("10.0.0.0/8".into()))
        .caveat(Caveat::Exp(now() + 60))
        .build();
    let tok = sign_and_encode_b64url(&cap, &StaticKeys).unwrap();

    let dec = verify_token(&cfg(), &tok, &ctx_with_ip("192.168.1.42"), &StaticKeys).unwrap();
    match dec {
        Decision::Deny { reasons } => assert!(reasons.contains(&DenyReason::IpNotAllowed)),
        _ => panic!("expected Deny"),
    }
}

#[test]
fn ip_cidr_deny_malformed() {
    let scope = Scope {
        prefix: None,
        methods: vec!["GET".into()],
        max_bytes: None,
    };
    let cap = CapabilityBuilder::new(scope, "test", "k1")
        .caveat(Caveat::Aud("aud-demo".into()))
        .caveat(Caveat::IpCidr("not-a-cidr".into()))
        .caveat(Caveat::Exp(now() + 60))
        .build();
    let tok = sign_and_encode_b64url(&cap, &StaticKeys).unwrap();

    let dec = verify_token(&cfg(), &tok, &ctx_with_ip("127.0.0.1"), &StaticKeys).unwrap();
    match dec {
        Decision::Deny { reasons } => assert!(reasons.contains(&DenyReason::IpNotAllowed)),
        _ => panic!("expected Deny"),
    }
}

```

### crates/ron-auth/tests/loom_verify.rs
<a id="crates-ron-auth-tests-loomverify-rs"></a>

```rust
// test: loom concurrency model placeholder

```

### crates/ron-auth/tests/parser_fixtures.rs
<a id="crates-ron-auth-tests-parserfixtures-rs"></a>

```rust
// test: parser fixtures placeholder

```

### crates/ron-auth/tests/verify_batch_order.rs
<a id="crates-ron-auth-tests-verifybatchorder-rs"></a>

```rust
// RO:WHAT   Batch verify order preservation on mixed good/bad tokens.
// RO:WHY    Ensure verify_many returns decisions in input order.
// RO:INVARIANTS No I/O; deterministic; avoid hard errors (Malformed/UnknownKid) in this test.

use ron_auth::{
    sign_and_encode_b64url, verify_many, CapabilityBuilder, Caveat, Decision, MacKey,
    MacKeyProvider, RequestCtx, Scope, VerifierConfig,
};
use serde_cbor::Value;
use std::net::IpAddr;
use std::str::FromStr;

#[derive(Clone)]
struct StaticKeys;
impl MacKeyProvider for StaticKeys {
    fn key_for(&self, kid: &str, tid: &str) -> Option<MacKey> {
        // Known good pair for tests
        if kid == "k1" && tid == "test" {
            Some(MacKey(*b"0123456789abcdef0123456789abcdef"))
        } else {
            None
        }
    }
}

fn now() -> u64 {
    1_700_000_000
}

fn cfg() -> VerifierConfig {
    VerifierConfig {
        max_token_bytes: 4096,
        max_caveats: 64,
        clock_skew_secs: 60,
        soa_threshold: 8,
    }
}

fn ctx() -> RequestCtx {
    RequestCtx {
        now_unix_s: now(),
        method: "GET".into(),
        path: "/index/items/42".into(),
        peer_ip: Some(IpAddr::from_str("127.0.0.1").unwrap()),
        object_addr: None,
        tenant: "test".into(),
        amnesia: false,
        policy_digest_hex: Some("aud-demo".into()),
        extras: Value::Null,
    }
}

fn tok_allow() -> String {
    let scope = Scope {
        prefix: Some("/index/".into()),
        methods: vec!["GET".into()],
        max_bytes: None,
    };
    let cap = CapabilityBuilder::new(scope, "test", "k1")
        .caveat(Caveat::Aud("aud-demo".into()))
        .caveat(Caveat::Tenant("test".into()))
        .caveat(Caveat::PathPrefix("/index/".into()))
        .caveat(Caveat::Method(vec!["GET".into()]))
        .caveat(Caveat::Exp(now() + 300))
        .build();
    sign_and_encode_b64url(&cap, &StaticKeys).unwrap()
}

// Valid token that will evaluate to Deny (path/method mismatch) — NOT malformed, NOT unknown kid.
fn tok_deny() -> String {
    let scope = Scope {
        prefix: Some("/admin/".into()),
        methods: vec!["POST".into()],
        max_bytes: None,
    };
    let cap = CapabilityBuilder::new(scope, "test", "k1")
        .caveat(Caveat::Aud("aud-demo".into()))
        .caveat(Caveat::Tenant("test".into()))
        .caveat(Caveat::PathPrefix("/admin/".into()))
        .caveat(Caveat::Method(vec!["POST".into()]))
        .caveat(Caveat::Exp(now() + 300))
        .build();
    sign_and_encode_b64url(&cap, &StaticKeys).unwrap()
}

#[test]
fn order_preserved_mixed() {
    // Mixed batch: Allow, Deny(valid), Allow, Allow
    let batch = vec![tok_allow(), tok_deny(), tok_allow(), tok_allow()];

    let decisions = verify_many(&cfg(), &batch, &ctx(), &StaticKeys).unwrap();
    assert_eq!(decisions.len(), 4);

    assert!(matches!(decisions[0], Decision::Allow { .. }));
    assert!(matches!(decisions[1], Decision::Deny { .. }));
    assert!(matches!(decisions[2], Decision::Allow { .. }));
    assert!(matches!(decisions[3], Decision::Allow { .. }));
}

```

### crates/ron-auth/tests/verify_error_path.rs
<a id="crates-ron-auth-tests-verifyerrorpath-rs"></a>

```rust
//! Error-path sanity: UnknownKid, Expired, Malformed (tuple variant), and basic shape.
use ron_auth::{
    verify_token, AuthError, CapabilityBuilder, MacKey, MacKeyProvider, RequestCtx, Scope,
    VerifierConfig,
};
use serde_cbor::Value;

#[derive(Clone)]
struct KeysOk;
impl MacKeyProvider for KeysOk {
    fn key_for(&self, kid: &str, tid: &str) -> Option<MacKey> {
        if kid == "k1" && tid == "tenant-a" {
            Some(MacKey(*b"0123456789abcdef0123456789abcdef"))
        } else {
            None
        }
    }
}

#[derive(Clone)]
struct KeysEmpty;
impl MacKeyProvider for KeysEmpty {
    fn key_for(&self, _kid: &str, _tid: &str) -> Option<MacKey> {
        None
    }
}

fn base_ctx() -> RequestCtx {
    RequestCtx {
        now_unix_s: 1_700_000_000,
        method: "GET".into(),
        path: "/index/abc".into(),
        peer_ip: None,
        object_addr: None,
        tenant: "tenant-a".into(),
        amnesia: false,
        policy_digest_hex: Some("aud-demo".into()),
        extras: Value::Null,
    }
}

fn cfg() -> VerifierConfig {
    VerifierConfig {
        max_token_bytes: 4096,
        max_caveats: 128,
        clock_skew_secs: 60,
        soa_threshold: 8,
    }
}

fn signed_ok() -> String {
    let scope = Scope {
        prefix: Some("/index/".into()),
        methods: vec!["GET".into()],
        max_bytes: None,
    };
    let cap = CapabilityBuilder::new(scope, "tenant-a", "k1")
        .caveat(ron_auth::Caveat::Aud("aud-demo".into()))
        .caveat(ron_auth::Caveat::Tenant("tenant-a".into()))
        .caveat(ron_auth::Caveat::PathPrefix("/index/".into()))
        .caveat(ron_auth::Caveat::Method(vec!["GET".into()]))
        .caveat(ron_auth::Caveat::Exp(base_ctx().now_unix_s + 60))
        .build();
    ron_auth::sign_and_encode_b64url(&cap, &KeysOk).unwrap()
}

#[test]
fn unknown_kid() {
    let tok = signed_ok();
    let err = verify_token(&cfg(), &tok, &base_ctx(), &KeysEmpty).unwrap_err();
    // tuple variant carries a &'static str
    assert!(matches!(err, AuthError::UnknownKid));
}

#[test]
fn expired() {
    let scope = Scope {
        prefix: Some("/index/".into()),
        methods: vec!["GET".into()],
        max_bytes: None,
    };
    let cap = CapabilityBuilder::new(scope, "tenant-a", "k1")
        .caveat(ron_auth::Caveat::Aud("aud-demo".into()))
        .caveat(ron_auth::Caveat::Tenant("tenant-a".into()))
        .caveat(ron_auth::Caveat::Exp(base_ctx().now_unix_s - 61))
        .build();
    let tok = ron_auth::sign_and_encode_b64url(&cap, &KeysOk).unwrap();
    let err = verify_token(&cfg(), &tok, &base_ctx(), &KeysOk).unwrap_err();
    assert!(matches!(err, AuthError::Expired));
}

#[test]
fn malformed_base64() {
    let bad = "!!!this-is-not-base64url!!!";
    let err = verify_token(&cfg(), bad, &base_ctx(), &KeysOk).unwrap_err();
    // tuple variant requires payload pattern
    assert!(matches!(err, AuthError::Malformed(_)));
}

```

### crates/ron-auth/tests/verify_happy_path.rs
<a id="crates-ron-auth-tests-verifyhappypath-rs"></a>

```rust
//! Happy-path verification: small token that should ALLOW.
use ron_auth::{
    verify_token, CapabilityBuilder, Caveat, Decision, MacKey, MacKeyProvider, RequestCtx, Scope,
    VerifierConfig,
};
use serde_cbor::Value;

#[derive(Clone)]
struct StaticKeys;
impl MacKeyProvider for StaticKeys {
    fn key_for(&self, kid: &str, tid: &str) -> Option<MacKey> {
        if kid == "k1" && tid == "tenant-a" {
            Some(MacKey(*b"0123456789abcdef0123456789abcdef"))
        } else {
            None
        }
    }
}

fn ctx() -> RequestCtx {
    RequestCtx {
        now_unix_s: 1_700_000_000,
        method: "GET".into(),
        path: "/index/abc".into(),
        peer_ip: None,
        object_addr: None,
        tenant: "tenant-a".into(),
        amnesia: false,
        policy_digest_hex: Some("aud-demo".into()),
        extras: Value::Null,
    }
}

fn cfg() -> VerifierConfig {
    VerifierConfig {
        max_token_bytes: 4096,
        max_caveats: 128,
        clock_skew_secs: 60,
        // keep your hybrid crossover knob (as in benches)
        soa_threshold: 8,
    }
}

#[test]
fn allow_small_token() {
    // Build a minimal “allow GET /index/*” token for tenant-a, kid k1
    let scope = Scope {
        prefix: Some("/index/".into()),
        methods: vec!["GET".into()],
        max_bytes: None,
    };
    let cap = CapabilityBuilder::new(scope, "tenant-a", "k1")
        .caveat(Caveat::Aud("aud-demo".into()))
        .caveat(Caveat::Tenant("tenant-a".into()))
        .caveat(Caveat::PathPrefix("/index/".into()))
        .caveat(Caveat::Method(vec!["GET".into()]))
        .caveat(Caveat::Exp(ctx().now_unix_s + 600))
        .build();

    // Use the same signing helper your benches use.
    let token_b64 = ron_auth::sign_and_encode_b64url(&cap, &StaticKeys).expect("sign");

    let d = verify_token(&cfg(), &token_b64, &ctx(), &StaticKeys).expect("verify");
    match d {
        Decision::Allow { scope } => {
            assert_eq!(scope.prefix.as_deref(), Some("/index/"));
            assert!(scope.methods.iter().any(|m| m == "GET"));
        }
        _ => panic!("expected Allow, got {d:?}"),
    }
}

```



---



# micronode

_Source: crates/micronode/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-11-18T21:01:02Z -->
# Code Bundle — `micronode`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/micronode/.clippy.toml](#crates-micronode--clippy-toml)
- [crates/micronode/.rustfmt.toml](#crates-micronode--rustfmt-toml)
- [crates/micronode/Cargo.toml](#crates-micronode-Cargo-toml)
- [crates/micronode/benches/http_kv.rs](#crates-micronode-benches-httpkv-rs)
- [crates/micronode/benches/oap_frame_perf.rs](#crates-micronode-benches-oapframeperf-rs)
- [crates/micronode/benches/pq_overhead.rs](#crates-micronode-benches-pqoverhead-rs)
- [crates/micronode/benches/readiness_walk.rs](#crates-micronode-benches-readinesswalk-rs)
- [crates/micronode/build.rs](#crates-micronode-build-rs)
- [crates/micronode/configs/micronode.amnesia.off.toml](#crates-micronode-configs-micronode-amnesia-off-toml)
- [crates/micronode/configs/micronode.dev.toml](#crates-micronode-configs-micronode-dev-toml)
- [crates/micronode/configs/micronode.facets.toml](#crates-micronode-configs-micronode-facets-toml)
- [crates/micronode/configs/micronode.pq.required.toml](#crates-micronode-configs-micronode-pq-required-toml)
- [crates/micronode/configs/micronode.pq.toml](#crates-micronode-configs-micronode-pq-toml)
- [crates/micronode/configs/micronode.toml](#crates-micronode-configs-micronode-toml)
- [crates/micronode/deny.toml](#crates-micronode-deny-toml)
- [crates/micronode/dev_facets/docs.toml](#crates-micronode-devfacets-docs-toml)
- [crates/micronode/dev_facets/echo.toml](#crates-micronode-devfacets-echo-toml)
- [crates/micronode/examples/quickstart.rs](#crates-micronode-examples-quickstart-rs)
- [crates/micronode/fuzz/config_from_env_fuzz.rs](#crates-micronode-fuzz-configfromenvfuzz-rs)
- [crates/micronode/fuzz/pq_kex_fuzz.rs](#crates-micronode-fuzz-pqkexfuzz-rs)
- [crates/micronode/scripts/beta_check.sh](#crates-micronode-scripts-betacheck-sh)
- [crates/micronode/scripts/chaos_degrade_shed.sh](#crates-micronode-scripts-chaosdegradeshed-sh)
- [crates/micronode/scripts/fs_spy_amnesia.sh](#crates-micronode-scripts-fsspyamnesia-sh)
- [crates/micronode/scripts/gen_diagrams.sh](#crates-micronode-scripts-gendiagrams-sh)
- [crates/micronode/scripts/pq_matrix_ci.sh](#crates-micronode-scripts-pqmatrixci-sh)
- [crates/micronode/scripts/run_dev.sh](#crates-micronode-scripts-rundev-sh)
- [crates/micronode/scripts/smoke_micronode.sh](#crates-micronode-scripts-smokemicronode-sh)
- [crates/micronode/scripts/smoke_oap_limits.sh](#crates-micronode-scripts-smokeoaplimits-sh)
- [crates/micronode/specs/oap_vectors.json](#crates-micronode-specs-oapvectors-json)
- [crates/micronode/specs/pq_handshake_cases.json](#crates-micronode-specs-pqhandshakecases-json)
- [crates/micronode/src/adapters/index_client.rs](#crates-micronode-src-adapters-indexclient-rs)
- [crates/micronode/src/adapters/mailbox_client.rs](#crates-micronode-src-adapters-mailboxclient-rs)
- [crates/micronode/src/adapters/mod.rs](#crates-micronode-src-adapters-mod-rs)
- [crates/micronode/src/adapters/overlay_client.rs](#crates-micronode-src-adapters-overlayclient-rs)
- [crates/micronode/src/adapters/policy_client.rs](#crates-micronode-src-adapters-policyclient-rs)
- [crates/micronode/src/adapters/storage_client.rs](#crates-micronode-src-adapters-storageclient-rs)
- [crates/micronode/src/app.rs](#crates-micronode-src-app-rs)
- [crates/micronode/src/cli/args.rs](#crates-micronode-src-cli-args-rs)
- [crates/micronode/src/cli/mod.rs](#crates-micronode-src-cli-mod-rs)
- [crates/micronode/src/cli/run.rs](#crates-micronode-src-cli-run-rs)
- [crates/micronode/src/concurrency/backpressure.rs](#crates-micronode-src-concurrency-backpressure-rs)
- [crates/micronode/src/concurrency/mod.rs](#crates-micronode-src-concurrency-mod-rs)
- [crates/micronode/src/concurrency/registry.rs](#crates-micronode-src-concurrency-registry-rs)
- [crates/micronode/src/concurrency/shutdown.rs](#crates-micronode-src-concurrency-shutdown-rs)
- [crates/micronode/src/config/cli_overlay.rs](#crates-micronode-src-config-clioverlay-rs)
- [crates/micronode/src/config/env_overlay.rs](#crates-micronode-src-config-envoverlay-rs)
- [crates/micronode/src/config/hot_reload.rs](#crates-micronode-src-config-hotreload-rs)
- [crates/micronode/src/config/load.rs](#crates-micronode-src-config-load-rs)
- [crates/micronode/src/config/mod.rs](#crates-micronode-src-config-mod-rs)
- [crates/micronode/src/config/schema.rs](#crates-micronode-src-config-schema-rs)
- [crates/micronode/src/config/validate.rs](#crates-micronode-src-config-validate-rs)
- [crates/micronode/src/errors.rs](#crates-micronode-src-errors-rs)
- [crates/micronode/src/facets/feed.rs](#crates-micronode-src-facets-feed-rs)
- [crates/micronode/src/facets/graph.rs](#crates-micronode-src-facets-graph-rs)
- [crates/micronode/src/facets/loader.rs](#crates-micronode-src-facets-loader-rs)
- [crates/micronode/src/facets/manifest.rs](#crates-micronode-src-facets-manifest-rs)
- [crates/micronode/src/facets/media.rs](#crates-micronode-src-facets-media-rs)
- [crates/micronode/src/facets/mod.rs](#crates-micronode-src-facets-mod-rs)
- [crates/micronode/src/facets/search.rs](#crates-micronode-src-facets-search-rs)
- [crates/micronode/src/http/admin.rs](#crates-micronode-src-http-admin-rs)
- [crates/micronode/src/http/kv.rs](#crates-micronode-src-http-kv-rs)
- [crates/micronode/src/http/mod.rs](#crates-micronode-src-http-mod-rs)
- [crates/micronode/src/http/routes.rs](#crates-micronode-src-http-routes-rs)
- [crates/micronode/src/layers/body_cap.rs](#crates-micronode-src-layers-bodycap-rs)
- [crates/micronode/src/layers/concurrency.rs](#crates-micronode-src-layers-concurrency-rs)
- [crates/micronode/src/layers/decode_guard.rs](#crates-micronode-src-layers-decodeguard-rs)
- [crates/micronode/src/layers/mod.rs](#crates-micronode-src-layers-mod-rs)
- [crates/micronode/src/layers/security.rs](#crates-micronode-src-layers-security-rs)
- [crates/micronode/src/lib.rs](#crates-micronode-src-lib-rs)
- [crates/micronode/src/limits.rs](#crates-micronode-src-limits-rs)
- [crates/micronode/src/main.rs](#crates-micronode-src-main-rs)
- [crates/micronode/src/observability/health.rs](#crates-micronode-src-observability-health-rs)
- [crates/micronode/src/observability/http_metrics.rs](#crates-micronode-src-observability-httpmetrics-rs)
- [crates/micronode/src/observability/logging.rs](#crates-micronode-src-observability-logging-rs)
- [crates/micronode/src/observability/metrics.rs](#crates-micronode-src-observability-metrics-rs)
- [crates/micronode/src/observability/mod.rs](#crates-micronode-src-observability-mod-rs)
- [crates/micronode/src/observability/ready.rs](#crates-micronode-src-observability-ready-rs)
- [crates/micronode/src/observability/version.rs](#crates-micronode-src-observability-version-rs)
- [crates/micronode/src/security/amnesia.rs](#crates-micronode-src-security-amnesia-rs)
- [crates/micronode/src/security/auth_macaroon.rs](#crates-micronode-src-security-authmacaroon-rs)
- [crates/micronode/src/security/mod.rs](#crates-micronode-src-security-mod-rs)
- [crates/micronode/src/security/pq_config.rs](#crates-micronode-src-security-pqconfig-rs)
- [crates/micronode/src/security/pq_observe.rs](#crates-micronode-src-security-pqobserve-rs)
- [crates/micronode/src/security/pq_toggle.rs](#crates-micronode-src-security-pqtoggle-rs)
- [crates/micronode/src/security/tls_rustls.rs](#crates-micronode-src-security-tlsrustls-rs)
- [crates/micronode/src/state.rs](#crates-micronode-src-state-rs)
- [crates/micronode/src/storage/mod.rs](#crates-micronode-src-storage-mod-rs)
- [crates/micronode/src/storage/sled_store.rs](#crates-micronode-src-storage-sledstore-rs)
- [crates/micronode/src/types.rs](#crates-micronode-src-types-rs)
- [crates/micronode/tests/admin_parity.rs](#crates-micronode-tests-adminparity-rs)
- [crates/micronode/tests/amnesia_proof.rs](#crates-micronode-tests-amnesiaproof-rs)
- [crates/micronode/tests/auth_gate.rs](#crates-micronode-tests-authgate-rs)
- [crates/micronode/tests/backpressure.rs](#crates-micronode-tests-backpressure-rs)
- [crates/micronode/tests/cli_smoke.rs](#crates-micronode-tests-clismoke-rs)
- [crates/micronode/tests/facets_loader.rs](#crates-micronode-tests-facetsloader-rs)
- [crates/micronode/tests/facets_proxy.rs](#crates-micronode-tests-facetsproxy-rs)
- [crates/micronode/tests/guard_behavior.rs](#crates-micronode-tests-guardbehavior-rs)
- [crates/micronode/tests/kv_roundtrip.rs](#crates-micronode-tests-kvroundtrip-rs)
- [crates/micronode/tests/oap_limits.rs](#crates-micronode-tests-oaplimits-rs)
- [crates/micronode/tests/pq_fallback.rs](#crates-micronode-tests-pqfallback-rs)
- [crates/micronode/tests/pq_modes.rs](#crates-micronode-tests-pqmodes-rs)
- [crates/micronode/tests_chaos/degrade_shed.rs](#crates-micronode-testschaos-degradeshed-rs)
- [crates/micronode/tests_loom/shutdown_interleavings.rs](#crates-micronode-testsloom-shutdowninterleavings-rs)
- [crates/micronode/tests_property/oap_fuzz.rs](#crates-micronode-testsproperty-oapfuzz-rs)
- [crates/micronode/tests_property/pq_handshake_props.rs](#crates-micronode-testsproperty-pqhandshakeprops-rs)

### crates/micronode/.clippy.toml
<a id="crates-micronode--clippy-toml"></a>

```toml
# Minimal, valid Clippy config (use only supported keys)
cognitive-complexity-threshold = 35
too-many-lines-threshold = 400

```

### crates/micronode/.rustfmt.toml
<a id="crates-micronode--rustfmt-toml"></a>

```toml
max_width = 100
use_small_heuristics = "Max"
# Keep stable-only options here; nightly-only options (like format_code_in_doc_comments) are removed.

```

### crates/micronode/Cargo.toml
<a id="crates-micronode-Cargo-toml"></a>

```toml
[package]
name = "micronode"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
publish = false
build = "build.rs"

[lib]
name = "micronode"
path = "src/lib.rs"

[[bin]]
name = "micronode"
path = "src/main.rs"

[features]
# RO:WHAT  — Feature flags for Micronode.
# RO:WHY   — Let us pick storage engines (mem vs sled) and later gate facets.
# RO:NOTE  — For now we only gate storage; graph/search/feed/media remain stubs.
default = ["mem-store"]

# In-memory storage engine (hashmap/RwLock). Always available.
mem-store = []

# Sled-backed storage engine (optional, may be used by KV v1 later).
sled-store = ["sled"]

[dependencies]
# RON workspace crates
ron-kernel = { path = "../ron-kernel" }
ron-proto  = { path = "../ron-proto" }
oap        = { path = "../oap" }

# Async/HTTP stack (workspace-standard pins)
tokio       = { version = "1", features = ["macros", "rt-multi-thread", "signal", "time", "io-util", "sync", "net", "fs"] }
axum        = { version = "0.7", default-features = false, features = ["tokio", "http1", "http2", "json"] }
tower       = "0.5"
tower-http  = { version = "0.6.6", features = ["trace"] }
http        = "1"

# Obs & logging
tracing            = "0.1"
tracing-subscriber = { version = "0.3", features = ["fmt", "env-filter"] }
prometheus         = "0.14"

# Config & serde
serde           = { version = "1.0", features = ["derive"] }
serde_json      = "1"
toml            = "0.8"
humantime-serde = "1"
anyhow          = "1.0"
thiserror       = "1.0"

# Utilities
parking_lot = "0.12"

# Storage engine (optional; gated by 'sled-store' feature)
sled = { version = "0.34", optional = true }

[dev-dependencies]
# HTTP client for admin/guard/KV tests
reqwest = { version = "0.12", features = ["rustls-tls-native-roots", "json"] }
tempfile = "3"

# Criterion for micro-benchmarks (in-process HTTP router benches)
criterion = { version = "0.5", features = ["html_reports", "async"] }

[[bench]]
name = "http_kv"
harness = false

```

### crates/micronode/benches/http_kv.rs
<a id="crates-micronode-benches-httpkv-rs"></a>

```rust
// crates/micronode/benches/http_kv.rs
//! Simple HTTP-level benchmarks for micronode.
//!
//! RO:WHAT — Benchmark the in-process Axum router for:
//!   - `/healthz` fast-path.
//!   - `/v1/kv/{bucket}/{key}` small PUT/GET/DELETE roundtrip.
//!   - `/v1/kv/{bucket}/{key}` hot reject via DecodeGuard (Content-Encoding).
//!
//! RO:WHY  — Give us a quick sanity check on HTTP latencies for the Micronode
//!           profile without binding a real TCP port.
//!
//! RO:HOW  — Build the Router via `build_router(Config::default())` and drive
//!           requests with a Tokio runtime + `Router::oneshot(req)` inside a
//!           Criterion `b.iter(...)` loop.

use axum::body::Body;
use axum::Router;
use criterion::{criterion_group, criterion_main, Criterion};
use http::{Method, Request, StatusCode};
use micronode::app::build_router;
use micronode::config::schema::Config;
use tower::ServiceExt as _; // for `oneshot`

fn build_app() -> Router {
    // For benches we can rely on Config::default(): it should give us
    // localhost bind + in-memory storage engine.
    let cfg = Config::default();
    let (router, _state) = build_router(cfg);
    router
}

fn bench_healthz(c: &mut Criterion) {
    let router = build_app();

    // Shared runtime for this benchmark.
    let rt = tokio::runtime::Builder::new_multi_thread()
        .worker_threads(2)
        .enable_all()
        .build()
        .expect("failed to build tokio runtime for benches");

    c.bench_function("http_healthz_fast_path", |b| {
        b.iter(|| {
            // Clone the Router so `oneshot(self, req)` can take ownership.
            let router = router.clone();

            rt.block_on(async move {
                let req = Request::builder()
                    .method(Method::GET)
                    .uri("/healthz")
                    .body(Body::empty())
                    .expect("healthz request build failed");

                let resp = router.oneshot(req).await.expect("healthz handler failed");

                // Sanity: ensure we stayed on the happy path.
                assert_eq!(resp.status(), StatusCode::OK);
            });
        });
    });
}

fn bench_kv_small_roundtrip(c: &mut Criterion) {
    let router = build_app();

    // Shared runtime for this benchmark.
    let rt = tokio::runtime::Builder::new_multi_thread()
        .worker_threads(2)
        .enable_all()
        .build()
        .expect("failed to build tokio runtime for benches");

    c.bench_function("http_kv_small_put_get_delete", |b| {
        b.iter(|| {
            // Clone the Router so `oneshot(self, req)` can take ownership.
            let router = router.clone();

            rt.block_on(async move {
                let bucket = "bench";
                let key = "k";

                // Payload for PUT — we must set an accurate Content-Length
                // because BodyCapLayer enforces it for POST/PUT/PATCH.
                let payload = "hello-micronode";
                let payload_len = payload.len().to_string();

                // PUT small value
                let put_req = Request::builder()
                    .method(Method::PUT)
                    .uri(format!("/v1/kv/{}/{}", bucket, key))
                    .header("content-type", "application/octet-stream")
                    .header("content-length", payload_len)
                    .body(Body::from(payload.to_owned()))
                    .expect("PUT request build failed");

                let put_resp = router.clone().oneshot(put_req).await.expect("PUT handler failed");
                assert!(
                    put_resp.status().is_success(),
                    "expected PUT success, got {}",
                    put_resp.status()
                );

                // GET the value
                let get_req = Request::builder()
                    .method(Method::GET)
                    .uri(format!("/v1/kv/{}/{}", bucket, key))
                    .body(Body::empty())
                    .expect("GET request build failed");

                let get_resp = router.clone().oneshot(get_req).await.expect("GET handler failed");
                assert_eq!(get_resp.status(), StatusCode::OK);

                // DELETE it
                let del_req = Request::builder()
                    .method(Method::DELETE)
                    .uri(format!("/v1/kv/{}/{}", bucket, key))
                    .body(Body::empty())
                    .expect("DELETE request build failed");

                let del_resp = router.oneshot(del_req).await.expect("DELETE handler failed");
                assert!(
                    del_resp.status().is_success(),
                    "expected DELETE success, got {}",
                    del_resp.status()
                );
            });
        });
    });
}

fn bench_kv_decode_guard_hot_reject(c: &mut Criterion) {
    let router = build_app();

    // Shared runtime for this benchmark.
    let rt = tokio::runtime::Builder::new_multi_thread()
        .worker_threads(2)
        .enable_all()
        .build()
        .expect("failed to build tokio runtime for benches");

    c.bench_function("http_kv_decode_guard_hot_reject", |b| {
        b.iter(|| {
            // Clone the Router so `oneshot(self, req)` can take ownership.
            let router = router.clone();

            rt.block_on(async move {
                let bucket = "bench";
                let key = "guard";

                // Tiny payload with accurate length so BodyCapLayer is satisfied
                // and we actually exercise DecodeGuard.
                let payload = "x";
                let payload_len = payload.len().to_string();

                let req = Request::builder()
                    .method(Method::PUT)
                    .uri(format!("/v1/kv/{}/{}", bucket, key))
                    .header("content-type", "application/octet-stream")
                    .header("content-length", payload_len)
                    .header("content-encoding", "gzip")
                    .body(Body::from(payload.to_owned()))
                    .expect("decode-guard PUT request build failed");

                let resp = router.oneshot(req).await.expect("decode-guard handler failed");

                // Sanity: ensure we’re measuring the hot reject, not a 411 from BodyCap.
                assert_eq!(
                    resp.status(),
                    StatusCode::UNSUPPORTED_MEDIA_TYPE,
                    "expected 415 from DecodeGuard, got {}",
                    resp.status()
                );
            });
        });
    });
}

criterion_group!(
    micronode_http,
    bench_healthz,
    bench_kv_small_roundtrip,
    bench_kv_decode_guard_hot_reject
);
criterion_main!(micronode_http);

```

### crates/micronode/benches/oap_frame_perf.rs
<a id="crates-micronode-benches-oapframeperf-rs"></a>

```rust


```

### crates/micronode/benches/pq_overhead.rs
<a id="crates-micronode-benches-pqoverhead-rs"></a>

```rust


```

### crates/micronode/benches/readiness_walk.rs
<a id="crates-micronode-benches-readinesswalk-rs"></a>

```rust


```

### crates/micronode/build.rs
<a id="crates-micronode-build-rs"></a>

```rust
// RO:WHAT — build script that stamps a UNIX build time for /version.
// RO:WHY  — Observability/versioning; helps triage running binaries.
// RO:INVARIANTS — Emits MICRONODE_BUILD_UNIX env var always.
fn main() {
    println!("cargo:rustc-env=MICRONODE_BUILD_UNIX={}", chrono_unix());
}

fn chrono_unix() -> String {
    use std::time::{SystemTime, UNIX_EPOCH};
    SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map(|d| d.as_secs().to_string())
        .unwrap_or_else(|_| "0".to_string())
}

```

### crates/micronode/configs/micronode.amnesia.off.toml
<a id="crates-micronode-configs-micronode-amnesia-off-toml"></a>

```toml

```

### crates/micronode/configs/micronode.dev.toml
<a id="crates-micronode-configs-micronode-dev-toml"></a>

```toml

```

### crates/micronode/configs/micronode.facets.toml
<a id="crates-micronode-configs-micronode-facets-toml"></a>

```toml
[server]
bind = "127.0.0.1:5310"
dev_routes = true

[storage]
engine = "mem"

[security]
mode = "dev_allow"

[facets]
enabled = true
dir = "crates/micronode/dev_facets"

```

### crates/micronode/configs/micronode.pq.required.toml
<a id="crates-micronode-configs-micronode-pq-required-toml"></a>

```toml

```

### crates/micronode/configs/micronode.pq.toml
<a id="crates-micronode-configs-micronode-pq-toml"></a>

```toml

```

### crates/micronode/configs/micronode.toml
<a id="crates-micronode-configs-micronode-toml"></a>

```toml
# RO:WHAT — Default Micronode config (beta profile).
# RO:WHY  — Workspace-local defaults for dev and smoke tests.
#           This file is safe to check in: it binds to localhost and
#           uses in-memory storage (amnesia-first).
# RO:INVARIANTS —
#   - Localhost-only bind.
#   - Dev routes enabled for quick smokes.
#   - Storage is in-memory (`engine = "mem"`) by default.

[server]
bind = "127.0.0.1:5310"
dev_routes = true

[storage]
# Amnesia-first: keep everything in memory unless explicitly changed.
engine = "mem"

# Optional: uncomment and switch engine to "sled" when you want
# persistence for this Micronode instance.
#
# engine = "sled"
# path = "micronode-data"

```

### crates/micronode/deny.toml
<a id="crates-micronode-deny-toml"></a>

```toml
[advisories]
yanked = "deny"
unmaintained = "deny"
vulnerability = "deny"

[licenses]
allow = ["MIT", "Apache-2.0"]

```

### crates/micronode/dev_facets/docs.toml
<a id="crates-micronode-devfacets-docs-toml"></a>

```toml
[facet]
id = "docs"
kind = "static"

[[route]]
method = "GET"
path = "/hello"
file = "crates/micronode/dev_facets/hello.txt"

```

### crates/micronode/dev_facets/echo.toml
<a id="crates-micronode-devfacets-echo-toml"></a>

```toml
[facet]
id = "echoer"
kind = "echo"

[[route]]
method = "GET"
path = "/who"

```

### crates/micronode/examples/quickstart.rs
<a id="crates-micronode-examples-quickstart-rs"></a>

```rust
// crates/micronode/examples/quickstart.rs
//! RO:WHAT — Minimal example entrypoint so `cargo build` succeeds.
//! RO:HOW  — Prints a hint to use the primary binary (`cargo run -p micronode`).
//! RO:FUTURE — Can be replaced later with a runnable SDK demo.

fn main() {
    println!("Micronode quickstart example.");
    println!("Run the server with:");
    println!("  MICRONODE_DEV_ROUTES=1 cargo run -p micronode");
}

```

### crates/micronode/fuzz/config_from_env_fuzz.rs
<a id="crates-micronode-fuzz-configfromenvfuzz-rs"></a>

```rust

```

### crates/micronode/fuzz/pq_kex_fuzz.rs
<a id="crates-micronode-fuzz-pqkexfuzz-rs"></a>

```rust

```

### crates/micronode/scripts/beta_check.sh
<a id="crates-micronode-scripts-betacheck-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Simple beta gate for `micronode`.
#
# Runs (from repo root):
#   1) fmt + clippy (warnings = errors)
#   2) unit + integration tests
#   3) HTTP+KV benchmarks (http_kv)
#   4) Smoke test via scripts/smoke_micronode.sh with dev routes enabled
#
# Usage:
#   bash crates/micronode/scripts/beta_check.sh
#
# Env toggles:
#   SKIP_BENCH=1  → skip Criterion benches (useful on battery / CI)

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../../.." && pwd)"
CRATE="micronode"

echo "[beta-check] crate=${CRATE} root=${ROOT_DIR}"

cd "${ROOT_DIR}"

###############################################################################
# 1) fmt + clippy
###############################################################################
echo "[beta-check] 1) fmt + clippy"
cargo fmt -p "${CRATE}"
cargo clippy -p "${CRATE}" --no-deps -- -D warnings

###############################################################################
# 2) Tests (unit + integration + doc tests)
###############################################################################
echo "[beta-check] 2) cargo test -p ${CRATE}"
cargo test -p "${CRATE}"

###############################################################################
# 3) HTTP+KV benchmarks (optional)
###############################################################################
if [[ "${SKIP_BENCH:-0}" != "1" ]]; then
  echo "[beta-check] 3) cargo bench -p ${CRATE} --bench http_kv"
  cargo bench -p "${CRATE}" --bench http_kv
else
  echo "[beta-check] 3) benches skipped (SKIP_BENCH=1)"
fi

###############################################################################
# 4) Smoke test (admin plane + KV roundtrip)
###############################################################################
echo "[beta-check] 4) smoke_micronode.sh (with MICRONODE_DEV_ROUTES=1)"

MICRONODE_DEV_ROUTES=1 cargo run -p "${CRATE}" &
APP_PID=$!

# Give the server a moment to bind.
sleep 2

# Run the smoke script (expects 127.0.0.1:5310 by default).
bash "crates/${CRATE}/scripts/smoke_micronode.sh"

echo "[beta-check] smoke_micronode.sh OK, shutting down micronode (pid=${APP_PID})"
kill "${APP_PID}" >/dev/null 2>&1 || true
wait "${APP_PID}" 2>/dev/null || true

echo "[beta-check] ✅ ${CRATE} beta gate PASSED"

```

### crates/micronode/scripts/chaos_degrade_shed.sh
<a id="crates-micronode-scripts-chaosdegradeshed-sh"></a>

```bash

```

### crates/micronode/scripts/fs_spy_amnesia.sh
<a id="crates-micronode-scripts-fsspyamnesia-sh"></a>

```bash

```

### crates/micronode/scripts/gen_diagrams.sh
<a id="crates-micronode-scripts-gendiagrams-sh"></a>

```bash

```

### crates/micronode/scripts/pq_matrix_ci.sh
<a id="crates-micronode-scripts-pqmatrixci-sh"></a>

```bash

```

### crates/micronode/scripts/run_dev.sh
<a id="crates-micronode-scripts-rundev-sh"></a>

```bash

```

### crates/micronode/scripts/smoke_micronode.sh
<a id="crates-micronode-scripts-smokemicronode-sh"></a>

```bash
#!/usr/bin/env bash
# smoke_micronode.sh — one-shot smoke test for Micronode
# Modes:
#   (default)   — assumes micronode already running on ADDR (two-terminal workflow)
#   --spawn     — kills port holder on 5310, spawns micronode in background, runs checks, then cleans up
#
# Env knobs:
#   ADDR                 — admin/API addr (default 127.0.0.1:5310)
#   RUST_LOG             — log level when spawning (default info,micronode=debug)
#   MICRONODE_DEV_ROUTES — when spawning, enable dev routes (default 1)

set -euo pipefail

ADDR="${ADDR:-127.0.0.1:5310}"
RUST_LOG="${RUST_LOG:-info,micronode=debug}"

SPAWN=0
if [[ "${1:-}" == "--spawn" ]]; then
  SPAWN=1
fi

# Utilities (macOS-friendly)
die() { echo "[ERR] $*" >&2; exit 1; }
info() { echo "[INFO] $*"; }
ok() { echo "[OK] $*"; }
step() { echo "[STEP] $*"; }

kill_port_holders() {
  local port="$1"
  local pids
  if pids=$(lsof -ti tcp:"$port" 2>/dev/null); then
    if [[ -n "$pids" ]]; then
      info "Port $port busy. Killing holder(s)…"
      # shellcheck disable=SC2086
      kill -9 $pids || true
      sleep 0.2
    fi
  fi
}

wait_for_healthz() {
  local url="$1"
  local retries="${2:-60}" # ~60s max
  local i=0
  info "Waiting for $url ..."
  until curl -sSf -o /dev/null "$url"; do
    i=$((i+1)) || true
    if [[ "$i" -ge "$retries" ]]; then
      die "Timed out waiting for $url"
    fi
    sleep 1
  done
  ok "Healthy: $url"
}

MICRO_PID=""
LOG_FILE=""

cleanup() {
  if [[ -n "$MICRO_PID" ]]; then
    info "Killing micronode (pid=$MICRO_PID)…"
    kill "$MICRO_PID" 2>/dev/null || true
  fi
  if [[ -n "$LOG_FILE" && -f "$LOG_FILE" ]]; then
    info "Micronode logs were captured in: $LOG_FILE"
  fi
}
trap cleanup EXIT

if [[ "$SPAWN" -eq 1 ]]; then
  info "Spawn mode: will start micronode on ${ADDR}"
  # Assume ADDR is host:port; we only care about the port for kill_port_holders
  PORT="${ADDR##*:}"
  kill_port_holders "$PORT"

  LOG_FILE="$(mktemp -t micronode-smoke-XXXX.log)"
  info "Spawning micronode (logs -> $LOG_FILE)…"

  MICRONODE_DEV_ROUTES="${MICRONODE_DEV_ROUTES:-1}" \
  RUST_LOG="$RUST_LOG" \
    cargo run -p micronode >"$LOG_FILE" 2>&1 &

  MICRO_PID=$!
  sleep 0.5
fi

BASE_URL="http://${ADDR}"

step "Admin plane checks"
wait_for_healthz "${BASE_URL}/healthz"

info "GET /metrics (head)"
curl -sSf "${BASE_URL}/metrics" | head -n 20 >/tmp/micronode_metrics_head.$$ || die "/metrics not reachable"
ok "/metrics reachable"

# Optional: assert our http metrics family is present
if curl -sSf "${BASE_URL}/metrics" | grep -q "micronode_http_requests_total"; then
  ok "micronode_http_requests_total present in /metrics"
else
  info "micronode_http_requests_total not seen yet (may appear after more traffic)"
fi

step "Readiness (/readyz)"
curl -sSf "${BASE_URL}/readyz" | jq . || die "/readyz failed"
ok "/readyz returned JSON"

step "Version (/version)"
curl -sSf "${BASE_URL}/version" | jq . || die "/version failed"
ok "/version returned JSON"

step "KV roundtrip via /v1/kv/{bucket}/{key}"
BUCKET="${BUCKET:-smoke}"
KEY="${KEY:-k}"
VALUE="${VALUE:-hello-micronode}"

PUT_CODE=$(curl -sS -o /dev/null -w "%{http_code}" \
  -X PUT "${BASE_URL}/v1/kv/${BUCKET}/${KEY}" \
  -H 'content-type: application/octet-stream' \
  --data-binary "${VALUE}" || true)

echo "[INFO] PUT status: ${PUT_CODE}"
if [[ "${PUT_CODE}" != "201" && "${PUT_CODE}" != "204" ]]; then
  die "Expected 201/204 from PUT, got ${PUT_CODE}"
fi
ok "PUT /v1/kv/${BUCKET}/${KEY} → ${PUT_CODE}"

GET_BODY=$(curl -sS "${BASE_URL}/v1/kv/${BUCKET}/${KEY}" || true)
echo "[INFO] GET body: ${GET_BODY}"
if [[ "${GET_BODY}" != "${VALUE}" ]]; then
  die "Expected GET body '${VALUE}', got '${GET_BODY}'"
fi
ok "GET /v1/kv/${BUCKET}/${KEY} roundtrip OK"

DEL_CODE=$(curl -sS -o /dev/null -w "%{http_code}" \
  -X DELETE "${BASE_URL}/v1/kv/${BUCKET}/${KEY}" || true)

echo "[INFO] DELETE status: ${DEL_CODE}"
if [[ "${DEL_CODE}" != "204" ]]; then
  die "Expected 204 from DELETE, got ${DEL_CODE}"
fi
ok "DELETE /v1/kv/${BUCKET}/${KEY} → ${DEL_CODE}"

echo "✅ micronode smoke OK"

```

### crates/micronode/scripts/smoke_oap_limits.sh
<a id="crates-micronode-scripts-smokeoaplimits-sh"></a>

```bash

```

### crates/micronode/specs/oap_vectors.json
<a id="crates-micronode-specs-oapvectors-json"></a>

```json

```

### crates/micronode/specs/pq_handshake_cases.json
<a id="crates-micronode-specs-pqhandshakecases-json"></a>

```json

```

### crates/micronode/src/adapters/index_client.rs
<a id="crates-micronode-src-adapters-indexclient-rs"></a>

```rust
//! RO:WHAT — Lightweight handle for talking to the index service
//!           (svc-index) from Micronode.
//!
//! RO:WHY  — Keep any future index-related flows behind a tiny,
//!           testable wrapper so Micronode core is not sprinkled with
//!           raw URLs.
//!
//! RO:INVARIANTS —
//!   * No network I/O here; this is just a configuration container.
//!   * `base_url` is assumed to point at the svc-index HTTP or OAP
//!     ingress surface depending on how the node is wired.
//!
//! RO:TEST — Trivial type; basic behavior is indirectly tested via
//!           the `adapters` module tests.

#[derive(Clone, Debug)]
pub struct IndexClient {
    base_url: String,
}

impl IndexClient {
    /// Construct a new index client from a base URL.
    ///
    /// The `base_url` should be something like
    /// `http://127.0.0.1:9913` or an internal overlay address once
    /// svc-index is running on the same node.
    pub fn new(base_url: impl Into<String>) -> Self {
        Self { base_url: base_url.into() }
    }

    /// Return the base URL this client is configured for.
    pub fn base_url(&self) -> &str {
        &self.base_url
    }

    /// Short, stable tag suitable for metrics or logging labels.
    pub fn tag(&self) -> &'static str {
        "svc-index"
    }
}

```

### crates/micronode/src/adapters/mailbox_client.rs
<a id="crates-micronode-src-adapters-mailboxclient-rs"></a>

```rust
//! RO:WHAT — Handle for a future mailbox service used by Micronode.
//!
//! RO:WHY  — Some Micronode deployments may want a durable inbox or
//!           outbox for messages, notifications, or scheduled work.
//!           This client provides the configuration hook without
//!           forcing the mailbox concept into the core.
//!
//! RO:INVARIANTS —
//!   * No networking in this module for now.
//!   * The mailbox abstraction is intentionally vague until the
//!     concrete svc-mailbox design settles.

#[derive(Clone, Debug)]
pub struct MailboxClient {
    base_url: String,
}

impl MailboxClient {
    pub fn new(base_url: impl Into<String>) -> Self {
        Self { base_url: base_url.into() }
    }

    pub fn base_url(&self) -> &str {
        &self.base_url
    }

    /// Short, stable tag suitable for metrics or logging labels.
    pub fn tag(&self) -> &'static str {
        "svc-mailbox"
    }
}

```

### crates/micronode/src/adapters/mod.rs
<a id="crates-micronode-src-adapters-mod-rs"></a>

```rust
//! RO:WHAT — Adapter layer for Micronode.
//! RO:WHY  — Provide typed, low-friction handles for talking to other
//!           RON-CORE services (index, mailbox, storage, overlay,
//!           policy) without coupling Micronode core to any specific
//!           HTTP or RPC client.
//!
//! RO:INTERACTS — In future cuts, these clients will wrap a shared
//!                HTTP or OAP/1 client and offer small, well-typed
//!                methods for a few high-value flows. For the
//!                foundation cut they are simple data holders.
//!
//! RO:INVARIANTS —
//!   * No network I/O in this module for now.
//!   * Handles are cheap to clone and can be stored in `AppState`.
//!   * Adapters are optional: Micronode can run without any of them.
//!
//! RO:CONFIG — Construction of each client is driven by higher-layer
//!             config modules or CLI overlays, not from here.
//!
//! RO:SECURITY — Capability handling and macaroon verification are
//!               handled by dedicated security services; these
//!               adapters should carry any required capability tokens
//!               as opaque strings, not parse them.
//!
//! RO:TEST — Light unit tests here ensure the basic ergonomics work;
//!           future integration tests can live in `tests/adapters_*.rs`
//!           once we wire Micronode to real remote services.

mod index_client;
mod mailbox_client;
mod overlay_client;
mod policy_client;
mod storage_client;

pub use index_client::IndexClient;
pub use mailbox_client::MailboxClient;
pub use overlay_client::OverlayClient;
pub use policy_client::PolicyClient;
pub use storage_client::StorageClient;

/// Bag of optional adapters that Micronode may use.
///
/// This is a convenience struct for higher layers that want to pass
/// around a single handle rather than five independent options.
/// Nothing in the core currently depends on this type; it is provided
/// as ready-made glue for future integration with `AppState`.
#[derive(Clone, Debug, Default)]
pub struct Adapters {
    pub index: Option<IndexClient>,
    pub mailbox: Option<MailboxClient>,
    pub storage: Option<StorageClient>,
    pub overlay: Option<OverlayClient>,
    pub policy: Option<PolicyClient>,
}

impl Adapters {
    /// Construct a new, empty adapter bag.
    ///
    /// This is equivalent to `Adapters::default()` but reads more
    /// clearly at call sites.
    pub fn new() -> Self {
        Self::default()
    }

    /// Return `true` if no adapters are configured.
    ///
    /// This is useful for callers that want to short-circuit any
    /// remote flows if Micronode is running in a completely isolated
    /// profile.
    pub fn is_empty(&self) -> bool {
        self.index.is_none()
            && self.mailbox.is_none()
            && self.storage.is_none()
            && self.overlay.is_none()
            && self.policy.is_none()
    }

    /// Convenience builder for setting the index client.
    pub fn with_index(mut self, client: IndexClient) -> Self {
        self.index = Some(client);
        self
    }

    /// Convenience builder for setting the mailbox client.
    pub fn with_mailbox(mut self, client: MailboxClient) -> Self {
        self.mailbox = Some(client);
        self
    }

    /// Convenience builder for setting the storage client.
    pub fn with_storage(mut self, client: StorageClient) -> Self {
        self.storage = Some(client);
        self
    }

    /// Convenience builder for setting the overlay client.
    pub fn with_overlay(mut self, client: OverlayClient) -> Self {
        self.overlay = Some(client);
        self
    }

    /// Convenience builder for setting the policy client.
    pub fn with_policy(mut self, client: PolicyClient) -> Self {
        self.policy = Some(client);
        self
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn empty_adapters_reports_empty() {
        let adapters = Adapters::new();
        assert!(adapters.is_empty());
        assert!(adapters.index.is_none());
        assert!(adapters.mailbox.is_none());
        assert!(adapters.storage.is_none());
        assert!(adapters.overlay.is_none());
        assert!(adapters.policy.is_none());
    }

    #[test]
    fn builder_methods_mark_adapters_present() {
        let idx = IndexClient::new("http://idx");
        let mbx = MailboxClient::new("http://mbx");
        let st = StorageClient::new("http://st");
        let ov = OverlayClient::new("http://ov");
        let pol = PolicyClient::new("http://pol");

        let adapters = Adapters::new()
            .with_index(idx.clone())
            .with_mailbox(mbx.clone())
            .with_storage(st.clone())
            .with_overlay(ov.clone())
            .with_policy(pol.clone());

        assert!(!adapters.is_empty());
        assert_eq!(adapters.index.as_ref().unwrap().base_url(), "http://idx");
        assert_eq!(adapters.mailbox.as_ref().unwrap().base_url(), "http://mbx");
        assert_eq!(adapters.storage.as_ref().unwrap().base_url(), "http://st");
        assert_eq!(adapters.overlay.as_ref().unwrap().base_url(), "http://ov");
        assert_eq!(adapters.policy.as_ref().unwrap().base_url(), "http://pol");
    }
}

```

### crates/micronode/src/adapters/overlay_client.rs
<a id="crates-micronode-src-adapters-overlayclient-rs"></a>

```rust
//! RO:WHAT — Handle for the overlay or discovery service
//!           (svc-overlay / svc-dht).
//!
//! RO:WHY  — Micronode may need to ask the overlay about other nodes,
//!           capabilities, or routes. Keeping that behind an adapter
//!           lets us mock or swap it out cleanly.
//!
//! RO:INVARIANTS —
//!   * Pure configuration container for now.
//!   * Does not assume a particular protocol; `base_url` is just a
//!     locator string that higher layers agree on.

#[derive(Clone, Debug)]
pub struct OverlayClient {
    base_url: String,
}

impl OverlayClient {
    pub fn new(base_url: impl Into<String>) -> Self {
        Self { base_url: base_url.into() }
    }

    pub fn base_url(&self) -> &str {
        &self.base_url
    }

    /// Short, stable tag suitable for metrics or logging labels.
    pub fn tag(&self) -> &'static str {
        "svc-overlay"
    }
}

```

### crates/micronode/src/adapters/policy_client.rs
<a id="crates-micronode-src-adapters-policyclient-rs"></a>

```rust
//! RO:WHAT — Handle for the policy service (ron-policy / svc-policy)
//!           as seen from Micronode.
//!
//! RO:WHY  — Leave policy evaluation and rich authorization to a
//!           dedicated service. Micronode can forward the minimal
//!           context it knows about a request and let policy decide.
//!
//! RO:SECURITY — Capability tokens or macaroons should be treated as
//!               opaque values and passed along as such. Parsing or
//!               verifying them belongs in dedicated security code,
//!               not in this adapter.
//!
//! RO:INVARIANTS —
//!   * No networking in this module.
//!   * The adapter may be absent in some deployments; Micronode
//!     should continue to function with local-only policy.

#[derive(Clone, Debug)]
pub struct PolicyClient {
    base_url: String,
}

impl PolicyClient {
    pub fn new(base_url: impl Into<String>) -> Self {
        Self { base_url: base_url.into() }
    }

    pub fn base_url(&self) -> &str {
        &self.base_url
    }

    /// Short, stable tag suitable for metrics or logging labels.
    pub fn tag(&self) -> &'static str {
        "svc-policy"
    }
}

```

### crates/micronode/src/adapters/storage_client.rs
<a id="crates-micronode-src-adapters-storageclient-rs"></a>

```rust
//! RO:WHAT — Handle for the storage service (svc-storage) as seen
//!           from Micronode.
//!
//! RO:WHY  — Even though Micronode already has an in-process KV
//!           engine, some deployments will prefer to delegate
//!           large-object or CAS responsibilities to svc-storage.
//!           This client provides the configuration hook.
//!
//! RO:INTERACTS — In the future this will likely send OAP/1 requests
//!                over ron-transport rather than raw HTTP. For now it
//!                remains a pure data type.
//!
//! RO:INVARIANTS —
//!   * `base_url` typically points at the svc-storage ingress surface.
//!   * No implicit retries or backoff here; callers should own policy.

#[derive(Clone, Debug)]
pub struct StorageClient {
    base_url: String,
}

impl StorageClient {
    pub fn new(base_url: impl Into<String>) -> Self {
        Self { base_url: base_url.into() }
    }

    pub fn base_url(&self) -> &str {
        &self.base_url
    }

    /// Short, stable tag suitable for metrics or logging labels.
    pub fn tag(&self) -> &'static str {
        "svc-storage"
    }
}

```

### crates/micronode/src/app.rs
<a id="crates-micronode-src-app-rs"></a>

```rust
//! RO:WHAT — Router assembly for Micronode.
//! RO:WHY  — Central composition point for routes and layers.
//! RO:INTERACTS — config::schema::Config, http::{admin,routes,kv}, facets, layers,
//!                limits, state::AppState.
//! RO:INVARIANTS — Compose routers with state=(), then attach AppState once at the end.
//! RO:SECURITY — SecurityLayer (extract) + RequireAuthLayer (enforce) for KV & Facets.
//! RO:TEST — Covered by integration tests (admin parity, kv_roundtrip, guard_behavior, concurrency,
//!           facets, auth_gate).

use crate::{
    config::schema::Config,
    http::{admin, kv, routes},
    layers::{
        body_cap::BodyCapLayer,
        concurrency::ConcurrencyLayer,
        decode_guard,
        security::{RequireAuthLayer, SecurityLayer},
    },
    limits::HTTP_BODY_CAP_BYTES,
    observability::http_metrics,
    state::AppState,
};
use axum::{
    middleware,
    routing::{get, post, put},
    Router,
};
use http::Error as HttpError;
use std::{convert::Infallible, path::PathBuf, sync::Arc};
use tokio::sync::Semaphore;
use tower_http::trace::TraceLayer;

pub fn build_router(cfg: Config) -> (Router, AppState) {
    let st = AppState::new(cfg.clone());

    // Prewarm metrics.
    http_metrics::prewarm();

    // --- Admin plane ---
    let admin_routes = Router::new()
        .route("/healthz", get(admin::healthz))
        .route("/readyz", get(admin::readyz))
        .route("/version", get(admin::version))
        .route("/metrics", get(admin::metrics));

    // --- Dev plane (guarded) ---
    let dev = if st.cfg.server.dev_routes {
        let echo_conc = Arc::new(Semaphore::new(256));
        Router::new().route(
            "/dev/echo",
            post(routes::dev::echo)
                .layer::<_, HttpError>(ConcurrencyLayer::new(echo_conc))
                .layer(BodyCapLayer::new(HTTP_BODY_CAP_BYTES))
                .layer::<_, Infallible>(middleware::from_fn(decode_guard::guard))
                .layer(SecurityLayer::new()),
        )
    } else {
        Router::new()
    };

    // --- API v1 (public) ---
    let kv_conc = Arc::new(Semaphore::new(256));
    let api_v1 = Router::new().route("/ping", get(routes::ping)).route(
        "/kv/:bucket/:key",
        put(kv::put_kv)
            .delete(kv::delete_kv)
            .get(kv::get_kv)
            .layer(RequireAuthLayer::new(st.cfg.security.mode))
            .layer::<_, HttpError>(ConcurrencyLayer::new(kv_conc.clone()))
            .layer(BodyCapLayer::new(HTTP_BODY_CAP_BYTES))
            .layer::<_, Infallible>(middleware::from_fn(decode_guard::guard))
            .layer(SecurityLayer::new()),
    );

    // Compose top-level router core.
    let mut router = Router::new().merge(admin_routes).nest("/v1", api_v1).merge(dev);

    // --- Facets plane (manifest-driven if enabled) ---
    if st.cfg.facets.enabled {
        if let Some(dir) = st.cfg.facets.dir.clone() {
            let p = PathBuf::from(dir);
            match crate::facets::loader::load_facets(&p) {
                Ok(reg) => {
                    router = crate::facets::mount_with_registry(router, reg, st.cfg.security.mode);
                }
                Err(e) => {
                    // Loader error: make readiness reflect truth.
                    tracing::error!("facet loader failed: {e}");
                    st.probes.set_deps_ok(false);
                    router = crate::facets::mount(router); // keep meta + demo ping for visibility
                }
            }
        } else {
            tracing::warn!("facets.enabled=true but facets.dir not set");
            st.probes.set_deps_ok(false);
            router = crate::facets::mount(router);
        }
    } else {
        // Disabled => keep demo + empty meta for operator sanity.
        router = crate::facets::mount(router);
    }

    // Attach state + global observability.
    let router = router
        .with_state(st.clone())
        .layer(http_metrics::layer())
        .layer(TraceLayer::new_for_http());

    (router, st)
}

```

### crates/micronode/src/cli/args.rs
<a id="crates-micronode-src-cli-args-rs"></a>

```rust

```

### crates/micronode/src/cli/mod.rs
<a id="crates-micronode-src-cli-mod-rs"></a>

```rust
//! RO:WHAT — Micronode CLI surface (shape only).
//! RO:WHY  — Give micronode a stable CLI shape (`serve`, `check`) without
//!           committing yet to any particular argument parser crate.
//! RO:INTERACTS — `main.rs` can later call `Cli::from_env()` instead of
//!                hard-coding config/env logic.
//! RO:INVARIANTS —
//!     - All types here are `pub` so `dead_code` does not fire when the CLI
//!       is not yet wired into `main.rs`.
//!     - No external dependencies (no `clap`/`argh` yet); safe to evolve later.
//!     RO:TEST — Exercised by `tests/cli_smoke.rs`.

/// High-level profile for Micronode behavior.
///
/// This is intentionally coarse; config/env can refine details later.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum Profile {
    /// Developer profile: dev routes enabled, in-memory storage, verbose logs.
    #[default]
    Dev,
    /// Amnesia-first profile: prefer non-persistent storage where possible.
    Amnesia,
    /// Durable profile: persistent storage (sled or remote CAS) is allowed.
    Durable,
}

/// Options for the `serve` subcommand.
#[derive(Debug, Clone)]
pub struct ServeOpts {
    /// Optional path to a config file; if `None`, Micronode will fall back
    /// to its default config discovery (env vars, default paths, etc.).
    pub config_path: Option<String>,
    /// Optional bind override for the HTTP listener (e.g., "127.0.0.1:5310").
    pub bind_addr: Option<String>,
    /// High-level runtime profile (dev/amnesia/durable).
    pub profile: Profile,
    /// Whether to expose dev-only routes (e.g. `/dev/echo`).
    pub dev_routes: bool,
}

impl Default for ServeOpts {
    fn default() -> Self {
        Self { config_path: None, bind_addr: None, profile: Profile::default(), dev_routes: true }
    }
}

/// Supported Micronode CLI commands.
///
/// More subcommands (e.g., `smoke`, `diag`) can be added without breaking
/// the existing API surface.
#[derive(Debug, Clone)]
pub enum Command {
    /// Run the Micronode HTTP server.
    Serve(ServeOpts),
    /// Validate config and exit (non-zero status on error).
    Check {
        /// Optional path to a config file.
        config_path: Option<String>,
    },
}

/// Top-level CLI representation.
///
/// For now we provide only a very small API:
/// - `Cli::from_env()` to construct a baseline value.
/// - `command()` accessor to drive dispatch in `main.rs` later.
#[derive(Debug, Clone)]
pub struct Cli {
    pub cmd: Command,
}

impl Cli {
    /// Construct a CLI representation from the environment.
    ///
    /// Foundation cut:
    /// - Ignores actual `std::env::args()` for now.
    /// - Always returns `Command::Serve(ServeOpts::default())`.
    ///
    /// This gives us a stable type and test surface; later we can replace
    /// the body with a proper parser (e.g., `clap`) without changing call
    /// sites or tests.
    pub fn from_env() -> Self {
        // Placeholder behavior: default to `serve` with default options.
        Self { cmd: Command::Serve(ServeOpts::default()) }
    }

    /// Borrow the parsed command.
    pub fn command(&self) -> &Command {
        &self.cmd
    }
}

```

### crates/micronode/src/cli/run.rs
<a id="crates-micronode-src-cli-run-rs"></a>

```rust

```

### crates/micronode/src/concurrency/backpressure.rs
<a id="crates-micronode-src-concurrency-backpressure-rs"></a>

```rust
//! RO:WHAT — Shared vocabulary for backpressure queues and metrics labels.
//! RO:WHY  — Avoid stringly-typed queue names scattered across the crate;
//!           keep backpressure docs and code in sync.
//! RO:INVARIANTS —
//!   * Queue names are stable across releases.
//!   * Metrics (e.g. `queue_depth{queue=...}`) use the same labels.

/// Logical name for the primary work queue feeding Micronode handlers.
///
/// This corresponds to the “work” queue discussed in `CONCURRENCY.MD`.
pub const QUEUE_WORK: &str = "work";

/// Logical name for the broadcast bus queue (used when tracking lag/backpressure).
pub const QUEUE_BUS: &str = "bus";

/// Logical name for telemetry/export queues (best-effort, drop-oldest on overflow).
pub const QUEUE_TELEMETRY: &str = "telemetry";

```

### crates/micronode/src/concurrency/mod.rs
<a id="crates-micronode-src-concurrency-mod-rs"></a>

```rust
//! RO:WHAT — Concurrency plane for Micronode (limits, registry, backpressure labels).
//! RO:WHY  — Central home for per-route concurrency caps and work queues.
//! RO:INTERACTS — `layers::concurrency::ConcurrencyLayer`, HTTP router, future worker pools.
//! RO:INVARIANTS — Bounded, non-blocking admission; prefer shed (429) over buffering;
//!                 no locks held across `.await`.
//! RO:TEST — Exercised indirectly by `tests/backpressure.rs`.

pub mod backpressure;
pub mod registry;
pub mod shutdown;

/// Named concurrency limit for a class of operations.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct ConcurrencyLimit {
    /// Stable name used for metrics labels and registry keys.
    pub name: &'static str,
    /// Maximum number of inflight operations allowed for this class.
    pub max_inflight: usize,
}

/// Static concurrency configuration for Micronode.
///
/// Today this is **in-code** and sized for a small, single-node Micronode.
/// Later we can source this from `Config` / env once the config plane grows.
#[derive(Debug, Clone)]
pub struct ConcurrencyConfig {
    pub http_admin: ConcurrencyLimit,
    pub http_dev_echo: ConcurrencyLimit,
    pub http_kv: ConcurrencyLimit,
    pub http_facets: ConcurrencyLimit,
}

impl Default for ConcurrencyConfig {
    fn default() -> Self {
        Self {
            // Admin is cheap and should basically never be the bottleneck.
            http_admin: ConcurrencyLimit { name: HTTP_ADMIN_BUDGET, max_inflight: 64 },
            // Dev echo is purely DX; keep it modest so it cannot starve real traffic.
            http_dev_echo: ConcurrencyLimit { name: HTTP_DEV_ECHO_BUDGET, max_inflight: 32 },
            // KV is the main hot-path for Micronode; give it a healthier budget.
            http_kv: ConcurrencyLimit { name: HTTP_KV_BUDGET, max_inflight: 256 },
            // Facets will typically fan back into KV and CAS; sized conservatively for now.
            http_facets: ConcurrencyLimit { name: HTTP_FACETS_BUDGET, max_inflight: 128 },
        }
    }
}

impl ConcurrencyConfig {
    /// Lookup a limit by its logical name.
    ///
    /// This is primarily intended for tests and for any code that wants to
    /// introspect the static configuration.
    pub fn limit_for(&self, name: &str) -> Option<ConcurrencyLimit> {
        match name {
            HTTP_ADMIN_BUDGET => Some(self.http_admin),
            HTTP_DEV_ECHO_BUDGET => Some(self.http_dev_echo),
            HTTP_KV_BUDGET => Some(self.http_kv),
            HTTP_FACETS_BUDGET => Some(self.http_facets),
            _ => None,
        }
    }

    /// Build a `ConcurrencyRegistry` from this configuration.
    pub fn build_registry(&self) -> ConcurrencyRegistry {
        ConcurrencyRegistry::from_config(self)
    }
}

// Stable string constants for concurrency budget names. These are meant to be
// shared between the registry, metrics labels, and any future worker pools.

/// Budget name for admin-plane HTTP endpoints (`/healthz`, `/readyz`, `/metrics`, `/version`).
pub const HTTP_ADMIN_BUDGET: &str = "http_admin";

/// Budget name for dev DX endpoints such as `/dev/echo`.
pub const HTTP_DEV_ECHO_BUDGET: &str = "http_dev_echo";

/// Budget name for KV HTTP endpoints (`/v1/kv/...`).
pub const HTTP_KV_BUDGET: &str = "http_kv";

/// Budget name for facet-exposed HTTP endpoints (`/facets/...`).
pub const HTTP_FACETS_BUDGET: &str = "http_facets";

pub use registry::ConcurrencyRegistry;

```

### crates/micronode/src/concurrency/registry.rs
<a id="crates-micronode-src-concurrency-registry-rs"></a>

```rust
//! RO:WHAT — Registry for named concurrency pools.
//! RO:WHY  — Let HTTP routes and worker pools share semaphores by logical name,
//!           rather than each constructing ad-hoc caps.
//! RO:INTERACTS — `ConcurrencyConfig`, `layers::concurrency::ConcurrencyLayer`.
//! RO:INVARIANTS —
//!   * Each known budget name maps to a bounded `Semaphore`.
//!   * Registry is immutable after construction (no runtime mutation).
//!   * Unknown names fall back to a safe, modest default (no panics).

use std::{collections::HashMap, sync::Arc};

use tokio::sync::Semaphore;

use super::{ConcurrencyConfig, ConcurrencyLimit};

/// Immutable registry of concurrency pools keyed by logical budget name.
#[derive(Debug)]
pub struct ConcurrencyRegistry {
    inner: HashMap<&'static str, Arc<Semaphore>>,
}

impl ConcurrencyRegistry {
    /// Build a registry from the static concurrency configuration.
    ///
    /// Each `ConcurrencyLimit` becomes a distinct semaphore keyed by `limit.name`.
    pub fn from_config(cfg: &ConcurrencyConfig) -> Self {
        let mut inner = HashMap::new();

        for limit in [cfg.http_admin, cfg.http_dev_echo, cfg.http_kv, cfg.http_facets] {
            Self::insert_limit(&mut inner, limit);
        }

        Self { inner }
    }

    fn insert_limit(inner: &mut HashMap<&'static str, Arc<Semaphore>>, limit: ConcurrencyLimit) {
        // If a name is duplicated in the config, last-one-wins. That should not
        // happen in practice, but this keeps behavior deterministic.
        inner.insert(limit.name, Arc::new(Semaphore::new(limit.max_inflight)));
    }

    /// Fetch a semaphore for the given logical budget name.
    ///
    /// If the name is unknown (e.g. future budgets added without updating the
    /// registry construction), we fall back to a modest default (256). This
    /// ensures callers never panic on a missing entry.
    pub fn get(&self, name: &'static str) -> Arc<Semaphore> {
        self.inner.get(name).cloned().unwrap_or_else(|| Arc::new(Semaphore::new(256)))
    }
}

```

### crates/micronode/src/concurrency/shutdown.rs
<a id="crates-micronode-src-concurrency-shutdown-rs"></a>

```rust
//! RO:WHAT — Placeholder module for concurrency-aware shutdown helpers.
//! RO:WHY  — Keep a stable home for future drain orchestration (e.g. draining
//!           work queues before shutdown, coordinating with bus + HTTP).
//! RO:NOTE — Today Micronode reuses the kernel’s shutdown wiring and does not
//!           need additional helpers here. This module exists so the
//!           concurrency blueprint has a concrete code anchor.

// This module is intentionally empty for now. Once Micronode grows its own
// work queues / worker pools, shutdown coordination types can live here.

```

### crates/micronode/src/config/cli_overlay.rs
<a id="crates-micronode-src-config-clioverlay-rs"></a>

```rust
//! RO:WHAT — Placeholder for CLI-overlay support (kept for tree parity).
//! RO:WHY  — Future: clap/argp integration without bloating foundation.

pub fn _apply_cli_overlays() {
    // Intentionally empty for foundation cut.
}

```

### crates/micronode/src/config/env_overlay.rs
<a id="crates-micronode-src-config-envoverlay-rs"></a>

```rust
//! RO:WHAT — Placeholder for richer env overlays (kept for tree parity).
//! RO:WHY  — Your TODO tree references this module explicitly.

pub fn _apply_env_overlays() {
    // Intentionally empty for foundation cut.
}

```

### crates/micronode/src/config/hot_reload.rs
<a id="crates-micronode-src-config-hotreload-rs"></a>

```rust
//! RO:WHAT — Placeholder for config hot-reload (notify-based).
//! RO:WHY  — Wire later; keep module present so imports won't break.

pub fn _spawn_config_watcher() {
    // Intentionally empty for foundation cut.
}

```

### crates/micronode/src/config/load.rs
<a id="crates-micronode-src-config-load-rs"></a>

```rust
//! RO:WHAT — Load config from file + env overlays into a validated `Config`.
//! RO:WHY  — Keep `main.rs` tiny; centralize config precedence and invariants.
//! RO:ORDER —
//!   1) Start from `Config::default()`.
//!   2) If `MICRONODE_CONFIG` set, load that TOML and merge.
//!   3) Else try `./configs/micronode.toml`, then `./crates/micronode/configs/micronode.toml`.
//!   4) Apply env overrides (bind/dev-routes only; storage/security via TOML).
//!   5) Validate invariants; on error return `Error::Config` (fail-fast).
//!
//! RO:INVARIANTS — Safe defaults (amnesia-first, local bind); deterministic overlay order.

use super::schema::Config;
use super::validate::validate;
use crate::errors::{Error, Result};

use std::{env, fs, net::SocketAddr, path::PathBuf};

/// Entry point used by `main.rs`.
pub fn load_config() -> Result<Config> {
    let mut cfg = Config::default();

    if let Some(path) = discover_config_path() {
        overlay_file(&mut cfg, path)?;
    }

    overlay_env(&mut cfg)?;
    validate(&cfg)?;
    Ok(cfg)
}

/// Resolve a config path by env or well-known files.
fn discover_config_path() -> Option<PathBuf> {
    if let Ok(p) = env::var("MICRONODE_CONFIG") {
        let pb = PathBuf::from(p);
        if pb.exists() {
            return Some(pb);
        }
    }

    let workspace_local = PathBuf::from("configs/micronode.toml");
    if workspace_local.exists() {
        return Some(workspace_local);
    }

    let crate_local = PathBuf::from("crates/micronode/configs/micronode.toml");
    if crate_local.exists() {
        return Some(crate_local);
    }

    None
}

/// Overlay TOML at `path` onto `cfg`.
fn overlay_file(cfg: &mut Config, path: PathBuf) -> Result<()> {
    let s =
        fs::read_to_string(&path).map_err(|e| Error::Config(format!("read {:?}: {e}", path)))?;
    let from: Config =
        toml::from_str(&s).map_err(|e| Error::Config(format!("parse {:?}: {e}", path)))?;

    let base = std::mem::take(cfg);
    *cfg = merge(base, from);
    Ok(())
}

/// Apply env-var overrides on top (bind/dev only).
///
/// Supported env:
/// - MICRONODE_BIND = "127.0.0.1:5310"
/// - MICRONODE_DEV_ROUTES = "1" | "true" | "yes"
fn overlay_env(cfg: &mut Config) -> Result<()> {
    if let Ok(bind_s) = env::var("MICRONODE_BIND") {
        let bind: SocketAddr = bind_s.parse().map_err(|e| {
            Error::Config(format!("MICRONODE_BIND parse failed for {:?}: {e}", bind_s))
        })?;
        cfg.server.bind = bind;
    }

    if let Ok(dev_s) = env::var("MICRONODE_DEV_ROUTES") {
        let dev = matches!(dev_s.to_ascii_lowercase().as_str(), "1" | "true" | "yes" | "on");
        cfg.server.dev_routes = dev;
    }

    Ok(())
}

/// Merge `from` onto `base`, field-by-field.
///
/// NOTE: This is where we must carry **security** from TOML, otherwise
/// a file like `[security]\nmode="dev_allow"` won’t take effect.
fn merge(mut base: Config, from: Config) -> Config {
    base.server = from.server;
    base.storage = from.storage;
    base.security = from.security;
    base.facets = from.facets;
    base
}

#[cfg(test)]
mod tests {
    use super::super::schema::{SecurityCfg, SecurityMode};
    use super::*;

    #[test]
    fn merge_applies_security_mode() {
        let base = Config::default(); // DenyAll by default
        let from =
            Config { security: SecurityCfg { mode: SecurityMode::DevAllow }, ..Config::default() };
        let merged = merge(base, from);
        assert_eq!(merged.security.mode, SecurityMode::DevAllow);
    }

    #[test]
    fn overlay_env_parses_bind_and_dev_routes() {
        let _ = env::remove_var("MICRONODE_BIND");
        let _ = env::remove_var("MICRONODE_DEV_ROUTES");
        let mut cfg = Config::default();

        env::set_var("MICRONODE_BIND", "127.0.0.1:5311");
        env::set_var("MICRONODE_DEV_ROUTES", "true");
        overlay_env(&mut cfg).unwrap();

        assert_eq!(cfg.server.bind, "127.0.0.1:5311".parse::<SocketAddr>().unwrap());
        assert!(cfg.server.dev_routes);
    }
}

```

### crates/micronode/src/config/mod.rs
<a id="crates-micronode-src-config-mod-rs"></a>

```rust
//! RO:WHAT — Config module root.
//! RO:WHY  — Schema + loaders + validation + overlays (env/CLI).
pub mod cli_overlay;
pub mod env_overlay;
pub mod hot_reload;
pub mod load;
pub mod schema;
pub mod validate;

```

### crates/micronode/src/config/schema.rs
<a id="crates-micronode-src-config-schema-rs"></a>

```rust
//! RO:WHAT — Config schema for Micronode.
//! RO:WHY  — Define a typed configuration model (TOML + env overlays)
//!           including server bind options, storage posture, security mode, and facets.
//! RO:INTERACTS — Parsed from TOML in `config::load`, validated in
//!                `config::validate`, stored in `AppState`.
//! RO:INVARIANTS —
//!   - Defaults are safe and amnesia-first (in-memory storage).
//!   - `StorageEngine::Sled` requires a non-empty `storage.path` (enforced in `validate`).
//!   - Config is cloneable and sendable across tasks.

use serde::Deserialize;
use std::net::SocketAddr;

#[derive(Debug, Clone, Deserialize, Default)]
pub struct Config {
    /// Server settings; defaults to 127.0.0.1:5310 with dev_routes=false
    #[serde(default)]
    pub server: Server,
    #[serde(default)]
    pub storage: StorageCfg,
    /// Security posture (deny-by-default unless explicitly relaxed).
    #[serde(default)]
    pub security: SecurityCfg,
    /// Facet loading configuration.
    #[serde(default)]
    pub facets: FacetsCfg,
}

/// HTTP server configuration.
#[derive(Debug, Clone, Deserialize)]
pub struct Server {
    /// Bind address for the Micronode HTTP listener.
    pub bind: SocketAddr,
    /// Whether to expose `/dev/*` routes (echo, etc.).
    #[serde(default)]
    pub dev_routes: bool,
}

impl Default for Server {
    fn default() -> Self {
        let bind: SocketAddr =
            "127.0.0.1:5310".parse().expect("hard-coded default bind must be valid SocketAddr");
        Server { bind, dev_routes: false }
    }
}

/// Storage configuration.
///
/// Beta scope:
/// - `engine = "mem"` — in-memory KV (amnesia-first, no persistence).
/// - `engine = "sled"` — persistent sled-backed KV (requires `path`).
#[derive(Debug, Clone, Deserialize, Default)]
pub struct StorageCfg {
    /// Storage engine selection, defaults to `"mem"`.
    ///
    /// Serialized as lowercase strings: `"mem"`, `"sled"`.
    #[serde(default)]
    pub engine: StorageEngine,
    /// Optional on-disk path for sled.
    ///
    /// Required (non-empty) when `engine = "sled"`.
    #[serde(default)]
    pub path: Option<String>,
}

/// Storage engine kind.
#[derive(Debug, Clone, Deserialize, PartialEq, Eq, Default)]
#[serde(rename_all = "lowercase")]
pub enum StorageEngine {
    /// In-memory store (amnesia-first profile).
    #[default]
    Mem,
    /// Sled-backed KV store (persistent profile).
    Sled,
}

/// Security configuration.
#[derive(Debug, Clone, Deserialize)]
pub struct SecurityCfg {
    /// Security policy for Micronode HTTP surfaces.
    #[serde(default)]
    pub mode: SecurityMode,
}

impl Default for SecurityCfg {
    fn default() -> Self {
        Self { mode: SecurityMode::DenyAll }
    }
}

/// Security enforcement modes.
#[derive(Debug, Clone, Copy, Deserialize, PartialEq, Eq, Default)]
#[serde(rename_all = "snake_case")]
pub enum SecurityMode {
    /// Deny all non-admin surfaces unless explicitly allowed.
    #[default]
    DenyAll,
    /// Developer convenience: allow KV/facets without a macaroon.
    DevAllow,
    /// Delegate verification to external auth/policy service (future).
    External,
}

/// Facet loader configuration.
#[derive(Debug, Clone, Deserialize, Default)]
pub struct FacetsCfg {
    /// Enable manifest-driven facets.
    #[serde(default)]
    pub enabled: bool,
    /// Directory containing `*.toml` facet manifests.
    #[serde(default)]
    pub dir: Option<String>,
}

```

### crates/micronode/src/config/validate.rs
<a id="crates-micronode-src-config-validate-rs"></a>

```rust
//! RO:WHAT — Validation for Micronode configuration.
//! RO:WHY  — Catch invalid configs early (on startup) with clear
//!           error messages instead of failing deep in runtime code.
//! RO:INTERACTS — Called from `config::load::load_config` once TOML
//!                and env overlays have been applied.
//! RO:INVARIANTS —
//!   - Bind address must be usable (non-zero port).
//!   - `StorageEngine::Sled` requires a non-empty path.
//!   - Validation never mutates the config.

use crate::errors::{Error, Result};

use super::schema::{Config, StorageEngine};

/// Validate a fully assembled configuration.
///
/// Returns `Ok(())` if the config is usable; otherwise returns
/// `Error::Config` with a human-readable description.
pub fn validate(cfg: &Config) -> Result<()> {
    // Basic sanity on server.bind.
    if cfg.server.bind.port() == 0 {
        return Err(Error::Config("server.bind must not use port 0 (ephemeral)".to_string()));
    }

    // Storage posture checks.
    match cfg.storage.engine {
        StorageEngine::Mem => {
            // In-memory is always valid; path is ignored.
        }
        StorageEngine::Sled => {
            // Sled requires a non-empty path so we don't silently spray
            // data into the working directory.
            let path_ok =
                cfg.storage.path.as_deref().map(|s| !s.trim().is_empty()).unwrap_or(false);

            if !path_ok {
                return Err(Error::Config(
                    "storage.engine=\"sled\" requires storage.path to be set and non-empty"
                        .to_string(),
                ));
            }
        }
    }

    Ok(())
}

```

### crates/micronode/src/errors.rs
<a id="crates-micronode-src-errors-rs"></a>

```rust
//! RO:WHAT — Error types for Micronode (foundation).
//! RO:WHY  — Stable envelopes and anyhow interop.
//! RO:INVARIANTS — Avoid leaking secrets; messages deterministic for SDKs.

use thiserror::Error;

#[derive(Debug, Error)]
pub enum Error {
    #[error("config: {0}")]
    Config(String),
    #[error("internal error")]
    Internal,
}

pub type Result<T> = std::result::Result<T, Error>;

```

### crates/micronode/src/facets/feed.rs
<a id="crates-micronode-src-facets-feed-rs"></a>

```rust
// crates/micronode/src/facets/feed.rs
//! RO:WHAT — Placeholder for feed/fanout facet wiring.
//! RO:WHY  — Feed-style workloads (timelines, notifications) are a primary
//!           target for Micronode facets; this file will bridge to svc-mailbox
//!           and svc-index in future iterations.
//! RO:INTERACTS — Planned: `svc-index`, `svc-mailbox`, `svc-storage` adapters.
//! RO:STATUS — Stub only; no runtime behavior yet.

#[derive(Debug, Clone)]
pub struct FeedFacetConfig {
    // TODO: topic/bucket config, retention, fanout policies.
    _placeholder: (),
}

```

### crates/micronode/src/facets/graph.rs
<a id="crates-micronode-src-facets-graph-rs"></a>

```rust
// crates/micronode/src/facets/graph.rs
//! RO:WHAT — Placeholder for graph/index facet wiring.
//! RO:WHY  — Graph-style queries (follows, relationships, recommendations)
//!           will be hosted as facets backed by `svc-index`.
//! RO:STATUS — Stub only; no runtime behavior yet.

#[derive(Debug, Clone)]
pub struct GraphFacetConfig {
    // TODO: index families, graph projections, query presets.
    _placeholder: (),
}

```

### crates/micronode/src/facets/loader.rs
<a id="crates-micronode-src-facets-loader-rs"></a>

```rust
//! RO:WHAT — Facet registry loader for manifest-driven facets.
//! RO:WHY  — Reads all `*.toml` manifests from a directory and returns a registry.
//! RO:INVARIANTS — Unique facet IDs; route validation applied; static files must exist.

use super::manifest::FacetManifest;
use crate::errors::{Error, Result};
use std::{
    collections::HashSet,
    fs,
    path::{Path, PathBuf},
};

#[derive(Debug, Clone)]
pub struct FacetRegistry {
    pub manifests: Vec<FacetManifest>,
}

pub fn load_facets(dir: &Path) -> Result<FacetRegistry> {
    if !dir.exists() {
        return Err(Error::Config(format!("facet dir {:?} does not exist", dir)));
    }
    if !dir.is_dir() {
        return Err(Error::Config(format!("facet dir {:?} is not a directory", dir)));
    }

    let mut manifests = Vec::new();
    let mut ids = HashSet::new();

    for entry in fs::read_dir(dir).map_err(|e| Error::Config(format!("read_dir {:?}: {e}", dir)))? {
        let entry = entry.map_err(|e| Error::Config(format!("read_dir entry error: {e}")))?;
        let path = entry.path();
        if path.extension().and_then(|s| s.to_str()) != Some("toml") {
            continue;
        }

        let s = fs::read_to_string(&path)
            .map_err(|e| Error::Config(format!("read {:?}: {e}", path)))?;
        let manifest: FacetManifest =
            toml::from_str(&s).map_err(|e| Error::Config(format!("parse {:?}: {e}", path)))?;
        manifest.validate().map_err(|msg| Error::Config(format!("validate {:?}: {msg}", path)))?;

        if !ids.insert(manifest.facet.id.clone()) {
            return Err(Error::Config(format!("duplicate facet id: {}", manifest.facet.id)));
        }

        // Extra static checks: file must exist.
        if let super::manifest::FacetKind::Static = manifest.facet.kind {
            for r in &manifest.route {
                if let Some(ref f) = r.file {
                    let fp = PathBuf::from(f);
                    if !fp.exists() {
                        return Err(Error::Config(format!("static file not found: {:?}", fp)));
                    }
                }
            }
        }

        manifests.push(manifest);
    }

    Ok(FacetRegistry { manifests })
}

```

### crates/micronode/src/facets/manifest.rs
<a id="crates-micronode-src-facets-manifest-rs"></a>

```rust
//! RO:WHAT — Facet manifest schema (TOML).
//! RO:WHY  — Declarative facets loaded from a directory.
//! RO:FORMAT —
//!   [[route]]
//!   method = "GET" | "POST"
//!   path = "/ping"
//!   # for kind="static":
//!   file = "configs/static/hello.txt"
//!
//!   [facet]
//!   id = "docs"
//!   kind = "static" | "echo" | "proxy"

use serde::Deserialize;

#[derive(Debug, Clone, Deserialize)]
pub struct FacetManifest {
    pub facet: FacetHeader,
    #[serde(default)]
    pub route: Vec<RouteSpec>,
}

#[derive(Debug, Clone, Deserialize)]
pub struct FacetHeader {
    pub id: String,
    #[serde(rename = "kind")]
    pub kind: FacetKind,
}

#[derive(Debug, Clone, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum FacetKind {
    Static,
    Echo,
    Proxy,
}

#[derive(Debug, Clone, Deserialize)]
pub struct RouteSpec {
    /// "GET" or "POST" (case-insensitive accepted by our parser).
    pub method: String,
    /// Must start with "/".
    pub path: String,
    /// For Static kind: local file to serve for GET.
    #[serde(default)]
    pub file: Option<String>,
}

impl FacetManifest {
    /// Minimal validation and normalization.
    pub fn validate(&self) -> Result<(), String> {
        if self.facet.id.trim().is_empty() {
            return Err("facet.id must not be empty".into());
        }
        for r in &self.route {
            if !r.path.starts_with('/') {
                return Err(format!("route.path must start with '/': {}", r.path));
            }
            let m = r.method.to_ascii_uppercase();
            if m != "GET" && m != "POST" {
                return Err(format!("route.method must be GET or POST: {}", r.method));
            }
            if let FacetKind::Static = self.facet.kind {
                if m != "GET" {
                    return Err("static routes must be GET".into());
                }
                if r.file.as_ref().map(|s| s.is_empty()).unwrap_or(true) {
                    return Err("static route requires non-empty 'file'".into());
                }
            }
        }
        Ok(())
    }
}

```

### crates/micronode/src/facets/media.rs
<a id="crates-micronode-src-facets-media-rs"></a>

```rust
// crates/micronode/src/facets/media.rs
//! RO:WHAT — Placeholder for media facet wiring.
//! RO:WHY  — Media upload/transform pipelines (thumbnails, transcoding) sit
//!           behind Micronode and svc-storage; this file will hold configs.
//! RO:STATUS — Stub only; no runtime behavior yet.

#[derive(Debug, Clone)]
pub struct MediaFacetConfig {
    // TODO: allowed mime types, size caps, transform presets.
    _placeholder: (),
}

```

### crates/micronode/src/facets/mod.rs
<a id="crates-micronode-src-facets-mod-rs"></a>

```rust
//! RO:WHAT — Facet surface composition and demo/meta handlers.
//! RO:WHY  — Centralize facet mounting (demo + manifest-driven) and meta truth.
//! RO:INTERACTS — config::schema::SecurityMode, layers::security::RequireAuthLayer,
//!                facets::{loader,manifest}, axum Router.
//! RO:INVARIANTS —
//!   - `mount()` is safe to call when facets are disabled or loader fails.
//!   - `mount_with_registry()` mounts manifest-driven routes under
//!       `/facets/{facet_id}{route.path}`
//!     and exposes truthful `GET /facets/meta` and `GET /facets/_meta`.
//!   - Manifest `route.path` values are validated to start with `/`.
//!   - In `SecurityMode::DevAllow`, manifest facets are *not* gated by auth.
//!   - In stricter modes (DenyAll/External), manifest facets are gated via
//!     `RequireAuthLayer`.
//! RO:SECURITY —
//!   - Static facets: dev-friendly in `DevAllow`, gated in stricter modes.
//!   - Echo/proxy facets: also dev-open in `DevAllow`, gated otherwise.
//! RO:TEST — Covered by integration tests in `tests/facets_loader.rs`,
//!           `tests/facets_proxy.rs`, and the global auth-gate tests.

use crate::config::schema::SecurityMode;
use crate::layers::security::RequireAuthLayer;
use axum::{
    body::Body,
    http::StatusCode,
    routing::{get, post},
    Json, Router,
};
use serde::Serialize;

pub mod loader;
pub mod manifest;

use loader::FacetRegistry;
use manifest::{FacetKind, FacetManifest};

/// Mount demo facet + empty meta when loader is disabled or empty.
/// Generic over router state `S` (must satisfy Axum’s Router bounds).
///
/// Used by `app::build_router` when:
///   - facets are disabled, or
///   - loader fails / dir missing.
///
/// This keeps a *predictable* surface for operators:
///   - `GET /facets/demo/ping`
///   - `GET /facets/meta` and `GET /facets/_meta` (with `loaded: []`)
pub fn mount<S>(router: Router<S>) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    router
        .route("/facets/demo/ping", get(demo_ping))
        .route("/facets/meta", get(meta_empty))
        .route("/facets/_meta", get(meta_empty))
}

/// Mount facets using a concrete registry.
///
/// Generic over router state `S`.
///
/// Behavior:
///   - Always mounts truthful meta endpoints:
///       * `GET /facets/meta`
///       * `GET /facets/_meta` (legacy/alt alias)
///   - Mounts each manifest’s routes under `/facets/{facet_id}{route.path}`.
///   - Gating:
///       * `SecurityMode::DevAllow`  => facets are *not* wrapped in
///         `RequireAuthLayer` (dev-friendly).
///       * Any other mode (DenyAll/External/…) => facets are wrapped in
///         `RequireAuthLayer`, mirroring KV semantics.
///
/// This is what the `facets_loader` and `facets_proxy` integration tests exercise.
pub fn mount_with_registry<S>(
    mut router: Router<S>,
    reg: FacetRegistry,
    mode: SecurityMode,
) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    // If nothing is loaded, fall back to demo + empty meta for sanity.
    if reg.manifests.is_empty() {
        return mount(router);
    }

    // Truthful meta endpoint, listing all loaded facets.
    //
    // NOTE: We capture the summary at mount time — good enough for current
    // design where manifests are loaded once at boot.
    let meta = Meta { loaded: reg.manifests.iter().map(FacetSummary::from).collect() };

    // Expose both `/facets/meta` and `/facets/_meta` using the same payload.
    router = router
        .route(
            "/facets/meta",
            get({
                let meta = meta.clone();
                move || {
                    let meta = meta.clone();
                    async move { Json(meta) }
                }
            }),
        )
        .route(
            "/facets/_meta",
            get({
                let meta = meta.clone();
                move || {
                    let meta = meta.clone();
                    async move { Json(meta) }
                }
            }),
        );

    // Mount each manifest's routes under `/facets/{id}{route.path}`.
    for m in &reg.manifests {
        let sub = build_router_for_manifest::<S>(m);

        router = match mode {
            // DevAllow => facets are dev-friendly: no auth gate here.
            SecurityMode::DevAllow => router.merge(sub),

            // All stricter modes (DenyAll, External, etc.) => gate via RequireAuth.
            _ => router.merge(sub.layer(RequireAuthLayer::new(mode))),
        };
    }

    router
}

/// Build a sub-router for a single manifest.
///
/// The router returned here is *not* gated by auth; callers decide whether to
/// wrap it with `RequireAuthLayer` or not based on `SecurityMode`.
///
/// Paths are mounted as:
///   `/facets/{facet_id}{route.path}`
/// e.g.:
///   facet.id   = "docs"
///   route.path = "/hello"
///   → `/facets/docs/hello`
fn build_router_for_manifest<S>(m: &FacetManifest) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    let mut r = Router::new();
    let base = format!("/facets/{}", m.facet.id);

    match m.facet.kind {
        FacetKind::Echo => {
            for rs in &m.route {
                let full_path = format!("{}{}", base, rs.path);
                match rs.method.to_ascii_uppercase().as_str() {
                    "GET" => {
                        r = r.route(&full_path, get(echo_handler));
                    }
                    "POST" => {
                        r = r.route(&full_path, post(echo_handler));
                    }
                    _ => {
                        // Unknown methods are ignored; manifest validation should
                        // have caught bad methods earlier.
                    }
                }
            }
        }
        FacetKind::Static => {
            for rs in &m.route {
                let full_path = format!("{}{}", base, rs.path);
                let file = rs.file.clone().expect("validated: file present for static facets");
                // Capture the file path by clone into the handler closure.
                r = r.route(&full_path, get(move || static_handler(file.clone())));
            }
        }
        FacetKind::Proxy => {
            // Placeholder: 501 Not Implemented for all declared routes.
            //
            // Future: wire this to svc-index / svc-storage / other services.
            for rs in &m.route {
                let full_path = format!("{}{}", base, rs.path);
                match rs.method.to_ascii_uppercase().as_str() {
                    "GET" => {
                        r = r.route(&full_path, get(proxy_not_implemented));
                    }
                    "POST" => {
                        r = r.route(&full_path, post(proxy_not_implemented));
                    }
                    _ => {}
                }
            }
        }
    }

    r
}

// -------- Handlers --------

async fn demo_ping() -> &'static str {
    "pong"
}

async fn meta_empty() -> Json<Meta> {
    Json(Meta { loaded: vec![] })
}

// Keep echo simple to avoid needing Axum's `query` feature.
// We just return a static acknowledgement JSON.
async fn echo_handler() -> Json<serde_json::Value> {
    Json(serde_json::json!({ "echo": "ok" }))
}

async fn static_handler(file: String) -> (StatusCode, Body) {
    match tokio::fs::read(file).await {
        Ok(bytes) => (StatusCode::OK, Body::from(bytes)),
        Err(_) => (StatusCode::NOT_FOUND, Body::from("not found")),
    }
}

// Temporary placeholder for proxy facets.
async fn proxy_not_implemented() -> StatusCode {
    StatusCode::NOT_IMPLEMENTED
}

// -------- Meta types --------

#[derive(Debug, Clone, Serialize)]
struct Meta {
    loaded: Vec<FacetSummary>,
}

#[derive(Debug, Clone, Serialize)]
struct FacetSummary {
    id: String,
    kind: String,
    routes: Vec<RouteSummary>,
}

#[derive(Debug, Clone, Serialize)]
struct RouteSummary {
    method: String,
    path: String,
}

impl From<&FacetManifest> for FacetSummary {
    fn from(m: &FacetManifest) -> Self {
        Self {
            id: m.facet.id.clone(),
            kind: match m.facet.kind {
                FacetKind::Static => "static".into(),
                FacetKind::Echo => "echo".into(),
                FacetKind::Proxy => "proxy".into(),
            },
            routes: m
                .route
                .iter()
                .map(|r| RouteSummary {
                    method: r.method.to_ascii_uppercase(),
                    // For meta, it’s more operator-friendly to show the full
                    // mounted path (`/facets/{id}{route.path}`) rather than
                    // the raw manifest path.
                    path: format!("/facets/{}{}", m.facet.id, r.path),
                })
                .collect(),
        }
    }
}

```

### crates/micronode/src/facets/search.rs
<a id="crates-micronode-src-facets-search-rs"></a>

```rust
// crates/micronode/src/facets/search.rs
//! RO:WHAT — Placeholder for search facet wiring.
//! RO:WHY  — Search endpoints (full-text, filters) will surface svc-index
//!           capabilities via Micronode facets.
//! RO:STATUS — Stub only; no runtime behavior yet.

#[derive(Debug, Clone)]
pub struct SearchFacetConfig {
    // TODO: index names, query limits, ranking configs.
    _placeholder: (),
}

```

### crates/micronode/src/http/admin.rs
<a id="crates-micronode-src-http-admin-rs"></a>

```rust
//! RO:WHAT — Admin plane: /metrics, /healthz, /readyz, /version.
//! RO:WHY  — Golden surfaces; shared by all RON services.
//! RO:INVARIANTS — Truthful readyz; explicit dev override in handler.

use crate::{observability, state::AppState};
use axum::{extract::State, http::StatusCode, response::IntoResponse};
use prometheus::{Encoder, TextEncoder};

pub async fn metrics(_: State<AppState>) -> impl IntoResponse {
    let families = prometheus::gather();
    let mut buf = Vec::new();
    let _ = TextEncoder::new().encode(&families, &mut buf);
    (StatusCode::OK, buf)
}

pub async fn healthz() -> impl IntoResponse {
    observability::health::handler().await
}

pub async fn readyz(State(st): State<AppState>) -> impl IntoResponse {
    observability::ready::handler(st.probes.clone()).await
}

pub async fn version() -> impl IntoResponse {
    observability::version::handler().await
}

```

### crates/micronode/src/http/kv.rs
<a id="crates-micronode-src-http-kv-rs"></a>

```rust
//! RO:WHAT — KV v1 HTTP handlers: PUT/GET/DELETE /kv/{bucket}/{key}.
//! RO:WHY  — Provide a minimal key/value API for Micronode, backed by Storage.
//! RO:INTERACTS — state::AppState (storage), storage::Storage, layers (body cap, decode guard).
//! RO:INVARIANTS — Binary-safe; no JSON; caps/enforced by layers; no auth yet.
//! RO:METRICS — HTTP metrics handled by global middleware; KV domain metrics later.
//! RO:CONFIG — No per-route config yet; concurrency/body caps are applied in app.rs.
//! RO:SECURITY — No auth/policy here; must be added via middleware in a later step.
//! RO:TEST — To be covered by integration tests (kv_roundtrip, guard_behavior).

use crate::state::AppState;
use axum::{
    body::Bytes,
    extract::{Path, State},
    http::{header, StatusCode},
    response::IntoResponse,
};

/// PUT /kv/{bucket}/{key}
///
/// Body is treated as opaque bytes with `Content-Type: application/octet-stream`.
/// Returns 201 on create, 204 on update, 500 on internal errors.
pub async fn put_kv(
    State(st): State<AppState>,
    Path((bucket, key)): Path<(String, String)>,
    body: Bytes,
) -> impl IntoResponse {
    match st.storage.put(&bucket, &key, &body) {
        Ok(true) => StatusCode::CREATED,
        Ok(false) => StatusCode::NO_CONTENT,
        Err(_e) => StatusCode::INTERNAL_SERVER_ERROR,
    }
}

/// GET /kv/{bucket}/{key}
///
/// Returns 200 with raw bytes and `Content-Type: application/octet-stream`
/// or 404 if the key is absent.
pub async fn get_kv(
    State(st): State<AppState>,
    Path((bucket, key)): Path<(String, String)>,
) -> impl IntoResponse {
    match st.storage.get(&bucket, &key) {
        Ok(Some(bytes)) => {
            (StatusCode::OK, [(header::CONTENT_TYPE, "application/octet-stream")], bytes)
                .into_response()
        }
        Ok(None) => StatusCode::NOT_FOUND.into_response(),
        Err(_e) => StatusCode::INTERNAL_SERVER_ERROR.into_response(),
    }
}

/// DELETE /kv/{bucket}/{key}
///
/// Returns 204 if a value was deleted, 404 if it did not exist.
pub async fn delete_kv(
    State(st): State<AppState>,
    Path((bucket, key)): Path<(String, String)>,
) -> impl IntoResponse {
    match st.storage.delete(&bucket, &key) {
        Ok(true) => StatusCode::NO_CONTENT,
        Ok(false) => StatusCode::NOT_FOUND,
        Err(_e) => StatusCode::INTERNAL_SERVER_ERROR,
    }
}

```

### crates/micronode/src/http/mod.rs
<a id="crates-micronode-src-http-mod-rs"></a>

```rust
//! RO:WHAT — HTTP handlers (admin + basic routes + dev).
//! RO:WHY  — Keep app.rs readable.

pub mod admin;
pub mod kv;
pub mod routes;

pub mod dev {
    pub use super::routes::dev::echo;
}

```

### crates/micronode/src/http/routes.rs
<a id="crates-micronode-src-http-routes-rs"></a>

```rust
//! RO:WHAT — Public and dev routes for Micronode.

use axum::{http::StatusCode, Json};
use serde_json::{json, Value};

// --- /v1/ping ---
pub async fn ping() -> Json<Value> {
    Json(json!({ "pong": true }))
}

// --- /dev/echo ---
// Echoes JSON payload deterministically. Requires Content-Type: application/json
// and (by policy) Content-Length (enforced by BodyCap layer).
pub mod dev {
    use super::*;
    use axum::response::IntoResponse;

    /// Echo JSON back; reject non-JSON early.
    pub async fn echo(Json(body): Json<Value>) -> impl IntoResponse {
        (StatusCode::OK, Json(body))
    }
}

```

### crates/micronode/src/layers/body_cap.rs
<a id="crates-micronode-src-layers-bodycap-rs"></a>

```rust
// crates/micronode/src/layers/body_cap.rs
//! RO:WHAT  — Header-level body cap + content-length policy.
//! RO:WHY   — Enforce explicit Content-Length only on methods that typically
//!            carry bodies (POST/PUT/PATCH). Don't force it for GET/DELETE.
//! RO:NOTE  — Still reject if a Content-Length is present but exceeds the cap.
//! RO:HTTP  — 411 Length Required; 413 Payload Too Large.

use axum::http::{Request, StatusCode};
use axum::response::IntoResponse;
use std::convert::Infallible;
use std::future::Future;
use std::pin::Pin;
use std::task::{Context, Poll};
use tower::{Layer, Service};

#[derive(Clone, Copy)]
pub struct BodyCapLayer {
    cap_bytes: usize,
}

impl BodyCapLayer {
    pub fn new(cap_bytes: usize) -> Self {
        Self { cap_bytes }
    }
}

impl<S> Layer<S> for BodyCapLayer {
    type Service = BodyCapService<S>;

    fn layer(&self, inner: S) -> Self::Service {
        BodyCapService { inner, cap_bytes: self.cap_bytes }
    }
}

#[derive(Clone)]
pub struct BodyCapService<S> {
    inner: S,
    cap_bytes: usize,
}

impl<S, B> Service<Request<B>> for BodyCapService<S>
where
    S: Service<Request<B>, Response = axum::response::Response> + Clone + Send + 'static,
    S::Future: Send + 'static,
    B: Send + 'static,
{
    type Response = S::Response;
    type Error = Infallible;
    type Future =
        Pin<Box<dyn Future<Output = Result<Self::Response, Self::Error>> + Send + 'static>>;

    fn poll_ready(&mut self, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {
        // Delegate to inner; if inner errors, we still return Ready(Ok(())) and
        // map to 500 in call() to avoid bubbling error types here.
        match self.inner.poll_ready(cx) {
            Poll::Ready(Ok(())) => Poll::Ready(Ok(())),
            Poll::Ready(Err(_)) => Poll::Ready(Ok(())),
            Poll::Pending => Poll::Pending,
        }
    }

    fn call(&mut self, req: Request<B>) -> Self::Future {
        let mut inner = self.inner.clone();
        let cap = self.cap_bytes;

        // Methods that typically *carry* a body and must declare Content-Length explicitly.
        let requires_len = matches!(
            *req.method(),
            axum::http::Method::POST | axum::http::Method::PUT | axum::http::Method::PATCH
        );

        // Inspect Content-Length if present.
        let len_opt = req
            .headers()
            .get(axum::http::header::CONTENT_LENGTH)
            .and_then(|h| h.to_str().ok())
            .and_then(|s| s.parse::<usize>().ok());

        // If a Content-Length is present on ANY method, enforce the cap.
        if let Some(len) = len_opt {
            if len > cap {
                return Box::pin(async move {
                    Ok((StatusCode::PAYLOAD_TOO_LARGE, "payload too large").into_response())
                });
            }
        }

        // For methods that *require* an explicit Content-Length, enforce presence.
        if requires_len && len_opt.is_none() {
            return Box::pin(async move {
                Ok((StatusCode::LENGTH_REQUIRED, "length required").into_response())
            });
        }

        Box::pin(async move {
            Ok(inner.call(req).await.unwrap_or_else(|_| {
                (StatusCode::INTERNAL_SERVER_ERROR, "internal error").into_response()
            }))
        })
    }
}

```

### crates/micronode/src/layers/concurrency.rs
<a id="crates-micronode-src-layers-concurrency-rs"></a>

```rust
//! RO:WHAT — Per-route non-blocking concurrency cap (429 when saturated).
//! RO:WHY  — Shed load early without stalling worker threads.
//! RO:AXUM — Tower Layer to satisfy Axum 0.7 trait bounds.

use axum::{
    body::Body,
    http::Request,
    response::{IntoResponse, Response},
};
use http::StatusCode;
use std::{
    convert::Infallible,
    future::Future,
    pin::Pin,
    sync::Arc,
    task::{Context, Poll},
};
use tokio::sync::Semaphore;
use tower::{Layer, Service};

type BoxFut = Pin<Box<dyn Future<Output = Result<Response, Infallible>> + Send + 'static>>;

#[derive(Clone)]
pub struct ConcurrencyLayer {
    sema: Arc<Semaphore>,
}

impl ConcurrencyLayer {
    pub fn new(sema: Arc<Semaphore>) -> Self {
        Self { sema }
    }
}

impl<S> Layer<S> for ConcurrencyLayer {
    type Service = ConcurrencyService<S>;

    fn layer(&self, inner: S) -> Self::Service {
        ConcurrencyService { inner, sema: self.sema.clone() }
    }
}

#[derive(Clone)]
pub struct ConcurrencyService<S> {
    inner: S,
    sema: Arc<Semaphore>,
}

impl<S> Service<Request<Body>> for ConcurrencyService<S>
where
    S: Service<Request<Body>, Response = Response, Error = Infallible> + Clone + Send + 'static,
    S::Future: Send + 'static,
{
    type Response = Response;
    type Error = Infallible;
    type Future = BoxFut;

    fn poll_ready(&mut self, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {
        match self.inner.poll_ready(cx) {
            Poll::Ready(Ok(())) => Poll::Ready(Ok(())),
            Poll::Pending => Poll::Pending,
            Poll::Ready(Err(_)) => Poll::Ready(Ok(())),
        }
    }

    fn call(&mut self, req: Request<Body>) -> Self::Future {
        let mut inner = self.inner.clone();

        // Use OWNED permit so it is 'static-safe inside the async block.
        match self.sema.clone().try_acquire_owned() {
            Ok(permit) => Box::pin(async move {
                let resp = inner.call(req).await?;
                drop(permit); // explicit for clarity
                Ok(resp)
            }),
            Err(_) => Box::pin(async move {
                Ok((StatusCode::TOO_MANY_REQUESTS, "concurrency limit exceeded").into_response())
            }),
        }
    }
}

```

### crates/micronode/src/layers/decode_guard.rs
<a id="crates-micronode-src-layers-decodeguard-rs"></a>

```rust
// crates/micronode/src/layers/decode_guard.rs
//! RO:WHAT — Simple decode policy guard: reject any Content-Encoding and stacked encodings.
//! RO:WHY  — We don't transparently decompress; callers must send identity bodies.

use axum::{
    body::Body,
    http::{header, Request, StatusCode},
    middleware::Next,
    response::{IntoResponse, Response},
};

/// Stateless decode guard: 415 on any Content-Encoding; 415 on stacked encodings ("," in header).
pub async fn guard(req: Request<Body>, next: Next) -> Response {
    match req.headers().get(header::CONTENT_ENCODING) {
        None => next.run(req).await,
        Some(hv) => {
            let enc = match hv.to_str() {
                Ok(s) => s,
                Err(_) => {
                    return (StatusCode::UNSUPPORTED_MEDIA_TYPE, "invalid Content-Encoding header")
                        .into_response();
                }
            };

            if enc.contains(',') {
                return (
                    StatusCode::UNSUPPORTED_MEDIA_TYPE,
                    "stacked content encodings are not supported",
                )
                    .into_response();
            }

            (StatusCode::UNSUPPORTED_MEDIA_TYPE, "compressed request bodies are not supported")
                .into_response()
        }
    }
}

```

### crates/micronode/src/layers/mod.rs
<a id="crates-micronode-src-layers-mod-rs"></a>

```rust
//! RO:WHAT — Ingress guard layers (body cap, decode guard, concurrency).
//! RO:WHY  — Enforce limits *before* heavy work; deterministic early rejects.

pub mod body_cap;
pub mod concurrency;
pub mod decode_guard;
pub mod security;

```

### crates/micronode/src/layers/security.rs
<a id="crates-micronode-src-layers-security-rs"></a>

```rust
// crates/micronode/src/layers/security.rs
//! RO:WHAT — Security ingress layers.
//!
//! 1) `SecurityLayer`: extract raw macaroons into request extensions.
//! 2) `RequireAuthLayer`: enforce a simple, config-driven policy (MVP).
//!
//! RO:WHY — Keep handlers simple; centralize capability plumbing and gating.
//!
//! RO:INTERACTS — Uses `security::auth_macaroon::extract_raw_macaroon` and `RawMacaroon`.
//!
//! RO:INVARIANTS —
//! - Extraction never rejects and never logs token contents.
//! - Enforcement is deny-by-default unless `security.mode = "dev_allow"`.
//! - For now, `external` behaves like `deny_all` (until ron-auth wiring).
//!
//! RO:TEST — Covered by `tests/auth_gate.rs` and existing HTTP integration tests.

use crate::config::schema::SecurityMode;
use crate::security::auth_macaroon::{extract_raw_macaroon, RawMacaroon};
use axum::{
    body::Body,
    http::{header, Request, StatusCode},
    response::{IntoResponse, Response},
};
use std::{
    convert::Infallible,
    future::Future,
    pin::Pin,
    task::{Context, Poll},
};
use tower::{Layer, Service};

type BoxFut = Pin<Box<dyn Future<Output = Result<Response, Infallible>> + Send + 'static>>;

// ===============================
// 1) Extraction: SecurityLayer
// ===============================

/// Layer type used in app.rs for capability extraction.
#[derive(Clone, Default)]
pub struct SecurityLayer;

impl SecurityLayer {
    pub fn new() -> Self {
        Self
    }
}

impl<S> Layer<S> for SecurityLayer {
    type Service = SecurityService<S>;

    fn layer(&self, inner: S) -> Self::Service {
        SecurityService { inner }
    }
}

#[derive(Clone)]
pub struct SecurityService<S> {
    inner: S,
}

impl<S> Service<Request<Body>> for SecurityService<S>
where
    S: Service<Request<Body>, Response = Response, Error = Infallible> + Clone + Send + 'static,
    S::Future: Send + 'static,
{
    type Response = Response;
    type Error = Infallible;
    type Future = BoxFut;

    fn poll_ready(&mut self, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {
        match self.inner.poll_ready(cx) {
            Poll::Ready(Ok(())) => Poll::Ready(Ok(())),
            Poll::Pending => Poll::Pending,
            // Hide inner readiness errors behind 500 in call()
            Poll::Ready(Err(_)) => Poll::Ready(Ok(())),
        }
    }

    fn call(&mut self, mut req: Request<Body>) -> Self::Future {
        let mut inner = self.inner.clone();

        // Extract a RawMacaroon (if present) and park it in extensions.
        if let Some(mac) = extract_raw_macaroon(&req) {
            req.extensions_mut().insert::<RawMacaroon>(mac);
        }

        Box::pin(async move {
            Ok(inner.call(req).await.unwrap_or_else(|_| {
                (StatusCode::INTERNAL_SERVER_ERROR, "internal error").into_response()
            }))
        })
    }
}

// ===============================
// 2) Enforcement: RequireAuthLayer
// ===============================

/// Policy enforcement layer. Deny-by-default unless `DevAllow` is set.
#[derive(Clone, Copy)]
pub struct RequireAuthLayer {
    mode: SecurityMode,
}

impl RequireAuthLayer {
    pub fn new(mode: SecurityMode) -> Self {
        Self { mode }
    }
}

impl<S> Layer<S> for RequireAuthLayer {
    type Service = RequireAuthService<S>;

    fn layer(&self, inner: S) -> Self::Service {
        RequireAuthService { inner, mode: self.mode }
    }
}

#[derive(Clone)]
pub struct RequireAuthService<S> {
    inner: S,
    mode: SecurityMode,
}

impl<S> Service<Request<Body>> for RequireAuthService<S>
where
    S: Service<Request<Body>, Response = Response, Error = Infallible> + Clone + Send + 'static,
    S::Future: Send + 'static,
{
    type Response = Response;
    type Error = Infallible;
    type Future = BoxFut;

    fn poll_ready(&mut self, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {
        match self.inner.poll_ready(cx) {
            Poll::Ready(Ok(())) => Poll::Ready(Ok(())),
            Poll::Pending => Poll::Pending,
            // Hide inner readiness errors behind 500 in call()
            Poll::Ready(Err(_)) => Poll::Ready(Ok(())),
        }
    }

    fn call(&mut self, req: Request<Body>) -> Self::Future {
        let mut inner = self.inner.clone();
        let mode = self.mode;

        Box::pin(async move {
            match mode {
                SecurityMode::DevAllow => {
                    // DX-friendly: allow without header.
                    Ok(inner.call(req).await.unwrap_or_else(|_| {
                        (StatusCode::INTERNAL_SERVER_ERROR, "internal error").into_response()
                    }))
                }
                SecurityMode::DenyAll | SecurityMode::External => {
                    // External behaves like deny_all until wired to ron-auth.
                    let has_mac = req.extensions().get::<RawMacaroon>().is_some();

                    if !has_mac {
                        // 401 + WWW-Authenticate: Macro realm="micronode"
                        let resp = (
                            StatusCode::UNAUTHORIZED,
                            [(header::WWW_AUTHENTICATE, r#"Macro realm="micronode""#)],
                            "missing capability macaroon",
                        )
                            .into_response();
                        Ok(resp)
                    } else {
                        // Present but not allowed by current policy.
                        Ok((StatusCode::FORBIDDEN, "capability not allowed by policy")
                            .into_response())
                    }
                }
            }
        })
    }
}

```

### crates/micronode/src/lib.rs
<a id="crates-micronode-src-lib-rs"></a>

```rust
//! RO:WHAT — Micronode library surface (router assembly, config, observability).
//! RO:WHY  — Expose the pieces that tests, benches, and other crates need:
//!           router builder, config, concurrency plane, adapters, and HTTP layers.
//! RO:INTERACTS — Used by integration tests (admin, KV, facets, backpressure, CLI).

#![forbid(unsafe_code)]

pub mod adapters;
pub mod app;
pub mod cli;
pub mod concurrency;
pub mod config;
pub mod errors;
pub mod facets;
pub mod http;
pub mod layers;
pub mod limits;
pub mod observability;
pub mod security;
pub mod state;
pub mod storage;
pub mod types;

pub use app::build_router;

```

### crates/micronode/src/limits.rs
<a id="crates-micronode-src-limits-rs"></a>

```rust
//! RO:WHAT — Central HTTP/OAP limit constants (foundation only).
//! RO:WHY  — Hardening blueprint: size/time/concurrency must be explicit.
//! RO:INVARIANTS — OAP max_frame=1MiB; decoded body cap defaults to 1MiB.

pub const OAP_MAX_FRAME_BYTES: usize = 1_048_576; // 1 MiB
pub const HTTP_BODY_CAP_BYTES: usize = 1_048_576; // 1 MiB

```

### crates/micronode/src/main.rs
<a id="crates-micronode-src-main-rs"></a>

```rust
//! RO:WHAT — Micronode binary entry: load config, init logs, wire readiness, run HTTP.
//! RO:WHY  — Single-binary Micronode with truthful /readyz and dev override.
//! RO:INVARIANTS — No locks across .await; flip readiness probes at the right moments.

#![forbid(unsafe_code)]

use micronode::{app::build_router, config::load::load_config, observability::logging};
use ron_kernel::wait_for_ctrl_c;
use std::net::SocketAddr;
use tracing::{error, info};

#[tokio::main(flavor = "multi_thread")]
async fn main() {
    logging::init();

    // Load config
    let cfg = match load_config() {
        Ok(c) => c,
        Err(e) => {
            error!("config load failed: {e:#}");
            std::process::exit(2);
        }
    };

    // Build router and capture state
    let (router, st) = build_router(cfg.clone());

    // Probe: config successfully loaded
    st.probes.set_cfg_loaded(true);

    let bind: SocketAddr = cfg.server.bind;
    info!("micronode starting on http://{bind}");

    // Bind listener (readiness depends on this)
    let listener = match tokio::net::TcpListener::bind(bind).await {
        Ok(l) => {
            st.probes.set_listeners_bound(true);
            l
        }
        Err(e) => {
            error!("bind failed on {bind}: {e:#}");
            std::process::exit(98);
        }
    };

    // We've registered /metrics; treat exporter as "bound" (process-exposed).
    st.probes.set_metrics_bound(true);

    // Run server with graceful shutdown
    let server = axum::serve(listener, router).with_graceful_shutdown(async {
        wait_for_ctrl_c().await;
        info!("shutdown signal received");
    });

    if let Err(e) = server.await {
        error!("server error: {e:#}");
    }
}

```

### crates/micronode/src/observability/health.rs
<a id="crates-micronode-src-observability-health-rs"></a>

```rust
//! RO:WHAT — /healthz handler adapter (thin wrapper if we need custom shape later).
//! RO:WHY  — Keep admin.rs simple.
//! RO:INVARIANTS — Truthful.

use axum::{response::IntoResponse, Json};
use serde::Serialize;

#[derive(Serialize)]
struct Health {
    ok: bool,
}

pub async fn handler() -> impl IntoResponse {
    Json(Health { ok: true })
}

```

### crates/micronode/src/observability/http_metrics.rs
<a id="crates-micronode-src-observability-httpmetrics-rs"></a>

```rust
//! RO:WHAT — Minimal HTTP metrics middleware (request count + latency).
//! RO:WHY  — Golden metrics parity across services, with stable metric names:
//!           `micronode_http_requests_total` and `micronode_request_latency_seconds`.
//!
//! RO:INVARIANTS —
//!   - Never propagates errors (Error = Infallible).
//!   - Records a 500 status in metrics if the inner service errors.
//!   - No locks held across `.await`.
//!
//! RO:METRICS —
//!   - micronode_http_requests_total{method,route,status}
//!   - micronode_request_latency_seconds
//!
//! RO:CONFIG — Transparent; router decides which routes are wrapped.

use std::{
    convert::Infallible,
    future::Future,
    pin::Pin,
    sync::OnceLock,
    task::{Context, Poll},
    time::Instant,
};

use axum::{body::Body, http::Request, response::Response};
use prometheus::{Histogram, HistogramOpts, IntCounterVec, Opts};
use tower::{Layer, Service};
use tracing::error;

// --- Static metric families (initialized on first use) ---

static REQS: OnceLock<IntCounterVec> = OnceLock::new();
static LAT: OnceLock<Histogram> = OnceLock::new();

fn reqs() -> &'static IntCounterVec {
    REQS.get_or_init(|| {
        let opts = Opts::new(
            "micronode_http_requests_total",
            "Total HTTP requests processed by Micronode",
        );
        let vec = IntCounterVec::new(opts, &["method", "route", "status"])
            .expect("construct micronode_http_requests_total");

        prometheus::default_registry()
            .register(Box::new(vec.clone()))
            .expect("register micronode_http_requests_total");

        vec
    })
}

fn lat() -> &'static Histogram {
    LAT.get_or_init(|| {
        let opts = HistogramOpts::new(
            "micronode_request_latency_seconds",
            "HTTP request latency observed by Micronode",
        )
        .buckets(prometheus::DEFAULT_BUCKETS.to_vec());

        let hist = Histogram::with_opts(opts).expect("construct micronode_request_latency_seconds");

        prometheus::default_registry()
            .register(Box::new(hist.clone()))
            .expect("register micronode_request_latency_seconds");

        hist
    })
}

// --- Tower Layer implementation ---

#[derive(Clone, Default)]
pub struct HttpMetricsLayer;

impl<S> Layer<S> for HttpMetricsLayer {
    type Service = HttpMetrics<S>;

    fn layer(&self, inner: S) -> Self::Service {
        HttpMetrics { inner }
    }
}

#[derive(Clone)]
pub struct HttpMetrics<S> {
    inner: S,
}

impl<S> Service<Request<Body>> for HttpMetrics<S>
where
    S: Service<Request<Body>, Response = Response> + Clone + Send + 'static,
    S::Error: std::error::Error + Send + Sync + 'static,
    S::Future: Send + 'static,
{
    type Response = S::Response;
    type Error = Infallible;
    type Future = Pin<Box<dyn Future<Output = Result<Self::Response, Self::Error>> + Send>>;

    fn poll_ready(&mut self, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {
        match self.inner.poll_ready(cx) {
            Poll::Ready(Ok(())) => Poll::Ready(Ok(())),
            Poll::Pending => Poll::Pending,
            Poll::Ready(Err(e)) => {
                // For foundation cut, we log readiness errors but don't propagate them.
                error!("HttpMetrics inner not ready: {e}");
                Poll::Ready(Ok(()))
            }
        }
    }

    fn call(&mut self, req: Request<Body>) -> Self::Future {
        let method = req.method().as_str().to_owned();
        let route = req.uri().path().to_owned();
        let start = Instant::now();

        let mut inner = self.inner.clone();

        Box::pin(async move {
            let result = inner.call(req).await;
            let elapsed = start.elapsed().as_secs_f64();

            match result {
                Ok(resp) => {
                    let status = resp.status().as_u16().to_string();
                    reqs().with_label_values(&[&method, &route, &status]).inc();
                    lat().observe(elapsed);
                    Ok(resp)
                }
                Err(e) => {
                    error!("handler error in HttpMetrics: {e}");
                    // Record as a 500 in metrics.
                    let status = String::from("500");
                    reqs().with_label_values(&[&method, &route, &status]).inc();
                    lat().observe(elapsed);

                    let resp = Response::builder()
                        .status(500)
                        .body(Body::from("internal error"))
                        .expect("build 500 response in HttpMetrics");

                    Ok(resp)
                }
            }
        })
    }
}

/// Convenience constructor so app.rs can stay clean.
pub fn layer() -> HttpMetricsLayer {
    HttpMetricsLayer
}

/// Prewarm so the metric families are registered and visible at `/metrics`
/// even before the first real request hits.
pub fn prewarm() {
    let _ = reqs();
    let _ = lat();
}

```

### crates/micronode/src/observability/logging.rs
<a id="crates-micronode-src-observability-logging-rs"></a>

```rust
//! RO:WHAT — Tracing subscriber initialization.
//! RO:WHY  — Deterministic logs with env filter.

use tracing_subscriber::{fmt, EnvFilter};

pub fn init() {
    let filter = std::env::var("RUST_LOG").unwrap_or_else(|_| "info,micronode=debug".to_string());
    let _ = fmt().with_env_filter(EnvFilter::new(filter)).try_init();
}

```

### crates/micronode/src/observability/metrics.rs
<a id="crates-micronode-src-observability-metrics-rs"></a>

```rust


```

### crates/micronode/src/observability/mod.rs
<a id="crates-micronode-src-observability-mod-rs"></a>

```rust
//! RO:WHAT — Observability surfaces: logging and version/health/ready adapters.
//! RO:WHY  — Keep app.rs lean; centralize obs stack.

pub mod health;
pub mod http_metrics;
pub mod logging;
pub mod ready;
pub mod version;
// `metrics` module is kept for future richer gauges/counters; currently a stub.
pub mod metrics;

```

### crates/micronode/src/observability/ready.rs
<a id="crates-micronode-src-observability-ready-rs"></a>

```rust
//! RO:WHAT — Readiness probes and `/readyz` handler (truthful by default).
//! RO:WHY  — Operators need a machine-readable snapshot of liveness gates.
//! RO:INVARIANTS
//!   - Required probes: listeners_bound && cfg_loaded.
//!   - Optional probes: metrics_bound, deps_ok (storage/index/etc).
//!   - Dev override via MICRONODE_DEV_READY=1 returns 200 immediately.

use axum::{http::StatusCode, response::IntoResponse, Json};
use serde::Serialize;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;

#[derive(Debug)]
pub struct ReadyProbes {
    listeners_bound: AtomicBool,
    cfg_loaded: AtomicBool,
    metrics_bound: AtomicBool,
    deps_ok: AtomicBool, // placeholder: storage/index/queue/etc
}

impl ReadyProbes {
    /// Construct probes with a conservative-but-truthful baseline for the
    /// current Micronode profile.
    ///
    /// For the in-memory storage engine, `deps_ok` is effectively always true
    /// once the process is up: there is no fallible external dependency to
    /// gate on. We initialise `deps_ok` to true so that "truthful" mode
    /// reflects reality today.
    ///
    /// When we add a fallible engine (sled / overlay / remote index), that
    /// engine's open result should drive `set_deps_ok(false|true)` instead.
    pub fn new() -> Self {
        Self {
            listeners_bound: AtomicBool::new(false),
            cfg_loaded: AtomicBool::new(false),
            metrics_bound: AtomicBool::new(false),
            deps_ok: AtomicBool::new(true),
        }
    }

    // --- Setters (flip true when satisfied) ---

    pub fn set_listeners_bound(&self, v: bool) {
        self.listeners_bound.store(v, Ordering::Release);
    }

    pub fn set_cfg_loaded(&self, v: bool) {
        self.cfg_loaded.store(v, Ordering::Release);
    }

    pub fn set_metrics_bound(&self, v: bool) {
        self.metrics_bound.store(v, Ordering::Release);
    }

    pub fn set_deps_ok(&self, v: bool) {
        self.deps_ok.store(v, Ordering::Release);
    }

    // --- Snapshot & decision ---

    pub fn snapshot(&self) -> ReadySnapshot {
        ReadySnapshot {
            listeners_bound: self.listeners_bound.load(Ordering::Acquire),
            cfg_loaded: self.cfg_loaded.load(Ordering::Acquire),
            metrics_bound: self.metrics_bound.load(Ordering::Acquire),
            deps_ok: self.deps_ok.load(Ordering::Acquire),
        }
    }
}

// Clippy: new-without-default — keep `new()` as the semantic ctor and
// delegate `Default` to it.
impl Default for ReadyProbes {
    fn default() -> Self {
        Self::new()
    }
}

#[derive(Debug, Clone, Serialize)]
pub struct ReadySnapshot {
    pub listeners_bound: bool,
    pub cfg_loaded: bool,
    pub metrics_bound: bool,
    pub deps_ok: bool,
}

impl ReadySnapshot {
    /// REQUIRED probes for 200 OK. Adjust here if you want stricter gates.
    ///
    /// Today we keep this minimal: Micronode is "ready" once it is listening
    /// and config has been successfully loaded. Optional probes such as
    /// metrics_bound and deps_ok are still included in the JSON payload for
    /// operators and dashboards but do not flip the readiness bit.
    pub fn required_ready(&self) -> bool {
        self.listeners_bound && self.cfg_loaded
    }
}

#[derive(Serialize)]
#[serde(deny_unknown_fields)]
struct ReadyReport {
    ready: bool,
    probes: ReadySnapshot,
    mode: &'static str, // "dev-forced" or "truthful"
}

pub async fn handler(probes: Arc<ReadyProbes>) -> impl IntoResponse {
    // Dev override: force ready for local benches/smokes.
    if matches!(
        std::env::var("MICRONODE_DEV_READY").as_deref(),
        Ok("1") | Ok("true") | Ok("TRUE") | Ok("on") | Ok("ON")
    ) {
        let snap = probes.snapshot();
        let report = ReadyReport { ready: true, probes: snap, mode: "dev-forced" };
        return (StatusCode::OK, Json(report)).into_response();
    }

    let snap = probes.snapshot();
    let ok = snap.required_ready();
    let status = if ok { StatusCode::OK } else { StatusCode::SERVICE_UNAVAILABLE };

    let report = ReadyReport { ready: ok, probes: snap, mode: "truthful" };

    (status, Json(report)).into_response()
}

```

### crates/micronode/src/observability/version.rs
<a id="crates-micronode-src-observability-version-rs"></a>

```rust
//! RO:WHAT — /version payload.
//! RO:WHY  — Build provenance for ops.

use axum::{response::IntoResponse, Json};
use serde::Serialize;

#[derive(Serialize)]
struct VersionResp<'a> {
    name: &'a str,
    version: &'a str,
    built_at_unix: u64,
}

pub async fn handler() -> impl IntoResponse {
    let built =
        option_env!("MICRONODE_BUILD_UNIX").and_then(|s| s.parse::<u64>().ok()).unwrap_or(0);
    Json(VersionResp {
        name: "micronode",
        version: env!("CARGO_PKG_VERSION"),
        built_at_unix: built,
    })
}

```

### crates/micronode/src/security/amnesia.rs
<a id="crates-micronode-src-security-amnesia-rs"></a>

```rust
// crates/micronode/src/security/amnesia.rs
//! RO:WHAT — Amnesia posture helpers (RAM-only by default, persistence opt-in).
//! RO:WHY  — Micronode is designed to be "amnesia-first", avoiding durable writes
//!           unless the operator explicitly opts into persistence.
//! RO:INTERACTS — Uses process environment only; callers use this to decide which
//!                storage engine or profile to pick.
//! RO:INVARIANTS — Default posture is `Enabled` and env parsing never panics.
//! RO:CONFIG — `MICRO_AMNESIA` and legacy `MICRO_PERSIST` influence posture.
//! RO:SECURITY — Favor amnesia when configs are ambiguous and never silently
//!               enable persistence.
//! RO:TEST — Future `tests/amnesia_proof.rs` should walk env matrices.

/// Effective amnesia posture for this process.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum AmnesiaPosture {
    /// Amnesia ON — prefer RAM-only behavior, no durable writes.
    Enabled,
    /// Amnesia OFF — persistence allowed (subject to storage/profile).
    Disabled,
}

/// Returns the effective amnesia posture, considering environment overrides.
///
/// Priority:
/// 1. `MICRO_AMNESIA` (truthy/falsy).
/// 2. `MICRO_PERSIST` (legacy; truthy disables amnesia).
/// 3. Default: `AmnesiaPosture::Enabled`.
pub fn posture_from_env() -> AmnesiaPosture {
    use std::env;

    if let Ok(val) = env::var("MICRO_AMNESIA") {
        match classify_bool(&val) {
            Some(Boolish::True) => return AmnesiaPosture::Enabled,
            Some(Boolish::False) => return AmnesiaPosture::Disabled,
            None => {}
        }
    }

    if let Ok(val) = env::var("MICRO_PERSIST") {
        if matches!(classify_bool(&val), Some(Boolish::True)) {
            return AmnesiaPosture::Disabled;
        }
    }

    AmnesiaPosture::Enabled
}

/// Convenience: `true` if amnesia is enabled (RAM-only posture).
pub fn amnesia_enabled() -> bool {
    matches!(posture_from_env(), AmnesiaPosture::Enabled)
}

/// Convenience: `true` if persistence is allowed (amnesia disabled).
pub fn persistence_allowed() -> bool {
    !amnesia_enabled()
}

/// Internal classification for env bool-likes.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum Boolish {
    True,
    False,
}

/// Classify a string as a "truthy" or "falsy" value, or return `None` if unknown.
fn classify_bool(s: &str) -> Option<Boolish> {
    let v = s.trim();
    if v.is_empty() {
        return None;
    }

    let lower = v.to_ascii_lowercase();

    match lower.as_str() {
        "1" | "true" | "on" | "yes" => Some(Boolish::True),
        "0" | "false" | "off" | "no" => Some(Boolish::False),
        _ => None,
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn classify_bool_truthy_and_falsy() {
        assert_eq!(classify_bool("1"), Some(Boolish::True));
        assert_eq!(classify_bool("true"), Some(Boolish::True));
        assert_eq!(classify_bool("TRUE"), Some(Boolish::True));
        assert_eq!(classify_bool("on"), Some(Boolish::True));
        assert_eq!(classify_bool("yes"), Some(Boolish::True));

        assert_eq!(classify_bool("0"), Some(Boolish::False));
        assert_eq!(classify_bool("false"), Some(Boolish::False));
        assert_eq!(classify_bool("FALSE"), Some(Boolish::False));
        assert_eq!(classify_bool("off"), Some(Boolish::False));
        assert_eq!(classify_bool("no"), Some(Boolish::False));

        assert_eq!(classify_bool(""), None);
        assert_eq!(classify_bool("   "), None);
        assert_eq!(classify_bool("maybe"), None);
    }

    #[test]
    fn posture_defaults_to_amnesia_enabled() {
        let posture = posture_from_env();
        let _ = posture;
    }
}

```

### crates/micronode/src/security/auth_macaroon.rs
<a id="crates-micronode-src-security-authmacaroon-rs"></a>

```rust
// crates/micronode/src/security/auth_macaroon.rs
//! RO:WHAT — Minimal macaroon/capability extraction helpers for HTTP requests.
//! RO:WHY  — Keep header parsing logic out of handlers and treat macaroons as
//!           opaque blobs that downstream auth services can verify.
//! RO:INTERACTS — `http` handlers can call `extract_raw_macaroon(&Request<Body>)`.
//! RO:INVARIANTS — Never panic on malformed headers and never log token contents.
//! RO:CONFIG — Uses an `Authorization` header with the `Macro <token>` scheme.
//! RO:SECURITY — This module only parses macaroons; verification happens elsewhere.
//! RO:TEST — Covered by unit tests here and by higher-level integration tests.

use http::{header, Request};

/// Scheme prefix for macaroon-style capabilities carried in `Authorization`.
///
/// Example: `Authorization: Macro aGVsbG8uLi4`.
pub const MACROON_SCHEME: &str = "macro";

/// Opaque wrapper around a raw macaroon/capability token.
#[derive(Debug, Clone)]
pub struct RawMacaroon {
    token: String,
}

impl RawMacaroon {
    pub fn new(token: String) -> Self {
        Self { token }
    }

    pub fn as_str(&self) -> &str {
        &self.token
    }

    pub fn into_inner(self) -> String {
        self.token
    }
}

/// Attempt to extract a `RawMacaroon` from an HTTP request.
///
/// We look for an `Authorization` header of the form `Macro <token>`
/// and match the scheme case-insensitively.
pub fn extract_raw_macaroon<B>(req: &Request<B>) -> Option<RawMacaroon> {
    let hdr = req.headers().get(header::AUTHORIZATION)?;
    let value = hdr.to_str().ok()?.trim();

    let mut parts = value.splitn(2, char::is_whitespace);
    let scheme = parts.next()?.trim();
    let token = parts.next().unwrap_or("").trim();

    if scheme.eq_ignore_ascii_case(MACROON_SCHEME) && !token.is_empty() {
        Some(RawMacaroon::new(token.to_owned()))
    } else {
        None
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use http::{header, Request};

    #[test]
    fn extract_valid_macroon_authorization() {
        let req = Request::builder()
            .method("GET")
            .uri("/v1/kv/demo/k")
            .header(header::AUTHORIZATION, "Macro abc123")
            .body(())
            .unwrap();

        let mac = extract_raw_macaroon(&req).expect("expected macaroon");
        assert_eq!(mac.as_str(), "abc123");
    }

    #[test]
    fn extract_is_case_insensitive_on_scheme() {
        let req = Request::builder()
            .method("GET")
            .uri("/v1/kv/demo/k")
            .header(header::AUTHORIZATION, "mAcRo xyz")
            .body(())
            .unwrap();

        let mac = extract_raw_macaroon(&req).expect("expected macaroon");
        assert_eq!(mac.as_str(), "xyz");
    }

    #[test]
    fn extract_rejects_unrelated_schemes_or_missing_token() {
        let req = Request::builder()
            .method("GET")
            .uri("/v1/kv/demo/k")
            .header(header::AUTHORIZATION, "Bearer something")
            .body(())
            .unwrap();
        assert!(extract_raw_macaroon(&req).is_none());

        let req = Request::builder()
            .method("GET")
            .uri("/v1/kv/demo/k")
            .header(header::AUTHORIZATION, "Macro")
            .body(())
            .unwrap();
        assert!(extract_raw_macaroon(&req).is_none());

        let req = Request::builder().method("GET").uri("/v1/kv/demo/k").body(()).unwrap();
        assert!(extract_raw_macaroon(&req).is_none());
    }

    #[test]
    fn raw_macaroon_wrapper_roundtrips() {
        let mac = RawMacaroon::new("token-123".to_string());
        assert_eq!(mac.as_str(), "token-123");
        let owned = mac.clone().into_inner();
        assert_eq!(owned, "token-123");
    }
}

```

### crates/micronode/src/security/mod.rs
<a id="crates-micronode-src-security-mod-rs"></a>

```rust
// crates/micronode/src/security/mod.rs
//! RO:WHAT — Security helpers for Micronode (amnesia posture, capability extraction).
//! RO:WHY  — Keep core security decisions such as amnesia-first posture and macaroon
//!           headers in one place.
//! RO:INTERACTS — `amnesia` reads env toggles and `auth_macaroon` extracts raw
//!                macaroons from HTTP requests.
//! RO:INVARIANTS — Defaults are amnesia-first and macaroons are treated as opaque blobs.
//! RO:CONFIG — Env keys for amnesia include `MICRO_AMNESIA` and a legacy `MICRO_PERSIST`.
//! RO:SECURITY — This module does not verify capabilities; that work lives in
//!                `ron-auth` and `ron-policy`.
//! RO:TEST — To be covered by `tests/amnesia_proof.rs` and future security tests.

pub mod amnesia;
pub mod auth_macaroon;

// PQ / TLS modules are kept as stubs for now; they will be fleshed out later.
pub mod pq_config;
pub mod pq_observe;
pub mod pq_toggle;
pub mod tls_rustls;

```

### crates/micronode/src/security/pq_config.rs
<a id="crates-micronode-src-security-pqconfig-rs"></a>

```rust


```

### crates/micronode/src/security/pq_observe.rs
<a id="crates-micronode-src-security-pqobserve-rs"></a>

```rust


```

### crates/micronode/src/security/pq_toggle.rs
<a id="crates-micronode-src-security-pqtoggle-rs"></a>

```rust


```

### crates/micronode/src/security/tls_rustls.rs
<a id="crates-micronode-src-security-tlsrustls-rs"></a>

```rust


```

### crates/micronode/src/state.rs
<a id="crates-micronode-src-state-rs"></a>

```rust
//! RO:WHAT — Process state container: config, metrics, health, readiness probes, storage.
//! RO:WHY  — Keep shared handles in one place for Axum State.
//! RO:INTERACTS — config::schema::Config, observability::ready::ReadyProbes, ron_kernel::Metrics, storage::MemStore.
//! RO:INVARIANTS — No locks across `.await`; handles are clone-friendly; storage is behind a trait.
//! RO:METRICS — Metrics handle exported via /metrics (Prometheus).
//! RO:CONFIG — Config drives server bind/dev routes (storage engine later).
//! RO:SECURITY — No capabilities enforced here (auth/policy lives at handlers).
//! RO:TEST — Covered by HTTP integration tests that exercise AppState via routes.

use crate::config::schema::Config;
use crate::observability::ready::ReadyProbes;
use crate::storage::{DynStorage, MemStore};
use ron_kernel::metrics::health::HealthState;
use ron_kernel::Metrics;
use std::sync::Arc;

#[derive(Clone)]
pub struct AppState {
    pub cfg: Config,
    pub metrics: Arc<Metrics>,    // exported via /metrics
    pub health: Arc<HealthState>, // liveness
    pub probes: Arc<ReadyProbes>, // readiness (truthful)
    pub storage: DynStorage,      // key/value engine (mem today, pluggable later)
}

impl AppState {
    pub fn new(cfg: Config) -> Self {
        // false = we don't auto-serve exporter here (we expose /metrics via axum)
        let metrics: Arc<Metrics> = Metrics::new(false);
        let health = Arc::new(HealthState::new());
        let probes = Arc::new(ReadyProbes::new());

        // For now Micronode always boots with the in-memory store.
        // Later, Config::storage.engine will select sled vs mem.
        let storage: DynStorage = Arc::new(MemStore::new());

        // Baseline liveness true; readiness remains truthful via probes.
        health.set("micronode", true);

        Self { cfg, metrics, health, probes, storage }
    }
}

```

### crates/micronode/src/storage/mod.rs
<a id="crates-micronode-src-storage-mod-rs"></a>

```rust
//! RO:WHAT — Storage abstraction for Micronode (KV engine + in-memory implementation).
//! RO:WHY  — Give Micronode a boring key/value API that can later plug sled/RocksDB/etc.
//! RO:INTERACTS — Used by state::AppState and HTTP KV handlers (http::kv).
//! RO:INVARIANTS — No locks across `.await`; operations are short, bounded, and sync.
//! RO:METRICS — KV ops/bytes metrics can be layered on top later (domain counters).
//! RO:CONFIG — Engine selection will come from Config (engine="mem" | "sled") in a later step.
//! RO:SECURITY — No auth here; capability/policy checks live at HTTP layer.
//! RO:TEST — Unit tests for MemStore + HTTP integration tests for KV routes (future).

use crate::errors::Result;
use parking_lot::RwLock;
use std::collections::HashMap;
use std::sync::Arc;

/// Trait for Micronode KV engines.
///
/// This is intentionally small and synchronous; HTTP handlers stay async and
/// call into this trait without holding locks across `.await`.
pub trait Storage: Send + Sync {
    /// Insert or overwrite a value.
    ///
    /// Returns `Ok(true)` if the key was newly created, `Ok(false)` if it
    /// replaced an existing value.
    fn put(&self, bucket: &str, key: &str, value: &[u8]) -> Result<bool>;

    /// Fetch a value, if present.
    fn get(&self, bucket: &str, key: &str) -> Result<Option<Vec<u8>>>;

    /// Delete a value.
    ///
    /// Returns `Ok(true)` if a value existed and was removed, `Ok(false)` if
    /// the key was absent.
    fn delete(&self, bucket: &str, key: &str) -> Result<bool>;
}

/// Shared trait object type for storage engines.
pub type DynStorage = Arc<dyn Storage + Send + Sync>;

#[derive(Debug, Clone, Eq, PartialEq, Hash)]
struct BucketKey {
    bucket: String,
    key: String,
}

impl BucketKey {
    fn new(bucket: &str, key: &str) -> Self {
        Self { bucket: bucket.to_owned(), key: key.to_owned() }
    }
}

/// Simple in-memory store backed by a `RwLock<HashMap<BucketKey, Vec<u8>>>`.
///
/// Intended for:
///   - dev/prototyping
///   - amnesia-first micronode profiles
///   - tests
#[derive(Debug, Default)]
pub struct MemStore {
    inner: RwLock<HashMap<BucketKey, Vec<u8>>>,
}

impl MemStore {
    pub fn new() -> Self {
        Self::default()
    }
}

impl Storage for MemStore {
    fn put(&self, bucket: &str, key: &str, value: &[u8]) -> Result<bool> {
        let k = BucketKey::new(bucket, key);
        let mut guard = self.inner.write();
        let existed = guard.insert(k, value.to_vec()).is_some();
        Ok(!existed)
    }

    fn get(&self, bucket: &str, key: &str) -> Result<Option<Vec<u8>>> {
        let k = BucketKey::new(bucket, key);
        let guard = self.inner.read();
        Ok(guard.get(&k).cloned())
    }

    fn delete(&self, bucket: &str, key: &str) -> Result<bool> {
        let k = BucketKey::new(bucket, key);
        let mut guard = self.inner.write();
        Ok(guard.remove(&k).is_some())
    }
}

// In the next step we can add:
//
// #[cfg(feature = "sled-store")]
// pub mod sled_store;
//
// and implement `Storage` for a sled-backed engine.

```

### crates/micronode/src/storage/sled_store.rs
<a id="crates-micronode-src-storage-sledstore-rs"></a>

```rust
// crates/micronode/src/storage/sled_store.rs
//! RO:WHAT — Sled-backed Storage adapter (bucket = tree; key = binary value).
//! RO:MODE — Behind `sled-store` feature; not used by default.
//! RO:ERRS — Map sled errors to `Error::Internal` (beta scope).

#[cfg(feature = "sled-store")]
mod sled_adapter {
    use super::super::{Storage};
    use crate::errors::{Error, Result};
    use std::sync::Arc;

    pub struct SledStore {
        db: sled::Db,
    }

    impl SledStore {
        pub fn open(path: &str) -> Result<Arc<Self>> {
            let db = sled::open(path).map_err(|_| Error::Internal)?;
            Ok(Arc::new(Self { db }))
        }

        #[inline]
        fn tree(&self, bucket: &str) -> Result<sled::Tree> {
            self.db.open_tree(bucket).map_err(|_| Error::Internal)
        }
    }

    impl Storage for SledStore {
        fn put(&self, bucket: &str, key: &str, val: &[u8]) -> Result<()> {
            let t = self.tree(bucket)?;
            t.insert(key.as_bytes(), val).map_err(|_| Error::Internal)?;
            Ok(())
        }

        fn get(&self, bucket: &str, key: &str) -> Result<Option<Vec<u8>>> {
            let t = self.tree(bucket)?;
            let v = t.get(key.as_bytes()).map_err(|_| Error::Internal)?;
            Ok(v.map(|ivec| ivec.to_vec()))
        }

        fn del(&self, bucket: &str, key: &str) -> Result<bool> {
            let t = self.tree(bucket)?;
            let removed = t.remove(key.as_bytes()).map_err(|_| Error::Internal)?;
            Ok(removed.is_some())
        }
    }
}

// Public re-export only when feature is enabled.
#[cfg(feature = "sled-store")]
pub use sled_adapter::SledStore;

```

### crates/micronode/src/types.rs
<a id="crates-micronode-src-types-rs"></a>

```rust
//! RO:WHAT — Shared DTOs for tiny endpoints (/version, dev echo).
//! RO:WHY  — Keep handler files small and composable.
//! RO:INVARIANTS — DTO hygiene: #[serde(deny_unknown_fields)].

use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize)]
#[serde(deny_unknown_fields)]
pub struct Version {
    pub name: &'static str,
    pub version: &'static str,
    pub built_at_unix: u64,
}

#[derive(Debug, Deserialize, Serialize)]
#[serde(deny_unknown_fields)]
pub struct Echo {
    pub message: String,
}

```

### crates/micronode/tests/admin_parity.rs
<a id="crates-micronode-tests-adminparity-rs"></a>

```rust
//! RO:WHAT — Integration tests for Micronode admin plane.
//! RO:WHY  — Ensure `/healthz`, `/readyz`, `/version`, `/metrics` are wired
//!           and behave sanely in-process (no external binaries needed).
//! RO:HOW  — Spin up an ephemeral axum server using `build_router` and
//!           hit it with `reqwest`.
//!
//! These are intentionally high-level smoke tests:
//!   - If they fail, the node is not “basically alive”.
//!   - They double as a template for future KV / guard tests.

use std::{net::SocketAddr, time::Duration};

use micronode::app::build_router;
use micronode::config::schema::{Config, Server};
use reqwest::StatusCode;
use tokio::task::JoinHandle;

/// Spawn an in-process Micronode instance on an ephemeral port.
///
/// This mirrors the main binary’s bootstrap pattern but avoids config
/// files and uses a synthetic `Config` pointing at `127.0.0.1:0`.
async fn spawn_micronode() -> (SocketAddr, JoinHandle<()>) {
    // Bind an ephemeral port first so we know where to hit the server.
    let listener = tokio::net::TcpListener::bind("127.0.0.1:0").await.expect("bind test listener");
    let addr = listener.local_addr().expect("get local address for test listener");

    // Minimal config: bind address + dev routes (handy for future tests).
    let cfg = Config { server: Server { bind: addr, dev_routes: true }, ..Config::default() };

    // Build router + state the same way the binary does.
    let (router, state) = build_router(cfg);

    // Flip readiness probes to a “healthy” state.
    //
    // This matches what the main binary does after binding listeners
    // and wiring metrics. For now we treat deps_ok as true because the
    // in-memory store has no external failure mode.
    state.probes.set_cfg_loaded(true);
    state.probes.set_listeners_bound(true);
    state.probes.set_metrics_bound(true);
    state.probes.set_deps_ok(true);

    // Run the server in the background. Dropping the handle will cancel it.
    let handle = tokio::spawn(async move {
        if let Err(err) = axum::serve(listener, router).await {
            eprintln!("[micronode-test] server error: {err}");
        }
    });

    (addr, handle)
}

#[tokio::test]
async fn admin_endpoints_are_healthy_and_observable() {
    let (addr, _handle) = spawn_micronode().await;
    let base = format!("http://{}", addr);

    let client = reqwest::Client::builder()
        .timeout(Duration::from_secs(2))
        .build()
        .expect("build reqwest client");

    // /healthz — must be 200 and JSON { "ok": true }.
    let health = client.get(format!("{base}/healthz")).send().await.expect("GET /healthz");
    assert!(health.status().is_success(), "expected 2xx from /healthz, got {}", health.status());
    let health_body: serde_json::Value = health.json().await.expect("parse /healthz json");
    assert_eq!(
        health_body["ok"],
        serde_json::Value::Bool(true),
        "expected /healthz.ok == true, got {health_body}"
    );

    // /readyz — must be 200 and JSON { "ready": true, ... } in truthful mode.
    let ready = client.get(format!("{base}/readyz")).send().await.expect("GET /readyz");
    assert_eq!(ready.status(), StatusCode::OK, "expected 200 from /readyz, got {}", ready.status());
    let ready_body: serde_json::Value = ready.json().await.expect("parse /readyz json");
    assert_eq!(
        ready_body["ready"],
        serde_json::Value::Bool(true),
        "expected /readyz.ready == true, got {ready_body}"
    );

    // /version — must be 200 and at least contain `name: "micronode"`.
    let version = client.get(format!("{base}/version")).send().await.expect("GET /version");
    assert!(version.status().is_success(), "expected 2xx from /version, got {}", version.status());
    let version_body: serde_json::Value = version.json().await.expect("parse /version json");
    assert_eq!(
        version_body["name"],
        serde_json::Value::String("micronode".to_string()),
        "expected /version.name == \"micronode\", got {version_body}"
    );

    // /metrics — must be 200 and contain at least the micronode HTTP series.
    let metrics = client.get(format!("{base}/metrics")).send().await.expect("GET /metrics");
    assert!(metrics.status().is_success(), "expected 2xx from /metrics, got {}", metrics.status());
    let metrics_text = metrics.text().await.expect("read /metrics text");

    assert!(
        metrics_text.contains("micronode_http_requests_total"),
        "expected /metrics to contain micronode_http_requests_total; got:\n{}",
        metrics_text
    );
    assert!(
        metrics_text.contains("micronode_request_latency_seconds"),
        "expected /metrics to contain micronode_request_latency_seconds; got:\n{}",
        metrics_text
    );
}

```

### crates/micronode/tests/amnesia_proof.rs
<a id="crates-micronode-tests-amnesiaproof-rs"></a>

```rust


```

### crates/micronode/tests/auth_gate.rs
<a id="crates-micronode-tests-authgate-rs"></a>

```rust
//! RO:WHAT — Integration tests for Micronode auth enforcement (MVP layer).
//! RO:WHY  — Prove deny-by-default semantics and DX-friendly dev_allow mode.
//! RO:TESTS —
//!   1) deny_all without header -> 401 + WWW-Authenticate
//!   2) deny_all with header    -> 403
//!   3) dev_allow without header -> 201/200 on KV

use std::{net::SocketAddr, time::Duration};

use micronode::app::build_router;
use micronode::config::schema::{Config, SecurityCfg, SecurityMode, Server};
use reqwest::StatusCode;
use tokio::task::JoinHandle;

/// Spawn an in-process Micronode instance on an ephemeral port with the given security mode.
async fn spawn_with_security(mode: SecurityMode) -> (SocketAddr, JoinHandle<()>) {
    let listener = tokio::net::TcpListener::bind("127.0.0.1:0").await.expect("bind test listener");
    let addr = listener.local_addr().expect("local address");

    let cfg = Config {
        server: Server { bind: addr, dev_routes: false },
        security: SecurityCfg { mode },
        ..Config::default()
    };

    let (router, state) = build_router(cfg);

    // Make readiness truthful for the in-memory engine.
    state.probes.set_cfg_loaded(true);
    state.probes.set_listeners_bound(true);
    state.probes.set_metrics_bound(true);
    state.probes.set_deps_ok(true);

    let handle = tokio::spawn(async move {
        if let Err(err) = axum::serve(listener, router).await {
            eprintln!("[micronode-auth-test] server error: {err}");
        }
    });

    (addr, handle)
}

#[tokio::test]
async fn deny_all_without_header_yields_401_www_authenticate() {
    let (addr, _handle) = spawn_with_security(SecurityMode::DenyAll).await;
    let base = format!("http://{}", addr);
    let key_url = format!("{base}/v1/kv/a/k");

    let client =
        reqwest::Client::builder().timeout(Duration::from_secs(2)).build().expect("client");

    // Attempt a PUT without Authorization: expect 401 + WWW-Authenticate
    let put = client
        .put(&key_url)
        .header("content-type", "application/octet-stream")
        .body("hello")
        .send()
        .await
        .expect("PUT missing auth");
    assert_eq!(put.status(), StatusCode::UNAUTHORIZED, "expected 401, got {}", put.status());
    let hdr = put.headers().get("www-authenticate").and_then(|v| v.to_str().ok()).unwrap_or("");
    assert!(
        hdr.to_ascii_lowercase().contains("macro"),
        "expected Macro scheme in WWW-Authenticate, got {hdr:?}"
    );
}

#[tokio::test]
async fn deny_all_with_header_yields_403() {
    let (addr, _handle) = spawn_with_security(SecurityMode::DenyAll).await;
    let base = format!("http://{}", addr);
    let key_url = format!("{base}/v1/kv/a/k");

    let client =
        reqwest::Client::builder().timeout(Duration::from_secs(2)).build().expect("client");

    // With a dummy Macro token we still deny in MVP (no external auth yet)
    let put = client
        .put(&key_url)
        .header("content-type", "application/octet-stream")
        .header("authorization", "Macro dummy-token")
        .body("hello")
        .send()
        .await
        .expect("PUT with dummy auth");
    assert_eq!(put.status(), StatusCode::FORBIDDEN, "expected 403, got {}", put.status());
}

#[tokio::test]
async fn dev_allow_permits_kv_without_header() {
    let (addr, _handle) = spawn_with_security(SecurityMode::DevAllow).await;
    let base = format!("http://{}", addr);
    let key_url = format!("{base}/v1/kv/a/k");

    let client =
        reqwest::Client::builder().timeout(Duration::from_secs(2)).build().expect("client");

    // 1) PUT without Authorization should succeed in dev_allow.
    let put = client
        .put(&key_url)
        .header("content-type", "application/octet-stream")
        .body("hello")
        .send()
        .await
        .expect("PUT /v1/kv/a/k");
    assert_eq!(put.status(), StatusCode::CREATED, "expected 201, got {}", put.status());

    // 2) GET should return the value.
    let get = client.get(&key_url).send().await.expect("GET");
    assert_eq!(get.status(), StatusCode::OK, "expected 200, got {}", get.status());
    let body = get.bytes().await.expect("read body");
    assert_eq!(&body[..], b"hello");
}

```

### crates/micronode/tests/backpressure.rs
<a id="crates-micronode-tests-backpressure-rs"></a>

```rust
//! RO:WHAT — Integration-style tests for Micronode backpressure behavior.
//! RO:WHY  — Assert that the concurrency layer sheds overload with 429 and that
//!           the concurrency registry builds distinct, bounded pools.
//!
//! These tests operate entirely in-process (no real TCP sockets), driving the
//! Axum `Router` directly.

use std::sync::Arc;

use axum::{body::Body, routing::get, Router};
use http::{Request, StatusCode};
use micronode::{
    concurrency::{ConcurrencyConfig, ConcurrencyRegistry},
    layers::concurrency::ConcurrencyLayer,
};
use tokio::sync::Semaphore;
use tower::ServiceExt as _; // for `Router::oneshot`

#[tokio::test]
async fn concurrency_layer_sheds_with_429_when_pool_is_exhausted() {
    // Limit=1 and we hold the only permit up front so the layer sees a
    // saturated pool and must respond with 429 immediately.
    let sema = Arc::new(Semaphore::new(1));
    let _held = sema.clone().acquire_owned().await.expect("failed to acquire initial permit");

    let app =
        Router::new().route("/hot", get(|| async { "ok" })).layer(ConcurrencyLayer::new(sema));

    let req = Request::builder().uri("/hot").body(Body::empty()).expect("build request");

    let resp = app.oneshot(req).await.expect("router call failed");

    assert_eq!(
        resp.status(),
        StatusCode::TOO_MANY_REQUESTS,
        "expected 429 from ConcurrencyLayer when pool is exhausted"
    );
}

#[tokio::test]
async fn concurrency_registry_builds_distinct_pools_per_class() {
    let cfg = ConcurrencyConfig::default();
    let registry = ConcurrencyRegistry::from_config(&cfg);

    let admin = registry.get("http_admin");
    let kv = registry.get("http_kv");

    // Pointers must differ; these are distinct semaphores for distinct budgets.
    let admin_ptr: *const Semaphore = &*admin;
    let kv_ptr: *const Semaphore = &*kv;

    assert_ne!(admin_ptr, kv_ptr, "admin and kv should have distinct concurrency pools");

    // Both pools should honour their configured caps.
    assert_eq!(
        cfg.http_admin.max_inflight,
        admin.available_permits(),
        "admin pool should be initialized with the configured max_inflight"
    );
    assert_eq!(
        cfg.http_kv.max_inflight,
        kv.available_permits(),
        "kv pool should be initialized with the configured max_inflight"
    );
}

```

### crates/micronode/tests/cli_smoke.rs
<a id="crates-micronode-tests-clismoke-rs"></a>

```rust
//! RO:WHAT — Smoke tests for Micronode CLI surface.
//! RO:WHY  — Ensure `Cli::from_env()` produces a sensible default shape and
//!           that the public enums/types remain stable across refactors.

use micronode::cli::{Cli, Command, Profile};

#[test]
fn default_cli_uses_serve_command() {
    let cli = Cli::from_env();

    match cli.command() {
        Command::Serve(opts) => {
            // Default profile should be `Dev` to favor DX.
            assert_eq!(opts.profile, Profile::Dev);
            // Dev routes should be on by default.
            assert!(opts.dev_routes);
        }
        other => panic!("expected default command to be Serve(..), got {other:?}"),
    }
}

```

### crates/micronode/tests/facets_loader.rs
<a id="crates-micronode-tests-facetsloader-rs"></a>

```rust
//! RO:WHAT — Facet loader integration tests.
//! RO:WHY  — Prove manifest-driven loading and basic handlers; loader errors block readiness.

use std::{fs, net::SocketAddr, path::PathBuf, time::Duration};

use micronode::app::build_router;
use micronode::config::schema::{Config, FacetsCfg, SecurityCfg, SecurityMode, Server};
use reqwest::StatusCode;
use tokio::task::JoinHandle;

async fn spawn_with_facets(dir: PathBuf, mode: SecurityMode) -> (SocketAddr, JoinHandle<()>) {
    let listener = tokio::net::TcpListener::bind("127.0.0.1:0").await.expect("bind test listener");
    let addr = listener.local_addr().unwrap();

    let cfg = Config {
        server: Server { bind: addr, dev_routes: false },
        security: SecurityCfg { mode },
        facets: FacetsCfg { enabled: true, dir: Some(dir.to_string_lossy().to_string()) },
        ..Config::default()
    };

    let (router, state) = build_router(cfg);

    // Truthful readiness: mark other gates true; facets gate is handled by build_router.
    state.probes.set_cfg_loaded(true);
    state.probes.set_listeners_bound(true);
    state.probes.set_metrics_bound(true);

    let handle = tokio::spawn(async move {
        if let Err(err) = axum::serve(listener, router).await {
            eprintln!("[micronode-facet-test] server error: {err}");
        }
    });

    (addr, handle)
}

#[tokio::test]
async fn loads_static_and_echo_facets_and_enforces_auth() {
    // Temp dir with manifests + static file.
    let tmp = tempfile::tempdir().unwrap();
    let d = tmp.path();

    // Static file
    let file_path = d.join("hello.txt");
    fs::write(&file_path, b"hi\n").unwrap();

    // Static facet manifest
    let static_toml = format!(
        r#"
[facet]
id = "docs"
kind = "static"

[[route]]
method = "GET"
path = "/hello"
file = "{}"
"#,
        file_path.to_string_lossy()
    );
    fs::write(d.join("docs.toml"), static_toml).unwrap();

    // Echo facet manifest
    let echo_toml = r#"
[facet]
id = "echoer"
kind = "echo"

[[route]]
method = "GET"
path = "/who"
"#;
    fs::write(d.join("echo.toml"), echo_toml).unwrap();

    // Spawn in deny_all (requires auth, expect 401 for facets).
    let (addr, _h) = spawn_with_facets(d.to_path_buf(), SecurityMode::DenyAll).await;
    let base = format!("http://{}", addr);

    let client = reqwest::Client::builder().timeout(Duration::from_secs(2)).build().unwrap();

    // Meta should list both facets.
    let meta = client.get(format!("{base}/facets/meta")).send().await.unwrap();
    assert_eq!(meta.status(), StatusCode::OK);
    let j: serde_json::Value = meta.json().await.unwrap();
    let list = j.get("loaded").and_then(|v| v.as_array()).unwrap();
    assert_eq!(list.len(), 2);

    // GET /facets/docs/hello should be gated (401)
    let f = client.get(format!("{base}/facets/docs/hello")).send().await.unwrap();
    assert_eq!(f.status(), StatusCode::UNAUTHORIZED);

    // Now spawn dev_allow and ensure it returns content.
    let (addr2, _h2) = spawn_with_facets(d.to_path_buf(), SecurityMode::DevAllow).await;
    let base2 = format!("http://{}", addr2);
    let client2 = reqwest::Client::new();

    let f2 = client2.get(format!("{base2}/facets/docs/hello")).send().await.unwrap();
    assert_eq!(f2.status(), StatusCode::OK);
    let body = f2.text().await.unwrap();
    assert!(body.contains("hi"));
}

#[tokio::test]
async fn bad_manifest_blocks_readiness() {
    let tmp = tempfile::tempdir().unwrap();
    let d = tmp.path();

    // Bad: missing leading slash in path
    let bad_toml = r#"
[facet]
id = "bad"
kind = "echo"

[[route]]
method = "GET"
path = "nope"
"#;
    fs::write(d.join("bad.toml"), bad_toml).unwrap();

    let (addr, _h) = spawn_with_facets(d.to_path_buf(), SecurityMode::DevAllow).await;
    let base = format!("http://{}", addr);
    let client = reqwest::Client::new();
    let r = client.get(format!("{base}/readyz")).send().await.unwrap();
    // We set deps_ok = false on loader error, so readyz should NOT be ready (usually 200 with ready=false or non-200 depending on your impl).
    assert!(r.status().is_success() || r.status().is_server_error()); // tolerate either shape
    let t = r.text().await.unwrap();
    assert!(t.to_ascii_lowercase().contains("ready") || t.to_ascii_lowercase().contains("false"));
}

```

### crates/micronode/tests/facets_proxy.rs
<a id="crates-micronode-tests-facetsproxy-rs"></a>

```rust
// crates/micronode/tests/facets_proxy.rs
//! RO:WHAT — Integration tests for Micronode facet hosting.
//! RO:WHY  — Prove that we can mount a facet (demo) and reach it via HTTP
//!           using the same in-process router used by benches.

use axum::body::Body;
use http::{Request, StatusCode};
use micronode::{build_router, config::schema::Config};
use tower::ServiceExt as _; // for Router::oneshot

#[tokio::test]
async fn demo_facet_ping_works() {
    let cfg = Config::default();
    let (router, _state) = build_router(cfg);

    let resp = router
        .oneshot(
            Request::builder().method("GET").uri("/facets/demo/ping").body(Body::empty()).unwrap(),
        )
        .await
        .expect("router error");

    assert_eq!(resp.status(), StatusCode::OK);
}

#[tokio::test]
async fn facets_meta_endpoint_is_wired() {
    let cfg = Config::default();
    let (router, _state) = build_router(cfg);

    let resp = router
        .oneshot(Request::builder().method("GET").uri("/facets/_meta").body(Body::empty()).unwrap())
        .await
        .expect("router error");

    assert_eq!(resp.status(), StatusCode::OK);
}

```

### crates/micronode/tests/guard_behavior.rs
<a id="crates-micronode-tests-guardbehavior-rs"></a>

```rust
//! RO:WHAT — Integration tests for Micronode guard behavior (decode + body cap).
//! RO:WHY  — Assert that `DecodeGuard` and `BodyCapLayer` behave as specified
//!           on real HTTP routes (no mock services).
//!
//! RO:INVARIANTS —
//!   - Any `Content-Encoding` on guarded routes yields 415.
//!   - Payloads over `HTTP_BODY_CAP_BYTES` yield 413.
//!
//! These tests exercise `/dev/echo`, which is wired with:
//!   DecodeGuard -> BodyCapLayer -> ConcurrencyLayer -> handler.

use std::{net::SocketAddr, time::Duration};

use micronode::app::build_router;
use micronode::config::schema::{Config, Server};
use micronode::limits::HTTP_BODY_CAP_BYTES;
use reqwest::StatusCode;
use tokio::task::JoinHandle;

/// Spawn an in-process Micronode instance on an ephemeral port, with
/// dev routes enabled and readiness probes flipped to "healthy".
async fn spawn_micronode() -> (SocketAddr, JoinHandle<()>) {
    let listener = tokio::net::TcpListener::bind("127.0.0.1:0").await.expect("bind test listener");
    let addr = listener.local_addr().expect("get local address for test listener");

    let cfg = Config { server: Server { bind: addr, dev_routes: true }, ..Config::default() };

    let (router, state) = build_router(cfg);

    state.probes.set_cfg_loaded(true);
    state.probes.set_listeners_bound(true);
    state.probes.set_metrics_bound(true);
    state.probes.set_deps_ok(true);

    let handle = tokio::spawn(async move {
        if let Err(err) = axum::serve(listener, router).await {
            eprintln!("[micronode-guard-test] server error: {err}");
        }
    });

    (addr, handle)
}

#[tokio::test]
async fn decode_guard_rejects_any_content_encoding() {
    let (addr, _handle) = spawn_micronode().await;
    let base = format!("http://{}", addr);
    let url = format!("{base}/dev/echo");

    let client = reqwest::Client::builder()
        .timeout(Duration::from_secs(2))
        .build()
        .expect("build reqwest client");

    let resp = client
        .post(&url)
        .header("content-type", "application/json")
        .header("content-encoding", "gzip")
        .body(r#"{"message":"hi"}"#)
        .send()
        .await
        .expect("POST /dev/echo with content-encoding");

    assert_eq!(
        resp.status(),
        StatusCode::UNSUPPORTED_MEDIA_TYPE,
        "expected 415 from DecodeGuard on any Content-Encoding, got {}",
        resp.status()
    );
}

#[tokio::test]
async fn body_cap_enforces_max_payload_size() {
    let (addr, _handle) = spawn_micronode().await;
    let base = format!("http://{}", addr);
    let url = format!("{base}/dev/echo");

    let client = reqwest::Client::builder()
        .timeout(Duration::from_secs(5))
        .build()
        .expect("build reqwest client");

    // Construct a payload that is one byte over the configured cap.
    let over_cap_len = (HTTP_BODY_CAP_BYTES as usize).saturating_add(1);
    let payload = vec![b'a'; over_cap_len];

    let resp = client
        .post(&url)
        .header("content-type", "application/json")
        .body(payload)
        .send()
        .await
        .expect("POST /dev/echo with over-cap payload");

    assert_eq!(
        resp.status(),
        StatusCode::PAYLOAD_TOO_LARGE,
        "expected 413 from BodyCapLayer for payload > HTTP_BODY_CAP_BYTES, got {}",
        resp.status()
    );
}

```

### crates/micronode/tests/kv_roundtrip.rs
<a id="crates-micronode-tests-kvroundtrip-rs"></a>

```rust
//! RO:WHAT — KV roundtrip test (PUT/GET/DELETE) under dev_allow.
//! RO:WHY  — Default security mode is deny_all; for this behavioral test we
//!           exercise the storage surface in DX mode.
//! RO:INVARIANTS — Ensures status codes and body echo match expectations.

use std::{net::SocketAddr, time::Duration};

use micronode::app::build_router;
use micronode::config::schema::{Config, SecurityCfg, SecurityMode, Server};
use reqwest::StatusCode;
use tokio::task::JoinHandle;

async fn spawn_dev_allow() -> (SocketAddr, JoinHandle<()>) {
    let listener = tokio::net::TcpListener::bind("127.0.0.1:0").await.expect("bind test listener");
    let addr = listener.local_addr().expect("local address");

    let cfg = Config {
        server: Server { bind: addr, dev_routes: false },
        security: SecurityCfg { mode: SecurityMode::DevAllow },
        ..Config::default()
    };

    let (router, state) = build_router(cfg);

    // Make readiness truthful for the in-memory engine.
    state.probes.set_cfg_loaded(true);
    state.probes.set_listeners_bound(true);
    state.probes.set_metrics_bound(true);
    state.probes.set_deps_ok(true);

    let handle = tokio::spawn(async move {
        if let Err(err) = axum::serve(listener, router).await {
            eprintln!("[micronode-kv-roundtrip] server error: {err}");
        }
    });

    (addr, handle)
}

#[tokio::test]
async fn kv_put_get_delete_roundtrip() {
    let (addr, _handle) = spawn_dev_allow().await;
    let base = format!("http://{}", addr);
    let key_url = format!("{base}/v1/kv/demo/k");

    let client =
        reqwest::Client::builder().timeout(Duration::from_secs(2)).build().expect("client");

    // PUT
    let put = client
        .put(&key_url)
        .header("content-type", "application/octet-stream")
        .body("hello")
        .send()
        .await
        .expect("PUT /v1/kv/demo/k");
    assert_eq!(put.status(), StatusCode::CREATED, "expected 201 Created, got {}", put.status());

    // GET
    let get = client.get(&key_url).send().await.expect("GET /v1/kv/demo/k");
    assert_eq!(get.status(), StatusCode::OK, "expected 200 OK, got {}", get.status());
    let body = get.bytes().await.expect("read body");
    assert_eq!(&body[..], b"hello");

    // DELETE
    let del = client.delete(&key_url).send().await.expect("DELETE /v1/kv/demo/k");
    assert_eq!(
        del.status(),
        StatusCode::NO_CONTENT,
        "expected 204 No Content, got {}",
        del.status()
    );
}

```

### crates/micronode/tests/oap_limits.rs
<a id="crates-micronode-tests-oaplimits-rs"></a>

```rust


```

### crates/micronode/tests/pq_fallback.rs
<a id="crates-micronode-tests-pqfallback-rs"></a>

```rust


```

### crates/micronode/tests/pq_modes.rs
<a id="crates-micronode-tests-pqmodes-rs"></a>

```rust


```

### crates/micronode/tests_chaos/degrade_shed.rs
<a id="crates-micronode-testschaos-degradeshed-rs"></a>

```rust

```

### crates/micronode/tests_loom/shutdown_interleavings.rs
<a id="crates-micronode-testsloom-shutdowninterleavings-rs"></a>

```rust

```

### crates/micronode/tests_property/oap_fuzz.rs
<a id="crates-micronode-testsproperty-oapfuzz-rs"></a>

```rust

```

### crates/micronode/tests_property/pq_handshake_props.rs
<a id="crates-micronode-testsproperty-pqhandshakeprops-rs"></a>

```rust

```



---



# macronode

_Source: crates/macronode/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-11-22T01:56:29Z -->
# Code Bundle — `macronode`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/macronode/.github/workflows/ci.yml](#crates-macronode--github-workflows-ci-yml)
- [crates/macronode/.github/workflows/render-mermaid.yml](#crates-macronode--github-workflows-render-mermaid-yml)
- [crates/macronode/Cargo.toml](#crates-macronode-Cargo-toml)
- [crates/macronode/benches/admin_paths_latency.rs](#crates-macronode-benches-adminpathslatency-rs)
- [crates/macronode/scripts/dump_http_surface.sh](#crates-macronode-scripts-dumphttpsurface-sh)
- [crates/macronode/scripts/dump_metrics_names.sh](#crates-macronode-scripts-dumpmetricsnames-sh)
- [crates/macronode/scripts/render_mermaid.sh](#crates-macronode-scripts-rendermermaid-sh)
- [crates/macronode/src/bus/events.rs](#crates-macronode-src-bus-events-rs)
- [crates/macronode/src/bus/mod.rs](#crates-macronode-src-bus-mod-rs)
- [crates/macronode/src/cli/args.rs](#crates-macronode-src-cli-args-rs)
- [crates/macronode/src/cli/check.rs](#crates-macronode-src-cli-check-rs)
- [crates/macronode/src/cli/config_print.rs](#crates-macronode-src-cli-configprint-rs)
- [crates/macronode/src/cli/config_validate.rs](#crates-macronode-src-cli-configvalidate-rs)
- [crates/macronode/src/cli/doctor.rs](#crates-macronode-src-cli-doctor-rs)
- [crates/macronode/src/cli/mod.rs](#crates-macronode-src-cli-mod-rs)
- [crates/macronode/src/cli/run.rs](#crates-macronode-src-cli-run-rs)
- [crates/macronode/src/cli/version.rs](#crates-macronode-src-cli-version-rs)
- [crates/macronode/src/config/cli_overlay.rs](#crates-macronode-src-config-clioverlay-rs)
- [crates/macronode/src/config/env_overlay.rs](#crates-macronode-src-config-envoverlay-rs)
- [crates/macronode/src/config/hot_reload.rs](#crates-macronode-src-config-hotreload-rs)
- [crates/macronode/src/config/load.rs](#crates-macronode-src-config-load-rs)
- [crates/macronode/src/config/mod.rs](#crates-macronode-src-config-mod-rs)
- [crates/macronode/src/config/schema.rs](#crates-macronode-src-config-schema-rs)
- [crates/macronode/src/config/validate.rs](#crates-macronode-src-config-validate-rs)
- [crates/macronode/src/errors.rs](#crates-macronode-src-errors-rs)
- [crates/macronode/src/facets/mod.rs](#crates-macronode-src-facets-mod-rs)
- [crates/macronode/src/facets/permits.rs](#crates-macronode-src-facets-permits-rs)
- [crates/macronode/src/facets/quotas.rs](#crates-macronode-src-facets-quotas-rs)
- [crates/macronode/src/http_admin/handlers/healthz.rs](#crates-macronode-src-httpadmin-handlers-healthz-rs)
- [crates/macronode/src/http_admin/handlers/metrics.rs](#crates-macronode-src-httpadmin-handlers-metrics-rs)
- [crates/macronode/src/http_admin/handlers/mod.rs](#crates-macronode-src-httpadmin-handlers-mod-rs)
- [crates/macronode/src/http_admin/handlers/readyz.rs](#crates-macronode-src-httpadmin-handlers-readyz-rs)
- [crates/macronode/src/http_admin/handlers/reload.rs](#crates-macronode-src-httpadmin-handlers-reload-rs)
- [crates/macronode/src/http_admin/handlers/shutdown.rs](#crates-macronode-src-httpadmin-handlers-shutdown-rs)
- [crates/macronode/src/http_admin/handlers/status.rs](#crates-macronode-src-httpadmin-handlers-status-rs)
- [crates/macronode/src/http_admin/handlers/version.rs](#crates-macronode-src-httpadmin-handlers-version-rs)
- [crates/macronode/src/http_admin/middleware/auth.rs](#crates-macronode-src-httpadmin-middleware-auth-rs)
- [crates/macronode/src/http_admin/middleware/mod.rs](#crates-macronode-src-httpadmin-middleware-mod-rs)
- [crates/macronode/src/http_admin/middleware/rate_limit.rs](#crates-macronode-src-httpadmin-middleware-ratelimit-rs)
- [crates/macronode/src/http_admin/middleware/request_id.rs](#crates-macronode-src-httpadmin-middleware-requestid-rs)
- [crates/macronode/src/http_admin/middleware/timeout.rs](#crates-macronode-src-httpadmin-middleware-timeout-rs)
- [crates/macronode/src/http_admin/mod.rs](#crates-macronode-src-httpadmin-mod-rs)
- [crates/macronode/src/http_admin/router.rs](#crates-macronode-src-httpadmin-router-rs)
- [crates/macronode/src/main.rs](#crates-macronode-src-main-rs)
- [crates/macronode/src/observability/logging.rs](#crates-macronode-src-observability-logging-rs)
- [crates/macronode/src/observability/metrics.rs](#crates-macronode-src-observability-metrics-rs)
- [crates/macronode/src/observability/mod.rs](#crates-macronode-src-observability-mod-rs)
- [crates/macronode/src/pq/hybrid.rs](#crates-macronode-src-pq-hybrid-rs)
- [crates/macronode/src/pq/mod.rs](#crates-macronode-src-pq-mod-rs)
- [crates/macronode/src/readiness/deps.rs](#crates-macronode-src-readiness-deps-rs)
- [crates/macronode/src/readiness/mod.rs](#crates-macronode-src-readiness-mod-rs)
- [crates/macronode/src/readiness/probes.rs](#crates-macronode-src-readiness-probes-rs)
- [crates/macronode/src/security/amnesia.rs](#crates-macronode-src-security-amnesia-rs)
- [crates/macronode/src/security/macaroon.rs](#crates-macronode-src-security-macaroon-rs)
- [crates/macronode/src/security/mod.rs](#crates-macronode-src-security-mod-rs)
- [crates/macronode/src/security/tls.rs](#crates-macronode-src-security-tls-rs)
- [crates/macronode/src/services/mod.rs](#crates-macronode-src-services-mod-rs)
- [crates/macronode/src/services/registry.rs](#crates-macronode-src-services-registry-rs)
- [crates/macronode/src/services/spawn.rs](#crates-macronode-src-services-spawn-rs)
- [crates/macronode/src/services/svc_dht.rs](#crates-macronode-src-services-svcdht-rs)
- [crates/macronode/src/services/svc_gateway.rs](#crates-macronode-src-services-svcgateway-rs)
- [crates/macronode/src/services/svc_index.rs](#crates-macronode-src-services-svcindex-rs)
- [crates/macronode/src/services/svc_mailbox.rs](#crates-macronode-src-services-svcmailbox-rs)
- [crates/macronode/src/services/svc_overlay.rs](#crates-macronode-src-services-svcoverlay-rs)
- [crates/macronode/src/services/svc_storage.rs](#crates-macronode-src-services-svcstorage-rs)
- [crates/macronode/src/supervisor/backoff.rs](#crates-macronode-src-supervisor-backoff-rs)
- [crates/macronode/src/supervisor/crash_policy.rs](#crates-macronode-src-supervisor-crashpolicy-rs)
- [crates/macronode/src/supervisor/health_reporter.rs](#crates-macronode-src-supervisor-healthreporter-rs)
- [crates/macronode/src/supervisor/lifecycle.rs](#crates-macronode-src-supervisor-lifecycle-rs)
- [crates/macronode/src/supervisor/mod.rs](#crates-macronode-src-supervisor-mod-rs)
- [crates/macronode/src/supervisor/shutdown.rs](#crates-macronode-src-supervisor-shutdown-rs)
- [crates/macronode/src/types.rs](#crates-macronode-src-types-rs)
- [crates/macronode/src/util/dur.rs](#crates-macronode-src-util-dur-rs)
- [crates/macronode/src/util/sizes.rs](#crates-macronode-src-util-sizes-rs)
- [crates/macronode/tests/admin_smoke.rs](#crates-macronode-tests-adminsmoke-rs)
- [crates/macronode/tests/metrics_contract.rs](#crates-macronode-tests-metricscontract-rs)
- [crates/macronode/tests/readiness_drain.rs](#crates-macronode-tests-readinessdrain-rs)

### crates/macronode/.github/workflows/ci.yml
<a id="crates-macronode--github-workflows-ci-yml"></a>

```yaml

```

### crates/macronode/.github/workflows/render-mermaid.yml
<a id="crates-macronode--github-workflows-render-mermaid-yml"></a>

```yaml

```

### crates/macronode/Cargo.toml
<a id="crates-macronode-Cargo-toml"></a>

```toml
[package]
name = "macronode"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
publish = false

[[bin]]
name = "macronode"
path = "src/main.rs"

[dependencies]
# Core RON-CORE crates this node will coordinate.
ron-kernel  = { path = "../ron-kernel" }
ron-proto   = { path = "../ron-proto" }
oap         = { path = "../oap" }
svc-storage = { path = "../svc-storage" }
svc-index   = { path = "../svc-index" }

# Network & messaging planes (to be fully wired in next slices).
svc-overlay = { path = "../svc-overlay" }
svc-dht     = { path = "../svc-dht" }
svc-mailbox = { path = "../svc-mailbox" }

# Transport layer for overlay/DHT (TCP/TLS/Tor via features).
ron-transport = { path = "../ron-transport" }

# Async and HTTP stack
tokio = { version = "1.38", features = ["macros", "rt-multi-thread", "signal", "time", "net"] }
axum  = { version = "0.7", features = ["http1", "http2", "json", "tokio"] }
tower = "0.5"
http  = "1"

# Observability
tracing            = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "fmt"] }
prometheus         = "0.14"

# Config / serde
serde           = { version = "1", features = ["derive"] }
serde_json      = "1"
toml            = "0.8"
humantime       = "2.1"
humantime-serde = "1.1"

# Error handling
thiserror = "1"
anyhow    = "1"

# Misc
parking_lot = "0.12"

[dev-dependencies]
reqwest = { version = "0.12", features = ["rustls-tls-native-roots", "json"] }
tokio   = { version = "1.38", features = ["macros", "rt-multi-thread", "time", "net"] }

[[bench]]
name = "admin_paths_latency"
harness = false
path = "benches/admin_paths_latency.rs"
```

### crates/macronode/benches/admin_paths_latency.rs
<a id="crates-macronode-benches-adminpathslatency-rs"></a>

```rust
//! RO:WHAT — Ad-hoc latency probe for macronode admin endpoints.
//! RO:WHY  — Quick, zero-setup way to see per-path latency from a single client.
//!
//! HOW TO USE
//! ----------
//! 1) Make sure macronode is running, e.g.:
//!      RUST_LOG=info cargo run -p macronode -- run --config macronode.toml
//! 2) In another terminal, run:
//!      cargo bench -p macronode --bench admin_paths_latency
//!
//! By default this targets http://127.0.0.1:8080. Override with:
//!      RON_HTTP_ADDR=127.0.0.1:9090 cargo bench -p macronode --bench admin_paths_latency
//!
//! This is a plain binary bench; we’re not using the unstable `#[bench]`
//! harness or Criterion here — just a small async client.

use std::time::{Duration, Instant};

use reqwest::Client;

const DEFAULT_ADDR: &str = "127.0.0.1:8080";

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let addr = std::env::var("RON_HTTP_ADDR").unwrap_or_else(|_| DEFAULT_ADDR.to_string());
    let base = format!("http://{addr}");

    println!();
    println!("macronode admin latency probe");
    println!("  base = {base}");
    println!("  (override with RON_HTTP_ADDR=host:port)");
    println!();

    let client = Client::builder()
        .pool_idle_timeout(Some(Duration::from_secs(5)))
        .timeout(Duration::from_secs(2))
        .build()?;

    let paths = [
        "/healthz",
        "/readyz",
        "/version",
        "/metrics",
        "/api/v1/status",
    ];

    for path in paths {
        let url = format!("{base}{path}");
        let start = Instant::now();
        let resp = client.get(&url).send().await;
        let elapsed = start.elapsed();

        match resp {
            Ok(r) => {
                println!("{:<18} {:>3}  {:>8.3?}", path, r.status().as_u16(), elapsed);
            }
            Err(e) => {
                println!("{:<18} ERR  {:>8.3?}  ({e})", path, elapsed);
            }
        }
    }

    println!();
    Ok(())
}

```

### crates/macronode/scripts/dump_http_surface.sh
<a id="crates-macronode-scripts-dumphttpsurface-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT — Dump macronode admin HTTP surface.
# RO:WHY  — Quick visibility into /version, /healthz, /readyz, /metrics, /api/v1/status.
# RO:INVARIANTS —
#   - Never fails hard if optional tools (jq) are missing.
#   - Uses RON_HTTP_ADDR if set, otherwise 127.0.0.1:8080.

set -euo pipefail

ADDR="${RON_HTTP_ADDR:-127.0.0.1:8080}"
BASE="http://${ADDR}"

say() { printf '[macronode] %s\n' "$*"; }

say "Dumping admin HTTP surface from ${BASE}"

has_jq=0
if command -v jq >/dev/null 2>&1; then
  has_jq=1
fi

echo
say "GET /version"
if [[ "${has_jq}" == "1" ]]; then
  curl -sS "${BASE}/version" | jq . || true
else
  curl -sS "${BASE}/version" || true
fi
echo

say "GET /healthz"
curl -sS "${BASE}/healthz" || true
echo

say "GET /readyz"
curl -sS "${BASE}/readyz" || true
echo

say "HEAD /metrics (first headers)"
curl -sSI "${BASE}/metrics" | sed -n '1,15p' || true
echo

say "GET /api/v1/status"
if [[ "${has_jq}" == "1" ]]; then
  curl -sS "${BASE}/api/v1/status" | jq . || true
else
  curl -sS "${BASE}/api/v1/status" || true
fi
echo

say "Done."

```

### crates/macronode/scripts/dump_metrics_names.sh
<a id="crates-macronode-scripts-dumpmetricsnames-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT — Extract unique Prometheus metric names from /metrics.
# RO:WHY  — Quick sanity check on exposed metrics without digging through all samples.
# RO:INVARIANTS —
#   - Does not assume any specific metric set; just prints the current names.
#   - Uses RON_HTTP_ADDR if set, otherwise 127.0.0.1:8080.

set -euo pipefail

ADDR="${RON_HTTP_ADDR:-127.0.0.1:8080}"
BASE="http://${ADDR}"

say() { printf '[macronode] %s\n' "$*"; }

say "Fetching metrics from ${BASE}/metrics"

curl -sS "${BASE}/metrics" \
  | grep -E '^[a-zA-Z_][a-zA-Z0-9_:]*[[:space:]]' \
  | cut -d' ' -f1 \
  | sort -u

say "Done."

```

### crates/macronode/scripts/render_mermaid.sh
<a id="crates-macronode-scripts-rendermermaid-sh"></a>

```bash
#!/usr/bin/env bash
# RO:WHAT — Render Mermaid diagrams for macronode docs.
# RO:WHY  — Keep architecture docs (graphs/flows) in sync and easy to regenerate.
# RO:INVARIANTS —
#   - Operates only inside this crate (crates/macronode/docs).
#   - No-op if docs/ or any *.mmd files do not exist.
#   - Requires mermaid-cli (mmdc) if you want actual renders.

set -euo pipefail

CRATE_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
DOCS_DIR="${CRATE_ROOT}/docs"

say() { printf '[macronode] %s\n' "$*"; }
warn() { printf '[macronode][warn] %s\n' "$*" >&2; }

if [[ ! -d "${DOCS_DIR}" ]]; then
  warn "docs/ directory not found at ${DOCS_DIR} — nothing to render."
  exit 0
fi

if ! command -v mmdc >/dev/null 2>&1; then
  warn "mermaid-cli (mmdc) not found."
  warn "Install via: npm install -g @mermaid-js/mermaid-cli"
  exit 1
fi

shopt -s nullglob
files=( "${DOCS_DIR}"/*.mmd )
if (( ${#files[@]} == 0 )); then
  warn "No *.mmd files found under ${DOCS_DIR} — nothing to render."
  exit 0
fi

for src in "${files[@]}"; do
  out="${src%.mmd}.svg"
  say "rendering ${src} -> ${out}"
  mmdc -i "${src}" -o "${out}"
done

say "All Mermaid diagrams rendered."

```

### crates/macronode/src/bus/events.rs
<a id="crates-macronode-src-bus-events-rs"></a>

```rust
//! RO:WHAT — Typed events emitted on Macronode’s internal bus.
//! RO:WHY  — Keep the event surface small and aligned with the kernel’s
//!           `KernelEvent` so services can reason about a single enum.
//! RO:INVARIANTS —
//!   - We do not invent new event types here; we alias the canonical
//!     `ron-kernel::KernelEvent` so the control plane stays coherent.
//!   - Higher-level “topic groups” (overlay, storage, etc.) are modeled
//!     as variants/fields on `KernelEvent` in `ron-kernel`, not here.
//!
//! RO:INTERACTS —
//!   - `crate::bus::NodeBus` publishes/subscribes these events.
//!   - Supervisor and services will eventually publish things like
//!     `ConfigUpdated`, `ServiceCrashed`, etc. onto this bus.

use ron_kernel::KernelEvent;

/// Node-level event type carried by the Macronode bus.
///
/// For now this is *exactly* the kernel’s `KernelEvent` so there is a
/// single, shared event taxonomy across the project.
pub type NodeEvent = KernelEvent;

// Re-export for convenience so callers can `use crate::bus::KernelEvent;`
/// Re-export of the canonical kernel event type.
pub use ron_kernel::KernelEvent;

```

### crates/macronode/src/bus/mod.rs
<a id="crates-macronode-src-bus-mod-rs"></a>

```rust
// crates/macronode/src/bus/mod.rs

//! RO:WHAT — Lightweight broadcast bus wrapper for Macronode.
//! RO:WHY  — Provide bounded, lag-aware pub/sub over `NodeEvent` without
//!           leaking `tokio::sync::broadcast` details across the crate.
//!
//! RO:INVARIANTS —
//!   - Bus is bounded; senders see an error if subscribers lag too far.
//!   - Consumers must handle `Lagged` by reconciling from a snapshot
//!     (supervisor/status endpoints can always provide an up-to-date view).
//!   - The API is intentionally tiny: `publish` + `subscribe`.
//!
//! RO:INTERACTS —
//!   - Will be threaded into `Supervisor` in a later step so that
//!     supervisor, services, and admin handlers can exchange events.
//!   - Event type is `NodeEvent` (an alias for `ron_kernel::KernelEvent`).

// This module intentionally shapes a future-facing API (NodeBus/NodeEvent)
// that is not wired anywhere *yet*. We allow dead_code here so that
// `cargo clippy -D warnings` stays green while we incrementally integrate
// the bus into supervisor/services in later slices.
#![allow(dead_code)]

use std::fmt;

use tokio::sync::broadcast;

/// Canonical event type carried by the Macronode bus.
///
/// For now this is *exactly* the kernel’s `KernelEvent` so there is a
/// single, shared event taxonomy across the project.
pub type NodeEvent = ron_kernel::KernelEvent;

/// Default channel capacity for the node bus.
///
/// This is deliberately modest; we want backpressure via `Lagged` errors
/// instead of unbounded growth. We can tune this later if needed.
const DEFAULT_CAPACITY: usize = 1024;

/// Cloneable handle to the Macronode event bus.
///
/// Internally, this wraps a `tokio::sync::broadcast::Sender<NodeEvent>`.
/// Subscribers obtain a `broadcast::Receiver<NodeEvent>` via `subscribe()`.
#[derive(Clone)]
pub struct NodeBus {
    tx: broadcast::Sender<NodeEvent>,
}

impl NodeBus {
    /// Create a new bus with the given bounded capacity.
    pub fn with_capacity(capacity: usize) -> Self {
        let (tx, _rx) = broadcast::channel(capacity);
        Self { tx }
    }

    /// Create a new bus with a sensible default capacity.
    pub fn new() -> Self {
        Self::with_capacity(DEFAULT_CAPACITY)
    }

    /// Publish an event to all subscribers.
    ///
    /// Returns `Ok(())` on success or a `SendError` if there were no
    /// active subscribers or if the channel was otherwise unable to
    /// accept the event.
    pub fn publish(&self, event: NodeEvent) -> Result<(), broadcast::error::SendError<NodeEvent>> {
        self.tx.send(event)?;
        Ok(())
    }

    /// Subscribe to the stream of node events.
    ///
    /// Callers **must** be prepared to handle `RecvError::Lagged(_)` on
    /// the returned receiver by re-syncing from a snapshot (e.g. via
    /// `/api/v1/status`) before continuing.
    pub fn subscribe(&self) -> broadcast::Receiver<NodeEvent> {
        self.tx.subscribe()
    }

    /// Access the underlying sender for advanced integrations.
    ///
    /// Most code should prefer `publish()` instead of using this directly.
    pub fn sender(&self) -> broadcast::Sender<NodeEvent> {
        self.tx.clone()
    }
}

impl fmt::Debug for NodeBus {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        // We intentionally don’t expose internal channel state here.
        f.debug_struct("NodeBus").finish_non_exhaustive()
    }
}

```

### crates/macronode/src/cli/args.rs
<a id="crates-macronode-src-cli-args-rs"></a>

```rust
//! RO:WHAT — Macronode CLI command/option types.
//! RO:WHY  — Keep the CLI surface explicit and testable without tying
//!           directly to a particular parsing crate.
//! RO:INVARIANTS —
//!   - `Cli::parse()` is a tiny, predictable parser over `std::env::args`.
//!   - Unknown commands fall back to `run` with a warning.
//!   - For `run`, we parse a small subset of flags by hand.

#[derive(Debug, Clone)]
pub enum Command {
    /// Run the Macronode host (admin HTTP + services).
    Run(RunOpts),
    /// Print version/build information and exit.
    Version,
    /// Validate environment/config and exit.
    Check,
    /// Print effective redacted config.
    ConfigPrint,
    /// Validate a supplied config file without starting the node.
    ConfigValidate,
    /// Run diagnostics bundle (fs/dns/time drift/ports).
    Doctor,
}

/// Options for the `run` subcommand.
///
/// NOTE: Fields are intentionally conservative for now; we keep them
/// around so the CLI surface is stable while we gradually implement
/// overlays. `#[allow(dead_code)]` keeps clippy happy under `-D warnings`
/// until all fields are used.
#[allow(dead_code)]
#[derive(Debug, Clone, Default)]
pub struct RunOpts {
    /// Optional path to a config file (`--config`).
    pub config_path: Option<String>,
    /// Optional bind override for admin HTTP (`--http-addr`).
    pub http_addr: Option<String>,
    /// Optional bind override for metrics (`--metrics-addr`).
    pub metrics_addr: Option<String>,
    /// Optional log level override (`--log-level`).
    pub log_level: Option<String>,
    /// Optional amnesia flag (`--amnesia`).
    pub amnesia: Option<bool>,
}

impl RunOpts {
    /// Parse flags for the `run` command from a slice of arguments.
    ///
    /// Supported flags (MVP):
    ///   --config PATH
    ///   --http-addr ADDR
    ///   --log-level LEVEL
    ///
    /// Unknown flags are ignored with a warning.
    pub fn from_args(args: &[String]) -> Self {
        let mut opts = RunOpts::default();
        let mut i = 0;

        while i < args.len() {
            match args[i].as_str() {
                "--config" => {
                    if let Some(val) = args.get(i + 1) {
                        opts.config_path = Some(val.clone());
                        i += 1;
                    } else {
                        eprintln!("macronode: --config requires a path argument");
                    }
                }
                "--http-addr" => {
                    if let Some(val) = args.get(i + 1) {
                        opts.http_addr = Some(val.clone());
                        i += 1;
                    } else {
                        eprintln!("macronode: --http-addr requires an address argument");
                    }
                }
                "--log-level" => {
                    if let Some(val) = args.get(i + 1) {
                        opts.log_level = Some(val.clone());
                        i += 1;
                    } else {
                        eprintln!("macronode: --log-level requires a level argument");
                    }
                }
                "--metrics-addr" => {
                    if let Some(val) = args.get(i + 1) {
                        opts.metrics_addr = Some(val.clone());
                        i += 1;
                    } else {
                        eprintln!("macronode: --metrics-addr requires an address argument");
                    }
                }
                "--amnesia" => {
                    // For now we accept `--amnesia` as a bare flag and treat it as true.
                    opts.amnesia = Some(true);
                }
                other => {
                    // Ignore unknown flags for now, but let the operator know.
                    if other.starts_with('-') {
                        eprintln!(
                            "macronode: ignoring unknown flag `{other}` on `run` (see README CLI section)"
                        );
                    }
                }
            }

            i += 1;
        }

        opts
    }
}

/// Top-level CLI wrapper.
#[derive(Debug, Clone)]
pub struct Cli {
    pub cmd: Command,
}

impl Cli {
    /// Parse CLI arguments into a `Cli` value.
    ///
    /// Today we:
    ///   - Look at the first positional argument to decide the subcommand.
    ///   - For `run`, parse a small set of flags from the remaining args.
    pub fn parse() -> Self {
        let mut args = std::env::args().skip(1);
        let sub = args.next();

        let cmd = match sub.as_deref() {
            None => {
                // No subcommand; treat as `run` with default options.
                Command::Run(RunOpts::default())
            }
            Some("run") => {
                let rest: Vec<String> = args.collect();
                let opts = RunOpts::from_args(&rest);
                Command::Run(opts)
            }
            Some("version") | Some("--version") | Some("-V") => Command::Version,
            Some("check") => Command::Check,
            Some("config") => match args.next().as_deref() {
                Some("print") => Command::ConfigPrint,
                Some("validate") => Command::ConfigValidate,
                other => {
                    eprintln!(
                        "macronode: expected `config print` or `config validate`, got {:?}; \
                         defaulting to `config print`",
                        other
                    );
                    Command::ConfigPrint
                }
            },
            Some("doctor") => Command::Doctor,
            Some(other) => {
                eprintln!(
                    "macronode: unknown command `{other}`, defaulting to `run` (see README CLI section)"
                );
                Command::Run(RunOpts::default())
            }
        };

        Cli { cmd }
    }
}

```

### crates/macronode/src/cli/check.rs
<a id="crates-macronode-src-cli-check-rs"></a>

```rust
//! RO:WHAT — Implementation of the `check` subcommand.
//! RO:WHY  — Fast validation of config/env without starting listeners.
//! RO:INVARIANTS —
//!   - Returns non-error only if config loads successfully.

use crate::{config::load_config, errors::Result};

pub fn run() -> Result<()> {
    let cfg = load_config()?;
    println!(
        "macronode check: OK (http_addr={}, metrics_addr={}, log_level={})",
        cfg.http_addr, cfg.metrics_addr, cfg.log_level
    );
    Ok(())
}

```

### crates/macronode/src/cli/config_print.rs
<a id="crates-macronode-src-cli-configprint-rs"></a>

```rust
//! RO:WHAT — Implementation of `config print`.
//! RO:WHY  — Give operators a way to see the **effective** config after
//!           defaults, optional file (RON_CONFIG/MACRO_CONFIG), and env
//!           overlays have been applied.

use crate::{config::load_config, errors::Result};

pub fn run() -> Result<()> {
    let cfg = load_config()?;
    let json = serde_json::to_string_pretty(&cfg)?;
    println!("{json}");
    Ok(())
}

```

### crates/macronode/src/cli/config_validate.rs
<a id="crates-macronode-src-cli-configvalidate-rs"></a>

```rust
//! RO:WHAT — Implementation of `config validate`.
//! RO:WHY  — Off-line validation of config without starting listeners.
//! RO:NOTE — Uses the same loader as `config print`/`check`, which merges
//!           defaults + optional file (via `RON_CONFIG`) + env overlays.

use crate::{config::load_config, errors::Result};

pub fn run() -> Result<()> {
    let _cfg = load_config()?;
    println!("macronode config validate: OK (file/env-based config)");
    Ok(())
}

```

### crates/macronode/src/cli/doctor.rs
<a id="crates-macronode-src-cli-doctor-rs"></a>

```rust
//! RO:WHAT — Implementation of the `doctor` subcommand (MVP stub).
//! RO:WHY  — Placeholder for richer diagnostics (fs/dns/time drift/ports).

use crate::errors::Result;

pub fn run() -> Result<()> {
    println!("macronode doctor: stub (diagnostics not yet implemented)");
    Ok(())
}

```

### crates/macronode/src/cli/mod.rs
<a id="crates-macronode-src-cli-mod-rs"></a>

```rust
//! RO:WHAT — Macronode CLI surface and entrypoint.
//! RO:WHY  — Provide a stable operator-facing CLI (`run`, `version`, `check`,
//!           `config print|validate`, `doctor`) without committing to a
//!           specific argument parser crate yet.
//! RO:INVARIANTS —
//!   - Parsing is intentionally minimal but deterministic.
//!   - All subcommands return `errors::Result<()>` so main can stay boring.

pub mod args;
pub mod check;
pub mod config_print;
pub mod config_validate;
pub mod doctor;
pub mod run;
pub mod version;

use crate::errors::Result;
pub use args::{Cli, Command, RunOpts};

/// Parse CLI args and dispatch to the selected subcommand.
pub async fn entrypoint() -> Result<()> {
    let cli = Cli::parse();
    match cli.cmd {
        Command::Run(opts) => run::run(opts).await,
        Command::Version => {
            version::run();
            Ok(())
        }
        Command::Check => check::run(),
        Command::ConfigPrint => config_print::run(),
        Command::ConfigValidate => config_validate::run(),
        Command::Doctor => doctor::run(),
    }
}

```

### crates/macronode/src/cli/run.rs
<a id="crates-macronode-src-cli-run-rs"></a>

```rust
//! RO:WHAT — Implementation of the `run` subcommand.
//! RO:WHY  — Bridge between CLI surface and the existing runtime wiring
//!           (config, logging, readiness, admin HTTP, supervisor).
//! RO:INVARIANTS —
//!   - Config pipeline: defaults -> file (optional) -> env -> CLI overlays.
//!   - `RunOpts` is the only source of CLI overrides.
//!   - HTTP admin server uses graceful shutdown on Ctrl-C.

use std::{sync::Arc, time::Instant};

use axum::Router;
use ron_kernel::wait_for_ctrl_c;
use tokio::net::TcpListener;
use tracing::{error, info};

use crate::{
    bus::NodeBus,
    config::{
        cli_overlay::{apply_cli_overlays, CliOverlay},
        load_effective_config,
    },
    errors::Result,
    http_admin,
    observability::logging,
    readiness::ReadyProbes,
    supervisor::{ShutdownToken, Supervisor},
    types::AppState,
};

use super::RunOpts;

/// Execute the `run` subcommand.
pub async fn run(opts: RunOpts) -> Result<()> {
    // 1) Load config (defaults + optional file from CLI/env + env).
    //
    // Precedence for file path:
    //   1) CLI --config
    //   2) RON_CONFIG / MACRO_CONFIG (inside load_effective_config)
    let base_cfg = load_effective_config(opts.config_path.as_deref())?;

    // 2) Build CLI overlay from RunOpts and apply it.
    let overlay = CliOverlay {
        http_addr: opts.http_addr.clone(),
        metrics_addr: opts.metrics_addr.clone(),
        log_level: opts.log_level.clone(),
    };
    let cfg = apply_cli_overlays(base_cfg, &overlay)?;

    // 3) Initialize logging with config log level (RUST_LOG can still override).
    logging::init(&cfg.log_level);

    // 4) Build shared readiness probes and shutdown token.
    let probes = Arc::new(ReadyProbes::new());
    let shutdown_token = ShutdownToken::new();

    // Metrics are already served via `/metrics` as soon as the admin router
    // is bound, so we can treat this as "bound" from the perspective of
    // readiness once the listener is active.
    //
    // NOTE: `cfg.metrics_addr` is now plumbed through config/env/CLI but we
    // still serve metrics on the admin listener for this slice. A future
    // slice can spin a dedicated metrics listener when `metrics_addr != http_addr`.
    probes.set_metrics_bound(true);

    // 5) Start supervised services. Successful spawn marks deps_ok.
    let supervisor = Supervisor::new(probes.clone(), shutdown_token.clone());
    supervisor.start().await?;

    // 6) Build intra-node event bus.
    //
    // RO:WHAT — local bus for KernelEvent traffic (ConfigUpdated, Health, etc.).
    // RO:WHY  — lets admin handlers and supervisor/services communicate without
    //           tight coupling. In this slice we only use it from /reload.
    let bus = NodeBus::new();

    // 7) Build shared application state for HTTP handlers.
    let state = AppState {
        cfg: Arc::new(cfg.clone()),
        probes: probes.clone(),
        bus,
        started_at: Instant::now(),
    };

    // 8) Bind HTTP admin listener.
    let listener = TcpListener::bind(cfg.http_addr).await?;
    probes.set_listeners_bound(true);
    probes.set_cfg_loaded(true);

    let router: Router = http_admin::router::build_router(state);

    info!("macronode admin listening on {}", cfg.http_addr);

    // 9) Run HTTP admin server with graceful shutdown on Ctrl-C.
    let shutdown_signal = async move {
        wait_for_ctrl_c().await;
        info!("macronode: shutdown signal received, draining admin server");
        shutdown_token.trigger();
    };

    if let Err(err) = axum::serve(listener, router)
        .with_graceful_shutdown(shutdown_signal)
        .await
    {
        error!("macronode admin server error: {err}");
    }

    info!("macronode: admin server exited, shutdown complete");

    Ok(())
}

```

### crates/macronode/src/cli/version.rs
<a id="crates-macronode-src-cli-version-rs"></a>

```rust
//! RO:WHAT — Implementation of the `version` subcommand.
//! RO:WHY  — Provide a simple CLI-friendly equivalent to `/version`.

use crate::types::BuildInfo;

/// Print version information to stdout.
///
/// Shape matches the `/version` HTTP payload, minus the API version.
pub fn run() {
    let info = BuildInfo::current();
    println!(
        "service={service} version={version} git_sha={git_sha} build_ts={build_ts} rustc={rustc} msrv={msrv}",
        service = info.service,
        version = info.version,
        git_sha = info.git_sha,
        build_ts = info.build_ts,
        rustc = info.rustc,
        msrv = info.msrv,
    );
}

```

### crates/macronode/src/config/cli_overlay.rs
<a id="crates-macronode-src-config-clioverlay-rs"></a>

```rust
//! RO:WHAT — CLI overlays for Macronode config.
//! RO:WHY  — Let `macronode run` flags override defaults/env in a single place.
//! RO:INVARIANTS —
//!   - Only overrides fields that are explicitly set on `CliOverlay`.
//!   - Never panics on bad input; errors bubble as `Error::Config`.
//!   - If `--http-addr` is set and `--metrics-addr` is not, metrics inherits
//!     the HTTP bind, mirroring the env behavior.

use std::net::SocketAddr;

use crate::errors::{Error, Result};

use super::schema::Config;

/// Minimal set of config fields that can be overridden via CLI.
///
/// This deliberately mirrors the subset of `RunOpts` we support today.
/// We keep it here (in the config module) to avoid a circular dependency
/// on `crate::cli`.
#[derive(Debug, Default, Clone)]
pub struct CliOverlay {
    pub http_addr: Option<String>,
    pub metrics_addr: Option<String>,
    pub log_level: Option<String>,
}

pub fn apply_cli_overlays(mut cfg: Config, overlay: &CliOverlay) -> Result<Config> {
    // HTTP addr override
    if let Some(addr_str) = overlay.http_addr.as_deref() {
        let addr: SocketAddr = addr_str
            .parse()
            .map_err(|e| Error::config(format!("invalid --http-addr {addr_str:?}: {e}")))?;
        cfg.http_addr = addr;

        // If operator set an HTTP override but did not explicitly set a metrics
        // override, keep the "metrics inherits HTTP" invariant.
        if overlay.metrics_addr.is_none() {
            cfg.metrics_addr = addr;
        }
    }

    // Metrics addr override
    if let Some(addr_str) = overlay.metrics_addr.as_deref() {
        let addr: SocketAddr = addr_str
            .parse()
            .map_err(|e| Error::config(format!("invalid --metrics-addr {addr_str:?}: {e}")))?;
        cfg.metrics_addr = addr;
    }

    // Log level override
    if let Some(level) = overlay.log_level.as_ref() {
        if !level.trim().is_empty() {
            cfg.log_level = level.clone();
        }
    }

    Ok(cfg)
}

```

### crates/macronode/src/config/env_overlay.rs
<a id="crates-macronode-src-config-envoverlay-rs"></a>

```rust
//! RO:WHAT — Environment overlays for Macronode config.
//! RO:WHY  — Separate side-effectful env reading from pure config logic.
//! RO:INVARIANTS —
//!   - Never panics on bad env; all issues bubble as `Error::Config`.
//!   - Aliases `MACRO_*` are supported for one minor with a warning.
//!   - `metrics_addr` inherits `http_addr` when no explicit metrics env is set.

use std::{env, net::SocketAddr};

use humantime::parse_duration;

use crate::errors::{Error, Result};

use super::schema::Config;

/// Apply environment-based overlays to a `Config` value.
///
/// Supported env vars:
///   - `RON_HTTP_ADDR` / `MACRO_HTTP_ADDR`
///   - `RON_METRICS_ADDR` / `MACRO_METRICS_ADDR`
///   - `RON_LOG`
///   - `RON_READ_TIMEOUT` / `MACRO_READ_TIMEOUT`
///   - `RON_WRITE_TIMEOUT` / `MACRO_WRITE_TIMEOUT`
///   - `RON_IDLE_TIMEOUT` / `MACRO_IDLE_TIMEOUT`
pub fn apply_env_overlays(mut cfg: Config) -> Result<Config> {
    let mut metrics_overridden = false;

    // Metrics addr — may override HTTP if explicitly set.
    if let Some(val) = first_of(&["RON_METRICS_ADDR", "MACRO_METRICS_ADDR"]) {
        let addr: SocketAddr = val
            .parse()
            .map_err(|e| Error::config(format!("invalid metrics addr {val:?}: {e}")))?;
        cfg.metrics_addr = addr;
        metrics_overridden = true;
    }

    // HTTP addr — if set and metrics were not explicitly overridden, we keep
    // the invariant that metrics inherits HTTP by default.
    if let Some(val) = first_of(&["RON_HTTP_ADDR", "MACRO_HTTP_ADDR"]) {
        let addr: SocketAddr = val
            .parse()
            .map_err(|e| Error::config(format!("invalid HTTP addr {val:?}: {e}")))?;
        cfg.http_addr = addr;
        if !metrics_overridden {
            cfg.metrics_addr = addr;
        }
    }

    // Log level
    if let Ok(val) = env::var("RON_LOG") {
        if !val.trim().is_empty() {
            cfg.log_level = val;
        }
    }

    // Timeouts
    if let Some(val) = first_of(&["RON_READ_TIMEOUT", "MACRO_READ_TIMEOUT"]) {
        cfg.read_timeout = parse_duration_checked("read_timeout", &val)?;
    }

    if let Some(val) = first_of(&["RON_WRITE_TIMEOUT", "MACRO_WRITE_TIMEOUT"]) {
        cfg.write_timeout = parse_duration_checked("write_timeout", &val)?;
    }

    if let Some(val) = first_of(&["RON_IDLE_TIMEOUT", "MACRO_IDLE_TIMEOUT"]) {
        cfg.idle_timeout = parse_duration_checked("idle_timeout", &val)?;
    }

    Ok(cfg)
}

fn first_of(keys: &[&str]) -> Option<String> {
    for key in keys {
        if let Ok(v) = env::var(key) {
            if !v.trim().is_empty() {
                if key.starts_with("MACRO_") {
                    eprintln!(
                        "[macronode-config] WARNING: {key} is deprecated; \
                         prefer the RON_* variant instead."
                    );
                }
                return Some(v);
            }
        }
    }
    None
}

fn parse_duration_checked(field: &str, input: &str) -> Result<std::time::Duration> {
    parse_duration(input).map_err(|e| {
        Error::config(format!(
            "invalid duration for {field}: {input:?} ({e}) \
             — expected forms like \"10s\", \"500ms\", \"1m\""
        ))
    })
}

```

### crates/macronode/src/config/hot_reload.rs
<a id="crates-macronode-src-config-hotreload-rs"></a>

```rust
//! RO:WHAT — Config hot-reload stub.
//! RO:WHY  — `/api/v1/reload` calls this; later it will re-read config file/env.
//!
//! RO:INVARIANTS —
//!   - Non-blocking.
//!   - Does *not* mutate live config yet (will be replaced when we wire reload).

use crate::config::schema::Config;
use tracing::info;

pub fn hot_reload(_cfg: &Config) -> Result<(), String> {
    info!("macronode config hot_reload(): stub (no-op)");
    Ok(())
}

```

### crates/macronode/src/config/load.rs
<a id="crates-macronode-src-config-load-rs"></a>

```rust
//! RO:WHAT — Config load pipeline for Macronode.
//! RO:WHY  — Centralize config loading so CLI and runtime share precedence,
//!           env overlays, and validation.
//! RO:INVARIANTS —
//!   - Always start from `Config::default()`.
//!   - Precedence for config sources:
//!       1) Defaults
//!       2) Optional file from CLI `--config` or env (`RON_CONFIG` / `MACRO_CONFIG`)
//!       3) Env overlays (`RON_*` + `MACRO_*` aliases)
//!   - Validation always runs before returning a config to callers.
//!
//! RO:CONFIG SOURCES —
//!   - `--config PATH` (CLI) has highest precedence for the file path.
//!   - If no CLI path is supplied, `RON_CONFIG` is honored.
//!   - `MACRO_CONFIG` is accepted for one minor with a warning.

use std::{env, fs, path::Path};

use crate::errors::{Error, Result};

use super::{env_overlay::apply_env_overlays, schema::Config, validate::validate_config};

/// Load config using defaults + **optional file from env** + env overlays.
///
/// This is what non-`run` CLI commands (`check`, `config print`,
/// `config validate`) use: they do not accept `--config` themselves, but
/// operators can still provide a file via `RON_CONFIG`/`MACRO_CONFIG`.
pub fn load_config() -> Result<Config> {
    load_effective_config(None)
}

/// Load config using an explicit file path (if provided), then env overlays.
///
/// This is the low-level helper used by the higher-level
/// `load_effective_config`. Precedence inside this function is:
///
///   1) `Config::default()`
///   2) Optional file (if `file_path` is `Some(_)`)
///   3) Env overlays
///
/// Validation is always run before the config is returned.
pub fn load_config_with_file(file_path: Option<&str>) -> Result<Config> {
    let mut cfg = Config::default();

    if let Some(path) = file_path {
        let path = Path::new(path);
        cfg = load_from_file(path)?;
    }

    let cfg = apply_env_overlays(cfg)?;
    validate_config(&cfg)?;
    Ok(cfg)
}

/// Load the **effective** config, combining CLI and env-level file paths.
///
/// Precedence for the config *file path* is:
///
///   1) CLI `--config PATH` (if supplied)
///   2) `RON_CONFIG` (if set and non-empty)
///   3) `MACRO_CONFIG` (deprecated alias; emits a warning)
///
/// After the file (if any) is applied, env overlays and validation are run.
pub fn load_effective_config(cli_file_path: Option<&str>) -> Result<Config> {
    let chosen_path = match cli_file_path {
        Some(p) => Some(p.to_string()),
        None => env_config_path(),
    };

    load_config_with_file(chosen_path.as_deref())
}

/// Discover a config file path from env (`RON_CONFIG` / `MACRO_CONFIG`).
///
/// Returns `Some(path)` if a non-empty value is found, otherwise `None`.
fn env_config_path() -> Option<String> {
    if let Ok(val) = env::var("RON_CONFIG") {
        let trimmed = val.trim();
        if !trimmed.is_empty() {
            return Some(trimmed.to_owned());
        }
    }

    // Temporary compatibility alias for older docs/scripts.
    if let Ok(val) = env::var("MACRO_CONFIG") {
        let trimmed = val.trim();
        if !trimmed.is_empty() {
            eprintln!(
                "macronode: MACRO_CONFIG is deprecated; prefer RON_CONFIG for config file path"
            );
            return Some(trimmed.to_owned());
        }
    }

    None
}

/// Load a `Config` from a TOML or JSON file.
///
/// - If the extension is `.toml`, parse as TOML.
/// - If the extension is `.json`, parse as JSON.
/// - Otherwise, try TOML first, then JSON, and include both errors on failure.
fn load_from_file(path: &Path) -> Result<Config> {
    let raw = fs::read_to_string(path).map_err(|e| {
        Error::config(format!(
            "failed to read config file {}: {e}",
            path.display()
        ))
    })?;

    let ext = path
        .extension()
        .and_then(|s| s.to_str())
        .map(|s| s.to_ascii_lowercase())
        .unwrap_or_default();

    let parsed: Result<Config> = match ext.as_str() {
        "toml" => toml::from_str(&raw).map_err(|e| {
            Error::config(format!(
                "failed to parse TOML config {}: {e}",
                path.display()
            ))
        }),
        "json" => serde_json::from_str(&raw).map_err(|e| {
            Error::config(format!(
                "failed to parse JSON config {}: {e}",
                path.display()
            ))
        }),
        _ => {
            // Unknown extension: try TOML first, then JSON, and include both errors.
            let toml_err = toml::from_str::<Config>(&raw).map_err(|e| e.to_string());
            match toml_err {
                Ok(cfg) => Ok(cfg),
                Err(t_err) => {
                    let json_err = serde_json::from_str::<Config>(&raw).map_err(|e| e.to_string());
                    match json_err {
                        Ok(cfg) => Ok(cfg),
                        Err(j_err) => Err(Error::config(format!(
                            "failed to parse config {} as TOML or JSON:\n  TOML error: {t_err}\n  JSON error: {j_err}",
                            path.display()
                        ))),
                    }
                }
            }
        }
    };

    parsed
}

```

### crates/macronode/src/config/mod.rs
<a id="crates-macronode-src-config-mod-rs"></a>

```rust
//! RO:WHAT — Config module root for Macronode.
//! RO:WHY  — Centralize schema + loaders (env/file/CLI overlays).
//! RO:INVARIANTS —
//!   - `Config` is the single source of truth for runtime settings.
//!   - Callers use `load_config()` or `load_effective_config()`; no ad-hoc
//!     env/file access sprinkled around the crate.

pub mod cli_overlay;
pub mod env_overlay;
pub mod hot_reload;
pub mod load;
pub mod schema;
pub mod validate;

// Public facade:
// - `Config` type
// - `load_config()` for non-run CLI commands (env + optional file)
// - `load_effective_config()` for `run` (CLI --config + env)
// - `hot_reload()` used by `/api/v1/reload` handler.
pub use hot_reload::hot_reload;
pub use load::{load_config, load_effective_config};
pub use schema::Config;

```

### crates/macronode/src/config/schema.rs
<a id="crates-macronode-src-config-schema-rs"></a>

```rust
//! RO:WHAT — Minimal config schema for Macronode.
//! RO:WHY  — Bind HTTP admin, metrics, timeouts, and log level with sane
//!           defaults.
//! RO:INTERACTS —
//!   - Loaded via `config::load_config()` / `load_config_with_file()`.
//!   - Passed into runtime state and admin HTTP stack.

use serde::{Deserialize, Serialize};
use std::{net::SocketAddr, time::Duration};

fn default_http_addr() -> SocketAddr {
    "127.0.0.1:8080"
        .parse()
        .expect("default 127.0.0.1:8080 must parse")
}

fn default_metrics_addr() -> SocketAddr {
    // By default we bind metrics on the same address as the admin HTTP plane.
    default_http_addr()
}

fn default_log_level() -> String {
    "info".to_string()
}

fn default_read_timeout() -> Duration {
    Duration::from_secs(10)
}

fn default_write_timeout() -> Duration {
    Duration::from_secs(10)
}

fn default_idle_timeout() -> Duration {
    Duration::from_secs(60)
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(default)]
pub struct Config {
    /// HTTP admin bind address (`RON_HTTP_ADDR` / `MACRO_HTTP_ADDR`).
    #[serde(default = "default_http_addr")]
    pub http_addr: SocketAddr,

    /// Metrics bind address (`RON_METRICS_ADDR` / `MACRO_METRICS_ADDR`).
    ///
    /// Invariants:
    ///   - Defaults to the same value as `http_addr`.
    ///   - Env/CLI overlays may override it independently.
    #[serde(default = "default_metrics_addr")]
    pub metrics_addr: SocketAddr,

    /// Log level (fan-out via `RUST_LOG` env in logging bootstrap).
    #[serde(default = "default_log_level")]
    pub log_level: String,

    /// HTTP read timeout.
    ///
    /// File-config form uses humantime strings like `"5s"`, `"500ms"`, `"1m"`.
    /// Env overlay still respects `RON_READ_TIMEOUT` / `MACRO_READ_TIMEOUT`
    /// with the same humantime semantics.
    #[serde(default = "default_read_timeout", with = "humantime_serde")]
    pub read_timeout: Duration,

    /// HTTP write timeout.
    #[serde(default = "default_write_timeout", with = "humantime_serde")]
    pub write_timeout: Duration,

    /// HTTP idle timeout.
    #[serde(default = "default_idle_timeout", with = "humantime_serde")]
    pub idle_timeout: Duration,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            http_addr: default_http_addr(),
            metrics_addr: default_metrics_addr(),
            log_level: default_log_level(),
            read_timeout: default_read_timeout(),
            write_timeout: default_write_timeout(),
            idle_timeout: default_idle_timeout(),
        }
    }
}

```

### crates/macronode/src/config/validate.rs
<a id="crates-macronode-src-config-validate-rs"></a>

```rust
//! RO:WHAT — Config validation for Macronode.
//! RO:WHY  — Centralize invariants (ports, timeouts, limits) so we can
//!           evolve them without touching callers.
//! RO:INVARIANTS —
//!   - All durations must be > 0.
//!   - HTTP addr must be a valid SocketAddr (already enforced earlier).

use crate::errors::{Error, Result};

use super::schema::Config;

/// Validate a fully materialized config.
///
/// Returns `Ok(())` if the config is usable, or `Error::Config` with a
/// human-readable message if any invariant is violated.
pub fn validate_config(cfg: &Config) -> Result<()> {
    if cfg.read_timeout.as_millis() == 0 {
        return Err(Error::config("read_timeout must be > 0"));
    }
    if cfg.write_timeout.as_millis() == 0 {
        return Err(Error::config("write_timeout must be > 0"));
    }
    if cfg.idle_timeout.as_millis() == 0 {
        return Err(Error::config("idle_timeout must be > 0"));
    }

    Ok(())
}

```

### crates/macronode/src/errors.rs
<a id="crates-macronode-src-errors-rs"></a>

```rust
//! RO:WHAT — Error type and Result alias for Macronode.
//! RO:WHY  — Keep error plumbing boring and consistent across modules.
//! RO:INVARIANTS —
//!   - All fallible public fns in this crate return `errors::Result<T>`.
//!   - Config parsing collapses to `Error::Config` with human-readable messages.

use thiserror::Error;

/// Crate-local Result alias.
pub type Result<T> = std::result::Result<T, Error>;

#[derive(Debug, Error)]
pub enum Error {
    /// Configuration issues (env/file/cli overlays).
    #[error("config error: {0}")]
    Config(String),

    /// I/O errors (sockets, files, etc.).
    #[error(transparent)]
    Io(#[from] std::io::Error),

    /// JSON serialization / formatting issues.
    #[error(transparent)]
    SerdeJson(#[from] serde_json::Error),

    /// Catch-all for higher level composition until we tighten types.
    #[error(transparent)]
    Other(#[from] anyhow::Error),
}

impl Error {
    pub fn config<S: Into<String>>(msg: S) -> Self {
        Error::Config(msg.into())
    }
}

```

### crates/macronode/src/facets/mod.rs
<a id="crates-macronode-src-facets-mod-rs"></a>

```rust
// crates/macronode/src/facets/mod.rs

//! RO:WHAT — Facet helpers for Macronode (permits, quotas, etc.).
//! RO:WHY  — Provide a small, crate-local façade around admission/quotas so
//!           higher layers can talk in terms of `PermitRequest` / `QuotaRequest`
//!           without depending on the eventual policy engine wiring.
//!
//! RO:INVARIANTS —
//!   - This module is intentionally tiny and mostly type re-exports.
//!   - It is OK for these types to be "unused" inside this crate for now;
//!     they are part of the public surface we are shaping for future use.
//!   - No I/O, no global state: pure data types and helpers only.
//!
//! RO:STATUS —
//!   - `permits` and `quotas` are currently simple data containers.
//!   - Enforcement is NOT yet wired into admin handlers or services; that
//!     will come when we introduce real admission control.

// These re-exports are part of the shaped API surface for macronode, and
// clippy will flag them as "unused" until we start plumbing them through
// the admin handlers and services. We explicitly allow that here so
// `cargo clippy -D warnings` stays green during the incremental build.
#![allow(unused_imports)]

pub mod permits;
pub mod quotas;

// Re-export the core facet types so callers can use
// `macronode::facets::{PermitRequest, PermitDecision, ...}`.
pub use permits::{PermitDecision, PermitKind, PermitRequest};
pub use quotas::{QuotaDecision, QuotaKey, QuotaRequest, QuotaWindow};

```

### crates/macronode/src/facets/permits.rs
<a id="crates-macronode-src-facets-permits-rs"></a>

```rust
//! RO:WHAT — Permit vocabulary for Macronode admission control.
//! RO:WHY  — Give us a tiny, crate-local language for “may this caller do
//!           X?” without committing to any particular policy backend.
//!
//! RO:INVARIANTS —
//!   - Pure data types; no I/O, no global state.
//!   - Safe to round-trip through JSON/TOML if needed later.

#![allow(dead_code)]

/// Coarse-grained operation the caller is attempting.
///
/// This is intentionally small and MACRO-local; richer detail belongs in
/// the policy layer (e.g. ron-policy, auth/kms services).
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PermitKind {
    /// POST /api/v1/shutdown on the admin plane.
    AdminShutdown,
    /// POST /api/v1/reload on the admin plane.
    AdminReload,
    /// Inbound request on the gateway plane (svc-gateway).
    GatewayIngress,
    /// Read from storage plane (svc-storage).
    StorageRead,
    /// Write to storage plane (svc-storage).
    StorageWrite,
    /// Delete from storage plane (svc-storage).
    StorageDelete,
    /// Catch-all hook for future callers (feature flags, experiements).
    Custom(&'static str),
}

/// Minimal request context passed to a permit evaluator.
///
/// Foundation cut keeps this tiny. Higher layers can wrap this with richer
/// context (capability tokens, tenant IDs, paths, etc.) as needed.
#[derive(Debug, Clone)]
pub struct PermitRequest {
    /// Which logical operation is being attempted.
    pub kind: PermitKind,
    /// Optional identity for the caller (e.g. tenant/user ID).
    pub subject: Option<String>,
    /// Optional opaque capability/macaroon token (already parsed at edges).
    pub capability: Option<String>,
    /// Optional resource hint (e.g. HTTP path, bucket name).
    pub resource: Option<String>,
}

impl PermitRequest {
    #[must_use]
    pub fn new(kind: PermitKind) -> Self {
        Self {
            kind,
            subject: None,
            capability: None,
            resource: None,
        }
    }

    #[must_use]
    pub fn with_subject<S: Into<String>>(mut self, subject: S) -> Self {
        self.subject = Some(subject.into());
        self
    }

    #[must_use]
    pub fn with_capability<S: Into<String>>(mut self, cap: S) -> Self {
        self.capability = Some(cap.into());
        self
    }

    #[must_use]
    pub fn with_resource<S: Into<String>>(mut self, res: S) -> Self {
        self.resource = Some(res.into());
        self
    }
}

/// Result of a permit check.
///
/// This remains deliberately simple; a future slice could add structured
/// denial reasons or audit codes.
#[derive(Debug, Clone)]
pub enum PermitDecision {
    /// Operation is allowed to proceed.
    Allow,
    /// Operation is denied, with a human-readable reason.
    Deny { reason: String },
}

impl PermitDecision {
    /// Convenience helper to construct a denial.
    #[must_use]
    pub fn deny<S: Into<String>>(reason: S) -> Self {
        PermitDecision::Deny {
            reason: reason.into(),
        }
    }

    /// Returns true if the decision is an allow.
    #[must_use]
    pub const fn is_allowed(&self) -> bool {
        matches!(self, PermitDecision::Allow)
    }
}

```

### crates/macronode/src/facets/quotas.rs
<a id="crates-macronode-src-facets-quotas-rs"></a>

```rust
//! RO:WHAT — Quota vocabulary for Macronode admission control.
//! RO:WHY  — Provide a tiny, MACRO-local language for “how much is this
//!           caller allowed to do?” (rate limits, burst windows, etc.).
//!
//! RO:STATUS —
//!   - Foundation slice: pure types only, no counters or storage.
//!   - Evaluation engine will live alongside policy/registry later.
//!
//! RO:INVARIANTS —
//!   - All types are small and clone-friendly.
//!   - No direct dependency on any particular metrics or storage backend.

#![allow(dead_code)]

use std::time::Duration;

/// Logical window over which a quota applies.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum QuotaWindow {
    PerSecond,
    PerMinute,
    PerHour,
    PerDay,
    /// Custom-sized window for future extensions.
    Custom(Duration),
}

/// Stable key identifying a quota bucket.
///
/// Typical examples:
///   - subject = "tenant:abc", category = "gateway-requests"
///   - subject = "ip:203.0.113.1", category = "admin-shutdown"
#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord)]
pub struct QuotaKey {
    /// Entity being limited (user/tenant/IP/etc.).
    pub subject: String,
    /// Logical category (gateway, admin, storage, etc.).
    pub category: String,
}

impl QuotaKey {
    #[must_use]
    pub fn new<S: Into<String>, C: Into<String>>(subject: S, category: C) -> Self {
        Self {
            subject: subject.into(),
            category: category.into(),
        }
    }
}

/// Request to consume some quota from a bucket.
#[derive(Debug, Clone)]
pub struct QuotaRequest {
    /// Which bucket to charge.
    pub key: QuotaKey,
    /// How large this operation is, in arbitrary units (e.g. “1 request” or
    /// “N bytes”). Interpretation is up to the evaluator.
    pub cost: u64,
    /// Window the quota is evaluated over.
    pub window: QuotaWindow,
}

impl QuotaRequest {
    #[must_use]
    pub fn new(key: QuotaKey, cost: u64, window: QuotaWindow) -> Self {
        Self { key, cost, window }
    }
}

/// Result of a quota evaluation.
#[derive(Debug, Clone)]
pub enum QuotaDecision {
    /// Operation may proceed; remaining is a best-effort hint.
    Allow { remaining: Option<u64> },
    /// Operation is over quota; `retry_after` suggests when to try again.
    Deny { retry_after: Option<Duration> },
}

impl QuotaDecision {
    /// Returns true if this operation is allowed.
    #[must_use]
    pub const fn is_allowed(&self) -> bool {
        matches!(self, QuotaDecision::Allow { .. })
    }
}

```

### crates/macronode/src/http_admin/handlers/healthz.rs
<a id="crates-macronode-src-httpadmin-handlers-healthz-rs"></a>

```rust
//! RO:WHAT — `/healthz` liveness handler.
//! RO:WHY  — Simple "is the process alive" probe.

use axum::{response::IntoResponse, Json};
use serde::Serialize;

#[derive(Serialize)]
struct Checks<'a> {
    event_loop: &'a str,
    clock: &'a str,
}

#[derive(Serialize)]
struct HealthBody<'a> {
    ok: bool,
    checks: Checks<'a>,
}

pub async fn handler() -> impl IntoResponse {
    let checks = Checks {
        event_loop: "ok",
        clock: "ok",
    };

    Json(HealthBody { ok: true, checks })
}

```

### crates/macronode/src/http_admin/handlers/metrics.rs
<a id="crates-macronode-src-httpadmin-handlers-metrics-rs"></a>

```rust
//! RO:WHAT — `/metrics` handler (Prometheus text).
//! RO:WHY  — Single scrape surface for admin metrics.

use crate::observability::metrics::encode_prometheus;
use axum::{http::StatusCode, response::IntoResponse};

pub async fn handler() -> impl IntoResponse {
    let body = encode_prometheus();
    (StatusCode::OK, body)
}

```

### crates/macronode/src/http_admin/handlers/mod.rs
<a id="crates-macronode-src-httpadmin-handlers-mod-rs"></a>

```rust
//! RO:WHAT — Admin HTTP handlers for Macronode.

pub mod healthz;
pub mod metrics;
pub mod reload;
pub mod shutdown;
pub mod status;
pub mod version;

```

### crates/macronode/src/http_admin/handlers/readyz.rs
<a id="crates-macronode-src-httpadmin-handlers-readyz-rs"></a>

```rust
//! RO:WHAT — Axum adapter for `/readyz`.
//! RO:WHY  — Delegate to `readiness::handler` with shared probes.

use std::sync::Arc;

use axum::response::IntoResponse;

use crate::readiness::{self, ReadyProbes};

pub async fn handler(probes: Arc<ReadyProbes>) -> impl IntoResponse {
    readiness::handler(probes).await
}

```

### crates/macronode/src/http_admin/handlers/reload.rs
<a id="crates-macronode-src-httpadmin-handlers-reload-rs"></a>

```rust
//! RO:WHAT — `/api/v1/reload` handler.
//! RO:WHY  — Trigger config hot reload (stub v1) and emit a bus event.
//!
//! RO:INVARIANTS —
//!   - Must run under admin auth middleware.
//!   - Uses `config::hot_reload()` (stub for now).
//!   - Async safe; returns 202-style semantics (we currently reply 200 OK).

use axum::{response::IntoResponse, Json};
use serde::Serialize;
use tracing::info;

use crate::{bus::NodeEvent, config, types::AppState};

#[derive(Serialize)]
struct ReloadResp {
    status: &'static str,
}

pub async fn handler(
    axum::extract::State(state): axum::extract::State<AppState>,
) -> impl IntoResponse {
    info!("macronode admin: reload requested");

    // Call into our stub for now — later will reload config + emit events.
    if let Err(e) = config::hot_reload(&state.cfg) {
        info!("macronode admin: reload failed: {e}");
    }

    // Emit a ConfigUpdated event on the intra-node bus.
    //
    // NOTE: Version is currently stubbed as 0. Once we track config epochs
    // or generation IDs, this should carry the real version.
    if let Err(send_err) = state.bus.publish(NodeEvent::ConfigUpdated { version: 0 }) {
        info!("macronode admin: failed to publish ConfigUpdated event on bus: {send_err:?}");
    }

    Json(ReloadResp {
        status: "reload triggered",
    })
}

```

### crates/macronode/src/http_admin/handlers/shutdown.rs
<a id="crates-macronode-src-httpadmin-handlers-shutdown-rs"></a>

```rust
//! RO:WHAT — `/api/v1/shutdown` handler.
//! RO:WHY  — Allow operators to trigger a controlled process exit via HTTP.
//!           MVP: respond 202, then exit the process after a short delay so
//!           callers see a clean response before shutdown completes.

use std::time::Duration;

use axum::{http::StatusCode, response::IntoResponse, Json};
use serde::Serialize;
use tokio::time::sleep;
use tracing::info;

#[derive(Serialize)]
struct ShutdownBody<'a> {
    status: &'a str,
    delay_ms: u64,
}

/// POST `/api/v1/shutdown`
///
/// Semantics (MVP):
/// - Immediately returns `202 Accepted` with a small JSON payload.
/// - In the background, waits for a short delay and then calls `std::process::exit(0)`.
/// - This is a coarse, process-wide shutdown; we will replace this with
///   proper supervisor-driven graceful shutdown in a later pass.
pub async fn handler() -> impl IntoResponse {
    let delay_ms: u64 = 500;

    // Fire-and-forget task that will terminate the process shortly after
    // the HTTP response has been sent.
    tokio::spawn(async move {
        info!(
            "macronode admin: /api/v1/shutdown requested; exiting in {} ms",
            delay_ms
        );
        sleep(Duration::from_millis(delay_ms)).await;

        // NOTE: This is intentionally blunt for the first pass. A later
        // revision will coordinate shutdown through the supervisor so
        // services can drain gracefully.
        std::process::exit(0);
    });

    (
        StatusCode::ACCEPTED,
        Json(ShutdownBody {
            status: "shutdown scheduled",
            delay_ms,
        }),
    )
}

```

### crates/macronode/src/http_admin/handlers/status.rs
<a id="crates-macronode-src-httpadmin-handlers-status-rs"></a>

```rust
//! RO:WHAT — `/api/v1/status` handler.
//! RO:WHY  — Give operators a basic runtime + readiness + service snapshot
//!           in one call.
//!
//! RO:INTERACTS —
//!   - Uses `AppState` for config + probes + start time.
//!   - Reuses the same readiness logic as `/readyz` via `ReadyProbes::snapshot()`.
//!
//! RO:INVARIANTS —
//!   - `ready` field matches the `required_ready()` gate used by `/readyz`.
//!   - `deps` mirrors the `/readyz` dependency labels (config/network/gateway/storage).
//!   - `services` is a low-cardinality map of core services macronode supervises.
//!   - No blocking I/O; cheap and safe to call frequently.

use std::{collections::BTreeMap, time::Instant};

use axum::{response::IntoResponse, Json};
use serde::Serialize;

use crate::{observability::metrics::update_macronode_metrics, types::AppState};

#[derive(Serialize)]
struct StatusDeps {
    config: &'static str,
    network: &'static str,
    gateway: &'static str,
    storage: &'static str,
}

#[derive(Serialize)]
struct StatusBody {
    /// Seconds since this macronode process started.
    uptime_seconds: u64,
    /// Profile name for this node (always "macronode" for this crate).
    profile: &'static str,
    /// Admin HTTP bind address (where `/healthz`/`/readyz`/`/metrics` live).
    http_addr: String,
    /// Metrics bind address (currently shares the admin listener, but kept
    /// separate at the config level for future slices).
    metrics_addr: String,
    /// Effective log level for this process.
    log_level: String,
    /// Whether the node considers itself "ready" according to the same
    /// gates used by `/readyz`.
    ready: bool,
    /// Per-dependency status, mirroring `/readyz`.
    deps: StatusDeps,
    /// Per-service summary.
    ///
    /// Keys:
    ///   - "svc-gateway"
    ///   - "svc-storage"
    ///   - "svc-index"
    ///   - "svc-mailbox"
    ///   - "svc-overlay"
    ///   - "svc-dht"
    ///
    /// Values are simple strings for now:
    ///   - "ok"      — service is bound and reported healthy/coarse-ok.
    ///   - "pending" — service has not yet met its readiness condition.
    ///   - "stub"    — service is a placeholder worker without real health.
    services: BTreeMap<String, String>,
}

pub async fn handler(state: axum::extract::State<AppState>) -> impl IntoResponse {
    let AppState {
        cfg,
        probes,
        started_at,
        ..
    } = state.0;

    let uptime = Instant::now()
        .saturating_duration_since(started_at)
        .as_secs();

    let snap = probes.snapshot();
    let ready = snap.required_ready();

    // Keep metrics in sync with what we present via status.
    update_macronode_metrics(uptime, ready);

    let deps = StatusDeps {
        config: if snap.cfg_loaded { "loaded" } else { "pending" },
        network: if snap.listeners_bound {
            "ok"
        } else {
            "pending"
        },
        gateway: if snap.gateway_bound { "ok" } else { "pending" },
        // Today deps_ok flips true once gateway + storage + index workers are spawned.
        storage: if snap.deps_ok { "ok" } else { "pending" },
    };

    let mut services = BTreeMap::new();

    // Gateway: real listener + readiness bit.
    services.insert(
        "svc-gateway".to_string(),
        if snap.gateway_bound { "ok" } else { "pending" }.to_string(),
    );

    // Storage + index: now real embedded HTTP services; we treat them as "ok"
    // once deps_ok is true (spawn_all() only flips this after wiring them).
    let deps_status = if snap.deps_ok { "ok" } else { "pending" };

    services.insert("svc-storage".to_string(), deps_status.to_string());
    services.insert("svc-index".to_string(), deps_status.to_string());

    // Remaining services are still stub workers in this slice.
    services.insert("svc-mailbox".to_string(), "stub".to_string());
    services.insert("svc-overlay".to_string(), "stub".to_string());
    services.insert("svc-dht".to_string(), "stub".to_string());

    Json(StatusBody {
        uptime_seconds: uptime,
        profile: "macronode",
        http_addr: cfg.http_addr.to_string(),
        metrics_addr: cfg.metrics_addr.to_string(),
        log_level: cfg.log_level.clone(),
        ready,
        deps,
        services,
    })
}

```

### crates/macronode/src/http_admin/handlers/version.rs
<a id="crates-macronode-src-httpadmin-handlers-version-rs"></a>

```rust
//! RO:WHAT — `/version` handler for Macronode.
//! RO:WHY  — Provide build provenance and HTTP API version.

use axum::{response::IntoResponse, Json};
use serde::Serialize;

use crate::types::BuildInfo;

#[derive(Serialize)]
struct ApiInfo<'a> {
    http: &'a str,
}

#[derive(Serialize)]
struct VersionBody<'a> {
    service: &'a str,
    version: &'a str,
    git_sha: &'a str,
    build_ts: &'a str,
    rustc: &'a str,
    msrv: &'a str,
    api: ApiInfo<'a>,
}

pub async fn handler() -> impl IntoResponse {
    let info = BuildInfo::current();

    let body = VersionBody {
        service: info.service,
        version: info.version,
        git_sha: info.git_sha,
        build_ts: info.build_ts,
        rustc: info.rustc,
        msrv: info.msrv,
        api: ApiInfo { http: "v1" },
    };

    Json(body)
}

```

### crates/macronode/src/http_admin/middleware/auth.rs
<a id="crates-macronode-src-httpadmin-middleware-auth-rs"></a>

```rust
//! RO:WHAT — Admin auth middleware.
//! RO:WHY  — Guard sensitive POST endpoints (`/api/v1/shutdown`, `/api/v1/reload`).
//!
//! RO:INVARIANTS —
//!   - If `RON_ADMIN_TOKEN` is set, sensitive endpoints require
//!     `Authorization: Bearer <token>`.
//!   - If bound to loopback AND no token is set, we ALLOW but WARN.
//!   - If bound to NON-loopback AND no token is set, we BLOCK unless
//!     `MACRONODE_DEV_INSECURE=1`.
//!   - `MACRONODE_DEV_INSECURE=1` bypasses everything (dev ergonomics).

use axum::{
    body::Body,
    http::{header::AUTHORIZATION, Method, Request, StatusCode},
    middleware::Next,
    response::Response,
};
use std::net::IpAddr;
use tracing::{info, warn};

pub async fn layer(req: Request<Body>, next: Next) -> Result<Response, StatusCode> {
    // Only guard POST /shutdown & POST /reload
    let method = req.method().clone();
    let path = req.uri().path().to_string();

    let needs_guard =
        method == Method::POST && (path == "/api/v1/shutdown" || path == "/api/v1/reload");

    if !needs_guard {
        return Ok(next.run(req).await);
    }

    // Explicit dev bypass
    if dev_insecure() {
        warn!("MACRONODE_DEV_INSECURE=1 — bypassing admin auth for {method} {path}");
        return Ok(next.run(req).await);
    }

    // Determine if the admin listener is loopback-only
    let is_loopback = match req.headers().get("host").and_then(|h| h.to_str().ok()) {
        Some(host) => host
            .parse::<IpAddr>()
            .map(|ip| ip.is_loopback())
            .unwrap_or(true),
        None => true,
    };

    // Determine token
    let expected_token = std::env::var("RON_ADMIN_TOKEN")
        .ok()
        .filter(|t| !t.is_empty());

    match expected_token {
        Some(expected) => {
            // Token required — validate header
            let auth_header = req
                .headers()
                .get(AUTHORIZATION)
                .and_then(|h| h.to_str().ok());

            let ok = auth_header
                .and_then(|v| v.strip_prefix("Bearer "))
                .map(|v| v == expected)
                .unwrap_or(false);

            if !ok {
                warn!("unauthorized {method} {path} — missing/invalid token");
                return Err(StatusCode::UNAUTHORIZED);
            }

            info!("authorized admin {method} {path}");
            Ok(next.run(req).await)
        }

        None => {
            // No token set
            if is_loopback {
                warn!("RON_ADMIN_TOKEN is not set — allowing admin action on loopback {method} {path}");
                Ok(next.run(req).await)
            } else {
                warn!("BLOCKED admin action — RON_ADMIN_TOKEN missing + non-loopback bind {method} {path}");
                Err(StatusCode::UNAUTHORIZED)
            }
        }
    }
}

fn dev_insecure() -> bool {
    matches!(
        std::env::var("MACRONODE_DEV_INSECURE").as_deref(),
        Ok("1") | Ok("true") | Ok("TRUE") | Ok("on") | Ok("ON")
    )
}

```

### crates/macronode/src/http_admin/middleware/mod.rs
<a id="crates-macronode-src-httpadmin-middleware-mod-rs"></a>

```rust
//! RO:WHAT — Admin HTTP middleware for Macronode.
//! RO:WHY  — Cross-cutting behaviors around the admin router.
//!
//! RO:INVARIANTS —
//!   - Middlewares are pure functions over `Request<Body>` and `Next`.
//!   - No panics on malformed headers; we fail closed where appropriate.
//!   - Admin auth is opt-in via `RON_ADMIN_TOKEN` but loudly logs when unset.

pub mod auth;
pub mod rate_limit;
pub mod request_id;
pub mod timeout;

```

### crates/macronode/src/http_admin/middleware/rate_limit.rs
<a id="crates-macronode-src-httpadmin-middleware-ratelimit-rs"></a>

```rust
//! RO:WHAT — Rate limiting middleware (placeholder).
//! RO:WHY  — Anchor point for future per-endpoint throttling.
//!
//! RO:INVARIANTS —
//!   - Currently a no-op pass-through.
//!   - Safe to extend later with token buckets / IP-based limits.

use axum::{
    body::Body,
    http::{Request, StatusCode},
    middleware::Next,
    response::Response,
};

pub async fn layer(req: Request<Body>, next: Next) -> Result<Response, StatusCode> {
    // TODO: Implement per-endpoint/IP rate limiting once we have config knobs.
    Ok(next.run(req).await)
}

```

### crates/macronode/src/http_admin/middleware/request_id.rs
<a id="crates-macronode-src-httpadmin-middleware-requestid-rs"></a>

```rust
//! RO:WHAT — X-Request-Id middleware.
//! RO:WHY  — Give every request/response a stable request ID for tracing.
//!
//! RO:INVARIANTS —
//!   - If the client sends `x-request-id`, we preserve it.
//!   - Otherwise we generate a simple process-unique ID.

use std::time::{SystemTime, UNIX_EPOCH};

use axum::{
    body::Body,
    http::{header::HeaderName, HeaderValue, Request, StatusCode},
    middleware::Next,
    response::Response,
};
use tracing::trace;

const X_REQUEST_ID: &str = "x-request-id";

pub async fn layer(mut req: Request<Body>, next: Next) -> Result<Response, StatusCode> {
    let header_name = HeaderName::from_static(X_REQUEST_ID);

    // If there is no request-id, generate one and attach it to the request.
    if !req.headers().contains_key(&header_name) {
        let id = gen_request_id();
        if let Ok(v) = HeaderValue::from_str(&id) {
            req.headers_mut().insert(&header_name, v);
        }
    }

    // Grab an OWNED copy of the request-id for logging and response echo.
    let id_for_log: String = req
        .headers()
        .get(&header_name)
        .and_then(|v| v.to_str().ok())
        .map(|s| s.to_string())
        .unwrap_or_else(|| "<missing>".to_string());

    trace!(request_id = %id_for_log, "macronode admin: handling request");

    // Move the request into the next layer/handler.
    let mut res = next.run(req).await;

    // Echo the request-id back on the response if not already set.
    if !res.headers().contains_key(&header_name) {
        if let Ok(v) = HeaderValue::from_str(&id_for_log) {
            res.headers_mut().insert(&header_name, v);
        }
    }

    Ok(res)
}

fn gen_request_id() -> String {
    let now = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_default();
    // Not cryptographically strong — just unique-ish for tracing.
    format!("macronode-{}", now.as_nanos())
}

```

### crates/macronode/src/http_admin/middleware/timeout.rs
<a id="crates-macronode-src-httpadmin-middleware-timeout-rs"></a>

```rust
//! RO:WHAT — Simple per-request timeout middleware.
//! RO:WHY  — Prevent hung /admin calls from blocking probes forever.
//!
//! RO:INVARIANTS —
//!   - Uses a conservative fixed timeout for now.
//!   - Returns `504 Gateway Timeout` on expiry.

use std::time::Duration;

use axum::{
    body::Body,
    http::{Request, StatusCode},
    middleware::Next,
    response::Response,
};
use tokio::time::timeout;
use tracing::warn;

// For now this is a static admin timeout. We can later wire this to
// `Config` (e.g., `admin_timeout`) if we want it to be configurable.
const ADMIN_TIMEOUT: Duration = Duration::from_secs(10);

pub async fn layer(req: Request<Body>, next: Next) -> Result<Response, StatusCode> {
    match timeout(ADMIN_TIMEOUT, next.run(req)).await {
        Ok(resp) => Ok(resp),
        Err(_) => {
            warn!(
                "macronode admin: request timed out after {:?}",
                ADMIN_TIMEOUT
            );
            Err(StatusCode::GATEWAY_TIMEOUT)
        }
    }
}

```

### crates/macronode/src/http_admin/mod.rs
<a id="crates-macronode-src-httpadmin-mod-rs"></a>

```rust
//! RO:WHAT — HTTP admin/observability plane for Macronode.
//! RO:WHY  — Expose `/version`, `/healthz`, `/readyz`, `/metrics`, and basic admin APIs.
//! RO:INTERACTS —
//!   - `AppState` for config + probes.
//!   - `observability::metrics` for Prometheus encoding.

pub mod handlers;
pub mod middleware;
pub mod router;

```

### crates/macronode/src/http_admin/router.rs
<a id="crates-macronode-src-httpadmin-router-rs"></a>

```rust
//! RO:WHAT — Router builder for Macronode admin plane.

use std::sync::Arc;

use axum::{
    middleware::from_fn,
    routing::{get, post},
    Router,
};

use crate::{
    http_admin::middleware::{auth, rate_limit, request_id, timeout},
    readiness::{self, ReadyProbes},
    types::AppState,
};

pub fn build_router(state: AppState) -> Router {
    let probes: Arc<ReadyProbes> = state.probes.clone();

    let base = Router::new()
        .route(
            "/version",
            get(crate::http_admin::handlers::version::handler),
        )
        .route(
            "/healthz",
            get(crate::http_admin::handlers::healthz::handler),
        )
        .route(
            "/readyz",
            get(move || {
                let probes = probes.clone();
                readiness::handler(probes)
            }),
        )
        .route(
            "/metrics",
            get(crate::http_admin::handlers::metrics::handler),
        )
        .route(
            "/api/v1/status",
            get(crate::http_admin::handlers::status::handler),
        )
        .route(
            "/api/v1/reload",
            post(crate::http_admin::handlers::reload::handler),
        )
        .route(
            "/api/v1/shutdown",
            post(crate::http_admin::handlers::shutdown::handler),
        )
        .with_state(state);

    // Middleware stack:
    base.layer(from_fn(rate_limit::layer))
        .layer(from_fn(auth::layer)) // only applies to guarded paths
        .layer(from_fn(timeout::layer))
        .layer(from_fn(request_id::layer))
}

```

### crates/macronode/src/main.rs
<a id="crates-macronode-src-main-rs"></a>

```rust
//! RO:WHAT — Binary entrypoint for Macronode.
//! RO:WHY  — Wire config, logging, readiness, admin HTTP plane, and supervisor.
//! RO:INVARIANTS —
//!   - No public Rust API (binary-only crate).
//!   - Admin HTTP is truthful by default; dev overrides are explicit.

#![forbid(unsafe_code)]

mod bus;
mod cli;
mod config;
mod errors;
mod http_admin;
mod observability;
mod readiness;
mod services;
mod supervisor;
mod types;

use crate::errors::Result;

#[tokio::main]
async fn main() -> Result<()> {
    cli::entrypoint().await
}

```

### crates/macronode/src/observability/logging.rs
<a id="crates-macronode-src-observability-logging-rs"></a>

```rust
//! RO:WHAT — Tracing subscriber initialization for Macronode.
//! RO:WHY  — Deterministic logs with env filter and JSON-friendly format.

use tracing_subscriber::{fmt, EnvFilter};

pub fn init(log_level: &str) {
    let default = format!("macronode={log_level},info");
    let filter = std::env::var("RUST_LOG").unwrap_or(default);

    let _ = fmt().with_env_filter(EnvFilter::new(filter)).try_init();
}

```

### crates/macronode/src/observability/metrics.rs
<a id="crates-macronode-src-observability-metrics-rs"></a>

```rust
//! RO:WHAT — Metrics plumbing for Macronode.
//! RO:WHY  — Keep a home for Prometheus registration and HTTP-layer metrics.
//! RO:INVARIANTS —
//!   - Metric families are registered against the default Prometheus registry.
//!   - This module is safe to call from multiple threads; registration is
//!     guarded so we only build metric handles once.

use std::sync::OnceLock;

use prometheus::{Encoder, Gauge, Opts, TextEncoder};

/// Simple macronode metric set.
///
/// We keep this intentionally tiny for now: just uptime + ready flag.
/// This is enough to make `/metrics` non-empty and to give operators
/// a quick at-a-glance signal without pulling `/api/v1/status`.
struct MacronodeMetrics {
    uptime_seconds: Gauge,
    ready: Gauge,
}

static METRICS: OnceLock<MacronodeMetrics> = OnceLock::new();

fn metrics() -> &'static MacronodeMetrics {
    METRICS.get_or_init(|| {
        let uptime_opts = Opts::new(
            "macronode_uptime_seconds",
            "Seconds since this macronode process started.",
        )
        .namespace("ron");

        let ready_opts = Opts::new(
            "macronode_ready",
            "1 if macronode reports ready=true, 0 otherwise.",
        )
        .namespace("ron");

        let uptime_seconds = Gauge::with_opts(uptime_opts).expect("macronode_uptime_seconds gauge");
        let ready = Gauge::with_opts(ready_opts).expect("macronode_ready gauge");

        // Register with the default registry; failures here are fatal because
        // they indicate programmer error (duplicate names, etc.).
        prometheus::register(Box::new(uptime_seconds.clone()))
            .expect("register macronode_uptime_seconds");
        prometheus::register(Box::new(ready.clone())).expect("register macronode_ready");

        MacronodeMetrics {
            uptime_seconds,
            ready,
        }
    })
}

/// Update macronode-local metrics.
///
/// This is cheap enough to call whenever we build `/api/v1/status`, so we
/// keep the call surface simple: the admin path passes in its computed
/// uptime + readiness bit.
pub fn update_macronode_metrics(uptime_seconds: u64, ready: bool) {
    let m = metrics();
    m.uptime_seconds.set(uptime_seconds as f64);
    m.ready.set(if ready { 1.0 } else { 0.0 });
}

/// Encode all registered metrics in Prometheus text format.
///
/// This is intentionally minimal for the first pass; other crates in the
/// workspace may also register metrics against the default registry.
pub fn encode_prometheus() -> String {
    let metric_families = prometheus::gather();
    let encoder = TextEncoder::new();
    let mut buf = Vec::new();
    if let Err(err) = encoder.encode(&metric_families, &mut buf) {
        eprintln!("[macronode-metrics] encode error: {err}");
        return String::new();
    }

    String::from_utf8(buf).unwrap_or_default()
}

```

### crates/macronode/src/observability/mod.rs
<a id="crates-macronode-src-observability-mod-rs"></a>

```rust
//! RO:WHAT — Observability surfaces for Macronode.
//! RO:WHY  — Keep main/bootstrap clean; centralize logging/metrics wiring.
//! RO:INVARIANTS —
//!   - Logging is initialized exactly once per process.
//!   - Metrics module is present (even if initially a stub) so `/metrics` works.

pub mod logging;
pub mod metrics;

```

### crates/macronode/src/pq/hybrid.rs
<a id="crates-macronode-src-pq-hybrid-rs"></a>

```rust
//! RO:WHAT — Stub types for hybrid PQ keying configuration.
//! RO:WHY  — Keep the *shape* of PQ integration stable while we defer
//!           the actual cryptography and transport/KMS wiring to other
//!           crates (ron-transport, ron-kms, svc-gateway, svc-overlay).
//!
//! RO:STATUS —
//!   - Foundation slice; no crypto, no external dependencies.
//!   - Safe to extend once PQ libraries and envelopes are chosen.
//!
//! RO:INVARIANTS —
//!   - This module is purely descriptive and carries no secrets.
//!   - Default configuration is conservative (no PQ suite selected).

/// Logical identifier for a PQ-capable hybrid algorithm suite.
///
/// Foundation cut keeps this stringly-typed; once we lock in a concrete
/// set of KEM/sign combos (e.g. "x25519+mlkem768"), we can substitute a
/// richer enum or newtype.
pub type SuiteId = &'static str;

/// Minimal configuration describing which PQ suite (if any) this node
/// prefers for **hybrid** operation.
///
/// This is intentionally small and self-contained. Downstream crates
/// will decide how to interpret and enforce it at the transport and
/// KMS layers.
#[derive(Debug, Clone)]
pub struct HybridConfig {
    /// Selected hybrid suite identifier (e.g. "x25519+mlkem768").
    ///
    /// `None` means "no PQ preference" and is the current default.
    pub suite: Option<SuiteId>,
}

impl Default for HybridConfig {
    fn default() -> Self {
        // Foundation: do not force PQ on; macronode will remain classical
        // until operators enable PQ at the edges and downstream planes
        // are wired to support it.
        Self { suite: None }
    }
}

```

### crates/macronode/src/pq/mod.rs
<a id="crates-macronode-src-pq-mod-rs"></a>

```rust
//! RO:WHAT — Post-quantum (PQ) posture helpers for Macronode.
//! RO:WHY  — Interpret env/config flags into a simple runtime enum that
//!           higher layers (TLS, KMS, gateway/overlay) can inspect once
//!           they grow PQ support.
//!
//! RO:INVARIANTS —
//!   - This module performs *no* cryptographic operations.
//!   - Default posture is `PqPosture::Off` to preserve interop until
//!     operators explicitly opt in.
//!   - Unknown/invalid mode strings never panic; they map to `Off` with
//!     a best-effort warning to stderr.
//!
//! RO:CONFIG —
//!   - Env: `RON_PQ_MODE` (foundation cut)
//!       * "off" (default)  → PqPosture::Off
//!       * "hybrid"         → PqPosture::Hybrid
//!     Additional aliases: "0"/"false"/"" → Off, "1"/"true"/"on" → Hybrid.
//!
//! Future slices can add integration with structured config
//! (`config::schema` and overlays) once PQ is wired downstream.

use std::env;

/// Runtime PQ posture for this macronode process.
///
/// Foundation slice keeps this intentionally small: either PQ is off, or we
/// allow a **hybrid** posture where classical + PQ can both be used by
/// lower layers once they are ready.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PqPosture {
    /// PQ disabled; classical-only handshakes/keys.
    Off,
    /// Hybrid posture (classical + PQ), where downstream planes can
    /// negotiate PQ-enabled edges when peers support it.
    Hybrid,
}

impl PqPosture {
    /// Derive posture from the `RON_PQ_MODE` environment variable.
    ///
    /// This is intentionally forgiving and never panics: unrecognised
    /// values simply fall back to `Off` and emit a best-effort warning.
    #[must_use]
    pub fn from_env() -> Self {
        match env::var("RON_PQ_MODE") {
            Ok(raw) => Self::from_str(raw.trim()),
            Err(_) => PqPosture::Off,
        }
    }

    /// Parse posture from a string, accepting a few convenient aliases.
    ///
    /// Known values (case-insensitive):
    ///   - "off", "0", "false", ""       → Off
    ///   - "hybrid", "on", "1", "true"   → Hybrid
    #[must_use]
    pub fn from_str(raw: &str) => Self {
        let lowered = raw.to_ascii_lowercase();
        match lowered.as_str() {
            "" | "off" | "0" | "false" | "disabled" => PqPosture::Off,
            "hybrid" | "on" | "1" | "true" | "enabled" => PqPosture::Hybrid,
            other => {
                // Foundation cut: we don't have tracing plumbed into this
                // module yet, so log to stderr. Later we can route this
                // through `tracing::warn!` once call-sites exist.
                eprintln!(
                    "[macronode-pq] RON_PQ_MODE={other:?} not recognised; defaulting to Off"
                );
                PqPosture::Off
            }
        }
    }

    /// Convenience boolean for feature gating.
    #[must_use]
    pub const fn is_enabled(self) -> bool {
        !matches!(self, PqPosture::Off)
    }
}

#[cfg(test)]
mod tests {
    use super::PqPosture;

    #[test]
    fn from_str_off_aliases() {
        for v in ["", "off", "OFF", "0", "false", "FALSE", "disabled"] {
            assert_eq!(PqPosture::from_str(v), PqPosture::Off, "value={v:?}");
        }
    }

    #[test]
    fn from_str_hybrid_aliases() {
        for v in ["hybrid", "HYBRID", "1", "on", "ON", "true", "TRUE", "enabled"] {
            assert_eq!(PqPosture::from_str(v), PqPosture::Hybrid, "value={v:?}");
        }
    }

    #[test]
    fn unknown_values_fall_back_to_off() {
        assert_eq!(PqPosture::from_str("weird-mode"), PqPosture::Off);
    }
}

```

### crates/macronode/src/readiness/deps.rs
<a id="crates-macronode-src-readiness-deps-rs"></a>

```rust
// crates/macronode/src/readiness/deps.rs

//! RO:WHAT — JSON shapes and helpers for `/readyz` dependency reporting.
//! RO:WHY  — Keep HTTP response wiring separate from probe mechanics, while
//!           preserving a stable JSON contract for tests and operators.
//!
//! High-level JSON shape:
//!   {
//!     "ready": bool,
//!     "deps": {
//!       "config":  "loaded" | "pending",
//!       "network": "ok" | "pending",
//!       "gateway": "ok" | "pending",
//!       "storage": "ok" | "pending",
//!       "index":   "ok" | "pending",
//!       "overlay": "ok" | "pending",
//!       "mailbox": "ok" | "pending",
//!       "dht":     "ok" | "pending"
//!     },
//!     "mode": "truthful" | "dev-forced"
//!   }

use serde::Serialize;

use super::probes::ReadySnapshot;

/// Dependency state block for `/readyz`.
#[derive(Serialize)]
pub(super) struct ReadyDeps<'a> {
    pub(super) config: &'a str,
    pub(super) network: &'a str,
    pub(super) gateway: &'a str,
    pub(super) storage: &'a str,
    pub(super) index: &'a str,
    pub(super) overlay: &'a str,
    pub(super) mailbox: &'a str,
    pub(super) dht: &'a str,
}

/// Top-level `/readyz` response body.
#[derive(Serialize)]
pub(super) struct ReadyBody<'a> {
    pub(super) ready: bool,
    pub(super) deps: ReadyDeps<'a>,
    pub(super) mode: &'a str,
}

impl<'a> ReadyDeps<'a> {
    /// Construct dependency view from a snapshot.
    ///
    /// Mapping:
    ///   - config  ← cfg_loaded → "loaded"/"pending"
    ///   - network ← listeners_bound → "ok"/"pending"
    ///   - gateway ← gateway_bound → "ok"/"pending"
    ///   - storage ← deps_ok → "ok"/"pending"
    ///   - index   ← index_bound → "ok"/"pending"
    ///   - overlay ← overlay_bound → "ok"/"pending"
    ///   - mailbox ← mailbox_bound → "ok"/"pending"
    ///   - dht     ← dht_bound → "ok"/"pending"
    #[must_use]
    pub(super) fn from_snapshot(snap: &'a ReadySnapshot) -> Self {
        ReadyDeps {
            config: if snap.cfg_loaded { "loaded" } else { "pending" },
            network: if snap.listeners_bound {
                "ok"
            } else {
                "pending"
            },
            gateway: if snap.gateway_bound { "ok" } else { "pending" },
            storage: if snap.deps_ok { "ok" } else { "pending" },
            index: if snap.index_bound { "ok" } else { "pending" },
            overlay: if snap.overlay_bound { "ok" } else { "pending" },
            mailbox: if snap.mailbox_bound { "ok" } else { "pending" },
            dht: if snap.dht_bound { "ok" } else { "pending" },
        }
    }
}

impl<'a> ReadyBody<'a> {
    /// Helper to keep handler code small and readable.
    #[must_use]
    pub(super) fn new(ready: bool, deps: ReadyDeps<'a>, mode: &'a str) -> Self {
        ReadyBody { ready, deps, mode }
    }
}

```

### crates/macronode/src/readiness/mod.rs
<a id="crates-macronode-src-readiness-mod-rs"></a>

```rust
// crates/macronode/src/readiness/mod.rs

//! RO:WHAT — Readiness probes and `/readyz` handler for Macronode.
//! RO:WHY  — Truthful, operator-friendly readiness for orchestration
//!           (K8s/systemd/CI) with a clean separation of concerns.
//!
//! RO:INVARIANTS —
//!   Essential gates for ready=true: listeners_bound && cfg_loaded && deps_ok && gateway_bound.
//!   Per-service bits (index/overlay/mailbox/dht) are tracked and exposed in the JSON `deps`
//!   payload but do not gate readiness yet.
//!   Dev override: MACRONODE_DEV_READY=1 forces `ready=true` while still exposing actual
//!   dependency states in the body.

mod deps;
mod probes;

pub use probes::ReadyProbes;

use axum::{
    http::{HeaderMap, HeaderValue, StatusCode},
    response::IntoResponse,
    Json,
};
use std::sync::Arc;

use self::deps::{ReadyBody, ReadyDeps};

/// Check whether the dev override is enabled via `MACRONODE_DEV_READY`.
fn dev_override_enabled() -> bool {
    matches!(
        std::env::var("MACRONODE_DEV_READY").as_deref(),
        Ok("1") | Ok("true") | Ok("TRUE") | Ok("on") | Ok("ON")
    )
}

/// Axum handler for `/readyz`.
///
/// Responsibilities:
///   - Snapshot probes (cheap, lock-free).
///   - Apply dev override semantics.
///   - Map snapshot → JSON deps/body using `deps` helpers.
///   - Attach `Retry-After` when not ready in truthful mode.
pub async fn handler(probes: Arc<ReadyProbes>) -> impl IntoResponse {
    // Dev override: force ready=true, but still report what Macronode knows
    // about each dependency so operators can see "what's actually happening".
    if dev_override_enabled() {
        let snap = probes.snapshot();
        let deps = ReadyDeps::from_snapshot(&snap);
        let body = ReadyBody::new(true, deps, "dev-forced");

        return (StatusCode::OK, Json(body)).into_response();
    }

    // Truthful mode: rely on the required_ready() invariant and surface
    // dependency states directly.
    let snap = probes.snapshot();
    let ok = snap.required_ready();
    let deps = ReadyDeps::from_snapshot(&snap);

    let mut headers = HeaderMap::new();
    if !ok {
        // Friendly hint to orchestrators / callers to back off before retrying.
        headers.insert("Retry-After", HeaderValue::from_static("5"));
    }

    let body = ReadyBody::new(ok, deps, "truthful");
    let status = if ok {
        StatusCode::OK
    } else {
        StatusCode::SERVICE_UNAVAILABLE
    };

    (status, headers, Json(body)).into_response()
}

```

### crates/macronode/src/readiness/probes.rs
<a id="crates-macronode-src-readiness-probes-rs"></a>

```rust
// crates/macronode/src/readiness/probes.rs

//! RO:WHAT — In-process readiness probes and snapshot type.
//! RO:WHY  — Cheap, concurrency-friendly source of truth for `/readyz` and
//!           future status endpoints.
//!
//! RO:INVARIANTS —
//!   - All flags are atomic booleans with Release/Acquire semantics.
//!   - `required_ready()` encodes the essential gates for reporting
//!     `ready == true` in truthful mode.
//!   - Per-service bits (index/overlay/mailbox/dht) are tracked but do not
//!     gate readiness yet; they are surfaced in JSON only.

use serde::Serialize;
use std::sync::atomic::{AtomicBool, Ordering};

#[derive(Debug)]
pub struct ReadyProbes {
    // Essential gates
    listeners_bound: AtomicBool,
    cfg_loaded: AtomicBool,
    metrics_bound: AtomicBool,
    deps_ok: AtomicBool,
    gateway_bound: AtomicBool,

    // Per-service bits (informational for now)
    index_bound: AtomicBool,
    overlay_bound: AtomicBool,
    mailbox_bound: AtomicBool,
    dht_bound: AtomicBool,
}

impl ReadyProbes {
    /// Construct a fresh probe set with all gates set to `false`.
    #[must_use]
    pub fn new() -> Self {
        Self {
            listeners_bound: AtomicBool::new(false),
            cfg_loaded: AtomicBool::new(false),
            metrics_bound: AtomicBool::new(false),
            deps_ok: AtomicBool::new(false),
            gateway_bound: AtomicBool::new(false),
            index_bound: AtomicBool::new(false),
            overlay_bound: AtomicBool::new(false),
            mailbox_bound: AtomicBool::new(false),
            dht_bound: AtomicBool::new(false),
        }
    }

    // --- Essential gate setters ---

    pub fn set_listeners_bound(&self, v: bool) {
        self.listeners_bound.store(v, Ordering::Release);
    }

    pub fn set_cfg_loaded(&self, v: bool) {
        self.cfg_loaded.store(v, Ordering::Release);
    }

    pub fn set_metrics_bound(&self, v: bool) {
        self.metrics_bound.store(v, Ordering::Release);
    }

    pub fn set_deps_ok(&self, v: bool) {
        self.deps_ok.store(v, Ordering::Release);
    }

    pub fn set_gateway_bound(&self, v: bool) {
        self.gateway_bound.store(v, Ordering::Release);
    }

    // --- Per-service setters (informational) ---

    pub fn set_index_bound(&self, v: bool) {
        self.index_bound.store(v, Ordering::Release);
    }

    pub fn set_overlay_bound(&self, v: bool) {
        self.overlay_bound.store(v, Ordering::Release);
    }

    pub fn set_mailbox_bound(&self, v: bool) {
        self.mailbox_bound.store(v, Ordering::Release);
    }

    pub fn set_dht_bound(&self, v: bool) {
        self.dht_bound.store(v, Ordering::Release);
    }

    /// Take a consistent snapshot for use by HTTP handlers / metrics.
    #[must_use]
    pub fn snapshot(&self) -> ReadySnapshot {
        ReadySnapshot {
            listeners_bound: self.listeners_bound.load(Ordering::Acquire),
            cfg_loaded: self.cfg_loaded.load(Ordering::Acquire),
            metrics_bound: self.metrics_bound.load(Ordering::Acquire),
            deps_ok: self.deps_ok.load(Ordering::Acquire),
            gateway_bound: self.gateway_bound.load(Ordering::Acquire),
            index_bound: self.index_bound.load(Ordering::Acquire),
            overlay_bound: self.overlay_bound.load(Ordering::Acquire),
            mailbox_bound: self.mailbox_bound.load(Ordering::Acquire),
            dht_bound: self.dht_bound.load(Ordering::Acquire),
        }
    }
}

impl Default for ReadyProbes {
    fn default() -> Self {
        Self::new()
    }
}

#[derive(Debug, Clone, Serialize)]
pub struct ReadySnapshot {
    pub listeners_bound: bool,
    pub cfg_loaded: bool,
    pub metrics_bound: bool,
    pub deps_ok: bool,
    pub gateway_bound: bool,
    pub index_bound: bool,
    pub overlay_bound: bool,
    pub mailbox_bound: bool,
    pub dht_bound: bool,
}

impl ReadySnapshot {
    /// Essential readiness gates for reporting `"ready": true`.
    ///
    /// Deliberately *does not* include per-service bits yet. Once the
    /// non-core planes are wired and stable, we can tighten this gate.
    #[must_use]
    pub fn required_ready(&self) -> bool {
        self.listeners_bound && self.cfg_loaded && self.deps_ok && self.gateway_bound
    }
}

```

### crates/macronode/src/security/amnesia.rs
<a id="crates-macronode-src-security-amnesia-rs"></a>

```rust
//! RO:WHAT — Amnesia posture helpers for Macronode.
//! RO:WHY  — Provide a single source of truth for how "amnesia mode" is
//!           interpreted so config / CLI / services stay consistent.
//! RO:INVARIANTS —
//!   - `Persistent` is the default for Macronode (unlike Micronode).
//!   - `Amnesic` is a best-effort "RAM-first, no durable residue" posture.

#![allow(dead_code)]

/// High-level amnesia posture for this process.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum AmnesiaMode {
    /// Normal mode: services are allowed to persist state to disk.
    Persistent,
    /// Best-effort amnesia: avoid durable state, prefer RAM-only caches.
    Amnesic,
}

impl AmnesiaMode {
    /// Returns true if the node should avoid writing persistent state.
    #[must_use]
    pub const fn is_amnesic(self) -> bool {
        matches!(self, AmnesiaMode::Amnesic)
    }
}

/// Classify the mode from a simple boolean flag (e.g. config/CLI/env).
///
/// This keeps the rest of the code from re-encoding the boolean semantics
/// in multiple places.
#[must_use]
pub fn classify_amnesia(enabled: bool) -> AmnesiaMode {
    if enabled {
        AmnesiaMode::Amnesic
    } else {
        AmnesiaMode::Persistent
    }
}

```

### crates/macronode/src/security/macaroon.rs
<a id="crates-macronode-src-security-macaroon-rs"></a>

```rust
//! RO:WHAT — Opaque capability-token wrapper for Macronode.
//! RO:WHY  — Macronode itself does not parse or verify macaroons/JWTs;
//!           it just treats them as opaque bearer tokens that downstream
//!           services (KMS/auth) can validate.
//! RO:INVARIANTS —
//!   - This module never logs token contents.
//!   - Parsing is intentionally minimal: higher layers decide semantics.

#![allow(dead_code)]

/// Opaque capability or macaroon-style token.
///
/// In this crate we treat the token as an opaque string. Verification and
/// interpretation belong to dedicated auth/KMS services.
#[derive(Debug, Clone)]
pub struct CapabilityToken {
    raw: String,
}

impl CapabilityToken {
    /// Construct a token from a raw bearer string (without the "Bearer " prefix).
    #[must_use]
    pub fn new<S: Into<String>>(raw: S) -> Self {
        Self { raw: raw.into() }
    }

    /// View the underlying token bytes.
    #[must_use]
    pub fn as_str(&self) -> &str {
        &self.raw
    }
}

/// Parse a `Authorization` header value into a bearer token, if present.
///
/// This is intentionally tiny and does not validate the token format.
#[must_use]
pub fn parse_bearer_header(header: &str) -> Option<CapabilityToken> {
    // Common forms:
    //   "Bearer abc123"
    //   "bearer abc123"
    let trimmed = header.trim();
    let prefix_lower = "bearer ";

    if trimmed.len() <= prefix_lower.len() {
        return None;
    }

    if trimmed.to_ascii_lowercase().starts_with(prefix_lower) {
        let token = &trimmed[prefix_lower.len()..];
        if token.is_empty() {
            None
        } else {
            Some(CapabilityToken::new(token))
        }
    } else {
        None
    }
}

```

### crates/macronode/src/security/mod.rs
<a id="crates-macronode-src-security-mod-rs"></a>

```rust
//! RO:WHAT — Security utilities for Macronode.
//! RO:WHY  — Central home for amnesia posture, TLS options, and capability
//!           token helpers. This keeps security-related logic coherent and
//!           discoverable without bloating `main` or HTTP modules.
//! RO:INVARIANTS —
//!   - This module is pure helper surface; it does not perform I/O by itself.
//!   - Higher layers remain responsible for actually enforcing policies.

#![allow(dead_code)]

pub(crate) mod amnesia;
pub(crate) mod macaroon;
pub(crate) mod tls;

pub(crate) use amnesia::{classify_amnesia, AmnesiaMode};
pub(crate) use tls::{TlsConfig, TlsMode};

```

### crates/macronode/src/security/tls.rs
<a id="crates-macronode-src-security-tls-rs"></a>

```rust
//! RO:WHAT — TLS configuration helpers for Macronode.
//! RO:WHY  — Provide a small, self-contained representation of TLS posture
//!           so admin/gateway planes can be upgraded to TLS without each
//!           caller reinventing config parsing logic.
//! RO:INVARIANTS —
//!   - This module does **not** perform any I/O by itself.
//!   - The actual listener binding and rustls integration live elsewhere.

#![allow(dead_code)]

use std::path::{Path, PathBuf};

/// TLS mode for a given listener.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TlsMode {
    /// TLS is disabled; listener uses plain TCP.
    Disabled,
    /// TLS is enabled with a certificate/key pair.
    Enabled,
}

/// High-level TLS configuration for a listener.
#[derive(Debug, Clone)]
pub struct TlsConfig {
    mode: TlsMode,
    cert_path: Option<PathBuf>,
    key_path: Option<PathBuf>,
}

impl TlsConfig {
    /// Construct a disabled TLS configuration.
    #[must_use]
    pub const fn disabled() -> Self {
        Self {
            mode: TlsMode::Disabled,
            cert_path: None,
            key_path: None,
        }
    }

    /// Construct an enabled TLS configuration with the given paths.
    #[must_use]
    pub fn enabled(cert_path: PathBuf, key_path: PathBuf) -> Self {
        Self {
            mode: TlsMode::Enabled,
            cert_path: Some(cert_path),
            key_path: Some(key_path),
        }
    }

    /// Returns true if TLS is enabled.
    #[must_use]
    pub const fn is_enabled(&self) -> bool {
        matches!(self.mode, TlsMode::Enabled)
    }

    /// Accessor for the certificate path, if any.
    #[must_use]
    pub fn cert_path(&self) -> Option<&Path> {
        self.cert_path.as_deref()
    }

    /// Accessor for the private key path, if any.
    #[must_use]
    pub fn key_path(&self) -> Option<&Path> {
        self.key_path.as_deref()
    }
}

```

### crates/macronode/src/services/mod.rs
<a id="crates-macronode-src-services-mod-rs"></a>

```rust
//! RO:WHAT — Macronode managed services surface.
//! RO:WHY  — Single place to define which internal services (gateway, overlay,
//!           storage, index, mailbox, dht, etc.) this node composes.
//! RO:INVARIANTS —
//!   - Slice 1 only exposes `spawn_all()` and per-service stubs.
//!   - Future slices will add real service wiring and health reporting.

pub mod spawn;
pub mod svc_dht;
pub mod svc_gateway;
pub mod svc_index;
pub mod svc_mailbox;
pub mod svc_overlay;
pub mod svc_storage;

pub use spawn::spawn_all;

```

### crates/macronode/src/services/registry.rs
<a id="crates-macronode-src-services-registry-rs"></a>

```rust
//! RO:WHAT — In-memory registry of Macronode managed services.
//! RO:WHY  — Give `/api/v1/status` and the supervisor a shared place to
//!           track which services exist and their coarse health.
//! RO:INVARIANTS —
//!   - Registry is in-memory only; macronode owns no persistent data.
//!   - Service names are small static strings; no user input here.

#![allow(dead_code)]

use std::collections::BTreeMap;

/// Coarse status for a composed service.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ServiceStatus {
    /// Present but not yet doing real work (today's stubs).
    Stub,
    /// In the process of starting up.
    Starting,
    /// Fully running and healthy.
    Running,
    /// In the process of draining for shutdown.
    Draining,
    /// Failed permanently; requires operator intervention.
    Failed,
}

/// Simple registry mapping service name → status.
#[derive(Debug, Default)]
pub struct ServiceRegistry {
    inner: BTreeMap<&'static str, ServiceStatus>,
}

impl ServiceRegistry {
    /// Update the status for a named service.
    pub fn set_status(&mut self, name: &'static str, status: ServiceStatus) {
        self.inner.insert(name, status);
    }

    /// Fetch the status for a named service, if known.
    #[must_use]
    pub fn get_status(&self, name: &'static str) -> Option<ServiceStatus> {
        self.inner.get(name).copied()
    }

    /// Take a snapshot of all service statuses for serialization or logging.
    #[must_use]
    pub fn snapshot(&self) -> BTreeMap<&'static str, ServiceStatus> {
        self.inner.clone()
    }
}

```

### crates/macronode/src/services/spawn.rs
<a id="crates-macronode-src-services-spawn-rs"></a>

```rust
// crates/macronode/src/services/spawn.rs

//! RO:WHAT — Single entrypoint to spawn all managed Macronode services.
//! RO:WHY  — Keep supervisor wiring centralized so we can:
//!           * track JoinHandles for crash logging,
//!           * thread readiness probes into services,
//!           * pass shutdown tokens for graceful drain later.
//!
//! RO:INVARIANTS —
//!   - This slice still runs services until process shutdown (no restarts).
//!   - `ReadyProbes::set_deps_ok(true)` is flipped once workers are spawned;
//!     per-service bits (index/overlay/mailbox/dht) are flipped by the
//!     individual service modules.
//!   - No service-specific logic leaks into the supervisor; this module
//!     just coordinates spawns.

use std::sync::Arc;

use tracing::info;

use crate::{
    errors::Result,
    readiness::ReadyProbes,
    supervisor::{ManagedTask, ShutdownToken},
};

/// Spawn all managed services.
///
/// Today this is still “fire-and-forget”: each service runs until process
/// shutdown. We collect the JoinHandles as `ManagedTask`s so the Supervisor
/// can monitor exits and log them. No restart policies wired yet.
pub async fn spawn_all(
    probes: Arc<ReadyProbes>,
    shutdown: ShutdownToken,
) -> Result<Vec<ManagedTask>> {
    info!("macronode supervisor: spawn_all (starting service workers)");

    let tasks: Vec<ManagedTask> = vec![
        // Gateway: real HTTP ingress, marks gateway_bound=true when listener binds.
        crate::services::svc_gateway::spawn(probes.clone()),
        // svc-index: real embedded HTTP server using svc-index crate.
        // Flips index_bound=true once its listener binds.
        crate::services::svc_index::spawn(probes.clone()),
        // Remaining services are still stub workers; they just loop until shutdown.
        // Each one flips its own per-service readiness bit when the worker starts.
        crate::services::svc_overlay::spawn(probes.clone(), shutdown.clone()),
        crate::services::svc_storage::spawn(shutdown.clone()),
        crate::services::svc_mailbox::spawn(probes.clone(), shutdown.clone()),
        crate::services::svc_dht::spawn(probes.clone(), shutdown),
    ];

    // All deps are considered "ok" once their workers have been spawned.
    // At this slice we don’t yet distinguish per-dep gating in `required_ready()`.
    probes.set_deps_ok(true);

    Ok(tasks)
}

```

### crates/macronode/src/services/svc_dht.rs
<a id="crates-macronode-src-services-svcdht-rs"></a>

```rust
// crates/macronode/src/services/svc_dht.rs

//! RO:WHAT — Macronode wrapper for the DHT/routing plane.
//! RO:WHY  — Reserve a config-aware home for DHT workers so macronode can
//!           coordinate them without owning DHT internals.
//! RO:INVARIANTS —
//!   - Worker runs until shutdown is requested via `ShutdownToken`.
//!   - Bind address is resolved once and logged for operator introspection.
//!   - This module owns only host wiring; DHT semantics live in `svc-dht`.
//!
//! RO:FUTURE —
//!   - Call into `svc-dht` lib entrypoint with:
//!       * A transport handle (ron-transport).
//!       * Bus handle for overlay/DHT events.
//!       * ShutdownToken.
//!   - Expose routing health and table stats via metrics and `/status`.

use std::net::SocketAddr;
use std::sync::Arc;
use std::time::Duration;

use tokio::time::sleep;
use tracing::{error, info};

use crate::{
    readiness::ReadyProbes,
    supervisor::{ManagedTask, ShutdownToken},
};

/// Default bind for the DHT plane (local-only in this slice).
const DEFAULT_DHT_ADDR: &str = "127.0.0.1:5302";

/// Resolve the bind address for the DHT plane.
///
/// Env override:
///   - `RON_DHT_ADDR=IP:PORT`
fn resolve_bind_addr() -> SocketAddr {
    match std::env::var("RON_DHT_ADDR") {
        Ok(raw) => match raw.trim().parse::<SocketAddr>() {
            Ok(addr) => {
                info!("svc-dht: using RON_DHT_ADDR={addr}");
                addr
            }
            Err(err) => {
                error!(
                    "svc-dht: invalid RON_DHT_ADDR={raw:?}, \
                     falling back to {DEFAULT_DHT_ADDR}: {err}"
                );
                DEFAULT_DHT_ADDR
                    .parse()
                    .expect("DEFAULT_DHT_ADDR must be a valid SocketAddr")
            }
        },
        Err(_) => DEFAULT_DHT_ADDR
            .parse()
            .expect("DEFAULT_DHT_ADDR must be a valid SocketAddr"),
    }
}

/// Spawn the DHT worker.
///
/// For now this is a stub loop that just logs the resolved address and
/// waits on the shutdown token.
pub fn spawn(probes: Arc<ReadyProbes>, shutdown: ShutdownToken) -> ManagedTask {
    let handle = tokio::spawn(async move {
        let addr = resolve_bind_addr();
        info!(
            %addr,
            "svc-dht: started (host shell, waiting for real svc-dht wiring)"
        );

        // Flip the per-service readiness bit once the worker has started.
        probes.set_dht_bound(true);

        while !shutdown.is_triggered() {
            sleep(Duration::from_secs(5)).await;
        }

        info!("svc-dht: shutdown requested, exiting worker");
    });

    ManagedTask::new("svc-dht", handle)
}

```

### crates/macronode/src/services/svc_gateway.rs
<a id="crates-macronode-src-services-svcgateway-rs"></a>

```rust
//! RO:WHAT — Macronode HTTP ingress (svc-gateway MVP).
//! RO:WHY  — Stand up actual ingress listener + mark readiness correctly.
//! RO:INVARIANTS —
//!   - Binds to 127.0.0.1:8090 by default (override via RON_GATEWAY_ADDR).
//!   - Sets `gateway_bound=true` on successful bind to feed `/readyz` + status.
//!   - No locks held across `.await`.

use std::sync::Arc;
use std::{net::SocketAddr, str::FromStr};

use axum::{response::IntoResponse, routing::get, Json, Router};
use serde::Serialize;
use tokio::net::TcpListener;
use tracing::{error, info};

use crate::readiness::ReadyProbes;
use crate::supervisor::ManagedTask;

#[derive(Debug, Serialize)]
struct PingBody {
    ok: bool,
    service: &'static str,
    profile: &'static str,
}

async fn ping_handler() -> impl IntoResponse {
    Json(PingBody {
        ok: true,
        service: "svc-gateway",
        profile: "macronode",
    })
}

/// Resolve the bind address for the gateway plane.
///
/// Env override:
///   - `RON_GATEWAY_ADDR=IP:PORT`
fn resolve_bind_addr() -> SocketAddr {
    const DEFAULT_ADDR: &str = "127.0.0.1:8090";

    if let Ok(raw) = std::env::var("RON_GATEWAY_ADDR") {
        match SocketAddr::from_str(raw.trim()) {
            Ok(addr) => {
                info!("svc-gateway: using RON_GATEWAY_ADDR={addr}");
                return addr;
            }
            Err(err) => {
                error!(
                    "svc-gateway: invalid RON_GATEWAY_ADDR={raw:?}, \
                     falling back to {DEFAULT_ADDR}: {err}"
                );
            }
        }
    }

    SocketAddr::from_str(DEFAULT_ADDR).expect("DEFAULT_ADDR must be a valid SocketAddr")
}

/// Spawn the gateway HTTP ingress server.
///
/// Returns a `ManagedTask` wrapping the JoinHandle so the supervisor can
/// log when this service exits. Behavior is otherwise identical to the
/// previous fire-and-forget slice.
pub fn spawn(probes: Arc<ReadyProbes>) -> ManagedTask {
    let handle = tokio::spawn(async move {
        let addr = resolve_bind_addr();

        let listener = match TcpListener::bind(addr).await {
            Ok(listener) => {
                info!("svc-gateway: listening on {addr}");
                probes.set_gateway_bound(true);
                listener
            }
            Err(err) => {
                error!("svc-gateway: failed to bind to {addr}: {err}");
                return;
            }
        };

        let app = Router::new().route("/ingress/ping", get(ping_handler));

        if let Err(err) = axum::serve(listener, app).await {
            error!("svc-gateway: server error: {err}");
        } else {
            info!("svc-gateway: server exited cleanly");
        }
    });

    ManagedTask::new("svc-gateway", handle)
}

```

### crates/macronode/src/services/svc_index.rs
<a id="crates-macronode-src-services-svcindex-rs"></a>

```rust
// crates/macronode/src/services/svc_index.rs

//! RO:WHAT — Macronode wiring for svc-index (real HTTP server).
//! RO:WHY  — Stand up svc-index inside Macronode using its own Config/AppState/router.
//! RO:INVARIANTS —
//!   - Uses svc-index crate as the source of truth (Config/AppState/build_router).
//!   - Binds to the same address logic as svc-index/bin (INDEX_BIND or cfg.bind or 127.0.0.1:5304).
//!   - Does *not* yet participate in graceful shutdown; process exit stops the server.
//!   - Readiness for macronode remains governed by ReadyProbes; `deps_ok` is set
//!     in `spawn_all()`, and `index_bound` is flipped once the listener binds.

use std::{net::SocketAddr, sync::Arc};

use axum::Router;
use tokio::net::TcpListener;
use tracing::{error, info};

use crate::{readiness::ReadyProbes, supervisor::ManagedTask};

// Re-exported API from svc-index crate.
// lib.rs exposes:
//   pub use config::Config;
//   pub use router::build_router;
//   pub use state::AppState;
use svc_index::{
    build_router as build_index_router, AppState as IndexAppState, Config as IndexConfig,
};

/// Spawn the embedded svc-index HTTP server.
///
/// We take `ReadyProbes` so we can integrate svc-index into the macronode
/// readiness story (e.g., `index_bound=true` once the listener is bound).
/// Shutdown is still coarse: when macronode exits, this task ends.
///
/// NOTE: This intentionally mirrors `crates/svc-index/src/main.rs`’s flow:
///   config → state → bootstrap → router.with_state → TcpListener → axum::serve.
pub fn spawn(probes: Arc<ReadyProbes>) -> ManagedTask {
    let handle = tokio::spawn(async move {
        // 1) Load svc-index config (env + defaults).
        let cfg = match IndexConfig::load() {
            Ok(cfg) => cfg,
            Err(err) => {
                error!(?err, "svc-index (embedded): failed to load config");
                return;
            }
        };

        // 2) Build shared Arc<AppState>.
        let state: Arc<IndexAppState> = match IndexAppState::new(cfg.clone()).await {
            Ok(s) => Arc::new(s),
            Err(err) => {
                error!(?err, "svc-index (embedded): failed to build AppState");
                return;
            }
        };

        // 3) Bootstrap (index warmup / caches / readiness gates).
        let state = IndexAppState::bootstrap(state).await;

        // 4) Build router and inject state at the end (Axum 0.7 pattern).
        let app: Router = build_index_router().with_state(state.clone());

        // 5) Bind address: INDEX_BIND env > cfg.bind > 127.0.0.1:5304.
        let bind_str = std::env::var("INDEX_BIND").unwrap_or_else(|_| cfg.bind.clone());
        let bind: SocketAddr = bind_str
            .parse()
            .unwrap_or_else(|_| SocketAddr::from(([127, 0, 0, 1], 5304)));

        let listener: TcpListener = match TcpListener::bind(bind).await {
            Ok(l) => {
                // Flip the per-service readiness bit once the listener is bound.
                probes.set_index_bound(true);

                info!(
                    version = env!("CARGO_PKG_VERSION"),
                    %bind,
                    "svc-index (embedded) starting"
                );
                l
            }
            Err(err) => {
                error!(?err, %bind, "svc-index (embedded): failed to bind");
                return;
            }
        };

        // 6) Serve. For now we *don’t* wire macronode’s ShutdownToken in; when
        // the process exits, the server stops. That keeps behavior simple and
        // matches other embedded services at this slice.
        //
        // We use Router -> IntoMakeService pattern to avoid the generic
        // axum::serve<Router<Arc<AppState>>> bound issues.
        let make_svc = app.into_make_service();

        if let Err(err) = axum::serve(listener, make_svc).await {
            error!(?err, "svc-index (embedded): server error");
        } else {
            info!("svc-index (embedded): server exited cleanly");
        }
    });

    ManagedTask::new("svc-index", handle)
}

```

### crates/macronode/src/services/svc_mailbox.rs
<a id="crates-macronode-src-services-svcmailbox-rs"></a>

```rust
// crates/macronode/src/services/svc_mailbox.rs

//! RO:WHAT — Macronode wrapper for the mailbox plane.
//! RO:WHY  — Reserve a real home for queued message delivery / mailbox semantics
//!           with config-aware bind addresses and clean shutdown wiring.
//! RO:INVARIANTS —
//!   - Worker runs until shutdown is requested via `ShutdownToken`.
//!   - No locks are held across `.await` (once we add async work here).
//!   - This module owns *only* host-level wiring; the real mailbox logic will
//!     live in `svc-mailbox` crate once that lib surface is ready.
//!
//! RO:FUTURE —
//!   - Swap the internal loop to call into `svc-mailbox` crate (HTTP/transport)
//!     without changing the supervisor or `spawn_all` signatures.
//!   - Emit health/metrics via ron-metrics once mailbox has a proper surface.

use std::net::SocketAddr;
use std::sync::Arc;
use std::time::Duration;

use tokio::time::sleep;
use tracing::{error, info};

use crate::{
    readiness::ReadyProbes,
    supervisor::{ManagedTask, ShutdownToken},
};

/// Default bind for the mailbox plane (local-only in this slice).
const DEFAULT_MAILBOX_ADDR: &str = "127.0.0.1:5304";

/// Resolve the bind address for the mailbox plane.
///
/// Today this is purely informational: we log the resolved address so that
/// when `svc-mailbox` is wired in, it already has a stable config surface.
///
/// Env override:
///   - `RON_MAILBOX_ADDR=IP:PORT`
fn resolve_bind_addr() -> SocketAddr {
    match std::env::var("RON_MAILBOX_ADDR") {
        Ok(raw) => match raw.trim().parse::<SocketAddr>() {
            Ok(addr) => {
                info!("svc-mailbox: using RON_MAILBOX_ADDR={addr}");
                addr
            }
            Err(err) => {
                error!(
                    "svc-mailbox: invalid RON_MAILBOX_ADDR={raw:?}, \
                     falling back to {DEFAULT_MAILBOX_ADDR}: {err}"
                );
                DEFAULT_MAILBOX_ADDR
                    .parse()
                    .expect("DEFAULT_MAILBOX_ADDR must be a valid SocketAddr")
            }
        },
        Err(_) => DEFAULT_MAILBOX_ADDR
            .parse()
            .expect("DEFAULT_MAILBOX_ADDR must be a valid SocketAddr"),
    }
}

/// Spawn the mailbox worker.
///
/// This keeps behavior simple and test-friendly while giving us a stable
/// attach point for the future `svc-mailbox` integration.
pub fn spawn(probes: Arc<ReadyProbes>, shutdown: ShutdownToken) -> ManagedTask {
    let handle = tokio::spawn(async move {
        let addr = resolve_bind_addr();
        info!(
            %addr,
            "svc-mailbox: started (host shell, waiting for real svc-mailbox wiring)"
        );

        // Flip the per-service readiness bit once the worker has started.
        probes.set_mailbox_bound(true);

        // Lightweight wait loop; no busy-spin.
        while !shutdown.is_triggered() {
            sleep(Duration::from_secs(5)).await;
        }

        info!("svc-mailbox: shutdown requested, exiting worker");
    });

    ManagedTask::new("svc-mailbox", handle)
}

```

### crates/macronode/src/services/svc_overlay.rs
<a id="crates-macronode-src-services-svcoverlay-rs"></a>

```rust
// crates/macronode/src/services/svc_overlay.rs

//! RO:WHAT — Macronode wrapper for the overlay plane.
//! RO:WHY  — Provide a config-aware shell for overlay / gossip / connection
//!           management so we can later drop in the real `svc-overlay` crate
//!           without touching the supervisor surface.
//! RO:INVARIANTS —
//!   - Worker runs until shutdown is requested via `ShutdownToken`.
//!   - Bind address is resolved once at startup and logged.
//!   - No locks held across `.await` in this slice.
//!
//! RO:FUTURE —
//!   - Call into `svc-overlay` lib entrypoint with:
//!       * TransportConfig (from ron-transport)
//!       * Bus handle (for health/crash events)
//!       * ShutdownToken
//!   - Surface overlay health into `/api/v1/status` and Prometheus.

use std::net::SocketAddr;
use std::sync::Arc;
use std::time::Duration;

use tokio::time::sleep;
use tracing::{error, info};

use crate::{
    readiness::ReadyProbes,
    supervisor::{ManagedTask, ShutdownToken},
};

/// Default bind for the overlay plane (local-only in this slice).
const DEFAULT_OVERLAY_ADDR: &str = "127.0.0.1:5301";

/// Resolve the bind address for the overlay plane.
///
/// Env override:
///   - `RON_OVERLAY_ADDR=IP:PORT`
fn resolve_bind_addr() -> SocketAddr {
    match std::env::var("RON_OVERLAY_ADDR") {
        Ok(raw) => match raw.trim().parse::<SocketAddr>() {
            Ok(addr) => {
                info!("svc-overlay: using RON_OVERLAY_ADDR={addr}");
                addr
            }
            Err(err) => {
                error!(
                    "svc-overlay: invalid RON_OVERLAY_ADDR={raw:?}, \
                     falling back to {DEFAULT_OVERLAY_ADDR}: {err}"
                );
                DEFAULT_OVERLAY_ADDR
                    .parse()
                    .expect("DEFAULT_OVERLAY_ADDR must be a valid SocketAddr")
            }
        },
        Err(_) => DEFAULT_OVERLAY_ADDR
            .parse()
            .expect("DEFAULT_OVERLAY_ADDR must be a valid SocketAddr"),
    }
}

/// Spawn the overlay worker.
///
/// This keeps behavior simple and test-friendly while giving us a stable
/// attach point for the future `svc-overlay` integration.
pub fn spawn(probes: Arc<ReadyProbes>, shutdown: ShutdownToken) -> ManagedTask {
    let handle = tokio::spawn(async move {
        let addr = resolve_bind_addr();
        info!(
            %addr,
            "svc-overlay: started (host shell, waiting for real svc-overlay wiring)"
        );

        // Flip the per-service readiness bit once the worker has started.
        probes.set_overlay_bound(true);

        while !shutdown.is_triggered() {
            sleep(Duration::from_secs(5)).await;
        }

        info!("svc-overlay: shutdown requested, exiting worker");
    });

    ManagedTask::new("svc-overlay", handle)
}

```

### crates/macronode/src/services/svc_storage.rs
<a id="crates-macronode-src-services-svcstorage-rs"></a>

```rust
//! RO:WHAT — Macronode embedded svc-storage HTTP server.
//! RO:WHY  — Run the CAS storage plane (svc-storage) in-process as part of the
//!           macronode profile, instead of a separate process.
//! RO:INVARIANTS —
//!   - Binds to 127.0.0.1:5303 by default (override via RON_STORAGE_ADDR).
//!   - Uses in-memory MemoryStorage backend only in this slice (no disk I/O).
//!   - No locks held across `.await`; storage crate owns all HTTP details.

use std::net::SocketAddr;
use std::sync::Arc;

use tokio::task;
use tracing::{error, info};

use crate::supervisor::{ManagedTask, ShutdownToken};
use svc_storage::http::{extractors::AppState, server::serve_http};
use svc_storage::storage::{MemoryStorage, Storage};

/// Resolve the bind address for the embedded storage HTTP server.
///
/// Default: `127.0.0.1:5303`  
/// Override: `RON_STORAGE_ADDR=IP:PORT`
fn resolve_bind_addr() -> SocketAddr {
    const DEFAULT_ADDR: &str = "127.0.0.1:5303";

    match std::env::var("RON_STORAGE_ADDR") {
        Ok(raw) => match raw.trim().parse::<SocketAddr>() {
            Ok(addr) => {
                info!("svc-storage: using RON_STORAGE_ADDR={addr}");
                addr
            }
            Err(err) => {
                error!(
                    "svc-storage: invalid RON_STORAGE_ADDR={raw:?}, \
                     falling back to {DEFAULT_ADDR}: {err}"
                );
                DEFAULT_ADDR
                    .parse()
                    .expect("DEFAULT_ADDR must be a valid SocketAddr")
            }
        },
        Err(_) => DEFAULT_ADDR
            .parse()
            .expect("DEFAULT_ADDR must be a valid SocketAddr"),
    }
}

/// Spawn the embedded svc-storage HTTP server.
///
/// We now return a `ManagedTask` so the supervisor can watch the JoinHandle.
/// `shutdown` is still unused because `serve_http` does not yet accept a
/// shutdown signal; process exit tears it down.
pub fn spawn(_shutdown: ShutdownToken) -> ManagedTask {
    let handle = task::spawn(async move {
        let addr = resolve_bind_addr();

        info!("svc-storage: listening on {addr} (embedded in macronode)");

        // In-memory store (matches svc-storage/bin main wiring).
        let store: Arc<dyn Storage> = Arc::new(MemoryStorage::default());
        let state = AppState { store };

        // Delegate to svc-storage's HTTP server.
        match serve_http(addr, state).await {
            Ok(()) => {
                info!("svc-storage: server exited cleanly");
            }
            Err(err) => {
                error!("svc-storage: server error: {err:#}");
            }
        }
    });

    ManagedTask::new("svc-storage", handle)
}

```

### crates/macronode/src/supervisor/backoff.rs
<a id="crates-macronode-src-supervisor-backoff-rs"></a>

```rust
//! RO:WHAT — Exponential backoff helper for service restarts.
//! RO:WHY  — Give the supervisor a small, testable primitive to decide how
//!           long to wait before restarting a crashed worker.
//! RO:INVARIANTS —
//!   - Backoff never panics; it clamps at `max_delay`.
//!   - All math is done with safe, bounded integers.

#![allow(dead_code)]

use std::time::Duration;

/// Simple exponential backoff policy.
///
/// This is intentionally small; more elaborate jitter/strategy can be added
/// later without changing call sites.
#[derive(Debug, Clone)]
pub struct Backoff {
    base_delay: Duration,
    max_delay: Duration,
    attempt: u32,
}

impl Backoff {
    /// Construct a new backoff policy with the given base and max delay.
    #[must_use]
    pub fn new(base_delay: Duration, max_delay: Duration) -> Self {
        Self {
            base_delay,
            max_delay,
            attempt: 0,
        }
    }

    /// Reset the attempt counter back to zero.
    pub fn reset(&mut self) {
        self.attempt = 0;
    }

    /// Compute the next delay.
    ///
    /// Roughly: `delay = base_delay * 2^attempt`, clamped at `max_delay`.
    /// The attempt counter is incremented after each call.
    #[must_use]
    pub fn next_delay(&mut self) -> Duration {
        // 2^attempt as a u32, clamped so we never shift by >= 32.
        let exp = self.attempt.min(31);
        let factor: u32 = 1u32.checked_shl(exp).unwrap_or(u32::MAX);

        let candidate = self.base_delay.saturating_mul(factor);
        self.attempt = self.attempt.saturating_add(1);

        if candidate > self.max_delay {
            self.max_delay
        } else {
            candidate
        }
    }
}

```

### crates/macronode/src/supervisor/crash_policy.rs
<a id="crates-macronode-src-supervisor-crashpolicy-rs"></a>

```rust
//! RO:WHAT — Crash policy helper for the macronode supervisor.
//! RO:WHY  — Decide whether we should restart a crashing service based on
//!           how many times it has crashed within a rolling time window.
//! RO:INVARIANTS —
//!   - We only look at crashes within a sliding window (e.g. last 60s).
//!   - If the number of recent crashes exceeds `max_restarts`, we stop
//!     restarting and mark the service as permanently failed.
//!   - This module is *pure* logic: it has no side effects and can be
//!     unit-tested independently.
//!
//! RO:INTERACTS —
//!   - Intended to be used by `Supervisor` when a service task exits.
//!   - `crash_times` should be maintained by the supervisor as a log of
//!     `Instant`s when each service crashed.
//!
//! RO:NOTES —
//!   - This is groundwork: at the moment the supervisor still only spawns
//!     services once. Wiring this into the actual restart loop is a
//!     future slice so we keep behavior identical for now.

use std::time::{Duration, Instant};

/// Simple crash policy: allow up to `max_restarts` crashes within a
/// rolling `window` duration.
///
/// Example:
///   - `max_restarts = 5`
///   - `window = 60s`
///
/// If a service crashes 6+ times within the last 60 seconds, we should
/// stop trying to restart it and surface a permanent failure upstream.
#[derive(Debug, Clone, Copy)]
pub struct CrashPolicy {
    max_restarts: usize,
    window: Duration,
}

impl CrashPolicy {
    /// Construct a new crash policy.
    ///
    /// * `max_restarts` — maximum allowed crashes within `window`
    /// * `window`       — time window we consider "recent"
    pub fn new(max_restarts: usize, window: Duration) -> Self {
        CrashPolicy {
            max_restarts,
            window,
        }
    }

    /// Maximum allowed restarts within the window.
    pub fn max_restarts(&self) -> usize {
        self.max_restarts
    }

    /// Rolling window length used when counting recent crashes.
    pub fn window(&self) -> Duration {
        self.window
    }

    /// Decide whether we should attempt another restart *now* given the
    /// crash history for a service.
    ///
    /// * `crash_times` — slice of `Instant`s when this service crashed.
    ///   The supervisor owns and maintains this log.
    /// * `now`         — current time, usually `Instant::now()`.
    ///
    /// Returns `true` if we are still within the allowed restart budget
    /// for the configured window, `false` if we should stop restarting.
    pub fn should_restart(&self, crash_times: &[Instant], now: Instant) -> bool {
        // Compute the beginning of the window. On the off chance that
        // `now < window` (very early in process lifetime), we treat the
        // window start as `now` so that every crash is considered "recent"
        // and we still honor `max_restarts`.
        let window_start = now.checked_sub(self.window).unwrap_or(now);

        // Count crashes that occurred within [window_start, now].
        let recent = crash_times
            .iter()
            .copied()
            .filter(|&t| t >= window_start)
            .count();

        recent <= self.max_restarts
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn allows_restarts_below_threshold() {
        let policy = CrashPolicy::new(3, Duration::from_secs(60));
        let now = Instant::now();

        // Two crashes in the window, threshold is three.
        let crashes = vec![now - Duration::from_secs(10), now - Duration::from_secs(20)];

        assert!(policy.should_restart(&crashes, now));
    }

    #[test]
    fn denies_restarts_above_threshold() {
        let policy = CrashPolicy::new(3, Duration::from_secs(60));
        let now = Instant::now();

        // Four crashes all within the last 60 seconds.
        let crashes = vec![
            now - Duration::from_secs(5),
            now - Duration::from_secs(10),
            now - Duration::from_secs(20),
            now - Duration::from_secs(30),
        ];

        assert!(!policy.should_restart(&crashes, now));
    }

    #[test]
    fn ignores_crashes_outside_window() {
        let policy = CrashPolicy::new(2, Duration::from_secs(30));
        let now = Instant::now();

        // One very old crash (outside window), two recent ones.
        let crashes = vec![
            now - Duration::from_secs(300),
            now - Duration::from_secs(5),
            now - Duration::from_secs(10),
        ];

        // Only the two recent crashes should count → still within budget.
        assert!(policy.should_restart(&crashes, now));
    }
}

```

### crates/macronode/src/supervisor/health_reporter.rs
<a id="crates-macronode-src-supervisor-healthreporter-rs"></a>

```rust
//! RO:WHAT — Health reporting helper for Macronode supervisor.
//! RO:WHY  — Provide a small adapter object that can fan supervisor state
//!           into readiness probes or structured status maps.
//! RO:INVARIANTS —
//!   - This module is pure; it does not spawn tasks or own timers.

#![allow(dead_code)]

use std::collections::BTreeMap;

/// High-level status of a logical service.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ServiceHealth {
    Stub,
    Starting,
    Running,
    Draining,
    Failed,
}

impl ServiceHealth {
    #[must_use]
    pub const fn is_healthy(self) -> bool {
        matches!(self, ServiceHealth::Running | ServiceHealth::Draining)
    }
}

/// Aggregated view of service health used for `/api/v1/status`.
#[derive(Debug, Default)]
pub struct HealthSnapshot {
    services: BTreeMap<&'static str, ServiceHealth>,
}

impl HealthSnapshot {
    /// Record or update the health for a named service.
    pub fn set_service(&mut self, name: &'static str, health: ServiceHealth) {
        self.services.insert(name, health);
    }

    /// Immutable view of the underlying map for serialization or logging.
    #[must_use]
    pub fn services(&self) -> &BTreeMap<&'static str, ServiceHealth> {
        &self.services
    }
}

```

### crates/macronode/src/supervisor/lifecycle.rs
<a id="crates-macronode-src-supervisor-lifecycle-rs"></a>

```rust
//! RO:WHAT — Lifecycle primitives for supervised service tasks.
//! RO:WHY  — Provide a small abstraction for representing a running worker
//!           (JoinHandle + metadata) without yet implementing crash detection.
//! RO:INVARIANTS —
//!   - Zero side effects today.
//!   - No panics; noop watch() until the next slice.
//!   - Forward-compatible with crash detection and restart loops.

#![allow(dead_code)]

use std::fmt;
use tokio::task::JoinHandle;

/// High-level state of a supervised service.
///
/// This is intentionally simple; we'll expand once restart flows land.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum LifecycleState {
    Starting,
    Running,
    Stopping,
    Stopped,
}

/// A managed worker task.
///
/// Right now this is just a placeholder so that Supervisor can begin to
/// track per-service join handles without altering behavior.
pub struct ManagedTask {
    pub service_name: &'static str,
    pub handle: JoinHandle<()>,
}

impl ManagedTask {
    /// Construct a new managed worker.
    #[must_use]
    pub fn new(service_name: &'static str, handle: JoinHandle<()>) -> Self {
        Self {
            service_name,
            handle,
        }
    }

    /// Placeholder: later this will become the crash detection hook.
    ///
    /// For now it simply awaits the handle and swallows any JoinError so
    /// existing test behavior is unaffected.
    pub async fn watch(self) {
        let _ = self.handle.await;
        // In a future step:
        //   - detect crash vs clean exit
        //   - update probes
        //   - notify supervisor restart loop
    }
}

impl fmt::Debug for ManagedTask {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("ManagedTask")
            .field("service_name", &self.service_name)
            .finish()
    }
}

```

### crates/macronode/src/supervisor/mod.rs
<a id="crates-macronode-src-supervisor-mod-rs"></a>

```rust
//! RO:WHAT — Process supervisor scaffold for Macronode.
//! RO:WHY  — Central place to coordinate service startup/shutdown.
//! RO:INVARIANTS —
//!   - Crash policy + backoff are wired but *not yet* used to restart tasks.
//!   - Graceful shutdown orchestration is still a future slice.
//!   - Health reporting to readiness/admin planes is still a future slice.
//!   - This slice *adds* task watchers that log service exits, but they do
//!     NOT restart services or mutate readiness yet.

#![allow(dead_code)]

mod backoff;
mod crash_policy;
mod health_reporter;
mod lifecycle;
mod shutdown;

use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, Instant};

use crate::{errors::Result, readiness::ReadyProbes, services};

pub use lifecycle::ManagedTask;
pub use shutdown::ShutdownToken;

use backoff::Backoff;
use crash_policy::CrashPolicy;
use health_reporter::HealthSnapshot;
use lifecycle::LifecycleState;
use tracing::{error, info};

/// Macronode process supervisor (MVP).
///
/// Currently minimal: only boots services. This module now also contains the
/// internal logic for combining CrashPolicy + Backoff into a restart
/// decision API. In this slice we additionally attach *watchers* to service
/// tasks so we log when they exit, but we still DO NOT restart anything.
#[derive(Debug)]
pub struct Supervisor {
    /// Shared readiness probes used by admin plane and readiness endpoints.
    probes: Arc<ReadyProbes>,
    /// Cooperative shutdown token shared with all managed services.
    shutdown: ShutdownToken,
    /// Coarse lifecycle state.
    lifecycle: LifecycleState,
    /// Aggregated view of per-service health.
    health: HealthSnapshot,
    /// Policy controlling restart aggressiveness.
    crash_policy: CrashPolicy,
    /// Exponential backoff state used between restarts.
    backoff: Backoff,
    /// Rolling crash timestamps per logical service name.
    ///
    /// This log is consulted by `crash_policy.should_restart(...)` to decide
    /// whether a service is still within its restart budget.
    crash_log: HashMap<&'static str, Vec<Instant>>,
}

impl Supervisor {
    /// Construct a new supervisor handle.
    pub fn new(probes: Arc<ReadyProbes>, shutdown: ShutdownToken) -> Self {
        let crash_policy = CrashPolicy::new(5, Duration::from_secs(60));
        let backoff = Backoff::new(Duration::from_secs(1), Duration::from_secs(30));

        Supervisor {
            probes,
            shutdown,
            lifecycle: LifecycleState::Starting,
            health: HealthSnapshot::default(),
            crash_policy,
            backoff,
            crash_log: HashMap::new(),
        }
    }

    /// Start all managed services.
    ///
    /// This now delegates to `services::spawn_all`, receives a vector of
    /// `ManagedTask` handles, and attaches lightweight watcher tasks that
    /// simply log when services exit (cleanly, cancelled, or crashed).
    /// There is STILL no restart logic in this slice.
    pub async fn start(&self) -> Result<()> {
        let tasks: Vec<ManagedTask> =
            services::spawn_all(self.probes.clone(), self.shutdown.clone()).await?;

        self.spawn_watchers(tasks);
        Ok(())
    }

    /// Attach background watchers to each managed service task.
    ///
    /// Each watcher:
    ///   - awaits the JoinHandle
    ///   - logs on clean exit, cancellation, or crash
    ///   - does NOT restart or mutate readiness yet
    fn spawn_watchers(&self, tasks: Vec<ManagedTask>) {
        for task in tasks {
            let service = task.service_name;
            let handle = task.handle;

            tokio::spawn(async move {
                match handle.await {
                    Ok(()) => {
                        info!(
                            %service,
                            "macronode supervisor: service task exited cleanly"
                        );
                    }
                    Err(err) if err.is_cancelled() => {
                        info!(
                            %service,
                            "macronode supervisor: service task cancelled (likely shutdown)"
                        );
                    }
                    Err(err) => {
                        error!(
                            %service,
                            %err,
                            "macronode supervisor: service task crashed"
                        );
                    }
                }
            });
        }
    }

    // ---------------------------------------------------------------------
    //  Crash policy + backoff glue (internal API, not used for restarts yet)
    // ---------------------------------------------------------------------

    /// Record a crash event for a service.
    ///
    /// This is a pure bookkeeping method: it appends `Instant::now()` to the
    /// crash log for `service`. A future watcher loop will call this whenever
    /// a worker task exits with an error or panic.
    pub fn record_crash(&mut self, service: &'static str) {
        let now = Instant::now();
        let entry = self.crash_log.entry(service).or_default();
        entry.push(now);
    }

    /// Decide how long to wait before restarting a crashed service.
    ///
    /// Returns:
    ///   - `Some(delay)` if we are still within the restart budget for
    ///     `service`, where `delay` is derived from the exponential backoff.
    ///   - `None` if we should *not* restart anymore (permanent failure).
    ///
    /// This method is intentionally side-effect-free except for advancing
    /// the backoff state; it does not spawn tasks or toggle readiness flags.
    pub fn restart_delay(&mut self, service: &'static str) -> Option<Duration> {
        let now = Instant::now();

        let crashes = self
            .crash_log
            .get(service)
            .map(Vec::as_slice)
            .unwrap_or(&[]);

        // If we've exceeded the allowed number of restarts within the window,
        // bail out and let the caller surface a permanent failure.
        if !self.crash_policy.should_restart(crashes, now) {
            return None;
        }

        // Otherwise we are allowed to restart; advance the backoff sequence.
        Some(self.backoff.next_delay())
    }

    /// Reset backoff state and optionally clear crash history.
    ///
    /// For now we only reset the backoff counter and leave the crash log
    /// intact. A future slice may choose to clear `crash_log` entries for
    /// services that have been healthy for long enough.
    pub fn reset_backoff(&mut self) {
        self.backoff.reset();
    }
}

impl Default for Supervisor {
    fn default() -> Self {
        Supervisor::new(Arc::new(ReadyProbes::new()), ShutdownToken::new())
    }
}

```

### crates/macronode/src/supervisor/shutdown.rs
<a id="crates-macronode-src-supervisor-shutdown-rs"></a>

```rust
//! RO:WHAT — Simple cooperative shutdown token for Macronode.
//! RO:WHY  — Give the supervisor and services a shared, cheap way to
//!           coordinate graceful shutdown without pulling in extra deps.
//! RO:INVARIANTS —
//!   - `trigger()` is idempotent.
//!   - `is_triggered()` is lock-free and wait-free.

use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc,
};

/// Cheap, cloneable shutdown token.
///
/// This does not provide async notification; workers are expected to
/// periodically call `is_triggered()` inside their own loops.
#[derive(Clone, Debug)]
pub struct ShutdownToken {
    inner: Arc<AtomicBool>,
}

impl ShutdownToken {
    /// Construct a new token in the "not triggered" state.
    pub fn new() -> Self {
        Self {
            inner: Arc::new(AtomicBool::new(false)),
        }
    }

    /// Signal shutdown to all holders of this token.
    pub fn trigger(&self) {
        self.inner.store(true, Ordering::Release);
    }

    /// Check whether shutdown has been requested.
    pub fn is_triggered(&self) -> bool {
        self.inner.load(Ordering::Acquire)
    }
}

impl Default for ShutdownToken {
    fn default() -> Self {
        Self::new()
    }
}

```

### crates/macronode/src/types.rs
<a id="crates-macronode-src-types-rs"></a>

```rust
//! RO:WHAT — Shared runtime types for Macronode.
//! RO:WHY  — Keep main/http modules thin by centralizing state and build info.

use std::{sync::Arc, time::Instant};

use crate::{bus::NodeBus, config::Config, readiness::ReadyProbes};

#[derive(Clone)]
pub struct AppState {
    pub cfg: Arc<Config>,
    pub probes: Arc<ReadyProbes>,
    /// Intra-node event bus used for KernelEvent traffic (config updates,
    /// health changes, crash notices, etc.).
    pub bus: NodeBus,
    pub started_at: Instant,
}

/// Build-time info used by `/version`.
///
/// We keep this minimal for now; once a build script is in place
/// we can plumb git SHA, build timestamp, and rustc/msrv versions.
pub struct BuildInfo {
    pub service: &'static str,
    pub version: &'static str,
    pub git_sha: &'static str,
    pub build_ts: &'static str,
    pub rustc: &'static str,
    pub msrv: &'static str,
}

impl BuildInfo {
    pub fn current() -> Self {
        Self {
            service: "macronode",
            version: env!("CARGO_PKG_VERSION"),
            git_sha: "unknown",
            build_ts: "unknown",
            rustc: "unknown",
            msrv: "1.80.0",
        }
    }
}

```

### crates/macronode/src/util/dur.rs
<a id="crates-macronode-src-util-dur-rs"></a>

```rust
//! RO:WHAT — Duration helpers for Macronode.
//! RO:WHY  — Avoid sprinkling raw `Duration::from_secs` calls and magic
//!           numbers (like 1000) throughout the codebase.
//! RO:INVARIANTS —
//!   - Helpers are thin wrappers over `std::time::Duration`.
//!   - Parsing helpers never panic; they return `Result`.

#![allow(dead_code)]

use std::num::ParseIntError;
use std::time::Duration;

/// Construct a duration from whole milliseconds.
#[must_use]
pub const fn millis(ms: u64) -> Duration {
    Duration::from_millis(ms)
}

/// Construct a duration from whole seconds.
#[must_use]
pub const fn seconds(secs: u64) -> Duration {
    Duration::from_secs(secs)
}

/// Construct a duration from whole minutes.
#[must_use]
pub const fn minutes(mins: u64) -> Duration {
    Duration::from_secs(mins * 60)
}

/// Parse a duration expressed as whole seconds (e.g. from an env var).
///
/// Whitespace is trimmed; invalid inputs yield a `ParseIntError`.
pub fn parse_seconds(input: &str) -> Result<Duration, ParseIntError> {
    let secs: u64 = input.trim().parse()?;
    Ok(Duration::from_secs(secs))
}

```

### crates/macronode/src/util/sizes.rs
<a id="crates-macronode-src-util-sizes-rs"></a>

```rust
//! RO:WHAT — Byte-size helpers for Macronode.
//! RO:WHY  — Make size-related config and limits more readable (MiB/GiB)
//!           and avoid repeating 1024 * 1024 everywhere.
//! RO:INVARIANTS —
//!   - Helpers are simple arithmetic and never panic on normal inputs.

#![allow(dead_code)]

/// 1 KiB in bytes.
pub const KIB: u64 = 1024;
/// 1 MiB in bytes.
pub const MIB: u64 = 1024 * 1024;
/// 1 GiB in bytes.
pub const GIB: u64 = 1024 * 1024 * 1024;

/// Return `n` kibibytes in bytes.
#[must_use]
pub const fn kib(n: u64) -> u64 {
    n * KIB
}

/// Return `n` mebibytes in bytes.
#[must_use]
pub const fn mib(n: u64) -> u64 {
    n * MIB
}

/// Return `n` gibibytes in bytes.
#[must_use]
pub const fn gib(n: u64) -> u64 {
    n * GIB
}

```

### crates/macronode/tests/admin_smoke.rs
<a id="crates-macronode-tests-adminsmoke-rs"></a>

```rust
//! RO:WHAT — End-to-end smoke test for the Macronode admin plane.
//! RO:WHY  — Prove that `/version`, `/healthz`, `/readyz`, `/metrics`,
//!           `/api/v1/status`, and `/api/v1/shutdown` all behave sanely.
//!
//! This test boots the real `macronode` binary via `CARGO_BIN_EXE_macronode`,
//! waits for it to come up, hits the core admin endpoints, and then shuts the
//! node down via the HTTP control surface.

use std::process::{Child, Command, Stdio};
use std::time::Duration;

use anyhow::{anyhow, Context, Result};
use reqwest::Client;
use serde_json::Value;
use tokio::time::sleep;

const ADMIN_PORT: u16 = 18080;
const GATEWAY_PORT: u16 = 18090;

/// Spawn the macronode binary and wait until the **full admin HTTP stack** is
/// available by polling `/version`, not just `/healthz`.
///
/// `/healthz` only proves that the event loop is alive; `/version` requires
/// the admin listener, router, and middleware stack to be bound and serving.
async fn spawn_macronode() -> Result<(Child, Client, String)> {
    let bin = env!("CARGO_BIN_EXE_macronode");

    let mut cmd = Command::new(bin);
    cmd.arg("run")
        .env("RUST_LOG", "info,macronode=debug")
        // Per-test ports to avoid collisions when tests run in parallel.
        .env("RON_HTTP_ADDR", format!("127.0.0.1:{ADMIN_PORT}"))
        .env("RON_GATEWAY_ADDR", format!("127.0.0.1:{GATEWAY_PORT}"))
        // Keep test output quiet by default.
        .stdout(Stdio::null())
        .stderr(Stdio::null());

    let child = cmd.spawn().context("failed to spawn macronode binary")?;

    let client = Client::builder()
        .timeout(Duration::from_secs(5))
        .build()
        .context("failed to build reqwest client")?;

    let base = format!("http://127.0.0.1:{ADMIN_PORT}");

    // Wait for `/version` to go green, which implies the full HTTP stack is up.
    for _ in 0..50 {
        match client.get(format!("{base}/version")).send().await {
            Ok(resp) if resp.status().is_success() => return Ok((child, client, base)),
            _ => sleep(Duration::from_millis(200)).await,
        }
    }

    Err(anyhow!("macronode did not expose /version in time"))
}

async fn shutdown_macronode(mut child: Child, client: &Client, base: &str) -> Result<()> {
    let resp = client
        .post(format!("{base}/api/v1/shutdown"))
        .send()
        .await
        .context("failed to call /api/v1/shutdown")?;

    // Log status/body when tests are run with --nocapture or RUST_LOG on.
    let status = resp.status();
    let body_text = resp.text().await.unwrap_or_default();
    eprintln!("[admin_smoke] /shutdown status={status} body={body_text}");

    // Give the process a few seconds to exit cleanly.
    for _ in 0..50 {
        if let Ok(Some(_status)) = child.try_wait() {
            return Ok(());
        }
        sleep(Duration::from_millis(200)).await;
    }

    // If it is still running, kill it to avoid hanging tests.
    let _ = child.kill();
    Err(anyhow!("macronode did not exit cleanly after /shutdown"))
}

#[tokio::test(flavor = "multi_thread")]
async fn admin_plane_smoke() -> Result<()> {
    let (child, client, base) = spawn_macronode().await?;

    // /version
    let resp = client
        .get(format!("{base}/version"))
        .send()
        .await
        .context("GET /version failed")?;
    assert!(resp.status().is_success());
    let body: Value = resp.json().await.context("decode /version body")?;
    // /version contract: includes `service: "macronode"` plus build info.
    assert_eq!(body["service"], "macronode");
    assert!(body["version"].is_string());
    assert!(body["git_sha"].is_string());
    assert!(body["api"]["http"].is_string());

    // /healthz
    let resp = client
        .get(format!("{base}/healthz"))
        .send()
        .await
        .context("GET /healthz failed")?;
    assert!(resp.status().is_success());
    let body: Value = resp.json().await.context("decode /healthz body")?;
    assert_eq!(body["ok"], true);

    // /readyz
    let resp = client
        .get(format!("{base}/readyz"))
        .send()
        .await
        .context("GET /readyz failed")?;
    assert!(
        resp.status().is_success(),
        "expected /readyz 200 when node is up"
    );
    let body: Value = resp.json().await.context("decode /readyz body")?;
    assert_eq!(body["ready"], true);
    // Basic sanity on deps.
    assert_eq!(body["deps"]["config"], "loaded");
    assert_eq!(body["deps"]["network"], "ok");
    assert_eq!(body["deps"]["gateway"], "ok");

    // /metrics
    let resp = client
        .get(format!("{base}/metrics"))
        .send()
        .await
        .context("GET /metrics failed")?;
    assert!(resp.status().is_success(), "/metrics must return 200 OK");

    let headers = resp.headers().clone();
    let text = resp.text().await.context("decode /metrics body")?;

    // Content-type should be text/plain; charset=utf-8 (Axum default for String).
    if let Some(ct) = headers.get(reqwest::header::CONTENT_TYPE) {
        let ct = ct.to_str().unwrap_or_default();
        assert!(
            ct.starts_with("text/plain"),
            "expected text/plain content-type for /metrics, got {ct}"
        );
    }

    // We don't yet enforce that the metrics body is non-empty, only that it is
    // reasonably small and successfully returned as text.
    assert!(
        text.len() < 1024 * 1024,
        "/metrics body should not exceed 1 MiB in tests"
    );

    // /api/v1/status
    let resp = client
        .get(format!("{base}/api/v1/status"))
        .send()
        .await
        .context("GET /api/v1/status failed")?;
    assert!(resp.status().is_success());
    let body: Value = resp.json().await.context("decode /api/v1/status body")?;
    // Status contract: uses `profile: "macronode"` (not `service`).
    assert_eq!(body["profile"], "macronode");
    assert!(body["uptime_seconds"].as_f64().unwrap_or(0.0) >= 0.0);
    // We expect a services map with at least gateway present.
    let services = body["services"].as_object().expect("services map present");
    assert!(
        services.contains_key("svc-gateway"),
        "status.services should contain svc-gateway"
    );

    // Drive shutdown through the HTTP surface.
    shutdown_macronode(child, &client, &base).await?;

    Ok(())
}

```

### crates/macronode/tests/metrics_contract.rs
<a id="crates-macronode-tests-metricscontract-rs"></a>

```rust
//! RO:WHAT — Contract test for the `/metrics` surface.
//! RO:WHY  — Ensure Macronode always exposes a Prometheus text endpoint,
//!           even before we add richer metric series.

use std::process::{Child, Command, Stdio};
use std::time::Duration;

use anyhow::{anyhow, Context, Result};
use reqwest::Client;
use tokio::time::sleep;

const ADMIN_PORT: u16 = 18081;
const GATEWAY_PORT: u16 = 18091;

async fn spawn_macronode() -> Result<(Child, Client, String)> {
    let bin = env!("CARGO_BIN_EXE_macronode");

    let mut cmd = Command::new(bin);
    cmd.arg("run")
        .env("RUST_LOG", "info,macronode=debug")
        .env("RON_HTTP_ADDR", format!("127.0.0.1:{ADMIN_PORT}"))
        .env("RON_GATEWAY_ADDR", format!("127.0.0.1:{GATEWAY_PORT}"))
        .stdout(Stdio::null())
        .stderr(Stdio::null());

    let child = cmd.spawn().context("failed to spawn macronode binary")?;

    let client = Client::builder()
        .timeout(Duration::from_secs(5))
        .build()
        .context("failed to build reqwest client")?;

    let base = format!("http://127.0.0.1:{ADMIN_PORT}");

    // Wait for `/healthz` to be OK.
    for _ in 0..50 {
        match client.get(format!("{base}/healthz")).send().await {
            Ok(resp) if resp.status().is_success() => return Ok((child, client, base)),
            _ => sleep(Duration::from_millis(200)).await,
        }
    }

    Err(anyhow!("macronode did not become healthy in time"))
}

async fn shutdown_macronode(mut child: Child) {
    // Best-effort kill; this test is only concerned that /metrics is present.
    for _ in 0..10 {
        if let Ok(Some(_)) = child.try_wait() {
            return;
        }
        sleep(Duration::from_millis(100)).await;
    }
    let _ = child.kill();
}

#[tokio::test(flavor = "multi_thread")]
async fn metrics_endpoint_exists_and_is_text() -> Result<()> {
    let (child, client, base) = spawn_macronode().await?;

    let resp = client
        .get(format!("{base}/metrics"))
        .send()
        .await
        .context("GET /metrics failed")?;
    assert!(resp.status().is_success(), "/metrics must return 200 OK");

    let headers = resp.headers().clone();
    let body = resp.text().await.context("decode /metrics body")?;

    // Content-type should be text/plain; charset=utf-8 (Axum default for String).
    if let Some(ct) = headers.get(reqwest::header::CONTENT_TYPE) {
        let ct = ct.to_str().unwrap_or_default();
        assert!(
            ct.starts_with("text/plain"),
            "expected text/plain content-type for /metrics, got {ct}"
        );
    }

    // Even if we have no custom metrics yet, the body should not be enormous
    // and should be valid UTF-8 text.
    assert!(
        body.len() < 1024 * 1024,
        "metrics body should not exceed 1 MiB in tests"
    );

    shutdown_macronode(child).await;
    Ok(())
}

```

### crates/macronode/tests/readiness_drain.rs
<a id="crates-macronode-tests-readinessdrain-rs"></a>

```rust
//! RO:WHAT  — Contract tests for `/readyz` truthfulness vs dev-forced mode.
//! RO:WHY   — Ensure orchestrators (K8s/systemd/CI) can trust readiness, and
//!            that the dev override flag behaves exactly as documented.
//!
//! RO:INVARIANTS —
//!   - Truthful mode: `MACRONODE_DEV_READY` is *not* set in the child env.
//!       * `/readyz` eventually returns HTTP 200 with `"mode":"truthful"` and
//!         `"ready":true` once the node has finished booting.
//!   - Dev-forced mode: `MACRONODE_DEV_READY=1` in the child env.
//!       * `/readyz` quickly returns HTTP 200 with `"ready":true` even if some
//!         deps are still pending; `mode` should be either `"dev-forced"` or
//!         `"truthful"` depending on how far the node has progressed.
//!
//! These tests never rely on a config file path. All config comes from
//! environment variables passed to the spawned child, just like the
//! `admin_smoke` and `metrics_contract` tests.

use std::process::{Child, Command, Stdio};
use std::time::{Duration, Instant};

use reqwest::{Client, StatusCode};
use serde_json::Value;
use tokio::time::sleep;

// Use dedicated ports so we don't collide with other tests.
const ADMIN_PORT: u16 = 18082;
const GATEWAY_PORT: u16 = 18092;

/// Spawn a macronode child process with a controlled environment.
///
/// If `dev_ready` is:
///   - `None`        => ensure `MACRONODE_DEV_READY` is *removed* from the child env.
///   - `Some(true)`  => set `MACRONODE_DEV_READY=1`.
///   - `Some(false)` => set `MACRONODE_DEV_READY=0` (does NOT trigger dev mode).
fn spawn_macronode(dev_ready: Option<bool>) -> Child {
    let bin = env!("CARGO_BIN_EXE_macronode");

    let mut cmd = Command::new(bin);
    cmd.arg("run")
        // Keep logs visible enough for debugging without being spammy.
        .env("RUST_LOG", "info,macronode=debug")
        // Configure admin + gateway addresses via env (no config file).
        .env("RON_HTTP_ADDR", format!("127.0.0.1:{ADMIN_PORT}"))
        .env("RON_GATEWAY_ADDR", format!("127.0.0.1:{GATEWAY_PORT}"))
        // Silence child stdout/stderr by default (tests can use --nocapture if desired).
        .stdout(Stdio::null())
        .stderr(Stdio::null());

    match dev_ready {
        None => {
            cmd.env_remove("MACRONODE_DEV_READY");
        }
        Some(true) => {
            cmd.env("MACRONODE_DEV_READY", "1");
        }
        Some(false) => {
            cmd.env("MACRONODE_DEV_READY", "0");
        }
    }

    cmd.spawn().expect("failed to spawn macronode child")
}

/// Poll `/readyz` until it reports the expected mode + ready flag, or time out.
///
/// This function is tolerant of early connection failures (e.g. TCP
/// connection refused while the admin listener is still binding) and treats
/// them as "not ready yet".
async fn wait_for_readyz_mode(
    client: &Client,
    admin_base: &str,
    expected_mode: &str,
    expected_ready: bool,
    overall_timeout: Duration,
) {
    let deadline = Instant::now() + overall_timeout;

    loop {
        match client.get(&format!("{admin_base}/readyz")).send().await {
            Ok(resp) => {
                let status = resp.status();
                let body: Value = resp
                    .json()
                    .await
                    .expect("failed to parse /readyz JSON body");

                let mode = body
                    .get("mode")
                    .and_then(Value::as_str)
                    .unwrap_or_default()
                    .to_string();
                let ready = body.get("ready").and_then(Value::as_bool).unwrap_or(false);

                if mode == expected_mode && ready == expected_ready && status == StatusCode::OK {
                    // Reached desired state.
                    return;
                }
            }
            Err(_e) => {
                // Connection refused / timeout: admin plane not up yet.
                // Treat as "not ready yet" and keep polling until deadline.
            }
        }

        if Instant::now() >= deadline {
            panic!(
                "/readyz never reached mode={expected_mode:?}, ready={expected_ready} \
                 within {:?}",
                overall_timeout
            );
        }

        sleep(Duration::from_millis(100)).await;
    }
}

/// POST `/api/v1/shutdown` and wait for the child process to exit.
///
/// For these tests we only require that the node terminates in a bounded
/// amount of time. We do *not* enforce that the exit code is zero, since
/// dev/test profiles may choose to exit with non-zero codes for various
/// reasons (e.g. simulated faults).
async fn shutdown_and_wait(client: &Client, admin_base: &str, child: &mut Child) {
    let resp = client
        .post(&format!("{admin_base}/api/v1/shutdown"))
        .send()
        .await
        .expect("failed to send /shutdown");

    assert!(
        resp.status().is_success(),
        "/shutdown did not return success, got {}",
        resp.status()
    );

    let deadline = Instant::now() + Duration::from_secs(10);

    loop {
        if let Some(status) = child.try_wait().expect("failed to poll child status") {
            eprintln!("[readiness_drain] macronode exited after /shutdown: {status}");
            // Do not assert on success; for readiness tests we only care that
            // the process actually terminates within the timeout.
            return;
        }

        if Instant::now() >= deadline {
            panic!("macronode did not exit within timeout after /shutdown");
        }

        sleep(Duration::from_millis(100)).await;
    }
}

#[tokio::test(flavor = "multi_thread")]
async fn readyz_truthful_mode_eventually_ready() {
    // Spawn WITHOUT dev override; explicitly remove MACRONODE_DEV_READY from
    // the child env so we are not affected by whatever the parent shell has.
    let mut child = spawn_macronode(None);
    let client = Client::new();
    let admin_base = format!("http://127.0.0.1:{ADMIN_PORT}");

    // In truthful mode we expect:
    //   { "mode": "truthful", "ready": true }
    // within a reasonable timeout.
    wait_for_readyz_mode(
        &client,
        &admin_base,
        "truthful",
        true,
        Duration::from_secs(20),
    )
    .await;

    shutdown_and_wait(&client, &admin_base, &mut child).await;
}

#[tokio::test(flavor = "multi_thread")]
async fn readyz_dev_forced_mode() {
    // Spawn WITH dev override enabled only in the child env.
    let mut child = spawn_macronode(Some(true));
    let client = Client::new();
    let admin_base = format!("http://127.0.0.1:{ADMIN_PORT}");

    // In dev-forced mode we care primarily that readiness flips to true quickly.
    // The mode string may be "dev-forced" early, then "truthful" once all deps
    // are genuinely ready; either is acceptable as long as ready=true.
    let overall_timeout = Duration::from_secs(10);
    let deadline = Instant::now() + overall_timeout;

    loop {
        match client.get(&format!("{admin_base}/readyz")).send().await {
            Ok(resp) => {
                if resp.status() == StatusCode::OK {
                    let body: Value = resp
                        .json()
                        .await
                        .expect("failed to parse /readyz JSON body");

                    let ready = body.get("ready").and_then(Value::as_bool).unwrap_or(false);

                    if ready {
                        let mode = body
                            .get("mode")
                            .and_then(Value::as_str)
                            .unwrap_or_default()
                            .to_string();

                        // Sanity: mode should be one of the known variants.
                        assert!(
                            mode == "dev-forced" || mode == "truthful",
                            "unexpected /readyz mode in dev-forced test: {mode}"
                        );

                        shutdown_and_wait(&client, &admin_base, &mut child).await;
                        return;
                    }
                }
            }
            Err(_e) => {
                // Listener not up yet; keep trying until deadline.
            }
        }

        if Instant::now() >= deadline {
            panic!(
                "/readyz never reached ready=true within {:?} (dev-forced test)",
                overall_timeout
            );
        }

        sleep(Duration::from_millis(100)).await;
    }
}

```



---



# svc-registry

_Source: crates/svc-registry/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-11-10T22:41:06Z -->
# Code Bundle — `svc-registry`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/svc-registry/.github/workflows/ci.yml](#crates-svc-registry--github-workflows-ci-yml)
- [crates/svc-registry/.github/workflows/perf.yml](#crates-svc-registry--github-workflows-perf-yml)
- [crates/svc-registry/.github/workflows/render-mermaid.yml](#crates-svc-registry--github-workflows-render-mermaid-yml)
- [crates/svc-registry/Cargo.toml](#crates-svc-registry-Cargo-toml)
- [crates/svc-registry/benches/blake3_payload.rs](#crates-svc-registry-benches-blake3payload-rs)
- [crates/svc-registry/benches/verify_approvals.rs](#crates-svc-registry-benches-verifyapprovals-rs)
- [crates/svc-registry/build.rs](#crates-svc-registry-build-rs)
- [crates/svc-registry/fuzz/fuzz_targets/approval_payload.rs](#crates-svc-registry-fuzz-fuzztargets-approvalpayload-rs)
- [crates/svc-registry/fuzz/fuzz_targets/dto_decode.rs](#crates-svc-registry-fuzz-fuzztargets-dtodecode-rs)
- [crates/svc-registry/scripts/perf_sweep.sh](#crates-svc-registry-scripts-perfsweep-sh)
- [crates/svc-registry/scripts/render_mermaid.sh](#crates-svc-registry-scripts-rendermermaid-sh)
- [crates/svc-registry/scripts/run_local.sh](#crates-svc-registry-scripts-runlocal-sh)
- [crates/svc-registry/scripts/smoke_registry.sh](#crates-svc-registry-scripts-smokeregistry-sh)
- [crates/svc-registry/src/auth/macaroon.rs](#crates-svc-registry-src-auth-macaroon-rs)
- [crates/svc-registry/src/auth/uds.rs](#crates-svc-registry-src-auth-uds-rs)
- [crates/svc-registry/src/build_info.rs](#crates-svc-registry-src-buildinfo-rs)
- [crates/svc-registry/src/bus/events.rs](#crates-svc-registry-src-bus-events-rs)
- [crates/svc-registry/src/bus/mod.rs](#crates-svc-registry-src-bus-mod-rs)
- [crates/svc-registry/src/config/default.toml](#crates-svc-registry-src-config-default-toml)
- [crates/svc-registry/src/config/load.rs](#crates-svc-registry-src-config-load-rs)
- [crates/svc-registry/src/config/mod.rs](#crates-svc-registry-src-config-mod-rs)
- [crates/svc-registry/src/config/model.rs](#crates-svc-registry-src-config-model-rs)
- [crates/svc-registry/src/config/reload.rs](#crates-svc-registry-src-config-reload-rs)
- [crates/svc-registry/src/config/validate.rs](#crates-svc-registry-src-config-validate-rs)
- [crates/svc-registry/src/error.rs](#crates-svc-registry-src-error-rs)
- [crates/svc-registry/src/governance/approvals.rs](#crates-svc-registry-src-governance-approvals-rs)
- [crates/svc-registry/src/governance/mod.rs](#crates-svc-registry-src-governance-mod-rs)
- [crates/svc-registry/src/governance/quorum.rs](#crates-svc-registry-src-governance-quorum-rs)
- [crates/svc-registry/src/governance/signer_set.rs](#crates-svc-registry-src-governance-signerset-rs)
- [crates/svc-registry/src/governance/supersede.rs](#crates-svc-registry-src-governance-supersede-rs)
- [crates/svc-registry/src/http/middleware/auth.rs](#crates-svc-registry-src-http-middleware-auth-rs)
- [crates/svc-registry/src/http/middleware/corr_id.rs](#crates-svc-registry-src-http-middleware-corrid-rs)
- [crates/svc-registry/src/http/middleware/limits.rs](#crates-svc-registry-src-http-middleware-limits-rs)
- [crates/svc-registry/src/http/middleware/metrics.rs](#crates-svc-registry-src-http-middleware-metrics-rs)
- [crates/svc-registry/src/http/middleware/timeouts.rs](#crates-svc-registry-src-http-middleware-timeouts-rs)
- [crates/svc-registry/src/http/mod.rs](#crates-svc-registry-src-http-mod-rs)
- [crates/svc-registry/src/http/responses.rs](#crates-svc-registry-src-http-responses-rs)
- [crates/svc-registry/src/http/routes.rs](#crates-svc-registry-src-http-routes-rs)
- [crates/svc-registry/src/http/sse.rs](#crates-svc-registry-src-http-sse-rs)
- [crates/svc-registry/src/interop/dto.rs](#crates-svc-registry-src-interop-dto-rs)
- [crates/svc-registry/src/interop/event_shapes.rs](#crates-svc-registry-src-interop-eventshapes-rs)
- [crates/svc-registry/src/interop/openapi_stub.rs](#crates-svc-registry-src-interop-openapistub-rs)
- [crates/svc-registry/src/lib.rs](#crates-svc-registry-src-lib-rs)
- [crates/svc-registry/src/main.rs](#crates-svc-registry-src-main-rs)
- [crates/svc-registry/src/observability/endpoints.rs](#crates-svc-registry-src-observability-endpoints-rs)
- [crates/svc-registry/src/observability/logging.rs](#crates-svc-registry-src-observability-logging-rs)
- [crates/svc-registry/src/observability/metrics.rs](#crates-svc-registry-src-observability-metrics-rs)
- [crates/svc-registry/src/observability/mod.rs](#crates-svc-registry-src-observability-mod-rs)
- [crates/svc-registry/src/observability/tracing.rs](#crates-svc-registry-src-observability-tracing-rs)
- [crates/svc-registry/src/pipeline/approve.rs](#crates-svc-registry-src-pipeline-approve-rs)
- [crates/svc-registry/src/pipeline/bus_publish.rs](#crates-svc-registry-src-pipeline-buspublish-rs)
- [crates/svc-registry/src/pipeline/checkpoint.rs](#crates-svc-registry-src-pipeline-checkpoint-rs)
- [crates/svc-registry/src/pipeline/commit.rs](#crates-svc-registry-src-pipeline-commit-rs)
- [crates/svc-registry/src/pipeline/deep_verify.rs](#crates-svc-registry-src-pipeline-deepverify-rs)
- [crates/svc-registry/src/pipeline/mod.rs](#crates-svc-registry-src-pipeline-mod-rs)
- [crates/svc-registry/src/pipeline/propose.rs](#crates-svc-registry-src-pipeline-propose-rs)
- [crates/svc-registry/src/pipeline/retention.rs](#crates-svc-registry-src-pipeline-retention-rs)
- [crates/svc-registry/src/pq/mod.rs](#crates-svc-registry-src-pq-mod-rs)
- [crates/svc-registry/src/pq/policy.rs](#crates-svc-registry-src-pq-policy-rs)
- [crates/svc-registry/src/pq/verify_dilithium.rs](#crates-svc-registry-src-pq-verifydilithium-rs)
- [crates/svc-registry/src/pq/verify_falcon.rs](#crates-svc-registry-src-pq-verifyfalcon-rs)
- [crates/svc-registry/src/readiness/gate.rs](#crates-svc-registry-src-readiness-gate-rs)
- [crates/svc-registry/src/result.rs](#crates-svc-registry-src-result-rs)
- [crates/svc-registry/src/shutdown.rs](#crates-svc-registry-src-shutdown-rs)
- [crates/svc-registry/src/storage/checkpoint.rs](#crates-svc-registry-src-storage-checkpoint-rs)
- [crates/svc-registry/src/storage/head.rs](#crates-svc-registry-src-storage-head-rs)
- [crates/svc-registry/src/storage/inmem.rs](#crates-svc-registry-src-storage-inmem-rs)
- [crates/svc-registry/src/storage/log.rs](#crates-svc-registry-src-storage-log-rs)
- [crates/svc-registry/src/storage/mod.rs](#crates-svc-registry-src-storage-mod-rs)
- [crates/svc-registry/src/storage/sled_store.rs](#crates-svc-registry-src-storage-sledstore-rs)
- [crates/svc-registry/src/storage/sqlite_store.rs](#crates-svc-registry-src-storage-sqlitestore-rs)
- [crates/svc-registry/src/storage/types.rs](#crates-svc-registry-src-storage-types-rs)
- [crates/svc-registry/tests/api_commit.rs](#crates-svc-registry-tests-apicommit-rs)
- [crates/svc-registry/tests/chaos_ready.rs](#crates-svc-registry-tests-chaosready-rs)
- [crates/svc-registry/tests/concurrency_loom.rs](#crates-svc-registry-tests-concurrencyloom-rs)
- [crates/svc-registry/tests/http_contract.rs](#crates-svc-registry-tests-httpcontract-rs)
- [crates/svc-registry/tests/invariants.rs](#crates-svc-registry-tests-invariants-rs)
- [crates/svc-registry/tests/metrics_text.rs](#crates-svc-registry-tests-metricstext-rs)
- [crates/svc-registry/tests/storage_monotonic.rs](#crates-svc-registry-tests-storagemonotonic-rs)
- [crates/svc-registry/tests/vectors/approvals_ed25519.json](#crates-svc-registry-tests-vectors-approvalsed25519-json)
- [crates/svc-registry/tests/vectors/approvals_pq_mixed.json](#crates-svc-registry-tests-vectors-approvalspqmixed-json)
- [crates/svc-registry/tests/vectors/descriptor_set_v1.json](#crates-svc-registry-tests-vectors-descriptorsetv1-json)
- [crates/svc-registry/tests/vectors/proposal.json](#crates-svc-registry-tests-vectors-proposal-json)

### crates/svc-registry/.github/workflows/ci.yml
<a id="crates-svc-registry--github-workflows-ci-yml"></a>

```yaml
name: ci (scaffold)
on: [push, pull_request]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "CI scaffold (no build steps yet)."

```

### crates/svc-registry/.github/workflows/perf.yml
<a id="crates-svc-registry--github-workflows-perf-yml"></a>

```yaml
name: perf (scaffold)
on:
  schedule:
    - cron: "0 3 * * *"
jobs:
  perf:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "Nightly perf scaffold."

```

### crates/svc-registry/.github/workflows/render-mermaid.yml
<a id="crates-svc-registry--github-workflows-render-mermaid-yml"></a>

```yaml
name: render-mermaid (scaffold)
on: [push, pull_request]
jobs:
  mmdc:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm i -g @mermaid-js/mermaid-cli
      - run: |
          for f in $(git ls-files 'crates/svc-registry2/docs/*.mmd'); do
            out="${f%.mmd}.svg"
            mmdc -i "$f" -o "$out"
          done

```

### crates/svc-registry/Cargo.toml
<a id="crates-svc-registry-Cargo-toml"></a>

```toml
[package]
name = "svc-registry"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
publish = false

[dependencies]
# Workspace pins (exact versions come from the root)
tokio = { workspace = true, features = ["rt-multi-thread", "macros", "signal", "io-util", "time"] }
axum           = { workspace = true, features = ["tokio", "http1", "http2", "json", "matched-path"] }
tower          = { workspace = true, features = ["util", "timeout"] }
tower-http     = { workspace = true, features = ["cors", "limit", "timeout"] }
http           = { workspace = true }
tokio-util     = { workspace = true }
tokio-rustls   = { workspace = true }

tracing            = { workspace = true }
tracing-subscriber = { workspace = true, features = ["env-filter", "fmt", "std", "json"] }
prometheus         = { workspace = true }

serde           = { workspace = true }
serde_json      = { workspace = true }
toml            = { workspace = true }
humantime-serde = { workspace = true }

thiserror    = { workspace = true }
anyhow       = { workspace = true }
bytes        = { workspace = true }
parking_lot  = { workspace = true }
futures      = { workspace = true }
futures-util = { workspace = true }
rand         = { workspace = true }
fastrand     = { workspace = true }

# Needed by corr_id middleware
ulid = "1"

# --- storage + SSE needs (explicit to avoid workspace inherit issues) ---
async-trait  = "0.1.83"
# IMPORTANT: enable 'sync' for BroadcastStream
tokio-stream = { version = "0.1.17", features = ["sync"] }
chrono       = { version = "0.4.38", features = ["serde", "clock"] }

# Intra-workspace crates
ron-kernel   = { path = "../ron-kernel" }
ron-bus      = { path = "../ron-bus" }
ron-metrics  = { path = "../ron-metrics" }
ron-proto    = { path = "../ron-proto" }
ron-policy   = { path = "../ron-policy" }

[build-dependencies]
time = { version = "0.3", features = ["formatting"] }

[dev-dependencies]
# (add test-only deps here when we flesh out benches/tests further)

```

### crates/svc-registry/benches/blake3_payload.rs
<a id="crates-svc-registry-benches-blake3payload-rs"></a>

```rust
// Criterion bench placeholder (scaffold)
fn main() {}

```

### crates/svc-registry/benches/verify_approvals.rs
<a id="crates-svc-registry-benches-verifyapprovals-rs"></a>

```rust
// Criterion bench placeholder (scaffold)
fn main() {}

```

### crates/svc-registry/build.rs
<a id="crates-svc-registry-build-rs"></a>

```rust
// crates/svc-registry/build.rs
use std::process::Command;

fn main() {
    // Re-run if we change this file or git state changes
    println!("cargo:rerun-if-changed=build.rs");
    println!("cargo:rerun-if-changed=.git/HEAD");
    println!("cargo:rerun-if-changed=.git/refs/heads");
    println!("cargo:rerun-if-changed=.git/index");

    // RFC3339 build time (UTC)
    let now = time::OffsetDateTime::now_utc()
        .format(&time::format_description::well_known::Rfc3339)
        .unwrap_or_else(|_| "unknown".to_string());
    println!("cargo:rustc-env=BUILD_TIME_RFC3339={}", now);

    // Full + short commit (best-effort)
    let full = run_git(&["rev-parse", "--verify", "HEAD"]).unwrap_or_else(|| "unknown".into());
    let short = run_git(&["rev-parse", "--short", "HEAD"]).unwrap_or_else(|| "unknown".into());

    // Dirty flag (any uncommitted changes?)
    let dirty = run_git(&["status", "--porcelain"])
        .map(|s| !s.trim().is_empty())
        .unwrap_or(false);
    if dirty {
        println!("cargo:rustc-env=VERGEN_GIT_DIRTY=1");
    }

    // New envs expected by build_info.rs
    println!("cargo:rustc-env=VERGEN_GIT_SHA={}", full);
    println!("cargo:rustc-env=VERGEN_GIT_SHA_SHORT={}", short);

    // Legacy compatibility (you had these before)
    println!("cargo:rustc-env=GIT_COMMIT_HASH={}", full);
    println!("cargo:rustc-env=GIT_COMMIT_SHORT={}", short);
}

fn run_git(args: &[&str]) -> Option<String> {
    let out = Command::new("git").args(args).output().ok()?;
    if !out.status.success() {
        return None;
    }
    let s = String::from_utf8(out.stdout).ok()?;
    Some(s.trim().to_string())
}

```

### crates/svc-registry/fuzz/fuzz_targets/approval_payload.rs
<a id="crates-svc-registry-fuzz-fuzztargets-approvalpayload-rs"></a>

```rust
// cargo-fuzz target placeholder (scaffold)
fn main() {}

```

### crates/svc-registry/fuzz/fuzz_targets/dto_decode.rs
<a id="crates-svc-registry-fuzz-fuzztargets-dtodecode-rs"></a>

```rust
// cargo-fuzz target placeholder (scaffold)
fn main() {}

```

### crates/svc-registry/scripts/perf_sweep.sh
<a id="crates-svc-registry-scripts-perfsweep-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "Perf sweep scaffold — no benches wired yet."

```

### crates/svc-registry/scripts/render_mermaid.sh
<a id="crates-svc-registry-scripts-rendermermaid-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "Rendering mermaid (requires mmdc) ..."
for f in "$(dirname "$0")"/../docs/*.mmd; do
  [ -f "$f" ] || continue
  out="${f%.mmd}.svg"
  mmdc -i "$f" -o "$out"
  echo "Rendered: $out"
done

```

### crates/svc-registry/scripts/run_local.sh
<a id="crates-svc-registry-scripts-runlocal-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
echo "Run-local scaffold for svc-registry2. (No binary logic yet.)"

```

### crates/svc-registry/scripts/smoke_registry.sh
<a id="crates-svc-registry-scripts-smokeregistry-sh"></a>

```bash
#!/usr/bin/env bash
# smoke_registry.sh — one-shot smoke test for svc-registry
# Modes:
#   (default)   — assumes service already running (two-terminal workflow)
#   --spawn     — kills port holders, spawns svc-registry in background, runs checks, then cleans up

set -euo pipefail

ADMIN_ADDR="${ADMIN_ADDR:-127.0.0.1:9909}"
API_ADDR="${API_ADDR:-127.0.0.1:9444}"
RUST_LOG="${RUST_LOG:-info}"
SPAWN=0
if [[ "${1:-}" == "--spawn" ]]; then
  SPAWN=1
fi

# Utilities (macOS-friendly)
die() { echo "[ERR] $*" >&2; exit 1; }
info() { echo "[INFO] $*"; }
ok() { echo "[OK] $*"; }
step() { echo "[STEP] $*"; }

kill_port_holders() {
  local port="$1"
  local pids
  if pids=$(lsof -ti tcp:"$port" 2>/dev/null); then
    if [[ -n "$pids" ]]; then
      info "Port $port busy. Killing holder(s)…"
      # shellcheck disable=SC2086
      kill -9 $pids || true
      sleep 0.2
    fi
  fi
}

wait_for_healthz() {
  local url="$1"
  local retries="${2:-60}" # ~60s max
  local i=0
  info "Waiting for $url ..."
  until curl -sSf -o /dev/null "$url"; do
    ((i++)) || true
    if (( i >= retries )); then
      return 1
    fi
    sleep 1
  done
  ok "$url"
  return 0
}

# ── Metric helpers ──────────────────────────────────────────────────────────────
sum_head_requests() {
  # Sum requests_total counter values for route="/registry/head" across all methods/statuses
  curl -s "http://${ADMIN_ADDR}/metrics" \
  | awk -F' ' '/^requests_total\{.*route="\/registry\/head"/ { v=$NF; gsub(/\r/,"",v); s+=v } END { if (s=="") s=0; print s+0 }'
}

# Globals for --spawn
LOG_FILE="/tmp/svc-registry.log"
SVC_PID=""

spawn_service() {
  kill_port_holders "${ADMIN_ADDR##*:}"
  kill_port_holders "${API_ADDR##*:}"

  info "Spawning svc-registry (cargo run -p svc-registry)"
  : > "$LOG_FILE"
  if command -v setsid >/dev/null 2>&1; then
    RUST_LOG="$RUST_LOG" setsid bash -c 'cargo run -p svc-registry' > "$LOG_FILE" 2>&1 &
  else
    RUST_LOG="$RUST_LOG" bash -c 'cargo run -p svc-registry' > "$LOG_FILE" 2>&1 &
  fi
  SVC_PID="$!"
  info "svc-registry spawned (pid=${SVC_PID}); logs at $LOG_FILE"

  # Robust wait: “listening” log or /healthz 200
  local waited=0
  local max_wait=90
  while (( waited < max_wait )); do
    if grep -q '"message":"listening"' "$LOG_FILE" || grep -q 'listening' "$LOG_FILE"; then
      break
    fi
    if curl -sSf -o /dev/null "http://${ADMIN_ADDR}/healthz"; then
      break
    fi
    sleep 1
    ((waited++)) || true
  done

  if ! curl -sSf -o /dev/null "http://${ADMIN_ADDR}/healthz"; then
    if ! wait_for_healthz "http://${ADMIN_ADDR}/healthz" 10; then
      echo "----- last 120 log lines -----"
      tail -n 120 "$LOG_FILE" || true
      die "svc-registry failed to come up"
    fi
  fi
}

cleanup_spawn() {
  if [[ -n "${SVC_PID:-}" ]]; then
    info "Stopping svc-registry (pid=${SVC_PID})"
    kill -TERM "${SVC_PID}" 2>/dev/null || true
    sleep 0.5
    kill -9 "${SVC_PID}" 2>/dev/null || true
  fi
}

trap '[[ $SPAWN -eq 1 ]] && cleanup_spawn' EXIT

# If requested, spawn the service
if [[ $SPAWN -eq 1 ]]; then
  spawn_service
fi

# ────────────────────────────────────────────────────────────────────────────────
# Admin plane checks
# ────────────────────────────────────────────────────────────────────────────────
step "Admin plane checks"
wait_for_healthz "http://${ADMIN_ADDR}/healthz" 60

# Ready (truthful)
curl -is "http://${ADMIN_ADDR}/readyz" | sed -n '1,5p'
curl -s "http://${ADMIN_ADDR}/readyz" | jq -c . || die "jq required"

# Version
curl -s "http://${ADMIN_ADDR}/version" | jq -c . || die "jq required"

# Metrics (peek)
step "Metrics head (first 25 lines)"
curl -s "http://${ADMIN_ADDR}/metrics" | head -n 25

# ────────────────────────────────────────────────────────────────────────────────
# API: read head, drive some requests to move metrics, then commit
# ────────────────────────────────────────────────────────────────────────────────
step "API: /registry/head (capture current head)"
HEAD_JSON="$(curl -s "http://${API_ADDR}/registry/head")"
echo "HEAD: ${HEAD_JSON}"
HEAD_VER="$(echo "$HEAD_JSON" | jq -r '.version')"

step "Drive a few requests, then assert metrics moved"
before_val="$(sum_head_requests)"
# Hit /registry/head 5x
for _ in 1 2 3 4 5; do curl -s "http://${API_ADDR}/registry/head" >/dev/null; done
sleep 0.2
after_val="$(sum_head_requests)"
echo "[INFO] requests_total value before=${before_val} after=${after_val}"
delta=$(( ${after_val%.*} - ${before_val%.*} ))
if (( delta >= 5 )); then
  echo "✅ metrics advanced by >= 5 (delta=${delta})"
else
  die "requests_total did not advance as expected (delta=${delta})"
fi

# ────────────────────────────────────────────────────────────────────────────────
# SSE: start stream reader, commit, verify bump and event
# ────────────────────────────────────────────────────────────────────────────────
step "SSE smoke: start stream reader (capture a few lines incl. commits)"
SSE_LOG="$(mktemp -t svc-registry-sse.XXXXXX)"
curl -sN "http://${API_ADDR}/registry/stream" > "${SSE_LOG}" 2>&1 &
SSE_PID="$!"
sleep 0.3

step "POST /registry/commit and verify version bump"
RAND="$(LC_ALL=C tr -dc 'A-Za-z0-9' < /dev/urandom | head -c 16 || echo XxXxXxXxXxXxXxXx)"
RESP="$(curl -s -X POST "http://${API_ADDR}/registry/commit" \
  -H 'content-type: application/json' \
  --data "{\"payload_b3\":\"b3:${RAND}\"}")"
echo "COMMIT RESP: ${RESP}"
NEW_VER="$(echo "$RESP" | jq -r '.version')"
if [[ "$NEW_VER" != "null" ]] && (( NEW_VER == HEAD_VER + 1 )); then
  echo "✅ head.version bumped by +1"
else
  die "commit did not bump version (+1)"
fi

step "Verify /registry/head reflects the new version"
HEAD2="$(curl -s "http://${API_ADDR}/registry/head")"
echo "HEAD NOW: ${HEAD2}"
NEW_HEAD_VER="$(echo "$HEAD2" | jq -r '.version')"
if (( NEW_HEAD_VER == NEW_VER )); then
  echo "✅ /registry/head matches committed version"
else
  die "/registry/head mismatch"
fi

step "Wait briefly and check SSE log for a commit event"
sleep 0.5
kill -TERM "${SSE_PID}" 2>/dev/null || true
sleep 0.2
kill -KILL "${SSE_PID}" 2>/dev/null || true

if grep -q '^event: commit' "${SSE_LOG}"; then
  ok "SSE commit event observed"
else
  echo "----- SSE LOG (tail) -----"
  tail -n 120 "${SSE_LOG}" || true
  die "SSE commit event not observed"
fi

step "SSE heartbeat (optional quick check)"
grep -m1 '^event: heartbeat' "${SSE_LOG}" >/dev/null 2>&1 && echo "event: heartbeat" || true

echo "✅ svc-registry smoke OK"

```

### crates/svc-registry/src/auth/macaroon.rs
<a id="crates-svc-registry-src-auth-macaroon-rs"></a>

```rust
/*! Macaroon verifier (scaffold) */

```

### crates/svc-registry/src/auth/uds.rs
<a id="crates-svc-registry-src-auth-uds-rs"></a>

```rust
/*! UDS peer credential checks (scaffold) */

```

### crates/svc-registry/src/build_info.rs
<a id="crates-svc-registry-src-buildinfo-rs"></a>

```rust
//! RO:WHAT — Canonical build metadata struct and constructor.
//! RO:WHY  — Shared across admin/version and anywhere else needing service build info.
//! RO:INTERACTS — Used by `observability::endpoints::AdminState` and `/version` handler.

use serde::Serialize;

/// Service build metadata returned by `/version`.
#[derive(Clone, Debug, Serialize)]
pub struct BuildInfo {
    pub service: &'static str,
    pub version: &'static str,
    /// Build fingerprint (prefer git SHA; fall back to BLAKE3 or "unknown").
    pub commit: &'static str,
    pub schema: serde_json::Value,
    pub deprecations: Vec<String>,
}

/// Construct the current build info.
/// Priority: VERGEN_GIT_SHA (or GIT_COMMIT_SHA) → RON_BUILD_B3 → "unknown".
pub fn build_info() -> BuildInfo {
    // Prefer standard git SHA if present (via `vergen`, CI export, or custom build.rs).
    let commit = option_env!("VERGEN_GIT_SHA")
        .or(option_env!("GIT_COMMIT_SHA"))
        // Optional: your BLAKE3 fallback from CI/build.rs
        .or(option_env!("RON_BUILD_B3"))
        .unwrap_or("unknown");

    BuildInfo {
        service: "svc-registry",
        version: env!("CARGO_PKG_VERSION"),
        commit,
        schema: serde_json::json!({
            "registry": "1.0.0"
        }),
        deprecations: Vec::new(),
    }
}

```

### crates/svc-registry/src/bus/events.rs
<a id="crates-svc-registry-src-bus-events-rs"></a>

```rust
/*! Event constructors (scaffold) */

```

### crates/svc-registry/src/bus/mod.rs
<a id="crates-svc-registry-src-bus-mod-rs"></a>

```rust
/*! Bus facade (scaffold) */

```

### crates/svc-registry/src/config/default.toml
<a id="crates-svc-registry-src-config-default-toml"></a>

```toml
# svc-registry default configuration (dev-friendly)
bind_addr    = "127.0.0.1:9444"
metrics_addr = "127.0.0.1:9909"
max_conns    = 1024
read_timeout  = "5s"
write_timeout = "5s"
idle_timeout  = "60s"

[storage]
kind     = "sled"
data_dir = "./target/dev-registry"
fsync    = true

[limits]
max_request_bytes = 65536

[timeouts]
request_ms = 5000

[sse]
heartbeat_ms = 5000
max_clients  = 8192
drop_policy  = "lag-drop"

[cors]
# For dev you can keep "*" or replace with exact origins, e.g.:
# allowed_origins = ["http://localhost:5173", "http://127.0.0.1:8080"]
allowed_origins = ["*"]

```

### crates/svc-registry/src/config/load.rs
<a id="crates-svc-registry-src-config-load-rs"></a>

```rust
//! Config loading from env + optional file (TOML). Precedence aligns to docs.
//! Order of precedence (highest → lowest):
//!   1) Explicit function arg `explicit_path`
//!   2) Env var `SVCR_CONFIG_FILE`
//!   3) Workspace default: `crates/svc-registry/config/default.toml` (if exists)
//!   4) Built-in defaults (see `model.rs`)
use super::{model::Config, validate::validate_config};
use std::{env, fs, path::Path};

/// Load config following the documented precedence and apply `SVCR_*` env overrides.
pub fn load_config(explicit_path: Option<&str>) -> anyhow::Result<Config> {
    // 1) explicit path
    let mut cfg = if let Some(path) = explicit_path {
        load_if_exists(path)?.unwrap_or_default()
    } else {
        // 2) env var
        if let Ok(path) = env::var("SVCR_CONFIG_FILE") {
            load_if_exists(&path)?.unwrap_or_default()
        } else {
            // 3) workspace default file (best-effort)
            let default_path = "crates/svc-registry/config/default.toml";
            load_if_exists(default_path)?.unwrap_or_default()
        }
    };

    // 4) apply env overrides (scoped, explicit & bounded)
    apply_env_overrides(&mut cfg);

    validate_config(&cfg)?;
    Ok(cfg)
}

fn load_if_exists(path: &str) -> anyhow::Result<Option<Config>> {
    if Path::new(path).exists() {
        let s = fs::read_to_string(path)?;
        let cfg: Config = toml::from_str(&s)?;
        Ok(Some(cfg))
    } else {
        Ok(None)
    }
}

fn apply_env_overrides(cfg: &mut Config) {
    // Flat keys
    if let Ok(v) = std::env::var("SVCR_BIND_ADDR") {
        cfg.bind_addr = v;
    }
    if let Ok(v) = std::env::var("SVCR_METRICS_ADDR") {
        cfg.metrics_addr = v;
    }
    if let Ok(v) = std::env::var("SVCR_MAX_CONNS") {
        if let Ok(n) = v.parse::<u32>() {
            cfg.max_conns = n;
        }
    }
    if let Ok(v) = std::env::var("SVCR_READ_TIMEOUT") {
        cfg.read_timeout = v;
    }
    if let Ok(v) = std::env::var("SVCR_WRITE_TIMEOUT") {
        cfg.write_timeout = v;
    }
    if let Ok(v) = std::env::var("SVCR_IDLE_TIMEOUT") {
        cfg.idle_timeout = v;
    }

    // Storage
    if let Ok(v) = std::env::var("SVCR_STORAGE__KIND") {
        cfg.storage.kind = v;
    }
    if let Ok(v) = std::env::var("SVCR_STORAGE__DATA_DIR") {
        cfg.storage.data_dir = v;
    }
    if let Ok(v) = std::env::var("SVCR_STORAGE__FSYNC") {
        match v.to_ascii_lowercase().as_str() {
            "1" | "true" | "yes" | "on" => cfg.storage.fsync = true,
            "0" | "false" | "no" | "off" => cfg.storage.fsync = false,
            _ => {}
        }
    }

    // Limits
    if let Ok(v) = std::env::var("SVCR_LIMITS__MAX_REQUEST_BYTES") {
        if let Ok(n) = v.parse::<usize>() {
            cfg.limits.max_request_bytes = n;
        }
    }

    // Timeouts (structured)
    if let Ok(v) = std::env::var("SVCR_TIMEOUTS__REQUEST_MS") {
        if let Ok(n) = v.parse::<u64>() {
            cfg.timeouts.request_ms = n;
        }
    }

    // SSE
    if let Ok(v) = std::env::var("SVCR_SSE__HEARTBEAT_MS") {
        if let Ok(n) = v.parse::<u64>() {
            cfg.sse.heartbeat_ms = n;
        }
    }
    if let Ok(v) = std::env::var("SVCR_SSE__MAX_CLIENTS") {
        if let Ok(n) = v.parse::<usize>() {
            cfg.sse.max_clients = n;
        }
    }
    if let Ok(v) = std::env::var("SVCR_SSE__DROP_POLICY") {
        cfg.sse.drop_policy = v;
    }

    // CORS
    if let Ok(v) = std::env::var("SVCR_CORS__ALLOWED_ORIGINS") {
        // Comma-separated list.
        let list = v
            .split(',')
            .map(|s| s.trim().to_string())
            .filter(|s| !s.is_empty())
            .collect::<Vec<_>>();
        if !list.is_empty() {
            cfg.cors.allowed_origins = list;
        }
    }
}

```

### crates/svc-registry/src/config/mod.rs
<a id="crates-svc-registry-src-config-mod-rs"></a>

```rust
//! Config: model + load + validate (+ hot-reload later).
pub mod load;
pub mod model;
pub mod reload;
pub mod validate;

```

### crates/svc-registry/src/config/model.rs
<a id="crates-svc-registry-src-config-model-rs"></a>

```rust
//! Config model and defaults. Env prefix SVCR_.
use serde::{Deserialize, Serialize};

/// Service configuration (beta scope).
#[derive(Clone, Debug, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct Config {
    // Existing flat fields (kept for compatibility with current bootstrap)
    pub bind_addr: String,
    pub metrics_addr: String,
    pub max_conns: u32,
    pub read_timeout: String,
    pub write_timeout: String,
    pub idle_timeout: String,
    pub storage: Storage,

    // New structured sections (used by HTTP layers, SSE, and CORS).
    #[serde(default)]
    pub limits: Limits,
    #[serde(default)]
    pub timeouts: Timeouts,
    #[serde(default)]
    pub sse: Sse,
    #[serde(default)]
    pub cors: Cors,
}

#[derive(Clone, Debug, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct Storage {
    pub kind: String, // "sled" | "sqlite" (foundation uses stub)
    pub data_dir: String,
    pub fsync: bool,
}

#[derive(Clone, Debug, Serialize, Deserialize)]
#[serde(deny_unknown_fields, default)]
pub struct Limits {
    /// Max inbound request body size (bytes)
    pub max_request_bytes: usize,
}

impl Default for Limits {
    fn default() -> Self {
        Self {
            max_request_bytes: 64 * 1024,
        }
    }
}

#[derive(Clone, Debug, Serialize, Deserialize)]
#[serde(deny_unknown_fields, default)]
pub struct Timeouts {
    /// Per-request timeout in milliseconds (applied at HTTP layer).
    pub request_ms: u64,
}

impl Default for Timeouts {
    fn default() -> Self {
        Self { request_ms: 5_000 }
    }
}

#[derive(Clone, Debug, Serialize, Deserialize)]
#[serde(deny_unknown_fields, default)]
pub struct Sse {
    /// Heartbeat interval in milliseconds.
    pub heartbeat_ms: u64,
    /// Max clients (informational; enforcement may be best-effort).
    pub max_clients: usize,
    /// Informational drop policy label (e.g., "lag-drop").
    pub drop_policy: String,
}

impl Default for Sse {
    fn default() -> Self {
        Self {
            heartbeat_ms: 5_000,
            max_clients: 8_192,
            drop_policy: "lag-drop".to_string(),
        }
    }
}

#[derive(Clone, Debug, Serialize, Deserialize)]
#[serde(deny_unknown_fields, default)]
pub struct Cors {
    /// Exact origins like "http://localhost:5173". Use "*" for permissive dev.
    pub allowed_origins: Vec<String>,
}

impl Default for Cors {
    fn default() -> Self {
        Self {
            allowed_origins: vec!["*".to_string()],
        }
    }
}

impl Default for Config {
    fn default() -> Self {
        Self {
            bind_addr: "127.0.0.1:9444".into(),
            metrics_addr: "127.0.0.1:9909".into(),
            max_conns: 1024,
            read_timeout: "5s".into(),
            write_timeout: "5s".into(),
            idle_timeout: "60s".into(),
            storage: Storage {
                kind: "sled".into(),
                data_dir: "./target/dev-registry".into(),
                fsync: true,
            },
            limits: Limits::default(),
            timeouts: Timeouts::default(),
            sse: Sse::default(),
            cors: Cors::default(),
        }
    }
}

```

### crates/svc-registry/src/config/reload.rs
<a id="crates-svc-registry-src-config-reload-rs"></a>

```rust
//! Hot-reload stub (wired later to kernel watcher).
pub fn spawn_reloader() {
    // no-op foundation; real file/env watcher lands later
}

```

### crates/svc-registry/src/config/validate.rs
<a id="crates-svc-registry-src-config-validate-rs"></a>

```rust
//! Config validation + normalization.
use super::model::Config;

pub fn validate_config(c: &Config) -> anyhow::Result<()> {
    // existing checks
    if c.max_conns == 0 {
        anyhow::bail!("max_conns must be > 0");
    }
    if !c.bind_addr.contains(':') {
        anyhow::bail!("bind_addr must be host:port");
    }
    if !c.metrics_addr.contains(':') {
        anyhow::bail!("metrics_addr must be host:port");
    }

    // new structured guards (simple sanity; we avoid parsing times here)
    if c.limits.max_request_bytes == 0 {
        anyhow::bail!("limits.max_request_bytes must be > 0");
    }
    if c.timeouts.request_ms == 0 {
        anyhow::bail!("timeouts.request_ms must be > 0");
    }
    if c.sse.heartbeat_ms == 0 {
        anyhow::bail!("sse.heartbeat_ms must be > 0");
    }
    if c.sse.max_clients == 0 {
        anyhow::bail!("sse.max_clients must be > 0");
    }

    Ok(())
}

```

### crates/svc-registry/src/error.rs
<a id="crates-svc-registry-src-error-rs"></a>

```rust
//! Error types (intentionally small public surface). :contentReference[oaicite:10]{index=10}
use thiserror::Error;

/// Service-level error (non-exhaustive to allow additions without SemVer break). :contentReference[oaicite:11]{index=11}
#[derive(Debug, Error)]
#[non_exhaustive]
pub enum Error {
    #[error("configuration: {0}")]
    Config(String),
    #[error("storage: {0}")]
    Storage(String),
    #[error("busy")]
    Busy,
    #[error("unauthorized")]
    Unauthorized,
}

```

### crates/svc-registry/src/governance/approvals.rs
<a id="crates-svc-registry-src-governance-approvals-rs"></a>

```rust
/*! Approval verification (scaffold) */

```

### crates/svc-registry/src/governance/mod.rs
<a id="crates-svc-registry-src-governance-mod-rs"></a>

```rust
/*! Governance facade (scaffold) */

```

### crates/svc-registry/src/governance/quorum.rs
<a id="crates-svc-registry-src-governance-quorum-rs"></a>

```rust
/*! M-of-N quorum evaluation (scaffold) */

```

### crates/svc-registry/src/governance/signer_set.rs
<a id="crates-svc-registry-src-governance-signerset-rs"></a>

```rust
/*! Signer set lifecycle (scaffold) */

```

### crates/svc-registry/src/governance/supersede.rs
<a id="crates-svc-registry-src-governance-supersede-rs"></a>

```rust
/*! Supersede mechanics (scaffold) */

```

### crates/svc-registry/src/http/middleware/auth.rs
<a id="crates-svc-registry-src-http-middleware-auth-rs"></a>

```rust
//! Auth stub (foundation keeps public GETs unauthenticated).
#[derive(Clone, Default)]
pub struct AuthCfg {
    pub enabled: bool,
}

// Placeholder for future macaroon / UDS gating.

```

### crates/svc-registry/src/http/middleware/corr_id.rs
<a id="crates-svc-registry-src-http-middleware-corrid-rs"></a>

```rust
//! Correlation ID middleware (generates if missing).
use axum::{http::Request, response::Response};
use std::task::{Context, Poll};
use tower::{Layer, Service};
use ulid::Ulid;

#[derive(Clone, Default)]
pub struct CorrLayer;

impl CorrLayer {
    pub fn new() -> Self {
        Self
    }
}

impl<S> Layer<S> for CorrLayer {
    type Service = CorrSvc<S>;
    fn layer(&self, inner: S) -> Self::Service {
        CorrSvc { inner }
    }
}

#[derive(Clone)]
pub struct CorrSvc<S> {
    inner: S,
}

impl<S, B> Service<Request<B>> for CorrSvc<S>
where
    S: Service<Request<B>, Response = Response> + Clone,
{
    type Response = Response;
    type Error = S::Error;
    type Future = S::Future;

    fn poll_ready(&mut self, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {
        // delegate readiness directly; no pinning needed
        self.inner.poll_ready(cx)
    }

    fn call(&mut self, mut req: Request<B>) -> Self::Future {
        const HDR: &str = "X-Corr-ID";
        if !req.headers().contains_key(HDR) {
            let id = Ulid::new().to_string();
            if let Ok(val) = http::HeaderValue::from_str(&id) {
                req.headers_mut().insert(HDR, val);
            }
        }
        self.inner.call(req)
    }
}

```

### crates/svc-registry/src/http/middleware/limits.rs
<a id="crates-svc-registry-src-http-middleware-limits-rs"></a>

```rust
//! Request size limits using Axum's built-in limiter (preserves Response<Body>).

use axum::extract::DefaultBodyLimit;

/// Config for request body size limits.
#[derive(Clone, Copy, Debug)]
pub struct LimitCfg {
    /// Maximum allowed request body in bytes.
    pub max_body_bytes: usize,
}

impl Default for LimitCfg {
    fn default() -> Self {
        // Foundation: small cap; bump later per route if needed.
        Self {
            max_body_bytes: 64 * 1024,
        }
    }
}

/// Build the body-limit layer. Safe to apply at Router::layer with axum 0.7.9.
pub fn limits_layer(cfg: &LimitCfg) -> DefaultBodyLimit {
    DefaultBodyLimit::max(cfg.max_body_bytes)
}

```

### crates/svc-registry/src/http/middleware/metrics.rs
<a id="crates-svc-registry-src-http-middleware-metrics-rs"></a>

```rust
//! Per-route Prometheus metrics middleware.
//! Labels: method, route, status. Also records a per-route latency histogram.

use std::{
    future::Future,
    pin::Pin,
    task::{Context, Poll},
    time::Instant,
};

use axum::{http::Request, response::Response};
use tower::{Layer, Service};

use crate::observability::metrics::RegistryMetrics;

#[derive(Clone)]
pub struct MetricsLayer {
    metrics: RegistryMetrics,
}

impl MetricsLayer {
    pub fn new(metrics: RegistryMetrics) -> Self {
        Self { metrics }
    }
}

#[derive(Clone)]
pub struct MetricsSvc<S> {
    inner: S,
    metrics: RegistryMetrics,
}

impl<S> Layer<S> for MetricsLayer {
    type Service = MetricsSvc<S>;
    fn layer(&self, inner: S) -> Self::Service {
        MetricsSvc {
            inner,
            metrics: self.metrics.clone(),
        }
    }
}

impl<S, B> Service<Request<B>> for MetricsSvc<S>
where
    S: Service<Request<B>, Response = Response> + Clone + Send + 'static,
    S::Future: Send + 'static,
    B: Send + 'static,
{
    type Response = Response;
    type Error = S::Error;
    type Future =
        Pin<Box<dyn Future<Output = Result<Self::Response, Self::Error>> + Send + 'static>>;

    fn poll_ready(&mut self, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {
        self.inner.poll_ready(cx)
    }

    fn call(&mut self, req: Request<B>) -> Self::Future {
        // Capture route and method now; status is read from the response.
        let method = req.method().as_str().to_string();
        // Axum puts the matched path in an extension; fall back to "unmatched".
        let route = req
            .extensions()
            .get::<axum::extract::MatchedPath>()
            .map(|p| p.as_str().to_string())
            .unwrap_or_else(|| "unmatched".to_string());

        let metrics = self.metrics.clone();
        let start = Instant::now();

        let fut = self.inner.call(req);
        Box::pin(async move {
            let resp = fut.await?;
            let status_s = resp.status().as_u16().to_string();

            // Counter (labels: method, route, status) — matches NOTES and RegistryMetrics
            metrics
                .requests_total
                .with_label_values(&[&method, &route, &status_s])
                .inc();

            // Histogram (per route)
            metrics
                .request_latency_seconds
                .with_label_values(&[&route])
                .observe(start.elapsed().as_secs_f64());

            Ok(resp)
        })
    }
}

```

### crates/svc-registry/src/http/middleware/timeouts.rs
<a id="crates-svc-registry-src-http-middleware-timeouts-rs"></a>

```rust
//! Simple overall request timeout (foundation default).
use std::time::Duration;
// CHANGE: use tower_http's TimeoutLayer, not tower::timeout
use tower_http::timeout::TimeoutLayer;

#[derive(Clone)]
pub struct TimeoutCfg {
    pub overall_ms: u64,
}

impl Default for TimeoutCfg {
    fn default() -> Self {
        // Read-mostly service; 5s overall is generous for foundation.
        Self { overall_ms: 5_000 }
    }
}

pub fn timeouts_layer(cfg: &TimeoutCfg) -> TimeoutLayer {
    TimeoutLayer::new(Duration::from_millis(cfg.overall_ms))
}

```

### crates/svc-registry/src/http/mod.rs
<a id="crates-svc-registry-src-http-mod-rs"></a>

```rust
//! HTTP surface (routers, middleware, helpers).
pub mod routes;
pub mod sse;

pub mod middleware {
    pub mod auth;
    pub mod corr_id;
    pub mod limits;
    pub mod metrics;
    pub mod timeouts;
}

pub mod responses;

```

### crates/svc-registry/src/http/responses.rs
<a id="crates-svc-registry-src-http-responses-rs"></a>

```rust
//! Response helpers & error mapping (to be extended as write plane lands).
use axum::{response::IntoResponse, Json};
use http::StatusCode;

pub fn err(status: StatusCode, code: &str, message: &str, corr_id: &str) -> impl IntoResponse {
    let body = serde_json::json!({
        "error": { "code": code, "message": message, "corr_id": corr_id }
    });
    (status, Json(body))
}

```

### crates/svc-registry/src/http/routes.rs
<a id="crates-svc-registry-src-http-routes-rs"></a>

```rust
//! RO:WHAT — API routes: read plane + SSE + commit write path.
//! RO:INVARIANTS — POST /registry/commit monotonic bump; idempotency-by-value left to client.

use std::sync::Arc;

use axum::{
    extract::State,
    response::IntoResponse,
    routing::{get, post},
    Json, Router,
};
use http::StatusCode;
use tower::ServiceBuilder;
use tower_http::cors::{Any, CorsLayer};

use super::middleware::{
    auth::AuthCfg,
    corr_id::CorrLayer,
    limits::{limits_layer, LimitCfg},
    metrics::MetricsLayer,
    timeouts::{timeouts_layer, TimeoutCfg},
};
use super::sse::sse_stream;
use crate::config::model::Config;
use crate::http::responses;
use crate::observability::metrics::RegistryMetrics;
use crate::storage::RegistryStore;

/// Shared application state for HTTP handlers.
#[derive(Clone)]
pub struct AppState {
    pub metrics: RegistryMetrics,
    pub store: Arc<dyn RegistryStore>,

    // Config bits handlers need fast access to:
    pub sse_heartbeat_ms: u64,
}

pub fn registry_routes_with_cfg(
    metrics: RegistryMetrics,
    store: Arc<dyn RegistryStore>,
    cfg: &Config,
) -> Router {
    // Construct auth cfg and *read* a field so it’s not dead code until real auth wired.
    let auth = AuthCfg::default();
    let _auth_enabled = auth.enabled;

    let state = AppState {
        metrics: metrics.clone(),
        store,
        sse_heartbeat_ms: cfg.sse.heartbeat_ms,
    };

    // Build middleware stack in the intended order.
    let limit_cfg = LimitCfg {
        max_body_bytes: cfg.limits.max_request_bytes,
    };
    let timeout_cfg = TimeoutCfg {
        overall_ms: cfg.timeouts.request_ms,
    };

    let cors_layer = build_cors(&cfg.cors.allowed_origins);

    let stack = ServiceBuilder::new()
        .layer(MetricsLayer::new(metrics.clone()))
        .layer(limits_layer(&limit_cfg))
        .layer(timeouts_layer(&timeout_cfg))
        .layer(cors_layer)
        .layer(CorrLayer::new());

    Router::new()
        .route("/registry/head", get(get_head))
        .route("/registry/commit", post(post_commit))
        .route("/registry/stream", get(sse_stream))
        .fallback(|| async { (StatusCode::NOT_FOUND, "not found") })
        .with_state(state)
        .layer(stack)
}

fn build_cors(allowed_origins: &[String]) -> CorsLayer {
    // If "*" present, be permissive (dev)
    if allowed_origins.iter().any(|o| o == "*") {
        return CorsLayer::permissive();
    }
    // Otherwise allow the exact origins provided; if parsing fails, fall back to permissive.
    let mut layer = CorsLayer::new().allow_methods(Any).allow_headers(Any);
    for origin in allowed_origins {
        if let Ok(hv) = http::HeaderValue::from_str(origin) {
            layer = layer.allow_origin(hv);
        }
    }
    layer
}

/// GET /registry/head
async fn get_head(State(st): State<AppState>) -> impl IntoResponse {
    let head = st.store.head().await;
    st.metrics.set_head_version(head.version);
    Json(head)
}

/// POST /registry/commit
#[derive(Debug, serde::Deserialize)]
struct CommitReq {
    /// b3:<base64> payload; validated minimally here.
    payload_b3: String,
}

async fn post_commit(State(st): State<AppState>, Json(req): Json<CommitReq>) -> impl IntoResponse {
    if !req.payload_b3.starts_with("b3:") {
        return responses::err(
            StatusCode::BAD_REQUEST,
            "invalid_payload",
            "payload_b3 must start with 'b3:'",
            "",
        )
        .into_response();
    }

    match st.store.commit(req.payload_b3).await {
        Ok(head) => {
            st.metrics.inc_commit_ok();
            st.metrics.set_head_version(head.version);
            (StatusCode::OK, Json(head)).into_response()
        }
        Err(e) => {
            st.metrics.inc_commit_err();
            responses::err(
                StatusCode::INTERNAL_SERVER_ERROR,
                "commit_failed",
                &e.to_string(),
                "",
            )
            .into_response()
        }
    }
}

```

### crates/svc-registry/src/http/sse.rs
<a id="crates-svc-registry-src-http-sse-rs"></a>

```rust
//! RO:WHAT — Server-Sent Events for registry stream (heartbeat + commit events).
//! RO:INVARIANTS — Heartbeats at configured interval; slow clients are dropped by broadcast.

use std::{convert::Infallible, time::Duration};

use axum::response::sse::{Event, KeepAlive, Sse};
use axum::{extract::State, response::IntoResponse};
use futures_util::stream::Stream;
use tokio_stream::{
    wrappers::IntervalStream,
    StreamExt, // .filter, .map, .merge
};

use crate::http::routes::AppState;

pub async fn sse_stream(State(st): State<AppState>) -> impl IntoResponse {
    st.metrics.sse_client_connected();

    // subscribe() returns BroadcastStream<Result<Head, RecvError>>
    // 1) Synchronous filter keeps only Ok(..)
    // 2) Map Ok(head) -> SSE "commit" Event
    let commits = st.store.subscribe().filter(|res| res.is_ok()).map(|res| {
        // Safe due to the filter above.
        let head = match res {
            Ok(h) => h,
            Err(_) => unreachable!("filtered out Err by .filter(|r| r.is_ok())"),
        };
        let data = serde_json::to_string(&head).unwrap_or_else(|_| "{}".to_string());
        Ok::<Event, Infallible>(Event::default().event("commit").data(data))
    });

    // Heartbeat keepalive (SSE control frame)
    let keepalive = KeepAlive::new()
        .interval(Duration::from_millis(st.sse_heartbeat_ms))
        .text("heartbeat");

    Sse::new(merge_with_heartbeat(commits, st.sse_heartbeat_ms)).keep_alive(keepalive)
}

// Merge commit stream with periodic heartbeat events.
fn merge_with_heartbeat<S>(
    commits: S,
    heartbeat_ms: u64,
) -> impl Stream<Item = Result<Event, Infallible>> + Send
where
    S: Stream<Item = Result<Event, Infallible>> + Send + 'static,
{
    let heartbeats = {
        let interval =
            IntervalStream::new(tokio::time::interval(Duration::from_millis(heartbeat_ms)));
        interval.map(|_| Ok(Event::default().event("heartbeat").data("1")))
    };

    // `.merge` comes from `tokio_stream::StreamExt`
    commits.merge(heartbeats)
}

```

### crates/svc-registry/src/interop/dto.rs
<a id="crates-svc-registry-src-interop-dto-rs"></a>

```rust
/*! ron-proto DTO glue (scaffold) */

```

### crates/svc-registry/src/interop/event_shapes.rs
<a id="crates-svc-registry-src-interop-eventshapes-rs"></a>

```rust
/*! Bus event JSON shapes (scaffold) */

```

### crates/svc-registry/src/interop/openapi_stub.rs
<a id="crates-svc-registry-src-interop-openapistub-rs"></a>

```rust
/*! OpenAPI sync check (scaffold) */

```

### crates/svc-registry/src/lib.rs
<a id="crates-svc-registry-src-lib-rs"></a>

```rust
#![forbid(unsafe_code)]
#![deny(clippy::unwrap_used, clippy::expect_used, clippy::await_holding_lock)]
#![allow(missing_docs)]

//! svc-registry — authoritative, append-only registry service (foundation build)

pub mod build_info;
pub mod config;
pub mod error;
pub mod http;
pub mod observability;
pub mod shutdown;
pub mod storage; // <-- new

pub use build_info::BuildInfo;
pub use config::model::Config;
pub use error::Error;
pub use observability::metrics::RegistryMetrics as Metrics;

```

### crates/svc-registry/src/main.rs
<a id="crates-svc-registry-src-main-rs"></a>

```rust
#![deny(clippy::unwrap_used, clippy::expect_used, clippy::await_holding_lock)]

mod build_info;
mod config;
mod http;
mod observability;
mod storage;

use std::{net::SocketAddr, sync::Arc};

use axum::Router;
use ron_kernel::{wait_for_ctrl_c, HealthState};
use tokio::net::TcpListener;
use tracing::info;

use crate::config::load::load_config;
use crate::http::routes::registry_routes_with_cfg;
use crate::observability::endpoints::{admin_router, set_queues_ok, set_services_ok, AdminState};
use crate::observability::tracing::SERVICE_NAME;
use crate::storage::inmem::InMemoryStore;
use crate::storage::RegistryStore; // bring trait into scope for .subscribe()

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // Use the shared logger in observability::logging to avoid dead-code.
    crate::observability::logging::init_tracing();

    // Load config (env/file precedence handled in load_config)
    let cfg = load_config(None)?;
    let metrics = crate::observability::metrics::RegistryMetrics::new();
    let health = Arc::new(HealthState::default());

    // Spawn (stub) config reloader so the function isn't dead code.
    crate::config::reload::spawn_reloader();

    // Storage (in-memory for beta); after created, flip services_ok.
    let store = Arc::new(InMemoryStore::new());
    set_services_ok(&health, true);

    // Probe queues by trying a subscribe; on success flip queues_ok.
    {
        let _rx = store.subscribe();
        set_queues_ok(&health, true);
    }

    // Build routers
    let admin = admin_router(AdminState {
        health: health.clone(),
        build: build_info::build_info(),
        metrics: metrics.clone(),
    });
    let api: Router = registry_routes_with_cfg(metrics.clone(), store.clone(), &cfg);

    // Bind (cfg.metrics_addr == admin plane; cfg.bind_addr == public API)
    let admin_addr: SocketAddr = cfg.metrics_addr.parse()?;
    let api_addr: SocketAddr = cfg.bind_addr.parse()?;

    info!(
        service = SERVICE_NAME,
        admin_addr = %admin_addr,
        api_addr = %api_addr,
        "listening"
    );

    let admin_listener = TcpListener::bind(admin_addr).await?;
    let api_listener = TcpListener::bind(api_addr).await?;

    let admin_task = tokio::spawn(async move {
        axum::serve(admin_listener, admin.into_make_service())
            .with_graceful_shutdown(wait_for_ctrl_c())
            .await
            .ok();
    });

    let api_task = tokio::spawn(async move {
        axum::serve(api_listener, api.into_make_service())
            .with_graceful_shutdown(wait_for_ctrl_c())
            .await
            .ok();
    });

    // Wait for either to finish (Ctrl-C triggers graceful shutdown)
    let _ = tokio::join!(admin_task, api_task);

    Ok(())
}

```

### crates/svc-registry/src/observability/endpoints.rs
<a id="crates-svc-registry-src-observability-endpoints-rs"></a>

```rust
//! RO:WHAT — Admin plane endpoints (/metrics, /healthz, /readyz, /version) + readiness gates.
//! RO:WHY  — Truthful SLO surfaces and a simple flip-to-ready mechanism.

use std::sync::Arc;

use axum::{routing::get, Router};
use http::StatusCode;
use ron_kernel::HealthState;

use crate::build_info::BuildInfo;
use crate::observability::metrics::RegistryMetrics;

/// Shared admin-plane state.
#[derive(Clone)]
pub struct AdminState {
    pub health: Arc<HealthState>,
    pub build: BuildInfo,
    pub metrics: RegistryMetrics,
}

// Helpers to flip gates — call from main after init.
pub fn set_services_ok(health: &Arc<HealthState>, ok: bool) {
    health.set("services_ok", ok);
}
pub fn set_queues_ok(health: &Arc<HealthState>, ok: bool) {
    health.set("queues_ok", ok);
}

pub fn admin_router(state: AdminState) -> Router {
    Router::new()
        .route("/healthz", get(healthz))
        .route("/readyz", get(readyz))
        .route("/version", get(version))
        .route("/metrics", get(metrics))
        .with_state(state)
}

async fn healthz() -> impl axum::response::IntoResponse {
    (StatusCode::OK, "")
}

async fn readyz(
    axum::extract::State(st): axum::extract::State<AdminState>,
) -> impl axum::response::IntoResponse {
    let snap = st.health.snapshot();
    let services_ok = snap.get("services_ok").copied().unwrap_or(false);
    let queues_ok = snap.get("queues_ok").copied().unwrap_or(false);
    let ready = services_ok && queues_ok;
    let degraded = !(services_ok && queues_ok);

    let body = serde_json::json!({
        "ready": ready,
        "degraded": degraded,
        "services_ok": services_ok,
        "queues_ok": queues_ok
    });

    if ready {
        (StatusCode::OK, axum::Json(body))
    } else {
        (StatusCode::SERVICE_UNAVAILABLE, axum::Json(body))
    }
}

async fn version(
    axum::extract::State(st): axum::extract::State<AdminState>,
) -> impl axum::response::IntoResponse {
    // Return an owned clone to avoid borrowing state across the response.
    axum::Json(st.build.clone())
}

async fn metrics(
    axum::extract::State(st): axum::extract::State<AdminState>,
) -> impl axum::response::IntoResponse {
    // Use the instance method (fixes E0061 after making gather_text non-static).
    let body = st.metrics.gather_text();
    (StatusCode::OK, body)
}

```

### crates/svc-registry/src/observability/logging.rs
<a id="crates-svc-registry-src-observability-logging-rs"></a>

```rust
//! Tracing/logging init (JSON by default).
use tracing_subscriber::{fmt, layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};

pub fn init_tracing() {
    let env = EnvFilter::try_from_default_env()
        .unwrap_or_else(|_| EnvFilter::new("info,axum=warn,tower_http=warn,svc_registry=info"));
    let fmt = fmt::layer().json().flatten_event(true).with_target(true);
    tracing_subscriber::registry().with(env).with(fmt).init();
}

```

### crates/svc-registry/src/observability/metrics.rs
<a id="crates-svc-registry-src-observability-metrics-rs"></a>

```rust
//! RO:WHAT — Prometheus metrics for svc-registry.
//! RO:WHY  — Standardized counters/gauges/histograms with bounded label cardinality.
//! RO:INVARIANTS — label keys fixed; route labels reflect templates, not raw paths.
//!
//! Note: registration is made idempotent with a process-global OnceLock so tests
//! can construct multiple RegistryMetrics without "AlreadyReg" panics.

use prometheus::{
    opts, register_gauge, register_histogram_vec, register_int_counter, register_int_counter_vec,
    Encoder, Gauge, HistogramVec, IntCounter, IntCounterVec, TextEncoder,
};
use std::sync::OnceLock;

#[derive(Clone)]
pub struct RegistryMetrics {
    /// HTTP request totals by method/route/status.
    pub requests_total: IntCounterVec,
    /// HTTP request latency histogram by route.
    pub request_latency_seconds: HistogramVec,

    /// Write-path outcomes: {outcome="ok|error"}.
    pub registry_commits_total: IntCounterVec,
    /// Current head version (gauge).
    pub registry_head_version: Gauge,

    /// SSE lifecycle counters.
    pub registry_sse_clients_connected_total: IntCounter,
    pub registry_sse_clients_disconnected_total: IntCounter,
}

static METRICS_ONCE: OnceLock<RegistryMetrics> = OnceLock::new();

impl Default for RegistryMetrics {
    fn default() -> Self {
        Self::new()
    }
}

impl RegistryMetrics {
    /// Return a clone of the singleton metrics set; first caller registers.
    pub fn new() -> Self {
        METRICS_ONCE
            .get_or_init(|| Self::register_all())
            .clone()
    }

    /// Increment commit-success counter.
    pub fn inc_commit_ok(&self) {
        self.registry_commits_total
            .with_label_values(&["ok"])
            .inc();
    }

    /// Increment commit-error counter.
    pub fn inc_commit_err(&self) {
        self.registry_commits_total
            .with_label_values(&["error"])
            .inc();
    }

    /// Update the head-version gauge.
    pub fn set_head_version(&self, v: u64) {
        self.registry_head_version.set(v as f64);
    }

    /// Record an SSE **connect** event.
    pub fn sse_client_connected(&self) {
        self.registry_sse_clients_connected_total.inc();
    }

    /// Record an SSE **disconnect** (hooked post-beta when we have an on-close signal).
    #[allow(dead_code)]
    pub fn sse_client_disconnected(&self) {
        self.registry_sse_clients_disconnected_total.inc();
    }

    /// Gather current metrics into Prometheus text exposition format.
    pub fn gather_text(&self) -> String {
        let mf = prometheus::gather();
        let mut buf = Vec::with_capacity(64 * 1024);
        let encoder = TextEncoder::new();
        let _ = encoder.encode(&mf, &mut buf);
        String::from_utf8_lossy(&buf).into_owned()
    }

    // ---- internals ----

    /// Construct and register all collectors on the default registry once.
    #[allow(clippy::expect_used)]
    fn register_all() -> Self {
        // HTTP
        let requests_total = register_int_counter_vec!(
            opts!(
                "requests_total",
                "HTTP request totals by method/route/status"
            ),
            &["method", "route", "status"]
        )
        .expect("register requests_total");

        let request_latency_seconds = register_histogram_vec!(
            "request_latency_seconds",
            "HTTP request latency (seconds) by route",
            &["route"]
        )
        .expect("register request_latency_seconds");

        // Registry
        let registry_commits_total = register_int_counter_vec!(
            opts!(
                "registry_commits_total",
                "Registry commit outcomes (ok|error)"
            ),
            &["outcome"]
        )
        .expect("register registry_commits_total");

        let registry_head_version =
            register_gauge!("registry_head_version", "Current registry head version")
                .expect("register registry_head_version");

        // SSE lifecycle
        let registry_sse_clients_connected_total = register_int_counter!(
            "registry_sse_clients_connected_total",
            "SSE clients connected (lifetime)"
        )
        .expect("register registry_sse_clients_connected_total");

        let registry_sse_clients_disconnected_total = register_int_counter!(
            "registry_sse_clients_disconnected_total",
            "SSE clients disconnected (lifetime)"
        )
        .expect("register registry_sse_clients_disconnected_total");

        Self {
            requests_total,
            request_latency_seconds,
            registry_commits_total,
            registry_head_version,
            registry_sse_clients_connected_total,
            registry_sse_clients_disconnected_total,
        }
    }
}

```

### crates/svc-registry/src/observability/mod.rs
<a id="crates-svc-registry-src-observability-mod-rs"></a>

```rust
//! Observability: metrics, tracing/logging, and admin endpoints. :contentReference[oaicite:16]{index=16}
pub mod endpoints;
pub mod logging;
pub mod metrics;
pub mod tracing;

```

### crates/svc-registry/src/observability/tracing.rs
<a id="crates-svc-registry-src-observability-tracing-rs"></a>

```rust
//! Extra trace helpers (placeholders for spans/fields).
pub const SERVICE_NAME: &str = "svc-registry";

```

### crates/svc-registry/src/pipeline/approve.rs
<a id="crates-svc-registry-src-pipeline-approve-rs"></a>

```rust
/*! Add approval (scaffold) */

```

### crates/svc-registry/src/pipeline/bus_publish.rs
<a id="crates-svc-registry-src-pipeline-buspublish-rs"></a>

```rust
/*! Publish events non-blocking (scaffold) */

```

### crates/svc-registry/src/pipeline/checkpoint.rs
<a id="crates-svc-registry-src-pipeline-checkpoint-rs"></a>

```rust
/*! Periodic checkpoints (scaffold) */

```

### crates/svc-registry/src/pipeline/commit.rs
<a id="crates-svc-registry-src-pipeline-commit-rs"></a>

```rust
/*! Single-writer commit path (scaffold) */

```

### crates/svc-registry/src/pipeline/deep_verify.rs
<a id="crates-svc-registry-src-pipeline-deepverify-rs"></a>

```rust
/*! Background integrity verification (scaffold) */

```

### crates/svc-registry/src/pipeline/mod.rs
<a id="crates-svc-registry-src-pipeline-mod-rs"></a>

```rust
/*! Pipeline wiring (scaffold) */

```

### crates/svc-registry/src/pipeline/propose.rs
<a id="crates-svc-registry-src-pipeline-propose-rs"></a>

```rust
/*! Accept proposal, enqueue (scaffold) */

```

### crates/svc-registry/src/pipeline/retention.rs
<a id="crates-svc-registry-src-pipeline-retention-rs"></a>

```rust
/*! Retention/pruning (scaffold) */

```

### crates/svc-registry/src/pq/mod.rs
<a id="crates-svc-registry-src-pq-mod-rs"></a>

```rust
/*! PQ posture facade (scaffold) */

```

### crates/svc-registry/src/pq/policy.rs
<a id="crates-svc-registry-src-pq-policy-rs"></a>

```rust
/*! Mixed-quorum policy (scaffold) */

```

### crates/svc-registry/src/pq/verify_dilithium.rs
<a id="crates-svc-registry-src-pq-verifydilithium-rs"></a>

```rust
/*! Dilithium verify adapter (scaffold) */

```

### crates/svc-registry/src/pq/verify_falcon.rs
<a id="crates-svc-registry-src-pq-verifyfalcon-rs"></a>

```rust
/*! Falcon verify adapter (scaffold) */

```

### crates/svc-registry/src/readiness/gate.rs
<a id="crates-svc-registry-src-readiness-gate-rs"></a>

```rust
/*! Readiness aggregator (scaffold) */

```

### crates/svc-registry/src/result.rs
<a id="crates-svc-registry-src-result-rs"></a>

```rust
//! Local Result alias.
pub type Result<T, E = crate::error::Error> = core::result::Result<T, E>;

```

### crates/svc-registry/src/shutdown.rs
<a id="crates-svc-registry-src-shutdown-rs"></a>

```rust
//! Graceful shutdown helpers.
pub async fn graceful_shutdown() {
    tracing::info!("svc-registry shutdown complete");
}

```

### crates/svc-registry/src/storage/checkpoint.rs
<a id="crates-svc-registry-src-storage-checkpoint-rs"></a>

```rust
/*! Durable checkpoints (scaffold) */

```

### crates/svc-registry/src/storage/head.rs
<a id="crates-svc-registry-src-storage-head-rs"></a>

```rust
/*! HEAD snapshot & CAS (scaffold) */

```

### crates/svc-registry/src/storage/inmem.rs
<a id="crates-svc-registry-src-storage-inmem-rs"></a>

```rust
//! RO:WHAT — In-memory RegistryStore implementation with broadcasted commit events.
//! RO:WHY  — Fast foundation path; persistence can plug in later behind feature flags.
//! RO:INTERACTS — storage::RegistryStore trait; http::{routes,sse}.
//! RO:INVARIANTS — Single-writer discipline by &mut on commit path via Mutex gate.

use super::{Head, RegistryEvent, RegistryStore};
use chrono::Utc;
use std::sync::Arc;
use tokio::sync::{broadcast, Mutex, RwLock};
use tokio_stream::wrappers::BroadcastStream;

const BROADCAST_CAPACITY: usize = 1024; // bounded, drops oldest when overrun

#[derive(Clone)]
pub struct InMemoryStore {
    head: Arc<RwLock<Head>>,
    tx: broadcast::Sender<RegistryEvent>,
    // Single-writer commit gate; cheap because commit is tiny.
    writer: Arc<Mutex<()>>,
}

impl InMemoryStore {
    pub fn new() -> Self {
        let (tx, _rx) = broadcast::channel(BROADCAST_CAPACITY);
        let head = Head {
            version: 0,
            payload_b3: "b3:0".to_string(),
            committed_at: None,
        };
        Self {
            head: Arc::new(RwLock::new(head)),
            tx,
            writer: Arc::new(Mutex::new(())),
        }
    }
}

#[async_trait::async_trait]
impl RegistryStore for InMemoryStore {
    async fn head(&self) -> Head {
        self.head.read().await.clone()
    }

    async fn commit(&self, payload_b3: String) -> anyhow::Result<Head> {
        anyhow::ensure!(
            payload_b3.starts_with("b3:"),
            "payload must be base64-with-prefix (b3:..)"
        );

        // Single writer section
        let _guard = self.writer.lock().await;

        // Bump version/commit time
        let mut w = self.head.write().await;
        let new_head = Head {
            version: w.version.saturating_add(1),
            payload_b3,
            committed_at: Some(Utc::now()),
        };
        *w = new_head.clone();

        // Broadcast (best-effort; drop if no one is listening)
        let _ = self.tx.send(RegistryEvent::Commit {
            head: new_head.clone(),
        });

        Ok(new_head)
    }

    fn subscribe(&self) -> BroadcastStream<RegistryEvent> {
        BroadcastStream::new(self.tx.subscribe())
    }
}

impl Default for InMemoryStore {
    fn default() -> Self {
        Self::new()
    }
}

```

### crates/svc-registry/src/storage/log.rs
<a id="crates-svc-registry-src-storage-log-rs"></a>

```rust
/*! Append-only log (scaffold) */

```

### crates/svc-registry/src/storage/mod.rs
<a id="crates-svc-registry-src-storage-mod-rs"></a>

```rust
//! RO:WHAT — Storage facade for svc-registry (trait + in-memory backend).
//! RO:WHY  — Abstracts the read/write plane and the SSE event source.
//! RO:INTERACTS — http::{routes,sse}, observability::metrics, readiness gate.
//! RO:INVARIANTS — Monotonic head.version; subscribe is non-blocking.

pub mod inmem;

use chrono::{DateTime, Utc};
use tokio_stream::wrappers::BroadcastStream;

/// Public head shape returned to clients.
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct Head {
    pub version: u64,
    pub payload_b3: String,
    pub committed_at: Option<DateTime<Utc>>,
}

/// Internal SSE events exposed by the store.
#[derive(Debug, Clone, serde::Serialize)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum RegistryEvent {
    // Sent on successful commit with the resulting Head.
    Commit { head: Head },
}

#[async_trait::async_trait]
pub trait RegistryStore: Send + Sync {
    /// RO:WHAT — Fast read of the current head.
    async fn head(&self) -> Head;

    /// RO:WHAT — Commit a new payload; monotonically bumps version and returns new head.
    /// RO:INVARIANTS — version strictly increases; committed_at set to now.
    async fn commit(&self, payload_b3: String) -> anyhow::Result<Head>;

    /// RO:WHAT — Subscribe to store events (commit stream).
    /// RO:WHY  — Feeds SSE; non-blocking broadcast with bounded buffers.
    fn subscribe(&self) -> BroadcastStream<RegistryEvent>;
}

```

### crates/svc-registry/src/storage/sled_store.rs
<a id="crates-svc-registry-src-storage-sledstore-rs"></a>

```rust
/*! Sled backend adapter (scaffold) */

```

### crates/svc-registry/src/storage/sqlite_store.rs
<a id="crates-svc-registry-src-storage-sqlitestore-rs"></a>

```rust
/*! SQLite backend adapter (scaffold) */

```

### crates/svc-registry/src/storage/types.rs
<a id="crates-svc-registry-src-storage-types-rs"></a>

```rust
//! Storage-facing types (DTO-lite).
use serde::{Deserialize, Serialize};

/// The current head of the registry log.
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Head {
    /// Monotonic version (0 if empty).
    pub version: u64,
    /// Blake3 of the payload at head (dev: synthesized).
    pub payload_b3: String,
    /// RFC3339 timestamp if committed; null when empty.
    pub committed_at: Option<String>,
}

```

### crates/svc-registry/tests/api_commit.rs
<a id="crates-svc-registry-tests-apicommit-rs"></a>

```rust
use std::sync::Arc;

use axum::{body, http::Request, Router};
use svc_registry::{
    config::model::Config,
    http::routes::registry_routes_with_cfg,
    observability::metrics::RegistryMetrics,
    storage::inmem::InMemoryStore,
};
use tower::util::ServiceExt; // for .oneshot

#[tokio::test]
async fn commit_endpoint_roundtrip_and_body_shape() {
    let metrics = RegistryMetrics::default();
    let store = Arc::new(InMemoryStore::new());
    let cfg = Config::default();
    let api: Router = registry_routes_with_cfg(metrics, store.clone(), &cfg);

    // Commit once
    let req = Request::post("/registry/commit")
        .header("content-type", "application/json")
        .body(axum::body::Body::from(r#"{"payload_b3":"b3:roundtrip"}"#))
        .unwrap();

    let res = api.clone().oneshot(req).await.unwrap();
    assert!(res.status().is_success());
    let body = body::to_bytes(res.into_body(), 1 << 20).await.unwrap();
    let s = String::from_utf8(body.to_vec()).unwrap();
    assert!(s.contains(r#""version":1"#));
    assert!(s.contains(r#""payload_b3":"b3:roundtrip""#));

    // GET head via router to ensure JSON shape is stable
    let res = api
        .oneshot(
            Request::get("/registry/head")
                .body(axum::body::Body::empty())
                .unwrap(),
        )
        .await
        .unwrap();
    assert!(res.status().is_success());
    let body = body::to_bytes(res.into_body(), 1 << 20).await.unwrap();
    let s = String::from_utf8(body.to_vec()).unwrap();
    assert!(s.contains(r#""version":1"#));
}

```

### crates/svc-registry/tests/chaos_ready.rs
<a id="crates-svc-registry-tests-chaosready-rs"></a>

```rust
// Chaos readiness test placeholder (scaffold)
#[test]
fn chaos_ready_scaffold() {
    assert!(true);
}

```

### crates/svc-registry/tests/concurrency_loom.rs
<a id="crates-svc-registry-tests-concurrencyloom-rs"></a>

```rust
// Loom model placeholder (scaffold)
#[test]
fn loom_scaffold() {
    assert!(true);
}

```

### crates/svc-registry/tests/http_contract.rs
<a id="crates-svc-registry-tests-httpcontract-rs"></a>

```rust
use std::sync::Arc;

use axum::{body, http::Request, Router};
use ron_kernel::HealthState;
use svc_registry::{
    build_info,
    config::model::Config,
    http::routes::registry_routes_with_cfg,
    observability::{
        endpoints::{admin_router, AdminState},
        metrics::RegistryMetrics,
    },
    storage::{inmem::InMemoryStore, RegistryStore},
};
use tower::util::ServiceExt; // for .oneshot

#[tokio::test]
async fn readiness_flips_200_when_gates_true() {
    // Build admin plane and flip gates like main.rs does.
    let metrics = RegistryMetrics::default();
    let health = Arc::new(HealthState::default());
    health.set("services_ok", true);
    health.set("queues_ok", true);

    let admin: Router = admin_router(AdminState {
        health,
        build: build_info::build_info(),
        metrics,
    });

    // GET /readyz -> 200 with our flips
    let res = admin
        .clone()
        .oneshot(Request::get("/readyz").body(axum::body::Body::empty()).unwrap())
        .await
        .unwrap();

    assert!(res.status().is_success());

    // (Optional) also sanity-check /version and /healthz are reachable.
    let v = admin
        .clone()
        .oneshot(Request::get("/version").body(axum::body::Body::empty()).unwrap())
        .await
        .unwrap();
    assert!(v.status().is_success());

    let h = admin
        .oneshot(Request::get("/healthz").body(axum::body::Body::empty()).unwrap())
        .await
        .unwrap();
    assert!(h.status().is_success());
}

#[tokio::test]
async fn commit_bumps_head_and_returns_200() {
    let metrics = RegistryMetrics::default();
    let store = Arc::new(InMemoryStore::new());

    // Minimal config (routes only read the pieces they need)
    let cfg = Config::default();

    // Build API router
    let api: Router = registry_routes_with_cfg(metrics, store.clone(), &cfg);

    // Capture initial head
    let h0 = store.head().await;
    assert_eq!(h0.version, 0);

    // POST /registry/commit
    let req = Request::post("/registry/commit")
        .header("content-type", "application/json")
        .body(axum::body::Body::from(r#"{"payload_b3":"b3:test"}"#))
        .unwrap();

    let res = api.clone().oneshot(req).await.unwrap();
    assert!(res.status().is_success());

    // Head should bump to 1
    let h1 = store.head().await;
    assert_eq!(h1.version, 1);

    // And /registry/head returns the bumped version if we call through the router:
    let res = api
        .oneshot(Request::get("/registry/head").body(axum::body::Body::empty()).unwrap())
        .await
        .unwrap();
    assert!(res.status().is_success());
    let body = body::to_bytes(res.into_body(), 1 << 20).await.unwrap();
    let s = String::from_utf8(body.to_vec()).unwrap();
    assert!(s.contains(r#""version":1"#));
}

```

### crates/svc-registry/tests/invariants.rs
<a id="crates-svc-registry-tests-invariants-rs"></a>

```rust
// Property test placeholder (scaffold)
#[test]
fn invariants_scaffold() {
    assert!(true);
}

```

### crates/svc-registry/tests/metrics_text.rs
<a id="crates-svc-registry-tests-metricstext-rs"></a>

```rust
use std::sync::Arc;

use axum::{body, http::Request, Router};
use ron_kernel::HealthState;
use svc_registry::{
    build_info,
    observability::{
        endpoints::{admin_router, AdminState},
        metrics::RegistryMetrics,
    },
};
use tower::util::ServiceExt; // for .oneshot

#[tokio::test]
async fn metrics_text_includes_registry_counters() {
    // Build admin router with current state.
    let metrics = RegistryMetrics::default();
    let health = Arc::new(HealthState::default());
    let admin: Router = admin_router(AdminState {
        health,
        build: build_info::build_info(),
        metrics: metrics.clone(),
    });

    // GET /metrics
    let res = admin
        .clone()
        .oneshot(Request::get("/metrics").body(axum::body::Body::empty()).unwrap())
        .await
        .unwrap();

    assert!(res.status().is_success());

    // axum::body::to_bytes requires a limit param (bytes cap).
    let bytes = body::to_bytes(res.into_body(), 1 << 20).await.unwrap();
    let s = String::from_utf8(bytes.to_vec()).unwrap();

    // “Must-have” metric names:
    assert!(s.contains("registry_head_version"));
    assert!(s.contains("registry_sse_clients_connected_total"));
    assert!(s.contains("registry_sse_clients_disconnected_total"));
}

```

### crates/svc-registry/tests/storage_monotonic.rs
<a id="crates-svc-registry-tests-storagemonotonic-rs"></a>

```rust
// crates/svc-registry/tests/storage_monotonic.rs
use std::sync::Arc;
use std::time::Duration;

use svc_registry::storage::{inmem::InMemoryStore, RegistryStore};
use tokio::time::timeout;
use tokio_stream::StreamExt; // for .next()

#[tokio::test]
async fn head_is_monotonic_and_events_fire() {
    // Fresh in-memory store
    let store = Arc::new(InMemoryStore::new());

    // Head starts at version 0
    let h0 = store.head().await;
    assert_eq!(h0.version, 0);

    // Subscribe to events as a BroadcastStream
    let mut rx = store.subscribe();

    // Commit #1
    let h1 = store
        .commit("b3:abc".to_string())
        .await
        .expect("commit #1 ok");
    assert_eq!(h1.version, 1);

    // Expect an event within 500 ms
    let evt1 = timeout(Duration::from_millis(500), rx.next())
        .await
        .expect("event delivery timed out");
    assert!(evt1.is_some(), "stream ended unexpectedly");
    // If you want to assert it wasn't an error from channel:
    assert!(evt1.unwrap().is_ok(), "recv error on broadcast stream");

    // Head should now be 1
    let head_now = store.head().await;
    assert_eq!(head_now.version, 1);

    // Commit #2
    let h2 = store
        .commit("b3:def".to_string())
        .await
        .expect("commit #2 ok");
    assert_eq!(h2.version, 2);

    // Another event should arrive
    let evt2 = timeout(Duration::from_millis(500), rx.next())
        .await
        .expect("event delivery timed out (second)");
    assert!(evt2.is_some(), "stream ended unexpectedly (second)");
    assert!(evt2.unwrap().is_ok(), "recv error on broadcast stream (second)");
}

```

### crates/svc-registry/tests/vectors/approvals_ed25519.json
<a id="crates-svc-registry-tests-vectors-approvalsed25519-json"></a>

```json
{ "scaffold": "ed25519 approvals vector placeholder" }

```

### crates/svc-registry/tests/vectors/approvals_pq_mixed.json
<a id="crates-svc-registry-tests-vectors-approvalspqmixed-json"></a>

```json
{ "scaffold": "pq mixed approvals vector placeholder" }

```

### crates/svc-registry/tests/vectors/descriptor_set_v1.json
<a id="crates-svc-registry-tests-vectors-descriptorsetv1-json"></a>

```json
{ "scaffold": "descriptor set v1 placeholder" }

```

### crates/svc-registry/tests/vectors/proposal.json
<a id="crates-svc-registry-tests-vectors-proposal-json"></a>

```json
{ "scaffold": "proposal vector placeholder" }

```



---



# svc-edge

_Source: crates/svc-edge/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-11-14T02:18:37Z -->
# Code Bundle — `svc-edge`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/svc-edge/.cargo/config.toml](#crates-svc-edge--cargo-config-toml)
- [crates/svc-edge/.github/workflows/ci.yaml](#crates-svc-edge--github-workflows-ci-yaml)
- [crates/svc-edge/.github/workflows/perf-guard.yaml](#crates-svc-edge--github-workflows-perf-guard-yaml)
- [crates/svc-edge/.github/workflows/public-api.yaml](#crates-svc-edge--github-workflows-public-api-yaml)
- [crates/svc-edge/.github/workflows/render-mermaid.yaml](#crates-svc-edge--github-workflows-render-mermaid-yaml)
- [crates/svc-edge/Cargo.toml](#crates-svc-edge-Cargo-toml)
- [crates/svc-edge/benches/bench_blake3.rs](#crates-svc-edge-benches-benchblake3-rs)
- [crates/svc-edge/benches/bench_pack_read.rs](#crates-svc-edge-benches-benchpackread-rs)
- [crates/svc-edge/benches/bench_range.rs](#crates-svc-edge-benches-benchrange-rs)
- [crates/svc-edge/configs/svc-edge.toml](#crates-svc-edge-configs-svc-edge-toml)
- [crates/svc-edge/scripts/dev-run.sh](#crates-svc-edge-scripts-dev-run-sh)
- [crates/svc-edge/scripts/perf-smoke.sh](#crates-svc-edge-scripts-perf-smoke-sh)
- [crates/svc-edge/scripts/render-mermaid.sh](#crates-svc-edge-scripts-render-mermaid-sh)
- [crates/svc-edge/scripts/smoke_edge.sh](#crates-svc-edge-scripts-smokeedge-sh)
- [crates/svc-edge/src/adapters/cas.rs](#crates-svc-edge-src-adapters-cas-rs)
- [crates/svc-edge/src/adapters/live_fill.rs](#crates-svc-edge-src-adapters-livefill-rs)
- [crates/svc-edge/src/adapters/pack.rs](#crates-svc-edge-src-adapters-pack-rs)
- [crates/svc-edge/src/adapters/tls.rs](#crates-svc-edge-src-adapters-tls-rs)
- [crates/svc-edge/src/admission/body_cap.rs](#crates-svc-edge-src-admission-bodycap-rs)
- [crates/svc-edge/src/admission/decompress_guard.rs](#crates-svc-edge-src-admission-decompressguard-rs)
- [crates/svc-edge/src/admission/inflight_cap.rs](#crates-svc-edge-src-admission-inflightcap-rs)
- [crates/svc-edge/src/admission/mod.rs](#crates-svc-edge-src-admission-mod-rs)
- [crates/svc-edge/src/admission/rps_limit.rs](#crates-svc-edge-src-admission-rpslimit-rs)
- [crates/svc-edge/src/admission/timeout.rs](#crates-svc-edge-src-admission-timeout-rs)
- [crates/svc-edge/src/bin/svc-edge.rs](#crates-svc-edge-src-bin-svc-edge-rs)
- [crates/svc-edge/src/cli.rs](#crates-svc-edge-src-cli-rs)
- [crates/svc-edge/src/config.rs](#crates-svc-edge-src-config-rs)
- [crates/svc-edge/src/errors.rs](#crates-svc-edge-src-errors-rs)
- [crates/svc-edge/src/http/etag.rs](#crates-svc-edge-src-http-etag-rs)
- [crates/svc-edge/src/http/headers.rs](#crates-svc-edge-src-http-headers-rs)
- [crates/svc-edge/src/http/range.rs](#crates-svc-edge-src-http-range-rs)
- [crates/svc-edge/src/lib.rs](#crates-svc-edge-src-lib-rs)
- [crates/svc-edge/src/metrics.rs](#crates-svc-edge-src-metrics-rs)
- [crates/svc-edge/src/readiness.rs](#crates-svc-edge-src-readiness-rs)
- [crates/svc-edge/src/routes/assets.rs](#crates-svc-edge-src-routes-assets-rs)
- [crates/svc-edge/src/routes/health.rs](#crates-svc-edge-src-routes-health-rs)
- [crates/svc-edge/src/routes/mod.rs](#crates-svc-edge-src-routes-mod-rs)
- [crates/svc-edge/src/routes/prometheus.rs](#crates-svc-edge-src-routes-prometheus-rs)
- [crates/svc-edge/src/routes/ready.rs](#crates-svc-edge-src-routes-ready-rs)
- [crates/svc-edge/src/security/audit.rs](#crates-svc-edge-src-security-audit-rs)
- [crates/svc-edge/src/security/cors.rs](#crates-svc-edge-src-security-cors-rs)
- [crates/svc-edge/src/security/hsts.rs](#crates-svc-edge-src-security-hsts-rs)
- [crates/svc-edge/src/state.rs](#crates-svc-edge-src-state-rs)
- [crates/svc-edge/src/supervisor.rs](#crates-svc-edge-src-supervisor-rs)
- [crates/svc-edge/src/util/backoff.rs](#crates-svc-edge-src-util-backoff-rs)
- [crates/svc-edge/src/util/bytes.rs](#crates-svc-edge-src-util-bytes-rs)
- [crates/svc-edge/src/util/size_parse.rs](#crates-svc-edge-src-util-sizeparse-rs)
- [crates/svc-edge/src/work/queue.rs](#crates-svc-edge-src-work-queue-rs)
- [crates/svc-edge/src/work/shutdown.rs](#crates-svc-edge-src-work-shutdown-rs)
- [crates/svc-edge/src/work/worker.rs](#crates-svc-edge-src-work-worker-rs)
- [crates/svc-edge/tests/concurrency_backpressure.rs](#crates-svc-edge-tests-concurrencybackpressure-rs)
- [crates/svc-edge/tests/fuzz_headers.rs](#crates-svc-edge-tests-fuzzheaders-rs)
- [crates/svc-edge/tests/http_contract.rs](#crates-svc-edge-tests-httpcontract-rs)
- [crates/svc-edge/tests/i_10_deterministic_failures.rs](#crates-svc-edge-tests-i10deterministicfailures-rs)
- [crates/svc-edge/tests/i_11_pack_integrity.rs](#crates-svc-edge-tests-i11packintegrity-rs)
- [crates/svc-edge/tests/i_1_hardening_ingress.rs](#crates-svc-edge-tests-i1hardeningingress-rs)
- [crates/svc-edge/tests/i_4_http_semantics.rs](#crates-svc-edge-tests-i4httpsemantics-rs)
- [crates/svc-edge/tests/i_5_content_address.rs](#crates-svc-edge-tests-i5contentaddress-rs)
- [crates/svc-edge/tests/i_6_amnesia.rs](#crates-svc-edge-tests-i6amnesia-rs)
- [crates/svc-edge/tests/i_8_size_bounds.rs](#crates-svc-edge-tests-i8sizebounds-rs)
- [crates/svc-edge/tests/i_9_observability_contract.rs](#crates-svc-edge-tests-i9observabilitycontract-rs)
- [crates/svc-edge/tests/readiness_logic.rs](#crates-svc-edge-tests-readinesslogic-rs)

### crates/svc-edge/.cargo/config.toml
<a id="crates-svc-edge--cargo-config-toml"></a>

```toml
[build]
rustflags = ["-Dwarnings"]

[env]
RUST_LOG = "info"

```

### crates/svc-edge/.github/workflows/ci.yaml
<a id="crates-svc-edge--github-workflows-ci-yaml"></a>

```yaml
name: ci
on: [push, pull_request]
jobs:
  rust:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - run: cargo fmt --all --check
      - run: cargo clippy -p svc-edge2 -- -D warnings
      - run: cargo test -p svc-edge2

```

### crates/svc-edge/.github/workflows/perf-guard.yaml
<a id="crates-svc-edge--github-workflows-perf-guard-yaml"></a>

```yaml
name: perf-guard
on:
  schedule:
    - cron: '0 3 * * *'
jobs:
  perf:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo 'perf guard placeholder'

```

### crates/svc-edge/.github/workflows/public-api.yaml
<a id="crates-svc-edge--github-workflows-public-api-yaml"></a>

```yaml
name: public-api
on: [push, pull_request]
jobs:
  api:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - run: cargo install cargo-public-api || true
      - run: cargo public-api -p svc-edge2

```

### crates/svc-edge/.github/workflows/render-mermaid.yaml
<a id="crates-svc-edge--github-workflows-render-mermaid-yaml"></a>

```yaml
name: render-mermaid
on: [push, pull_request]
jobs:
  mmdc:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm i -g @mermaid-js/mermaid-cli
      - run: bash crates/svc-edge2/scripts/render-mermaid.sh

```

### crates/svc-edge/Cargo.toml
<a id="crates-svc-edge-Cargo-toml"></a>

```toml
[package]
name = "svc-edge"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
publish = false

[features]
default = ["cli"]
cli = ["dep:clap"]
tls = ["dep:tokio-rustls"]
pq = []
otel = []

[dependencies]
# Core utils
anyhow = { workspace = true, features = ["std"] }
once_cell = { workspace = true }
parking_lot = { workspace = true }
thiserror = { workspace = true }
toml = { workspace = true }

# Serde / JSON
serde = { workspace = true }
serde_json = { workspace = true }

# Logging / metrics
tracing = { workspace = true }
tracing-subscriber = { workspace = true, features = ["fmt","env-filter"] }
prometheus = { workspace = true }

# Axum & friends (Axum 0.7 via workspace pins)
# IMPORTANT: enable "tokio","http1","http2","json" so Router<S> works with axum::serve
axum = { workspace = true, features = ["tokio","http1","http2","json"] }
http = { workspace = true }

# Tokio runtime
tokio = { workspace = true, features = ["rt-multi-thread","macros","signal","net","time","io-util"] }
tokio-util = { workspace = true }              # for CancellationToken

# TLS (optional)
tokio-rustls = { workspace = true, optional = true }

# Tower stack (limits/timeout we actually use)
tower = { workspace = true, features = ["util","limit","timeout"] }
# We’re using Axum’s DefaultBodyLimit, but keeping tower-http 'limit' is fine for future use.
tower-http = { workspace = true, features = ["limit"] }

# CLI (optional)
clap = { version = "4", features = ["derive"], optional = true }

# project-internal
ron-kernel = { path = "../ron-kernel" }

# NEW: assets/CAS helpers
blake3 = "1.5.4"
percent-encoding = "2.3.1"
mime_guess = "2.0.5"

[dev-dependencies]

```

### crates/svc-edge/benches/bench_blake3.rs
<a id="crates-svc-edge-benches-benchblake3-rs"></a>

```rust

```

### crates/svc-edge/benches/bench_pack_read.rs
<a id="crates-svc-edge-benches-benchpackread-rs"></a>

```rust

```

### crates/svc-edge/benches/bench_range.rs
<a id="crates-svc-edge-benches-benchrange-rs"></a>

```rust

```

### crates/svc-edge/configs/svc-edge.toml
<a id="crates-svc-edge-configs-svc-edge-toml"></a>

```toml
# Minimal runnable config (admin plane only in this increment).
bind_addr = "0.0.0.0:8080"
metrics_addr = "127.0.0.1:9909"

[security]
amnesia = true

```

### crates/svc-edge/scripts/dev-run.sh
<a id="crates-svc-edge-scripts-dev-run-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
cd "$(dirname "${BASH_SOURCE[0]}")/.."
RUST_LOG=${RUST_LOG:-info} \
SVC_EDGE_BIND_ADDR=${SVC_EDGE_BIND_ADDR:-0.0.0.0:8080} \
SVC_EDGE_METRICS_ADDR=${SVC_EDGE_METRICS_ADDR:-127.0.0.1:9909} \
SVC_EDGE_SECURITY__AMNESIA=${SVC_EDGE_SECURITY__AMNESIA:-true} \
cargo run -p svc-edge2 -- \
  --config ./configs/svc-edge.toml

```

### crates/svc-edge/scripts/perf-smoke.sh
<a id="crates-svc-edge-scripts-perf-smoke-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
URL=${1:-http://127.0.0.1:8080/edge/assets/path}
bombardier -c 64 -d 60s -l "$URL"

```

### crates/svc-edge/scripts/render-mermaid.sh
<a id="crates-svc-edge-scripts-render-mermaid-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
cd "$(dirname "${BASH_SOURCE[0]}")/.."
for f in $(git ls-files 'docs/mmd/*.mmd'); do
  out=${f/mmd/svg}
  out=${out%.mmd}.svg
  mkdir -p $(dirname "$out")
  mmdc -i "$f" -o "$out"
done

```

### crates/svc-edge/scripts/smoke_edge.sh
<a id="crates-svc-edge-scripts-smokeedge-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

ADMIN=${ADMIN:-127.0.0.1:9909}
API=${API:-127.0.0.1:8080}
ASSETS_DIR=${SVC_EDGE_ASSETS_DIR:-assets}
TEST_FILE=${TEST_FILE:-hello.txt}

echo "[INFO] Admin plane checks @ http://${ADMIN}"
curl -fsS -o /dev/null http://${ADMIN}/healthz && echo "[OK] /healthz"
curl -fsS -o /dev/null http://${ADMIN}/metrics && echo "[OK] /metrics"

echo "[STEP] Ensure assets dir + test file"
mkdir -p "${ASSETS_DIR}"
if [ ! -f "${ASSETS_DIR}/${TEST_FILE}" ]; then
  echo "hello-edge" > "${ASSETS_DIR}/${TEST_FILE}"
fi

echo "[STEP] Readiness"
curl -fsS http://${ADMIN}/readyz && echo

echo "[STEP] GET /edge/assets/${TEST_FILE}"
resp_headers=$(mktemp)
curl -i -fsS http://${API}/edge/assets/${TEST_FILE} | tee "${resp_headers}" | sed -n '1,999p' >/dev/null
etag=$(grep -i '^etag:' "${resp_headers}" | awk '{print $2}' | tr -d '\r')
echo "[OK] ETag: ${etag}"

echo "[STEP] 304 via If-None-Match"
curl -i -fsS http://${API}/edge/assets/${TEST_FILE} -H "If-None-Match: ${etag}" | head -n 1

echo "[STEP] 206 via Range: bytes=2-"
curl -i -fsS http://${API}/edge/assets/${TEST_FILE} -H 'Range: bytes=2-' | sed -n '1,6p'

echo "[STEP] CAS demo (blake3)"
# Use the same ETag (it’s the blake3 digest) to stage CAS file
digest=$(echo "${etag}" | tr -d '"')
mkdir -p "${ASSETS_DIR}/cas/blake3"
cp "${ASSETS_DIR}/${TEST_FILE}" "${ASSETS_DIR}/cas/blake3/${digest}"
curl -i -fsS http://${API}/cas/blake3/${digest} | sed -n '1,6p'
curl -i -fsS http://${API}/cas/blake3/${digest} -H 'Range: bytes=2-' | sed -n '1,6p'

echo "[STEP] Burst /edge/assets/${TEST_FILE} (200×200)"
seq 1 200 | xargs -n1 -P200 -I{} curl -s -o /dev/null -w "%{http_code}\n" \
  http://${API}/edge/assets/${TEST_FILE} | sort | uniq -c

echo "[DONE] smoke_edge.sh completed successfully."

```

### crates/svc-edge/src/adapters/cas.rs
<a id="crates-svc-edge-src-adapters-cas-rs"></a>

```rust
//! Adapter: content-addressed storage (read-only) — stub.

/// Digest bytes (opaque placeholder).
pub type Digest = [u8; 32];

/// CAS interface (read-only, stubbed).
pub trait CasStore: Send + Sync {
    /// Fetch a blob by digest. Returns `None` if missing.
    fn get(&self, _digest: &Digest) -> Option<Vec<u8>>;
}

/// No-op CAS for early wiring.
#[derive(Debug, Clone, Default)]
pub struct NullCas;

impl CasStore for NullCas {
    fn get(&self, _digest: &Digest) -> Option<Vec<u8>> {
        None
    }
}

```

### crates/svc-edge/src/adapters/live_fill.rs
<a id="crates-svc-edge-src-adapters-livefill-rs"></a>

```rust
//! Adapter: live-fill miss handler (fetch-on-miss) — stub.

use super::cas::{CasStore, Digest};

/// Miss policy for live fill (placeholder).
#[derive(Debug, Clone, Copy)]
pub enum LiveFillPolicy {
    /// Do not attempt live-fill on misses.
    Off,
    /// Allow live-fill with bounded concurrency (details TBD).
    On,
}

impl Default for LiveFillPolicy {
    fn default() -> Self {
        LiveFillPolicy::Off
    }
}

/// Live-fill engine stub.
#[derive(Debug, Default)]
pub struct LiveFill;

impl LiveFill {
    /// Attempt to fill a digest; always returns `None` for now.
    pub async fn fill<C: CasStore>(&self, _cas: &C, _d: &Digest) -> Option<Vec<u8>> {
        None
    }
}

```

### crates/svc-edge/src/adapters/pack.rs
<a id="crates-svc-edge-src-adapters-pack-rs"></a>

```rust
//! Adapter: read-only pack access (e.g., PMTiles/pack files) — stub.

use std::path::PathBuf;

/// Pack source descriptor (placeholder).
#[derive(Debug, Clone)]
pub struct PackSource {
    /// Path to on-disk pack file (or future remote locator).
    pub path: PathBuf,
}

/// Minimal pack trait (read-only, stubbed).
pub trait PackStore: Send + Sync {
    /// Return `true` if the pack appears available.
    fn available(&self) -> bool;
}

/// No-op pack implementation used for wiring tests.
#[derive(Debug, Clone, Default)]
pub struct NullPack;

impl PackStore for NullPack {
    fn available(&self) -> bool {
        false
    }
}

```

### crates/svc-edge/src/adapters/tls.rs
<a id="crates-svc-edge-src-adapters-tls-rs"></a>

```rust
//! TLS adapter placeholders (server config wiring) — stub.

/// TLS mode (placeholder).
#[derive(Debug, Clone, Copy)]
pub enum TlsMode {
    /// Plain TCP (no TLS).
    Plain,
    /// TLS via rustls (details TBD).
    Rustls,
}

impl Default for TlsMode {
    fn default() -> Self {
        TlsMode::Plain
    }
}

```

### crates/svc-edge/src/admission/body_cap.rs
<a id="crates-svc-edge-src-admission-bodycap-rs"></a>

```rust
//! Admission guard: maximum request body bytes (stub).

/// Configuration for a future body cap guard.
#[derive(Debug, Clone, Copy)]
pub struct BodyCap {
    /// Maximum allowed bytes in the request body.
    pub max_bytes: u64,
}

impl Default for BodyCap {
    fn default() -> Self {
        Self { max_bytes: 1_048_576 } // 1 MiB
    }
}

impl BodyCap {
    /// Create a new cap with the given maximum.
    pub fn new(max_bytes: u64) -> Self {
        Self { max_bytes }
    }
}

```

### crates/svc-edge/src/admission/decompress_guard.rs
<a id="crates-svc-edge-src-admission-decompressguard-rs"></a>

```rust
//! Admission guard: optional transparent decompression (stub).

/// Decompression posture (placeholder).
#[derive(Debug, Clone, Copy)]
pub enum Decompress {
    /// Allow a safe set (e.g., gzip) — details TBD.
    Safe,
    /// Disable all decompression.
    Off,
}

impl Default for Decompress {
    fn default() -> Self {
        Decompress::Off
    }
}

```

### crates/svc-edge/src/admission/inflight_cap.rs
<a id="crates-svc-edge-src-admission-inflightcap-rs"></a>

```rust
//! Admission guard: cap concurrent in-flight requests (stub).

/// In-flight concurrency cap (placeholder).
#[derive(Debug, Clone, Copy)]
pub struct InflightCap {
    /// Maximum concurrent requests the service will process.
    pub max: usize,
}

impl Default for InflightCap {
    fn default() -> Self {
        Self { max: 256 }
    }
}

```

### crates/svc-edge/src/admission/mod.rs
<a id="crates-svc-edge-src-admission-mod-rs"></a>

```rust
//! Admission chain (custom minimal layer) for the API plane.
//!
//! RO:WHAT
//! - Enforce **timeout** and **inflight cap** with a tiny, cloneable Tower `Layer`.
//!
//! RO:WHY
//! - Keeps the service `Clone + Send + 'static` with `Error = Infallible` to satisfy
//!   `Router::route_layer` bounds in axum 0.7, avoiding brittle combinator stacks.
//! - No `http_body`/`bytes` deps; no body-type churn.
//!
//! RO:INVARIANTS
//! - No locks across `.await`; uses `Arc<Semaphore>`.
//! - Deterministic rejections (408/503); no ambiguous 500s from the layer itself.
//!
//! RO:METRICS
//! - Ticks `edge_rejects_total{reason}` on 408 (timeout) and 503 (busy).
//!
//! RO:CONFIG
//! - Prefer `apply_with(router, timeout, max_inflight)` for env/Config-driven caps.
//! - `apply_defaults(...)` kept for dev convenience.

use std::{
    convert::Infallible,
    future::Future,
    pin::Pin,
    sync::Arc,
    task::{Context, Poll},
    time::Duration,
};

use axum::{
    response::{IntoResponse, Response},
    Json, Router,
};
use http::{Request, StatusCode};
use serde_json::json;
use tokio::sync::Semaphore;
use tower::{Layer, Service};

/// Default tunables (dev convenience).
const DEFAULT_TIMEOUT: Duration = Duration::from_secs(5);
const DEFAULT_MAX_INFLIGHT: usize = 256;

/// Apply admission guards with dev defaults.
pub fn apply_defaults<S>(router: Router<S>) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    apply_with(router, DEFAULT_TIMEOUT, DEFAULT_MAX_INFLIGHT)
}

/// Apply admission guards with explicit caps (Config/env-friendly).
pub fn apply_with<S>(router: Router<S>, timeout: Duration, max_inflight: usize) -> Router<S>
where
    S: Clone + Send + Sync + 'static,
{
    let layer = AdmissionLayer::new(AdmissionConfig {
        timeout,
        max_inflight,
    });
    router.route_layer(layer)
}

/// Configuration for the admission guard.
#[derive(Debug, Clone, Copy)]
pub struct AdmissionConfig {
    /// Per-request wall-clock timeout (e.g., 5s → 408 on expiry).
    pub timeout: Duration,
    /// Maximum number of inflight requests (beyond this → 503).
    pub max_inflight: usize,
}

/// Layer that installs [`AdmissionService`] on the router.
#[derive(Clone)]
pub struct AdmissionLayer {
    cfg: AdmissionConfig,
}

impl AdmissionLayer {
    /// Build a new admission layer with the given config.
    pub fn new(cfg: AdmissionConfig) -> Self {
        Self { cfg }
    }
}

impl<S> Layer<S> for AdmissionLayer {
    type Service = AdmissionService<S>;

    fn layer(&self, inner: S) -> Self::Service {
        AdmissionService::new(inner, self.cfg)
    }
}

/// Service wrapper that enforces timeout and inflight limits.
#[derive(Clone)]
pub struct AdmissionService<S> {
    inner: S,
    cfg: AdmissionConfig,
    inflight: Arc<Semaphore>,
}

impl<S> AdmissionService<S> {
    fn new(inner: S, cfg: AdmissionConfig) -> Self {
        Self {
            inner,
            cfg,
            inflight: Arc::new(Semaphore::new(cfg.max_inflight)),
        }
    }
}

impl<S, B> Service<Request<B>> for AdmissionService<S>
where
    S: Service<Request<B>, Error = Infallible> + Clone + Send + 'static,
    S::Response: IntoResponse + Send + 'static,
    S::Future: Send + 'static,
    B: Send + 'static,
{
    // Use axum::Response so we can build responses from any IntoResponse.
    type Response = Response;
    type Error = Infallible;
    type Future =
        Pin<Box<dyn Future<Output = Result<Self::Response, Self::Error>> + Send + 'static>>;

    fn poll_ready(&mut self, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {
        // Error is already Infallible; just forward it.
        self.inner.poll_ready(cx)
    }

    fn call(&mut self, req: Request<B>) -> Self::Future {
        let cfg = self.cfg;
        let mut inner = self.inner.clone();
        let inflight = Arc::clone(&self.inflight);

        Box::pin(async move {
            // Inflight cap → 503 when saturated.
            let _permit = match inflight.try_acquire() {
                Ok(p) => p,
                Err(_) => {
                    crate::metrics::inc_reject("busy");
                    let body = Json(json!({ "ok": false, "reason": "busy" }));
                    return Ok((StatusCode::SERVICE_UNAVAILABLE, body).into_response());
                }
            };

            // Timeout → 408 when exceeded.
            match tokio::time::timeout(cfg.timeout, inner.call(req)).await {
                Ok(Ok(resp)) => Ok(resp.into_response()),
                Ok(Err(_)) => {
                    // Inner service promised Infallible; this should be unreachable.
                    let body = Json(json!({ "ok": false, "reason": "inner_error" }));
                    Ok((StatusCode::INTERNAL_SERVER_ERROR, body).into_response())
                }
                Err(_) => {
                    crate::metrics::inc_reject("timeout");
                    let body = Json(json!({ "ok": false, "reason": "timeout" }));
                    Ok((StatusCode::REQUEST_TIMEOUT, body).into_response())
                }
            }
        })
    }
}

```

### crates/svc-edge/src/admission/rps_limit.rs
<a id="crates-svc-edge-src-admission-rpslimit-rs"></a>

```rust
//! Admission guard: requests-per-second limiter (stub).

/// Simple RPS limiter configuration (placeholder).
#[derive(Debug, Clone, Copy)]
pub struct RpsLimit {
    /// Approximate target request rate (per second).
    pub rps: u64,
}

impl Default for RpsLimit {
    fn default() -> Self {
        Self { rps: 1000 }
    }
}

```

### crates/svc-edge/src/admission/timeout.rs
<a id="crates-svc-edge-src-admission-timeout-rs"></a>

```rust
//! Admission guard: per-request timeout (stub).

use std::time::Duration;

/// Timeout configuration (placeholder).
#[derive(Debug, Clone, Copy)]
pub struct Timeout {
    /// Maximum request processing time.
    pub duration: Duration,
}

impl Default for Timeout {
    fn default() -> Self {
        Self { duration: Duration::from_secs(5) }
    }
}

```

### crates/svc-edge/src/bin/svc-edge.rs
<a id="crates-svc-edge-src-bin-svc-edge-rs"></a>

```rust
/// GROK WROTE THIS (adapted to use svc-edge lib surface)
// svc-edge — bin wiring for Axum 0.7 with stateful routers and the real library state.
// - Uses Router directly with `axum::serve` (no manual make_service).
// - Clean graceful shutdown with CancellationToken.
// - Two listeners: admin (health/ready/metrics) and api (edge surface).
// RO:WHAT — Binary entrypoint for svc-edge.
// RO:WHY — Boots admin + API planes; uses Config/AppState/EdgeMetrics/HealthState from the lib.
// RO:INTERACTS — axum::serve, tokio::net, ron_kernel::wait_for_ctrl_c; AppState (config/metrics/health).
// RO:INVARIANTS — No ambient auth; binds config-driven; readiness is degrade-first until gates flip.
// RO:METRICS — /metrics exposes Prometheus; admission layer will tick rejects/latency later.
// RO:CONFIG — Uses `Config::from_sources(None)` (env + defaults) + temp env knobs for admission/assets.
// RO:SECURITY — Amnesia posture exposed via metrics (future: enforced persistence rules).
// RO:TEST — Driven by http_contract, readiness_logic, i_1_hardening_ingress, etc.

use std::{env, net::SocketAddr, sync::Arc, time::Duration};

use anyhow::Context;
use axum::{
    routing::{get, post},
    Router,
};
use tokio::{net::TcpListener, signal};
use tokio_util::sync::CancellationToken;
use tracing::{error, info, Level};
use tracing_subscriber::{fmt, EnvFilter};

use svc_edge::admission;
use svc_edge::metrics::seed_from_health;
use svc_edge::readiness::readiness_handler;
use svc_edge::routes::{assets, health, prometheus};
use svc_edge::{wait_for_ctrl_c, AppState, Config, EdgeMetrics, HealthState};

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    init_tracing();

    // --- Config (from svc-edge::Config, env + defaults) --------------------
    // Reads SVC_EDGE_BIND_ADDR, SVC_EDGE_METRICS_ADDR, SVC_EDGE_SECURITY__AMNESIA, etc.
    let cfg: Config = Config::from_sources(None).context("load svc-edge config")?;

    let admin_addr: SocketAddr = cfg.metrics_addr;
    let api_addr: SocketAddr = cfg.bind_addr;

    // Admission env overrides (temporary until wired into Config fully).
    let timeout_ms: u64 = env_var_parse("SVC_EDGE_ADMISSION_TIMEOUT_MS", 5_000);
    let max_inflight: usize = env_var_parse("SVC_EDGE_ADMISSION_MAX_INFLIGHT", 256);

    // Asset root (temporary; real path will come from Config.assets.root).
    // Default to ./assets relative to current working dir.
    let assets_root: String = env::var("SVC_EDGE_ASSETS_DIR").unwrap_or_else(|_| "assets".to_string());

    info!(
        %admin_addr, %api_addr, timeout_ms, max_inflight, assets_root,
        "svc-edge: resolved bind addresses and admission caps"
    );

    // --- Health + metrics + shared AppState --------------------------------
    let health: Arc<HealthState> = Arc::new(HealthState::new());
    let metrics = EdgeMetrics::new();

    // Seed metrics with amnesia posture (additional gates will be wired later).
    seed_from_health(health.clone(), &metrics, cfg.security.amnesia);

    // Flip readiness: config_loaded=true (we made it here).
    health.set("config_loaded", true);

    let state = AppState::new(cfg, metrics, health.clone());

    // --- Simple service readiness probe (assets dir exists) -----------------
    // For now, require that the assets root exists to consider "services_ok".
    let services_ok = std::path::Path::new(&assets_root).exists();
    health.set("services_ok", services_ok);

    // --- Bind listeners -----------------------------------------------------
    let admin_listener = TcpListener::bind(admin_addr)
        .await
        .with_context(|| format!("bind admin listener at {admin_addr}"))?;
    let api_listener = TcpListener::bind(api_addr)
        .await
        .with_context(|| format!("bind api listener at {api_addr}"))?;

    info!(%admin_addr, "svc-edge: admin plane listening");
    info!(%api_addr, "svc-edge: api plane listening");

    // --- Build routers (admin + api) ---------------------------------------

    // Admin plane: /healthz, /readyz, /metrics.
    let admin_app: Router = Router::new()
        .route("/healthz", get(health::healthz))
        .route("/readyz", get(readiness_handler))
        .route("/metrics", get(prometheus::metrics))
        .with_state(state.clone());

    // API plane: assets + CAS + test endpoints.
    let api_router: Router = Router::new()
        // Assets and CAS (basic ETag + Range)
        .route("/edge/assets/*path", get(assets::get_asset))
        .route("/cas/:algo/:digest", get(assets::get_cas))
        // Test helpers
        .route("/echo", post(assets::echo))
        .route("/echo/slow/:ms", post(assets::echo_slow))
        .with_state(state.clone());

    // Apply the admission chain with env-driven caps.
    let api_app: Router = admission::apply_with(
        api_router,
        Duration::from_millis(timeout_ms),
        max_inflight,
    );

    // --- Graceful shutdown wiring ------------------------------------------
    let cancel = CancellationToken::new();
    let t_admin = cancel.clone();
    let t_api = cancel.clone();

    let admin_srv = async move {
        axum::serve(admin_listener, admin_app)
            .with_graceful_shutdown(t_admin.cancelled_owned())
            .await
            .context("admin server failed")
    };

    let api_srv = async move {
        axum::serve(api_listener, api_app)
            .with_graceful_shutdown(t_api.cancelled_owned())
            .await
            .context("api server failed")
    };

    info!("svc-edge: up; waiting for traffic or shutdown signal");

    tokio::select! {
        res = admin_srv => {
            if let Err(e) = res {
                error!(error=%e, "admin server error");
                return Err(e);
            }
        }
        res = api_srv => {
            if let Err(e) = res {
                error!(error=%e, "api server error");
                return Err(e);
            }
        }
        _ = wait_for_shutdown_signal() => {
            info!("shutdown signal received");
        }
    }

    cancel.cancel();
    tokio::time::sleep(Duration::from_millis(100)).await;
    info!("svc-edge exiting");
    Ok(())
}

fn env_var_parse<T: std::str::FromStr>(key: &str, default: T) -> T {
    match std::env::var(key) {
        Ok(v) => v.parse().unwrap_or(default),
        Err(_) => default,
    }
}

async fn wait_for_shutdown_signal() {
    // Prefer the kernel helper if available, otherwise fallback.
    wait_for_ctrl_c().await;
    // Fallback: tokio ctrl-c (no-op if already triggered).
    let _ = signal::ctrl_c().await;
}

fn init_tracing() {
    // Example: RUST_LOG=info,hyper=warn,axum::rejection=trace
    let filter =
        EnvFilter::try_from_default_env().unwrap_or_else(|_| EnvFilter::new("info,hyper=warn"));

    fmt()
        .with_max_level(Level::INFO)
        .with_env_filter(filter)
        .with_target(false)
        .compact()
        .init();
}

```

### crates/svc-edge/src/cli.rs
<a id="crates-svc-edge-src-cli-rs"></a>

```rust
//! CLI parsing (flags are minimal for the first increment).

use std::path::PathBuf;

#[cfg(feature = "cli")]
use clap::Parser;

/// CLI flags (mirrors docs/CONFIG.md as we grow).
#[cfg_attr(feature = "cli", derive(Parser))]
#[derive(Clone, Debug, Default)]
#[cfg_attr(
    feature = "cli",
    command(name = "svc-edge", author, version, about = "svc-edge service")
)]
pub struct Cli {
    /// Path to the svc-edge TOML config file.
    #[cfg_attr(feature = "cli", arg(long = "config"))]
    pub config_path: Option<PathBuf>,
}

impl Cli {
    /// Parse CLI flags from the current process environment/argv.
    ///
    /// When the `cli` feature is disabled, returns defaults.
    #[cfg(feature = "cli")]
    pub fn parse_from_env() -> Self {
        <Self as clap::Parser>::parse()
    }

    /// Parse CLI flags from the current process environment/argv.
    ///
    /// When the `cli` feature is disabled, returns defaults.
    #[cfg(not(feature = "cli"))]
    pub fn parse_from_env() -> Self {
        Self::default()
    }
}

```

### crates/svc-edge/src/config.rs
<a id="crates-svc-edge-src-config-rs"></a>

```rust
//! Config for svc-edge.
//!
//! RO:WHAT
//! - Provides bind addresses, security posture, admission caps, and assets root.
//! - Loads from ENV (TOML reader can be added later without changing the API).
//!
//! RO:ENV
//! - `SVC_EDGE_BIND_ADDR`              (default `"0.0.0.0:8080"`)
//! - `SVC_EDGE_METRICS_ADDR`           (default `"127.0.0.1:9909"`)
//! - `SVC_EDGE_SECURITY__AMNESIA`      (default `"0"`)
//! - `SVC_EDGE_ADMISSION_TIMEOUT_MS`   (default `"5000"`)
//! - `SVC_EDGE_ADMISSION_MAX_INFLIGHT` (default `"256"`)
//! - `SVC_EDGE_ASSETS_DIR`             (default `"assets"`)

use std::{net::SocketAddr, path::PathBuf, str::FromStr};

/// Top-level configuration for the svc-edge process.
///
/// Values are derived from environment variables (see module docs).
#[derive(Clone, Debug)]
pub struct Config {
    /// Address for the public API plane (e.g., `/edge/assets/*`, `/cas/*`).
    pub bind_addr: SocketAddr,
    /// Address for the admin plane (e.g., `/healthz`, `/readyz`, `/metrics`).
    pub metrics_addr: SocketAddr,
    /// Security posture settings (e.g., amnesia mode).
    pub security: SecurityCfg,
    /// Admission guard settings (timeouts, inflight caps).
    pub admission: AdmissionCfg,
    /// Asset adapter settings (temporary FS root until pack/CAS adapters land).
    pub assets: AssetsCfg,
}

/// Security posture for the service.
#[derive(Clone, Debug)]
pub struct SecurityCfg {
    /// Amnesia mode (true = prefer RAM/avoid persistence; best-effort on this crate).
    pub amnesia: bool,
}

/// Admission caps for the API plane.
#[derive(Clone, Debug)]
pub struct AdmissionCfg {
    /// Per-request wall-clock timeout in milliseconds (→ HTTP 408 on expiry).
    pub timeout_ms: u64,
    /// Maximum number of inflight requests (→ HTTP 503 when saturated).
    pub max_inflight: usize,
}

/// Asset adapter configuration (temporary filesystem root).
#[derive(Clone, Debug)]
pub struct AssetsCfg {
    /// Filesystem root used by the current asset scaffold.
    pub root: PathBuf,
}

impl Config {
    /// Load configuration from environment variables.
    ///
    /// The `_maybe_path` parameter is reserved for future TOML loading and is
    /// ignored for now to keep the public API stable.
    pub fn from_sources(_maybe_path: Option<&str>) -> anyhow::Result<Self> {
        let bind_addr = env_parse("SVC_EDGE_BIND_ADDR", "0.0.0.0:8080".to_string());
        let metrics_addr = env_parse("SVC_EDGE_METRICS_ADDR", "127.0.0.1:9909".to_string());
        let amnesia = env_parse_bool("SVC_EDGE_SECURITY__AMNESIA", false);
        let timeout_ms = env_parse("SVC_EDGE_ADMISSION_TIMEOUT_MS", 5_000u64);
        let max_inflight = env_parse("SVC_EDGE_ADMISSION_MAX_INFLIGHT", 256usize);
        let assets_root = std::env::var("SVC_EDGE_ASSETS_DIR").unwrap_or_else(|_| "assets".into());

        Ok(Self {
            bind_addr: parse_addr(bind_addr)?,
            metrics_addr: parse_addr(metrics_addr)?,
            security: SecurityCfg { amnesia },
            admission: AdmissionCfg {
                timeout_ms,
                max_inflight,
            },
            assets: AssetsCfg {
                root: PathBuf::from(assets_root),
            },
        })
    }
}

/// Parse a `SocketAddr` from a string.
fn parse_addr(s: String) -> anyhow::Result<SocketAddr> {
    Ok(SocketAddr::from_str(&s)?)
}

/// Parse an environment variable into a type implementing `FromStr`,
/// falling back to `default` on absence or parse failure.
fn env_parse<T: FromStr>(key: &str, default: T) -> T {
    match std::env::var(key) {
        Ok(v) => v.parse().unwrap_or(default),
        Err(_) => default,
    }
}

/// Parse an environment boolean with common truthy/falsey values
/// (e.g., `1/0`, `true/false`, `yes/no`, `on/off`).
fn env_parse_bool(key: &str, default: bool) -> bool {
    match std::env::var(key) {
        Ok(v) => match v.as_str() {
            "1" | "true" | "TRUE" | "yes" | "on" => true,
            "0" | "false" | "FALSE" | "no" | "off" => false,
            _ => default,
        },
        Err(_) => default,
    }
}

```

### crates/svc-edge/src/errors.rs
<a id="crates-svc-edge-src-errors-rs"></a>

```rust
//! Error taxonomy → deterministic HTTP mapping (reserved for later endpoints).

use thiserror::Error;

/// Edge service error kinds used to categorize failures.
///
/// Mapping to HTTP status codes happens in the route layer.
#[derive(Debug, Error)]
pub enum EdgeError {
    /// Service is not yet ready to serve the requested operation.
    #[error("not ready: {0}")]
    NotReady(&'static str),

    /// The request was rejected by rate limiting or admission controls.
    #[error("rate limited")]
    RateLimited,

    /// The request was malformed or violated input constraints.
    #[error("bad request: {0}")]
    BadRequest(&'static str),

    /// An unexpected internal error occurred.
    #[error("internal error")]
    Internal,
}

impl EdgeError {
    /// Short machine-readable reason tag (for logs/metrics labels).
    pub fn reason(&self) -> &'static str {
        match self {
            EdgeError::NotReady(_) => "not_ready",
            EdgeError::RateLimited => "rate_limit",
            EdgeError::BadRequest(_) => "bad_request",
            EdgeError::Internal => "internal",
        }
    }
}

```

### crates/svc-edge/src/http/etag.rs
<a id="crates-svc-edge-src-http-etag-rs"></a>

```rust
//! ETag helpers (opaque ETag strings) — stub.

/// Strong ETag wrapper (opaque).
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct ETag(pub String);

impl ETag {
    /// Format as a strong ETag: `"value"`.
    pub fn strong(value: impl AsRef<str>) -> Self {
        Self(format!("\"{}\"", value.as_ref()))
    }
}

```

### crates/svc-edge/src/http/headers.rs
<a id="crates-svc-edge-src-http-headers-rs"></a>

```rust
//! HTTP helper utilities — header names and helpers (stub).

/// Common constant header names (subset, placeholders).
pub mod names {
    /// `ETag`
    pub const ETAG: &str = "ETag";
    /// `If-None-Match`
    pub const IF_NONE_MATCH: &str = "If-None-Match";
    /// `Accept-Ranges`
    pub const ACCEPT_RANGES: &str = "Accept-Ranges";
}

```

### crates/svc-edge/src/http/range.rs
<a id="crates-svc-edge-src-http-range-rs"></a>

```rust
//! HTTP range parsing primitives (single-range only) — stub.

/// Single byte range (inclusive start, inclusive end).
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct ByteRange {
    /// Start offset.
    pub start: u64,
    /// End offset (inclusive).
    pub end: u64,
}

impl ByteRange {
    /// Length of the range in bytes, saturating.
    pub fn len(&self) -> u64 {
        self.end.saturating_sub(self.start) + 1
    }
}

```

### crates/svc-edge/src/lib.rs
<a id="crates-svc-edge-src-lib-rs"></a>

```rust
#![forbid(unsafe_code)]
#![deny(missing_docs, clippy::all, clippy::pedantic)]
//! svc-edge — stateless edge service (admin + api scaffold).
//!
//! RO:WHAT
//! - Minimal library surface that re-exports kernel facilities used by the binary.
//! - Admission middleware, config, metrics, readiness, and routes are exposed for tests.
//!
//! RO:WHY
//! - Keep compile surface tiny so we can add features incrementally.
//!
//! RO:INVARIANTS
//! - Admin plane is always available: /metrics, /healthz, /readyz.
//! - Readiness is degrade-first until gates flip ready.
//! - `AppState` is `Clone + Send + Sync + 'static` so routers can use `into_make_service()`
//!   cleanly under Axum 0.7.

/// Command-line parsing and process flags.
pub mod cli;

/// Runtime configuration parsing/validation.
pub mod config;

/// Service-local error types.
pub mod errors;

/// Prometheus metrics (edge_* counters/histograms).
pub mod metrics;

/// Readiness gates and handler.
pub mod readiness;

/// HTTP route handlers (admin + API).
pub mod routes;

/// Shared application state (must be Clone + Send + Sync).
pub mod state;

/// Admission chain (ingress guards applied to API router).
pub mod admission;

// Re-export kernel helpers used by the bin.
pub use ron_kernel::{wait_for_ctrl_c, HealthState};

/// Public convenience re-exports for the binary and integration tests.
pub use config::Config;
pub use metrics::EdgeMetrics;
pub use state::AppState;

```

### crates/svc-edge/src/metrics.rs
<a id="crates-svc-edge-src-metrics-rs"></a>

```rust
//! Edge metrics (Prometheus).
//!
//! RO:WHAT
//! - Default-registry counters/histograms so we can tick from anywhere.
//! - Request accounting: requests_total{route,method,status}
//! - Rejects: edge_rejects_total{reason}
//! - Latency: edge_request_latency_seconds_bucket{route,method}
//! - Amnesia posture gauge.
//!
//! RO:USAGE
//! - In handlers: call `record_request(route, method, status, secs)`.
//! - In admission rejections: `inc_reject(reason)`.
//! - At startup: `seed_from_health(..., amnesia)`.

use once_cell::sync::Lazy;
use prometheus::{
    opts, register_histogram_vec, register_int_counter_vec, register_int_gauge, Encoder, HistogramVec,
    IntCounterVec, IntGauge, TextEncoder,
};
use std::time::Duration;

use crate::HealthState;

static HTTP_REQS: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        opts!("edge_requests_total", "HTTP requests by route/method/status"),
        &["route", "method", "status"]
    )
    .unwrap()
});

static HTTP_LATENCY: Lazy<HistogramVec> = Lazy::new(|| {
    // 1ms..10s range buckets (prometheus default-ish).
    register_histogram_vec!(
        "edge_request_latency_seconds",
        "Request latency seconds by route/method",
        &["route", "method"],
        vec![
            0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0
        ]
    )
    .unwrap()
});

static REJECTS: Lazy<IntCounterVec> = Lazy::new(|| {
    register_int_counter_vec!(
        opts!("edge_rejects_total", "Admission rejects"),
        &["reason"]
    )
    .unwrap()
});

static AMNESIA: Lazy<IntGauge> = Lazy::new(|| {
    register_int_gauge!(opts!("amnesia_mode", "Amnesia posture (1/0)")).unwrap()
});

/// Thin handle for metrics (future: attach more state here if needed).
#[derive(Clone, Debug)]
pub struct EdgeMetrics;

impl EdgeMetrics {
    /// Create and register all edge metrics in the default Prometheus registry.
    ///
    /// Touches each static to ensure registration has occurred before use.
    pub fn new() -> Self {
        let _ = &*HTTP_REQS;
        let _ = &*HTTP_LATENCY;
        let _ = &*REJECTS;
        let _ = &*AMNESIA;
        Self
    }
}

/// Seed gauges derived from initial health/config (currently just amnesia).
///
/// Call once at startup, after `EdgeMetrics::new()`.
pub fn seed_from_health(
    _health: std::sync::Arc<HealthState>,
    _metrics: &EdgeMetrics,
    amnesia: bool,
) {
    AMNESIA.set(if amnesia { 1 } else { 0 });
}

/// Record a single HTTP request outcome (increments counters and observes latency).
///
/// * `route`  — stable route label (e.g., `"/edge/assets/*path"`).
/// * `method` — HTTP method (e.g., `"GET"`, `"POST"`).
/// * `status` — final HTTP status code (e.g., `200`, `503`).
/// * `dur`    — wall time spent handling the request.
pub fn record_request(route: &str, method: &str, status: u16, dur: Duration) {
    HTTP_REQS
        .with_label_values(&[route, method, &status.to_string()])
        .inc();
    HTTP_LATENCY
        .with_label_values(&[route, method])
        .observe(dur.as_secs_f64());
}

/// Increment a reject counter for an admission-layer decision (e.g., `"timeout"`, `"busy"`).
pub fn inc_reject(reason: &str) {
    REJECTS.with_label_values(&[reason]).inc();
}

/// Render the Prometheus exposition text for `/metrics` (default registry).
///
/// This helper is used by the HTTP handler to return the encoded metrics body.
pub fn render() -> (axum::http::StatusCode, String) {
    let metric_families = prometheus::gather();
    let mut buf = Vec::new();
    let encoder = TextEncoder::new();
    encoder.encode(&metric_families, &mut buf).unwrap();
    (
        axum::http::StatusCode::OK,
        String::from_utf8(buf).unwrap_or_default(),
    )
}

```

### crates/svc-edge/src/readiness.rs
<a id="crates-svc-edge-src-readiness-rs"></a>

```rust
//! /readyz handler: degrade-first semantics with reasons payload.

use crate::state::AppState;
use axum::{extract::State, http::StatusCode, response::IntoResponse, Json};
use http::{header, HeaderValue};
use serde::Serialize;

/// JSON payload returned by `/readyz`.
#[derive(Serialize)]
struct ReadyPayload {
    /// Whether the service is ready to serve traffic.
    ready: bool,
    /// Missing gates/conditions preventing readiness.
    missing: Vec<String>,
}

/// Report readiness based on `HealthState` keyed flags.
///
/// Current policy: ready when `services_ok` and `config_loaded` are true.
/// Returns 503 with `Retry-After: 1` when not ready.
pub async fn readiness_handler(State(state): State<AppState>) -> impl IntoResponse {
    // HealthState::snapshot() returns a BTreeMap<&str,bool> in this project.
    let snapshot = state.health.snapshot();
    let services_ok = *snapshot.get("services_ok").unwrap_or(&false);
    let config_loaded = *snapshot.get("config_loaded").unwrap_or(&false);

    if services_ok && config_loaded {
        return (StatusCode::OK, Json(ReadyPayload { ready: true, missing: vec![] }))
            .into_response();
    }

    let mut missing = Vec::new();
    if !services_ok {
        missing.push("services_ok".to_string());
    }
    if !config_loaded {
        missing.push("config_loaded".to_string());
    }

    let payload = ReadyPayload { ready: false, missing };
    let mut res = (StatusCode::SERVICE_UNAVAILABLE, Json(payload)).into_response();
    res.headers_mut()
        .insert(header::RETRY_AFTER, HeaderValue::from_static("1"));
    res
}

```

### crates/svc-edge/src/routes/assets.rs
<a id="crates-svc-edge-src-routes-assets-rs"></a>

```rust
//! Edge surface routes.
//!
//! RO:WHAT
//! - `/echo` — counts request body bytes; returns `{ ok, len }`.
//! - `/echo/slow/:ms` — sleeps `ms` milliseconds, then echoes length.
//! - `GET /edge/assets/*path` — serve file from assets dir with ETag/Range.
//! - `GET /cas/:algo/:digest` — minimal CAS fetch (blake3 only), ETag/Range.
//!
//! RO:WHY
//! - Echo routes exercise admission guards.
//! - Assets/CAS scaffold the beta surface (packs/CAS later).
//!
//! RO:HTTP
//! - Strong ETag = BLAKE3(content).
//! - Honor `If-None-Match` → 304 when tag matches.
//! - Support a single range `bytes=start-` → 206; else 200.
//! - Always emit `Accept-Ranges: bytes`.
//!
//! RO:SECURITY
//! - Test-only surface; no auth. Keep payloads small.
//! - Path normalization protects against traversal.
//!
//! RO:METRICS
//! - Record `edge_requests_total` and `edge_request_latency_seconds` per route.

use std::{fs, io, path::PathBuf, time::{Duration, Instant}};

use axum::{
    body::Bytes,
    extract::{Path, State},
    http::{
        header::{ACCEPT_RANGES, CONTENT_LENGTH, CONTENT_RANGE, CONTENT_TYPE, ETAG, IF_NONE_MATCH, RANGE},
        HeaderMap, HeaderValue, StatusCode,
    },
    response::{IntoResponse, Response},
    Json,
};
use blake3::Hasher;
use mime_guess::mime;
use percent_encoding::percent_decode_str;
use serde::Serialize;
use tracing::warn;

use crate::{metrics, AppState};

// ---------- Echo test endpoints ----------

#[derive(Serialize)]
struct EchoResp {
    ok: bool,
    len: usize,
}

/// POST /echo
pub async fn echo(body: Bytes) -> impl IntoResponse {
    let t0 = Instant::now();
    let out = Json(EchoResp { ok: true, len: body.len() });
    metrics::record_request("echo", "POST", 200, t0.elapsed());
    out
}

/// POST /echo/slow/:ms
pub async fn echo_slow(Path(ms): Path<u64>, body: Bytes) -> impl IntoResponse {
    let t0 = Instant::now();
    if ms > 0 {
        tokio::time::sleep(Duration::from_millis(ms)).await;
    }
    let out = Json(EchoResp { ok: true, len: body.len() });
    metrics::record_request("echo_slow", "POST", 200, t0.elapsed());
    out
}

// ---------- Assets (filesystem scaffold) ----------

/// GET /edge/assets/*path
pub async fn get_asset(
    State(_state): State<AppState>,
    Path(path): Path<String>,
    headers: HeaderMap,
) -> Response {
    let t0 = Instant::now();

    // Resolve root from env (temp) — will come from Config later if not already.
    let root = std::env::var("SVC_EDGE_ASSETS_DIR").unwrap_or_else(|_| "assets".to_string());

    let resp = match resolve_and_read(&root, &path) {
        Ok(file) => reply_with_etag_range(file, &headers),
        Err(e) => map_fs_err(e),
    };

    metrics::record_request("edge_assets", "GET", resp.status().as_u16(), t0.elapsed());
    resp
}

// ---------- CAS (simple blake3 filesystem scaffold) ----------

/// GET /cas/:algo/:digest
///
/// Only supports algo=blake3 for now. Looks under assets/cas/blake3/{digest}
pub async fn get_cas(
    State(_state): State<AppState>,
    Path((algo, digest)): Path<(String, String)>,
    headers: HeaderMap,
) -> Response {
    let t0 = Instant::now();

    let resp = if algo != "blake3" {
        (StatusCode::BAD_REQUEST, "unsupported algo").into_response()
    } else {
        let root = std::env::var("SVC_EDGE_ASSETS_DIR").unwrap_or_else(|_| "assets".to_string());
        let mut p = PathBuf::from(root);
        p.push("cas");
        p.push("blake3");
        p.push(sanitize_component(&digest));

        match read_file(&p) {
            Ok(file) => reply_with_etag_range(file, &headers),
            Err(e) => map_fs_err(e),
        }
    };

    metrics::record_request("cas_get", "GET", resp.status().as_u16(), t0.elapsed());
    resp
}

// ---------- Helpers ----------

struct LoadedFile {
    bytes: Vec<u8>,
    etag: String, // blake3 hex
    mime: String,
}

fn resolve_and_read(root: &str, raw_path: &str) -> io::Result<LoadedFile> {
    // Decode URL components and prevent path traversal.
    let decoded = percent_decode_str(raw_path).decode_utf8_lossy();
    let safe = decoded.trim_start_matches('/');
    let safe = sanitize_path(safe);

    let mut p = PathBuf::from(root);
    p.push(safe);

    read_file(&p)
}

fn read_file(p: &PathBuf) -> io::Result<LoadedFile> {
    let data = fs::read(p)?;
    let mut hasher = Hasher::new();
    hasher.update(&data);
    let etag = hasher.finalize().to_hex().to_string();

    // Very simple content-type detection.
    let mime = mime_guess::from_path(p)
        .first_or(mime::APPLICATION_OCTET_STREAM)
        .essence_str()
        .to_string();

    Ok(LoadedFile { bytes: data, etag, mime })
}

fn reply_with_etag_range(file: LoadedFile, headers: &HeaderMap) -> Response {
    // If-None-Match
    if let Some(tag) = headers.get(IF_NONE_MATCH).and_then(|v| v.to_str().ok()) {
        if tag.trim_matches('"') == file.etag {
            return (
                StatusCode::NOT_MODIFIED,
                [(ETAG, quoted(&file.etag)), (ACCEPT_RANGES, HeaderValue::from_static("bytes"))],
            )
                .into_response();
        }
    }

    // Range: only support "bytes=start-"
    let total = file.bytes.len() as u64;
    if let Some(range) = headers.get(RANGE).and_then(|v| v.to_str().ok()) {
        if let Some(start) = parse_range_start(range) {
            if start >= total {
                // 416 Range Not Satisfiable
                let cr = format!("bytes */{}", total);
                return (
                    StatusCode::RANGE_NOT_SATISFIABLE,
                    [
                        (ACCEPT_RANGES, HeaderValue::from_static("bytes")),
                        (CONTENT_RANGE, HeaderValue::from_str(&cr).unwrap()),
                        (ETAG, quoted(&file.etag)),
                    ],
                )
                    .into_response();
            }
            let slice = &file.bytes[start as usize..];
            let len = slice.len() as u64;
            let cr = format!("bytes {}-{}/{}", start, start + len - 1, total);
            return (
                StatusCode::PARTIAL_CONTENT,
                [
                    (ACCEPT_RANGES, HeaderValue::from_static("bytes")),
                    (CONTENT_TYPE, HeaderValue::from_str(&file.mime).unwrap()),
                    (CONTENT_LENGTH, HeaderValue::from_str(&len.to_string()).unwrap()),
                    (CONTENT_RANGE, HeaderValue::from_str(&cr).unwrap()),
                    (ETAG, quoted(&file.etag)),
                ],
                slice.to_vec(),
            )
                .into_response();
        }
    }

    // 200 OK full
    (
        StatusCode::OK,
        [
            (ACCEPT_RANGES, HeaderValue::from_static("bytes")),
            (CONTENT_TYPE, HeaderValue::from_str(&file.mime).unwrap()),
            (
                CONTENT_LENGTH,
                HeaderValue::from_str(&file.bytes.len().to_string()).unwrap(),
            ),
            (ETAG, quoted(&file.etag)),
        ],
        file.bytes,
    )
        .into_response()
}

fn parse_range_start(range: &str) -> Option<u64> {
    // Accept "bytes=START-" only.
    let s = range.trim();
    if !s.starts_with("bytes=") || !s.ends_with('-') {
        return None;
    }
    let inner = &s[6..s.len() - 1]; // drop "bytes=" and trailing '-'
    inner.parse::<u64>().ok()
}

fn quoted(s: &str) -> HeaderValue {
    HeaderValue::from_str(&format!("\"{}\"", s)).unwrap()
}

fn sanitize_path(p: &str) -> String {
    // Simple traversal prevention: strip .. and normalize separators.
    let parts: Vec<_> = p
        .split('/')
        .filter(|seg| !seg.is_empty() && *seg != "." && *seg != "..")
        .collect();
    parts.join("/")
}

fn sanitize_component(c: &str) -> String {
    // Allow only hex-ish tokens for digests.
    let filtered: String = c.chars().filter(|ch| ch.is_ascii_hexdigit()).collect();
    if filtered.is_empty() {
        // fallback to avoid empty path
        "invalid".to_string()
    } else {
        filtered
    }
}

fn map_fs_err(e: io::Error) -> Response {
    match e.kind() {
        io::ErrorKind::NotFound => (StatusCode::NOT_FOUND, "not found").into_response(),
        io::ErrorKind::PermissionDenied => (StatusCode::FORBIDDEN, "forbidden").into_response(),
        _ => {
            warn!("asset error: {e:?}");
            (StatusCode::INTERNAL_SERVER_ERROR, "error").into_response()
        }
    }
}

```

### crates/svc-edge/src/routes/health.rs
<a id="crates-svc-edge-src-routes-health-rs"></a>

```rust
//! /healthz — liveness endpoint.

use axum::response::IntoResponse;
use http::StatusCode;

/// Liveness probe.
///
/// Returns `200 OK` unconditionally if the process is alive.
pub async fn healthz() -> impl IntoResponse {
    StatusCode::OK
}

```

### crates/svc-edge/src/routes/mod.rs
<a id="crates-svc-edge-src-routes-mod-rs"></a>

```rust
//! Route modules.

pub mod health;
pub mod prometheus;
pub mod assets; // temp API routes while we wire the stack
// ready route lives in crate::readiness

```

### crates/svc-edge/src/routes/prometheus.rs
<a id="crates-svc-edge-src-routes-prometheus-rs"></a>

```rust
//! /metrics — Prometheus exposition.

use crate::state::AppState;
use axum::{extract::State, response::IntoResponse};
use http::{header, HeaderValue, StatusCode};
use prometheus::{Encoder, TextEncoder};

/// Render the Prometheus metrics exposition format from the default registry.
pub async fn metrics(State(_state): State<AppState>) -> impl IntoResponse {
    let metric_families = prometheus::gather();
    let encoder = TextEncoder::new();

    let mut buf = Vec::new();
    if let Err(_e) = encoder.encode(&metric_families, &mut buf) {
        // Conservative fallback: don't leak internals; keep content-type text/plain.
        let mut res = (StatusCode::INTERNAL_SERVER_ERROR, "metrics encode error\n").into_response();
        res.headers_mut()
            .insert(header::CONTENT_TYPE, HeaderValue::from_static("text/plain; charset=utf-8"));
        return res;
    }

    let body = String::from_utf8(buf).unwrap_or_default();

    let mut res = (StatusCode::OK, body).into_response();
    res.headers_mut()
        .insert(header::CONTENT_TYPE, HeaderValue::from_static("text/plain; version=0.0.4"));
    res
}

```

### crates/svc-edge/src/routes/ready.rs
<a id="crates-svc-edge-src-routes-ready-rs"></a>

```rust

```

### crates/svc-edge/src/security/audit.rs
<a id="crates-svc-edge-src-security-audit-rs"></a>

```rust
//! Security audit trail placeholder (stub).

/// Minimal audit event (placeholder).
#[derive(Debug, Clone)]
pub struct AuditEvent {
    /// Category (e.g., "admission", "security", "policy").
    pub category: String,
    /// Short message.
    pub message: String,
}

/// Audit sink (no-op).
#[derive(Debug, Default, Clone)]
pub struct Auditor;

impl Auditor {
    /// Record an audit event (no-op).
    pub fn record(&self, _evt: AuditEvent) {
        // Future: write to structured log / metrics.
    }
}

```

### crates/svc-edge/src/security/cors.rs
<a id="crates-svc-edge-src-security-cors-rs"></a>

```rust
//! CORS policy placeholder (stub).

/// CORS posture (placeholder).
#[derive(Debug, Clone, Copy)]
pub enum Cors {
    /// Deny all cross-origin requests.
    Deny,
    /// Allow a restricted set (details TBD).
    Restricted,
}

impl Default for Cors {
    fn default() -> Self {
        Cors::Deny
    }
}

```

### crates/svc-edge/src/security/hsts.rs
<a id="crates-svc-edge-src-security-hsts-rs"></a>

```rust
//! HSTS policy placeholder (stub).

/// HSTS posture (placeholder).
#[derive(Debug, Clone, Copy)]
pub enum Hsts {
    /// Disabled.
    Off,
    /// Enabled with defaults (details TBD).
    On,
}

impl Default for Hsts {
    fn default() -> Self {
        Hsts::Off
    }
}

```

### crates/svc-edge/src/state.rs
<a id="crates-svc-edge-src-state-rs"></a>

```rust
//! Process-wide shared state for svc-edge.
//
// RO:WHAT
// - Holds immutable runtime config, metrics handle, and health gate.
// - Must be `Clone + Send + Sync + 'static` to satisfy axum 0.7 router state bounds.
//
// RO:INVARIANTS
// - No interior mutability hidden here; mutable bits live behind explicit APIs
//   (metrics handles, health gates) or are wrapped in Arcs.

use std::sync::Arc;

use crate::{Config, EdgeMetrics, HealthState};

/// Application state shared across axum handlers.
///
/// This type **must** be `Clone + Send + Sync + 'static` so that
/// `Router<AppState>::into_make_service()` is available in axum 0.7.
#[derive(Clone)]
pub struct AppState {
    /// Effective runtime configuration (immutable at runtime).
    pub cfg: Arc<Config>,
    /// Metrics handle (counters/histograms are internally synchronized).
    pub metrics: EdgeMetrics,
    /// Process health/readiness gates.
    pub health: Arc<HealthState>,
}

impl AppState {
    /// Construct a new [`AppState`].
    ///
    /// The `cfg` is wrapped into an `Arc` to make cloning cheap and to satisfy
    /// axum's `Clone + Send + Sync + 'static` bounds for router state.
    pub fn new(cfg: Config, metrics: EdgeMetrics, health: Arc<HealthState>) -> Self {
        Self {
            cfg: Arc::new(cfg),
            metrics,
            health,
        }
    }
}

```

### crates/svc-edge/src/supervisor.rs
<a id="crates-svc-edge-src-supervisor-rs"></a>

```rust
//! Process supervisor scaffold for svc-edge.
//!
//! RO:WHAT
//! - Placeholder for listener/task lifecycle management and orderly shutdown.
//!
//! RO:NEXT
//! - Add accept loops, task JoinHandles, and a `cancel()` to request drain.

/// No-op supervisor placeholder.
#[derive(Debug, Clone, Default)]
pub struct Supervisor;

impl Supervisor {
    /// Create a new no-op supervisor.
    pub fn new() -> Self {
        Self
    }
    /// Request shutdown (no-op for now).
    pub async fn shutdown(&self) {
        // Future: signal tasks and await joins with a timeout.
    }
}

```

### crates/svc-edge/src/util/backoff.rs
<a id="crates-svc-edge-src-util-backoff-rs"></a>

```rust
//! Simple exponential backoff calculator (stub).

use std::time::Duration;

/// Exponential backoff parameters (placeholder).
#[derive(Debug, Clone, Copy)]
pub struct Backoff {
    /// Base delay.
    pub base: Duration,
    /// Maximum delay.
    pub max: Duration,
    /// Multiplier per attempt.
    pub factor: f64,
}

impl Default for Backoff {
    fn default() -> Self {
        Self {
            base: Duration::from_millis(10),
            max: Duration::from_secs(2),
            factor: 2.0,
        }
    }
}

impl Backoff {
    /// Compute delay for `attempt` (0-based).
    pub fn delay(&self, attempt: u32) -> Duration {
        let ms = (self.base.as_millis() as f64) * self.factor.powi(attempt as i32);
        let d = Duration::from_millis(ms as u64);
        if d > self.max { self.max } else { d }
    }
}

```

### crates/svc-edge/src/util/bytes.rs
<a id="crates-svc-edge-src-util-bytes-rs"></a>

```rust
//! Byte utilities (stub).

/// Clamp `n` to `max`.
pub fn clamp_len(n: usize, max: usize) -> usize {
    if n > max { max } else { n }
}

```

### crates/svc-edge/src/util/size_parse.rs
<a id="crates-svc-edge-src-util-sizeparse-rs"></a>

```rust
//! Parse human-readable sizes like "64k", "10MiB" (stub).
//!
//! Accepted suffixes (case-insensitive; decimal only for now):
//! - k, m, g, t  → 10^3 steps.

/// Parse a simple size string. Returns bytes on success.
///
/// Examples: "0", "64k", "10m". Binary units and MiB/GiB will arrive later.
pub fn parse_decimal_size(s: &str) -> Option<u64> {
    let s = s.trim();
    if s.is_empty() {
        return None;
    }
    let (num, suf) = s.split_at(s.find(|c: char| !c.is_ascii_digit()).unwrap_or(s.len()));
    let mut n: u64 = num.parse().ok()?;
    let suffix = suf.trim().to_ascii_lowercase();
    n *= match suffix.as_str() {
        "" => 1,
        "k" => 1_000,
        "m" => 1_000_000,
        "g" => 1_000_000_000,
        "t" => 1_000_000_000_000,
        _ => return None,
    };
    Some(n)
}

```

### crates/svc-edge/src/work/queue.rs
<a id="crates-svc-edge-src-work-queue-rs"></a>

```rust
//! Work queue placeholder (bounded, no implementation yet).

/// Opaque job type (placeholder).
#[derive(Debug, Clone)]
pub struct Job {
    /// Human-readable label for diagnostics.
    pub label: String,
}

/// Bounded work queue (stub).
#[derive(Debug, Default)]
pub struct WorkQueue;

impl WorkQueue {
    /// Construct a new, empty work queue.
    pub fn new() -> Self {
        Self
    }
    /// Enqueue a job (no-op).
    pub fn push(&self, _job: Job) -> bool {
        false
    }
}

```

### crates/svc-edge/src/work/shutdown.rs
<a id="crates-svc-edge-src-work-shutdown-rs"></a>

```rust
//! Cooperative shutdown helpers (stub).

/// A cooperative shutdown token (stub).
#[derive(Debug, Clone, Default)]
pub struct ShutdownToken {
    /// Whether shutdown was requested.
    pub requested: bool,
}

impl ShutdownToken {
    /// Request shutdown (no-op).
    pub fn request(&mut self) {
        self.requested = true;
    }
    /// Check whether shutdown was requested.
    pub fn is_requested(&self) -> bool {
        self.requested
    }
}

```

### crates/svc-edge/src/work/worker.rs
<a id="crates-svc-edge-src-work-worker-rs"></a>

```rust
//! Worker placeholder for background tasks (stub).

use super::queue::WorkQueue;

/// Simple worker (no behavior yet).
#[derive(Debug, Default)]
pub struct Worker;

impl Worker {
    /// Run a no-op worker loop (immediate return for now).
    pub async fn run(&self, _queue: WorkQueue) {
        // Future: read jobs; process; record metrics; respect shutdown.
    }
}

```

### crates/svc-edge/tests/concurrency_backpressure.rs
<a id="crates-svc-edge-tests-concurrencybackpressure-rs"></a>

```rust

```

### crates/svc-edge/tests/fuzz_headers.rs
<a id="crates-svc-edge-tests-fuzzheaders-rs"></a>

```rust

```

### crates/svc-edge/tests/http_contract.rs
<a id="crates-svc-edge-tests-httpcontract-rs"></a>

```rust

```

### crates/svc-edge/tests/i_10_deterministic_failures.rs
<a id="crates-svc-edge-tests-i10deterministicfailures-rs"></a>

```rust

```

### crates/svc-edge/tests/i_11_pack_integrity.rs
<a id="crates-svc-edge-tests-i11packintegrity-rs"></a>

```rust

```

### crates/svc-edge/tests/i_1_hardening_ingress.rs
<a id="crates-svc-edge-tests-i1hardeningingress-rs"></a>

```rust

```

### crates/svc-edge/tests/i_4_http_semantics.rs
<a id="crates-svc-edge-tests-i4httpsemantics-rs"></a>

```rust

```

### crates/svc-edge/tests/i_5_content_address.rs
<a id="crates-svc-edge-tests-i5contentaddress-rs"></a>

```rust

```

### crates/svc-edge/tests/i_6_amnesia.rs
<a id="crates-svc-edge-tests-i6amnesia-rs"></a>

```rust

```

### crates/svc-edge/tests/i_8_size_bounds.rs
<a id="crates-svc-edge-tests-i8sizebounds-rs"></a>

```rust

```

### crates/svc-edge/tests/i_9_observability_contract.rs
<a id="crates-svc-edge-tests-i9observabilitycontract-rs"></a>

```rust

```

### crates/svc-edge/tests/readiness_logic.rs
<a id="crates-svc-edge-tests-readinesslogic-rs"></a>

```rust

```



---



# ron-audit

_Source: crates/ron-audit/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-11-16T15:43:54Z -->
# Code Bundle — `ron-audit`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-audit/.cargo/config.toml](#crates-ron-audit--cargo-config-toml)
- [crates/ron-audit/Cargo.toml](#crates-ron-audit-Cargo-toml)
- [crates/ron-audit/benches/hash_b3.rs](#crates-ron-audit-benches-hashb3-rs)
- [crates/ron-audit/benches/verify_chain.rs](#crates-ron-audit-benches-verifychain-rs)
- [crates/ron-audit/benches/wal_batching.rs](#crates-ron-audit-benches-walbatching-rs)
- [crates/ron-audit/deny.toml](#crates-ron-audit-deny-toml)
- [crates/ron-audit/fuzz/Cargo.toml](#crates-ron-audit-fuzz-Cargo-toml)
- [crates/ron-audit/fuzz/fuzz_targets/fuzz_canon_vectors.rs](#crates-ron-audit-fuzz-fuzztargets-fuzzcanonvectors-rs)
- [crates/ron-audit/fuzz/fuzz_targets/fuzz_record_roundtrip.rs](#crates-ron-audit-fuzz-fuzztargets-fuzzrecordroundtrip-rs)
- [crates/ron-audit/loom/chain_loom.rs](#crates-ron-audit-loom-chainloom-rs)
- [crates/ron-audit/rust-toolchain.toml](#crates-ron-audit-rust-toolchain-toml)
- [crates/ron-audit/scripts/beta_check.sh](#crates-ron-audit-scripts-betacheck-sh)
- [crates/ron-audit/src/bounds/mod.rs](#crates-ron-audit-src-bounds-mod-rs)
- [crates/ron-audit/src/canon/mod.rs](#crates-ron-audit-src-canon-mod-rs)
- [crates/ron-audit/src/canon/rules.rs](#crates-ron-audit-src-canon-rules-rs)
- [crates/ron-audit/src/canon/vectors.rs](#crates-ron-audit-src-canon-vectors-rs)
- [crates/ron-audit/src/dto.rs](#crates-ron-audit-src-dto-rs)
- [crates/ron-audit/src/errors.rs](#crates-ron-audit-src-errors-rs)
- [crates/ron-audit/src/hash/b3.rs](#crates-ron-audit-src-hash-b3-rs)
- [crates/ron-audit/src/hash/mod.rs](#crates-ron-audit-src-hash-mod-rs)
- [crates/ron-audit/src/lib.rs](#crates-ron-audit-src-lib-rs)
- [crates/ron-audit/src/metrics/mod.rs](#crates-ron-audit-src-metrics-mod-rs)
- [crates/ron-audit/src/prelude.rs](#crates-ron-audit-src-prelude-rs)
- [crates/ron-audit/src/privacy/mod.rs](#crates-ron-audit-src-privacy-mod-rs)
- [crates/ron-audit/src/sink/export.rs](#crates-ron-audit-src-sink-export-rs)
- [crates/ron-audit/src/sink/mod.rs](#crates-ron-audit-src-sink-mod-rs)
- [crates/ron-audit/src/sink/ram.rs](#crates-ron-audit-src-sink-ram-rs)
- [crates/ron-audit/src/sink/traits.rs](#crates-ron-audit-src-sink-traits-rs)
- [crates/ron-audit/src/sink/wal.rs](#crates-ron-audit-src-sink-wal-rs)
- [crates/ron-audit/src/stream/mod.rs](#crates-ron-audit-src-stream-mod-rs)
- [crates/ron-audit/src/verify/chain.rs](#crates-ron-audit-src-verify-chain-rs)
- [crates/ron-audit/src/verify/mod.rs](#crates-ron-audit-src-verify-mod-rs)
- [crates/ron-audit/src/verify/record.rs](#crates-ron-audit-src-verify-record-rs)
- [crates/ron-audit/testing/vectors/manifest_example.json](#crates-ron-audit-testing-vectors-manifestexample-json)
- [crates/ron-audit/testing/vectors/record_max.json](#crates-ron-audit-testing-vectors-recordmax-json)
- [crates/ron-audit/testing/vectors/record_small.json](#crates-ron-audit-testing-vectors-recordsmall-json)
- [crates/ron-audit/tests/api_compat.rs](#crates-ron-audit-tests-apicompat-rs)
- [crates/ron-audit/tests/append_only.rs](#crates-ron-audit-tests-appendonly-rs)
- [crates/ron-audit/tests/bounds.rs](#crates-ron-audit-tests-bounds-rs)
- [crates/ron-audit/tests/canonicalization.rs](#crates-ron-audit-tests-canonicalization-rs)
- [crates/ron-audit/tests/export_checkpoints.rs](#crates-ron-audit-tests-exportcheckpoints-rs)
- [crates/ron-audit/tests/idempotency.rs](#crates-ron-audit-tests-idempotency-rs)
- [crates/ron-audit/tests/multi_writer_ordering.rs](#crates-ron-audit-tests-multiwriterordering-rs)
- [crates/ron-audit/tests/privacy_policies.rs](#crates-ron-audit-tests-privacypolicies-rs)
- [crates/ron-audit/tests/verify_soa.rs](#crates-ron-audit-tests-verifysoa-rs)

### crates/ron-audit/.cargo/config.toml
<a id="crates-ron-audit--cargo-config-toml"></a>

```toml
[build]
rustflags = ["-Dwarnings"]

[target.'cfg(all())']
# Keep deterministic builds where possible.
rustflags = ["-C", "debuginfo=1"]

```

### crates/ron-audit/Cargo.toml
<a id="crates-ron-audit-Cargo-toml"></a>

```toml
[package]
name = "ron-audit"
version = "0.1.0"
edition = "2021"
rust-version = "1.80"
description = "RON-CORE audit-chain helpers (canon, hash, verify, sinks) for AuditRecord."
license = "MIT OR Apache-2.0"
repository = "https://github.com/rustyonions/RustyOnions"
homepage = "https://rustyonions.dev"

[lib]
name = "ron_audit"
path = "src/lib.rs"

[features]
# Minimal default: in-RAM sink only, no WAL/export/metrics/SIMD.
default = []

# Future: real write-ahead log sink.
wal = []

# Future: checkpoint / export helpers.
export = []

# Future: prometheus/ron-metrics wiring for audit ops.
with-metrics = []

# Optional: SIMD-accelerated linkage comparisons (std::simd).
# NOTE: Hashing remains delegated to blake3; this only affects how we compare
# prev/self_hash strings in verify_link/verify_chain_soa.
simd = []

[dependencies]
# Placeholder; DTOs currently live locally in `dto.rs`, but we keep the
# dependency wired so we can migrate `AuditRecord` into ron-proto later
# without changing host Cargo manifests.
ron-proto = { path = "../ron-proto" }

serde = { version = "1", features = ["derive"] }
serde_json = "1"

thiserror = "1"
blake3 = "1"
unicode-normalization = "0.1"

[dev-dependencies]
# Sync-only Criterion (no async needed here).
criterion = { version = "0.5", features = ["html_reports"] }

[[bench]]
name = "hash_b3"
harness = false

[[bench]]
name = "verify_chain"
harness = false

[[bench]]
name = "wal_batching"
harness = false

```

### crates/ron-audit/benches/hash_b3.rs
<a id="crates-ron-audit-benches-hashb3-rs"></a>

```rust
//! RO:WHAT — Criterion microbench for canonicalize + BLAKE3 hashing of AuditRecord.
//! RO:WHY  — PERF: baseline BLAKE3 throughput on canonical audit payloads.
//! RO:INTERACTS — ron_audit::hash::b3_no_self; dto::AuditRecord; serde_json.
//! RO:INVARIANTS — pure; no I/O; stable record shape; no global state.
//! RO:METRICS — bench-only; no runtime counters.
//! RO:CONFIG — in-code record sizes; no env knobs yet.
//! RO:SECURITY — synthetic records only; no real keys/PII.
//! RO:TEST — perf: Criterion group `hash_b3_small` / `hash_b3_large`.

use std::time::{SystemTime, UNIX_EPOCH};

use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::b3_no_self;
use ron_audit::AuditRecord;
use serde_json::json;

fn mk_record(attr_bytes: usize) -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    let payload = "x".repeat(attr_bytes.max(1));

    let mut rec = AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "bench@ron-audit".to_string(),
        seq: 0,
        stream: "hash_b3".to_string(),
        kind: AuditKind::IndexWrite,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("bench-hash-b3".to_string()),
        attrs: json!({ "payload": payload }),
        prev: "b3:0".to_string(),
        self_hash: String::new(),
    };

    // Fill self_hash once, even though `b3_no_self` ignores it, to keep the
    // record closer to real-world usage.
    rec.self_hash = b3_no_self(&rec).expect("hash");
    rec
}

fn hash_b3_small(c: &mut Criterion) {
    let rec = mk_record(64);

    c.bench_function("hash_b3_small_64B_attrs", |b| {
        b.iter(|| {
            let h = b3_no_self(black_box(&rec)).expect("hash");
            black_box(h);
        });
    });
}

fn hash_b3_large(c: &mut Criterion) {
    // ~1 KiB attrs to stay within DEFAULT_MAX_ATTRS_BYTES.
    let rec = mk_record(1024);

    c.bench_function("hash_b3_large_1KiB_attrs", |b| {
        b.iter(|| {
            let h = b3_no_self(black_box(&rec)).expect("hash");
            black_box(h);
        });
    });
}

criterion_group!(benches, hash_b3_small, hash_b3_large);
criterion_main!(benches);

```

### crates/ron-audit/benches/verify_chain.rs
<a id="crates-ron-audit-benches-verifychain-rs"></a>

```rust
//! RO:WHAT — Criterion microbench for chain verification (scalar API vs SoA).
//! RO:WHY  — PERF/RES: compare verify_chain (reference) and verify_chain_soa (fast path)
//!           on realistic chain lengths.
//! RO:INTERACTS — ron_audit::hash::b3_no_self;
//!                ron_audit::verify::{verify_record, verify_link, verify_chain, verify_chain_soa}.
//! RO:INVARIANTS — no unsafe; same semantics for scalar and SoA; only performance differs.
//! RO:METRICS — bench-only; no runtime counters.
//! RO:CONFIG — chain length configured in-code; env knobs can be added later.
//! RO:SECURITY — synthetic records only; no real keys/PII.
//! RO:TEST — unit: tests/verify_soa.rs; perf: this bench.

use std::time::{SystemTime, UNIX_EPOCH};

use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::b3_no_self;
use ron_audit::verify::{verify_chain, verify_chain_soa};
use ron_audit::AuditRecord;
use serde_json::json;

fn mk_chain(len: usize) -> Vec<AuditRecord> {
    assert!(len > 0);

    let mut out = Vec::with_capacity(len);

    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    // genesis
    let mut genesis = AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "bench@ron-audit".to_string(),
        seq: 0,
        stream: "verify_chain".to_string(),
        kind: AuditKind::CapIssued,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("bench-verify-chain".to_string()),
        attrs: json!({ "seq": 0u64 }),
        prev: "b3:0".to_string(),
        self_hash: String::new(),
    };
    genesis.self_hash = b3_no_self(&genesis).expect("hash");
    out.push(genesis);

    while out.len() < len {
        let prev = out.last().expect("non-empty");
        let mut rec = AuditRecord {
            v: 1,
            ts_ms,
            writer_id: prev.writer_id.clone(),
            seq: prev.seq + 1,
            stream: prev.stream.clone(),
            kind: AuditKind::IndexWrite,
            actor: ActorRef::default(),
            subject: SubjectRef::default(),
            reason: ReasonCode("bench-verify-chain".to_string()),
            attrs: json!({ "seq": prev.seq + 1 }),
            prev: prev.self_hash.clone(),
            self_hash: String::new(),
        };
        rec.self_hash = b3_no_self(&rec).expect("hash");
        out.push(rec);
    }

    out
}

/// For comparison: scalar reference API over an owned iterator.
///
/// NOTE: This includes the cost of cloning the chain when we call
/// `chain.clone().into_iter()`, which matches how callers would typically
/// use the public API.
fn bench_verify_chain_scalar_api(c: &mut Criterion) {
    let chain = mk_chain(512);

    // Sanity-check: scalar API must succeed once outside the hot loop.
    verify_chain(chain.clone().into_iter()).expect("verify_chain scalar API");

    c.bench_function("verify_chain_scalar_len_512", |b| {
        b.iter(|| {
            // Clone per-iteration to match real-world "owned iterator" usage.
            let owned = black_box(chain.clone());
            verify_chain(owned.into_iter()).expect("scalar verify");
        });
    });
}

/// SoA-style fast path over a contiguous slice.
///
/// This avoids per-iteration cloning and uses the SoA slice-based verifier.
/// It should be at least as fast as the scalar path, often faster for large chains.
fn bench_verify_chain_soa(c: &mut Criterion) {
    let chain = mk_chain(512);

    // Sanity-check: SoA API must succeed once outside the hot loop.
    verify_chain_soa(&chain).expect("verify_chain_soa");

    c.bench_function("verify_chain_soa_len_512", |b| {
        b.iter(|| {
            verify_chain_soa(black_box(&chain)).expect("soa verify");
        });
    });
}

criterion_group!(
    benches,
    bench_verify_chain_scalar_api,
    bench_verify_chain_soa
);
criterion_main!(benches);

```

### crates/ron-audit/benches/wal_batching.rs
<a id="crates-ron-audit-benches-walbatching-rs"></a>

```rust
//! RO:WHAT — Criterion microbench for per-record vs batched append into an AuditSink.
//! RO:WHY  — PERF/ECON: rough guidance for WAL/batch tuning in hosts (fsync cadence, batch size).
//! RO:INTERACTS — ron_audit::sink::{ram::RamSink, AuditSink}; stream::BufferedSink; hash::b3_no_self.
//! RO:INVARIANTS — append-only; prev == last.self_hash; bounded record sizes.
//! RO:METRICS — bench-only; host metrics will live in svc-* crates.
//! RO:CONFIG — batch size configured in code; env toggles can be added later.
//! RO:SECURITY — synthetic records; no real keys/PII; in-RAM only.
//! RO:TEST — perf: Criterion group `wal_single_append` / `wal_buffered_append`.

use std::time::{SystemTime, UNIX_EPOCH};

use criterion::{black_box, criterion_group, criterion_main, Criterion};
use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::b3_no_self;
use ron_audit::sink::{ram::RamSink, AuditSink};
use ron_audit::stream::BufferedSink;
use ron_audit::AuditRecord;
use serde_json::json;

fn mk_records(count: usize) -> Vec<AuditRecord> {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    let mut out = Vec::with_capacity(count);

    // genesis
    let mut prev_hash = "b3:0".to_string();
    for seq in 0..count as u64 {
        let mut rec = AuditRecord {
            v: 1,
            ts_ms,
            writer_id: "bench@ron-audit".to_string(),
            seq,
            stream: "wal_batching".to_string(),
            kind: AuditKind::IndexWrite,
            actor: ActorRef::default(),
            subject: SubjectRef::default(),
            reason: ReasonCode("bench-wal-batching".to_string()),
            attrs: json!({ "seq": seq }),
            prev: prev_hash.clone(),
            self_hash: String::new(),
        };
        rec.self_hash = b3_no_self(&rec).expect("hash");
        prev_hash = rec.self_hash.clone();
        out.push(rec);
    }

    out
}

fn wal_single_append(c: &mut Criterion) {
    // A moderately large batch to make per-record append overhead visible.
    let records = mk_records(512);

    c.bench_function("wal_single_append_512", |b| {
        b.iter(|| {
            let sink = RamSink::new();
            for rec in black_box(&records) {
                sink.append(rec).expect("append");
            }
        });
    });
}

fn wal_buffered_append(c: &mut Criterion) {
    let records = mk_records(512);

    c.bench_function("wal_buffered_append_512", |b| {
        b.iter(|| {
            let sink = RamSink::new();
            let buffered = BufferedSink::new(sink);
            buffered
                .append_all(black_box(&records))
                .expect("buffered append_all");
        });
    });
}

criterion_group!(benches, wal_single_append, wal_buffered_append);
criterion_main!(benches);

```

### crates/ron-audit/deny.toml
<a id="crates-ron-audit-deny-toml"></a>

```toml
# Keep aligned with workspace deny policy; local file allows per-crate notes.
[advisories]
yanked = "deny"

[bans]
multiple-versions = "deny"

[licenses]
allow = [
  "MIT",
  "Apache-2.0",
  "Unicode-DFS-2016",
  "Unicode-3.0",
  "CC0-1.0",
  "CDLA-Permissive-2.0",
  "OpenSSL",
]

```

### crates/ron-audit/fuzz/Cargo.toml
<a id="crates-ron-audit-fuzz-Cargo-toml"></a>

```toml
[package]
name = "ron-audit2-fuzz"
version = "0.0.0"
publish = false
edition = "2021"

[workspace]

[dependencies]
libfuzzer-sys = "0.4"

[dependencies.ron-audit2]
path = ".."

[profile.release]
debug = 1

[[bin]]
name = "fuzz_record_roundtrip"
path = "fuzz_targets/fuzz_record_roundtrip.rs"

[[bin]]
name = "fuzz_canon_vectors"
path = "fuzz_targets/fuzz_canon_vectors.rs"

```

### crates/ron-audit/fuzz/fuzz_targets/fuzz_canon_vectors.rs
<a id="crates-ron-audit-fuzz-fuzztargets-fuzzcanonvectors-rs"></a>

```rust

```

### crates/ron-audit/fuzz/fuzz_targets/fuzz_record_roundtrip.rs
<a id="crates-ron-audit-fuzz-fuzztargets-fuzzrecordroundtrip-rs"></a>

```rust

```

### crates/ron-audit/loom/chain_loom.rs
<a id="crates-ron-audit-loom-chainloom-rs"></a>

```rust

```

### crates/ron-audit/rust-toolchain.toml
<a id="crates-ron-audit-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["rustfmt", "clippy"]

```

### crates/ron-audit/scripts/beta_check.sh
<a id="crates-ron-audit-scripts-betacheck-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# Simple beta gate for ron-audit.
# Runs:
#   1) fmt + clippy + unit tests
#   2) benches for hash_b3, verify_chain, wal_batching with saved baselines
#
# Usage (from repo root):
#   bash crates/ron-audit/scripts/beta_check.sh
#   BASE=local-dev bash crates/ron-audit/scripts/beta_check.sh
#
# Notes:
#   - Baseline suffix defaults to YYYYMMDD if BASE is not set.
#   - This script does NOT enable any cargo features by default
#     (run simd benches separately if needed).

CRATE="ron-audit"

# Resolve repo root (two levels up from scripts/)
ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
cd "$ROOT_DIR"

BASE_SUFFIX="${BASE:-$(date +%Y%m%d)}"

echo "[beta-check] crate=${CRATE} root=${ROOT_DIR}"
echo "[beta-check] 1) fmt + clippy + unit tests"

cargo fmt -p "${CRATE}"
cargo clippy -p "${CRATE}" --no-deps -- -D warnings
cargo test -p "${CRATE}"

echo "[beta-check] 2) benches (hash_b3, verify_chain, wal_batching)"

cargo bench -p "${CRATE}" --bench hash_b3 \
  -- --save-baseline "audit-hash_b3-${BASE_SUFFIX}"

cargo bench -p "${CRATE}" --bench verify_chain \
  -- --save-baseline "audit-verify_chain-${BASE_SUFFIX}"

cargo bench -p "${CRATE}" --bench wal_batching \
  -- --save-baseline "audit-wal_batching-${BASE_SUFFIX}"

echo "[beta-check] done."

```

### crates/ron-audit/src/bounds/mod.rs
<a id="crates-ron-audit-src-bounds-mod-rs"></a>

```rust
//! Size bounds checks for audit records.

use crate::errors::BoundsError;
use crate::AuditRecord;

/// Default maximum serialized size (in bytes) for `attrs`.
pub const DEFAULT_MAX_ATTRS_BYTES: usize = 1024;

/// Default maximum serialized size (in bytes) for a full record.
pub const DEFAULT_MAX_RECORD_BYTES: usize = 4096;

/// Check size bounds on an `AuditRecord`.
///
/// Hosts can call this prior to hashing/append to enforce their SLOs.
pub fn check(
    rec: &AuditRecord,
    max_attrs_bytes: usize,
    max_record_bytes: usize,
) -> Result<(), BoundsError> {
    let attrs_bytes = serde_json::to_vec(&rec.attrs)
        .map(|v| v.len())
        .unwrap_or_default();

    if attrs_bytes > max_attrs_bytes {
        return Err(BoundsError::AttrsTooLarge {
            actual: attrs_bytes,
            max: max_attrs_bytes,
        });
    }

    let record_bytes = serde_json::to_vec(rec).map(|v| v.len()).unwrap_or_default();

    if record_bytes > max_record_bytes {
        return Err(BoundsError::RecordTooLarge {
            actual: record_bytes,
            max: max_record_bytes,
        });
    }

    Ok(())
}

```

### crates/ron-audit/src/canon/mod.rs
<a id="crates-ron-audit-src-canon-mod-rs"></a>

```rust
//! Canonicalization for `AuditRecord`.
//!
//! The goal is to produce a **stable byte representation** of a record
//! *without* its `self_hash` field, suitable for hashing and dedupe.
//!
//! Rules (as per IDB):
//! - Struct fields appear in a fixed order.
//! - Strings are NFC-normalized.
//! - Floats are rejected (only ints/booleans/strings/objects/arrays allowed).
//! - Unknown top-level fields are rejected.

use serde_json::{Map, Value};
use unicode_normalization::UnicodeNormalization;

use crate::AuditRecord;

/// Errors produced during canonicalization.
#[derive(Debug, thiserror::Error)]
pub enum CanonError {
    /// The record could not be encoded as a JSON object.
    #[error("record was not encodable as a JSON object")]
    NonObject,

    /// The record was missing a required field.
    #[error("record missing required field `{0}`")]
    MissingField(&'static str),

    /// The record contained unexpected extra fields.
    #[error("record contained unexpected fields")]
    UnexpectedFields,

    /// A floating-point number was encountered in the payload.
    #[error("floats are not allowed in audit payloads")]
    FloatDisallowed,

    /// JSON encoding failed.
    #[error("failed to encode canonical JSON")]
    Encode,
}

/// Produce canonical bytes for an `AuditRecord` *without* its `self_hash`.
///
/// This function:
/// - Removes the `self_hash` field entirely.
/// - Re-orders top-level fields into a stable order.
/// - NFC-normalizes all strings recursively.
/// - Rejects floats anywhere in the payload.
pub fn canonicalize_without_self_hash(rec: &AuditRecord) -> Result<Vec<u8>, CanonError> {
    // Serialize the record into a generic JSON value first.
    let mut value = serde_json::to_value(rec).map_err(|_| CanonError::Encode)?;

    let obj = value.as_object_mut().ok_or(CanonError::NonObject)?;

    // Drop self_hash; we'll recompute it from the canonical bytes.
    obj.remove("self_hash");

    // Expected top-level order (must match AuditRecord field layout).
    const ORDER: [&str; 11] = [
        "v",
        "ts_ms",
        "writer_id",
        "seq",
        "stream",
        "kind",
        "actor",
        "subject",
        "reason",
        "attrs",
        "prev",
    ];

    let mut out = Map::new();

    for key in ORDER {
        let value = obj.remove(key).ok_or(CanonError::MissingField(key))?;
        let normalized = normalize_value(value)?;
        out.insert(key.to_string(), normalized);
    }

    // If anything is left, the record had extra fields we don't know about.
    if !obj.is_empty() {
        return Err(CanonError::UnexpectedFields);
    }

    let canonical = Value::Object(out);
    serde_json::to_vec(&canonical).map_err(|_| CanonError::Encode)
}

fn normalize_value(value: Value) -> Result<Value, CanonError> {
    match value {
        Value::Null | Value::Bool(_) => Ok(value),
        Value::Number(n) => {
            // Only integral numbers are allowed; floats are rejected.
            if n.as_i64().is_some() || n.as_u64().is_some() {
                Ok(Value::Number(n))
            } else {
                Err(CanonError::FloatDisallowed)
            }
        }
        Value::String(s) => {
            let normalized: String = s.nfc().collect();
            Ok(Value::String(normalized))
        }
        Value::Array(values) => {
            let mut out = Vec::with_capacity(values.len());
            for v in values {
                out.push(normalize_value(v)?);
            }
            Ok(Value::Array(out))
        }
        Value::Object(map) => {
            // For nested maps we keep insertion order as provided by serde_json,
            // but still normalize all nested values and reject floats.
            let mut out = Map::new();
            for (k, v) in map {
                let normalized = normalize_value(v)?;
                out.insert(k, normalized);
            }
            Ok(Value::Object(out))
        }
    }
}

```

### crates/ron-audit/src/canon/rules.rs
<a id="crates-ron-audit-src-canon-rules-rs"></a>

```rust
//! Canon rules scaffold.

```

### crates/ron-audit/src/canon/vectors.rs
<a id="crates-ron-audit-src-canon-vectors-rs"></a>

```rust
//! Frozen test vectors scaffold.

```

### crates/ron-audit/src/dto.rs
<a id="crates-ron-audit-src-dto-rs"></a>

```rust
//! Small DTO helpers for ron-audit.
//!
//! For now, `AuditRecord` and its helper types live here. The long-term plan
//! (per the blueprints) is to host these DTOs in `ron-proto` and have
//! `ron-audit` re-export them, but that module doesn't exist yet.

use serde::{Deserialize, Serialize};
use serde_json::Value;

/// Canonical audit record shape.
///
/// This matches the IDB specification:
///
/// ```text
/// #[serde(deny_unknown_fields)]
/// pub struct AuditRecord {
///   pub v: u16,             // schema major
///   pub ts_ms: u64,         // advisory wall-clock millis
///   pub writer_id: String,  // "svc-gateway@inst-123" (lex order stable)
///   pub seq: u64,           // strictly monotone per (writer_id, stream)
///   pub stream: String,     // "ingress" | "policy" | ...
///   pub kind: AuditKind,    // CapIssued | PolicyChanged | IndexWrite | ...
///   pub actor: ActorRef,    // {cap_id?, key_fpr?, passport_id?, anon?:bool}
///   pub subject: SubjectRef,// {content_id? "b3:<hex>", ledger_txid?, name?}
///   pub reason: ReasonCode, // normalized taxonomy
///   pub attrs: serde_json::Value, // ≤ 1 KiB canonicalized
///   pub prev: String,       // "b3:<hex>" previous or "b3:0" for genesis
///   pub self_hash: String,  // "b3:<hex>" over canonicalized record excl. self_hash
/// }
/// ```
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct AuditRecord {
    /// Schema major version.
    pub v: u16,
    /// Advisory wall-clock timestamp (milliseconds since Unix epoch).
    pub ts_ms: u64,
    /// Logical writer identifier (e.g. "svc-edge@inst-123").
    pub writer_id: String,
    /// Strictly monotone per `(writer_id, stream)`.
    pub seq: u64,
    /// Logical stream (e.g. "ingress", "policy", "index").
    pub stream: String,
    /// High-level category of the event.
    pub kind: AuditKind,
    /// Actor performing the action.
    pub actor: ActorRef,
    /// Subject of the action.
    pub subject: SubjectRef,
    /// Normalized reason taxonomy.
    pub reason: ReasonCode,
    /// Free-form, canonicalized attributes (bounded in size).
    pub attrs: Value,
    /// Previous record's `self_hash` ("b3:<hex>" or "b3:0" for genesis).
    pub prev: String,
    /// Canonical BLAKE3 hash of the record excluding `self_hash`.
    pub self_hash: String,
}

/// High-level category of an audit event.
///
/// This is intentionally minimal for now; more variants can be added as the
/// taxonomy hardens.
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
#[serde(rename_all = "snake_case")]
pub enum AuditKind {
    /// Fallback for events that haven't been fully classified yet.
    #[default]
    Unknown,
    /// Capability issued (e.g. macaroon/passport/cap token).
    CapIssued,
    /// Capability revoked or invalidated.
    CapRevoked,
    /// Policy document changed.
    PolicyChanged,
    /// Storage/index write operation.
    IndexWrite,
    /// A read / get operation was served.
    GetServed,
    /// Request was rejected due to quotas/limits.
    QuotaReject,
}

/// Reference to the actor performing the audited action.
///
/// Fields are optional; different layers may populate different subsets.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct ActorRef {
    /// Capability identifier (e.g. passport/cap token id).
    #[serde(skip_serializing_if = "Option::is_none")]
    pub cap_id: Option<String>,

    /// Key fingerprint (e.g. Ed25519 public key hash).
    #[serde(skip_serializing_if = "Option::is_none")]
    pub key_fpr: Option<String>,

    /// Passport identifier (from svc-passport).
    #[serde(skip_serializing_if = "Option::is_none")]
    pub passport_id: Option<String>,

    /// Whether the actor is anonymous.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub anon: Option<bool>,
}

/// Reference to the subject of the audited action.
///
/// Again, all fields are optional so hosts can fill as much as they know.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct SubjectRef {
    /// ContentId / object hash ("b3:<hex>").
    #[serde(skip_serializing_if = "Option::is_none")]
    pub content_id: Option<String>,

    /// Ledger transaction id (when present).
    #[serde(skip_serializing_if = "Option::is_none")]
    pub ledger_txid: Option<String>,

    /// Human-readable name or label, if applicable.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

/// Normalized reason taxonomy.
///
/// For now this is a thin newtype over `String` so we can evolve the
/// vocabulary without breaking the wire schema.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
#[serde(transparent)]
pub struct ReasonCode(pub String);

/// Fixed-size dedupe key derived from the canonical bytes of an `AuditRecord`.
///
/// This is the raw BLAKE3 output used for indexing / dedupe structures.
pub type DedupeKey = [u8; 32];

/// Export-friendly representation of a chain head.
///
/// Host crates can use this when exposing heads over admin/diagnostic APIs.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChainHeadDto {
    /// Stream identifier (e.g. logical stream or partition key).
    pub stream: String,
    /// Last known sequence number within the stream.
    pub seq: u64,
    /// Last known `self_hash` at the head of the stream.
    pub head: String,
}

```

### crates/ron-audit/src/errors.rs
<a id="crates-ron-audit-src-errors-rs"></a>

```rust
//! Error types for ron-audit.
//!
//! These are intentionally small and host-friendly; higher layers can wrap them
//! in richer error stacks if desired.

use std::io;

use thiserror::Error;

use crate::canon::CanonError;

/// Errors produced while appending audit records into a sink.
#[derive(Debug, Error)]
pub enum AppendError {
    /// The sink is full / backpressure threshold hit.
    #[error("audit sink is full or backpressured")]
    Full,

    /// The record exceeded size bounds (attrs or full record).
    #[error("audit record size exceeded bounds")]
    SizeExceeded,

    /// The sink detected tampering or chain breakage (e.g. prev/self mismatch).
    #[error("audit chain tamper detected")]
    Tamper,

    /// Underlying IO error from a WAL or storage layer.
    #[error("io error while appending audit record: {0}")]
    Io(#[from] io::Error),

    /// Canonical form violated schema or invariants.
    #[error("schema / canonicalization error")]
    Schema,
}

/// Errors produced while verifying canonical form or chain linkage.
#[derive(Debug, Error)]
pub enum VerifyError {
    /// The computed hash did not match the record's `self_hash`.
    #[error("self hash mismatch")]
    HashMismatch,

    /// Canonicalization failed (NFC, floats, unknown fields, etc).
    #[error("canonicalization error: {0}")]
    Canon(#[from] CanonError),

    /// Chain linkage between two adjacent records failed.
    #[error("prev/self linkage mismatch")]
    LinkMismatch,
}

/// Errors produced by bounds checks (size limits).
#[derive(Debug, Error)]
pub enum BoundsError {
    /// `attrs` payload exceeded the configured maximum number of bytes.
    #[error("attrs too large: {actual} bytes (max {max})")]
    AttrsTooLarge {
        /// Actual serialized size in bytes.
        actual: usize,
        /// Configured maximum size in bytes.
        max: usize,
    },

    /// Full record exceeded the configured maximum number of bytes.
    #[error("record too large: {actual} bytes (max {max})")]
    RecordTooLarge {
        /// Actual serialized size in bytes.
        actual: usize,
        /// Configured maximum size in bytes.
        max: usize,
    },
}

```

### crates/ron-audit/src/hash/b3.rs
<a id="crates-ron-audit-src-hash-b3-rs"></a>

```rust
//! BLAKE3 hashing for canonical audit records.

use blake3::Hasher;

use crate::canon::{canonicalize_without_self_hash, CanonError};
use crate::dto::DedupeKey;
use crate::AuditRecord;

/// Compute the canonical BLAKE3 hash of a record, excluding `self_hash`,
/// and return it in the `"b3:<hex>"` string form used on-chain.
pub fn b3_no_self(rec: &AuditRecord) -> Result<String, CanonError> {
    let bytes = canonicalize_without_self_hash(rec)?;
    let mut hasher = Hasher::new();
    hasher.update(&bytes);
    let hash = hasher.finalize();
    Ok(format!("b3:{}", hash.to_hex()))
}

/// Compute the canonical BLAKE3 hash of a record, excluding `self_hash`,
/// and return the raw 32-byte output as a dedupe key.
pub fn dedupe_key(rec: &AuditRecord) -> Result<DedupeKey, CanonError> {
    let bytes = canonicalize_without_self_hash(rec)?;
    let mut hasher = Hasher::new();
    hasher.update(&bytes);
    let hash = hasher.finalize();
    let mut out = [0u8; 32];
    out.copy_from_slice(hash.as_bytes());
    Ok(out)
}

```

### crates/ron-audit/src/hash/mod.rs
<a id="crates-ron-audit-src-hash-mod-rs"></a>

```rust
//! Hash helpers for `AuditRecord`.

mod b3;

pub use b3::{b3_no_self, dedupe_key};

```

### crates/ron-audit/src/lib.rs
<a id="crates-ron-audit-src-lib-rs"></a>

```rust
//! ron-audit — audit-chain helpers for `AuditRecord`.
//!
//! RO:WHAT — Library for canonicalization, hashing, verification and sink traits
//!           over `AuditRecord`.
//! RO:WHY  — Give Micronode/Macronode hosts one precise place to agree on how
//!           audit chains are formed, hashed and checked.
//! RO:INTERACTS — Intended to be wired by svc-edge, svc-registry, svc-storage,
//!           micronode, macronode, etc. DTOs currently live locally; they can
//!           be migrated into `ron-proto` later without changing this crate's
//!           outward API.
//!
//! NOTE: The original IDB sketched `pub use ron_proto::audit::AuditRecord;`,
//! but `ron_proto::audit` does not exist yet. For now we define the DTOs
//! locally (in `dto`) and re-export from there.

#![forbid(unsafe_code)]
#![deny(missing_docs)]
#![deny(clippy::unwrap_used, clippy::expect_used, clippy::await_holding_lock)]

mod errors;

pub mod bounds;
pub mod canon;
pub mod dto;
pub mod hash;
pub mod metrics;
pub mod prelude;
pub mod privacy;
pub mod sink;
pub mod stream;
pub mod verify;

/// Primary DTO used by ron-audit — currently defined locally in `dto`.
pub use crate::dto::AuditRecord;

pub use crate::canon::CanonError;
pub use crate::errors::{AppendError, BoundsError, VerifyError};
pub use crate::sink::{AuditSink, AuditStream, ChainState};

```

### crates/ron-audit/src/metrics/mod.rs
<a id="crates-ron-audit-src-metrics-mod-rs"></a>

```rust
// crates/ron-audit/src/metrics/mod.rs
//! RO:WHAT  — Zero-IO metrics hook for ron-audit (library-only).
//! RO:WHY   — Let hosts publish `audit_*` metrics (Prometheus, etc.) without
//!            pulling heavy deps into the core crate.
//! RO:INTERACTS — Host services (svc-edge, svc-gateway, micronode, etc.) can
//!                install a recorder; ron-audit stays ignorant of the backend.
//!
//! Design notes:
//! - Default is a NO-OP recorder: no allocations, no locks on the hot path.
//! - This crate never depends on prometheus/tokio/axum; that’s host territory.
//! - API is intentionally tiny and stable: counter + histogram + gauge.
//! - Install is best-effort: first caller wins; later calls are ignored.
//!
//! Example (host crate):
//! ```ignore
//! use ron_audit::metrics::{install_recorder, MetricsRecorder};
//!
//! struct PromRecorder { /* wraps prometheus registry */ }
//! impl MetricsRecorder for PromRecorder {
//!     fn counter_add(&self, name: &'static str, by: u64) { /* ... */ }
//!     fn hist_ns(&self, name: &'static str, value: u64) { /* ... */ }
//!     fn gauge_set(&self, name: &'static str, value: i64) { /* ... */ }
//! }
//!
//! static PROM: PromRecorder = PromRecorder { /* ... */ };
//!
//! pub fn init_metrics() {
//!     ron_audit::metrics::install_recorder(&PROM);
//! }
//! ```
//!
//! Inside ron-audit we can call the helpers in hot paths (e.g. verify, append)
//! without knowing how they are implemented by the host.

use std::sync::OnceLock;

/// Minimal interface a host-side metrics backend must implement.
///
/// All methods must be cheap and non-blocking — they are called on the audit
/// hot path (verify/append). Any heavy lifting (aggregation, encoding, I/O)
/// should be done in the host, off the hot path.
pub trait MetricsRecorder: Send + Sync + 'static {
    /// Monotonic counter add.
    ///
    /// Example names (host suggestion):
    /// - "ron_audit_emit_total"
    /// - "ron_audit_verify_ok_total"
    /// - "ron_audit_verify_fail_total"
    fn counter_add(&self, name: &'static str, by: u64);

    /// Histogram observation in nanoseconds.
    ///
    /// Hosts may choose to export in seconds/milliseconds; the unit here is
    /// just a convention for the value we pass.
    fn hist_ns(&self, name: &'static str, value: u64);

    /// Gauge set for instantaneous values.
    ///
    /// Example names:
    /// - "ron_audit_heads_tracked"
    /// - "ron_audit_wal_queue_depth"
    fn gauge_set(&self, name: &'static str, value: i64);
}

/// NO-OP recorder used when no host has installed a real backend.
///
/// This is the default; it ensures we never panic or allocate on the hot path
/// even if nothing is wired up yet.
struct NoopRecorder;

impl MetricsRecorder for NoopRecorder {
    #[inline]
    fn counter_add(&self, _name: &'static str, _by: u64) {
        // no-op
    }

    #[inline]
    fn hist_ns(&self, _name: &'static str, _value: u64) {
        // no-op
    }

    #[inline]
    fn gauge_set(&self, _name: &'static str, _value: i64) {
        // no-op
    }
}

static NOOP_RECORDER: NoopRecorder = NoopRecorder;

/// Global recorder pointer; first install wins.
///
/// We store a `&'static dyn MetricsRecorder` so hosts can keep their own
/// statics and avoid extra allocations here.
static RECORDER: OnceLock<&'static dyn MetricsRecorder> = OnceLock::new();

#[inline]
fn recorder() -> &'static dyn MetricsRecorder {
    // If a host has installed a recorder, use it; otherwise fall back to NOOP.
    RECORDER.get().copied().unwrap_or(&NOOP_RECORDER)
}

/// Install a global metrics recorder.
///
/// This should be called once by a host crate at startup. If called multiple
/// times, only the first recorder is kept; subsequent calls are ignored.
///
/// This behavior is intentional: it avoids surprising mid-flight swaps.
pub fn install_recorder(rec: &'static dyn MetricsRecorder) {
    let _ = RECORDER.set(rec);
}

/// Increment a counter by `by`.
///
/// Thin wrapper around `MetricsRecorder::counter_add`.
#[inline]
pub fn counter_add(name: &'static str, by: u64) {
    recorder().counter_add(name, by);
}

/// Observe a latency value (nanoseconds) in a histogram.
///
/// Thin wrapper around `MetricsRecorder::hist_ns`.
#[inline]
pub fn hist_ns(name: &'static str, value: u64) {
    recorder().hist_ns(name, value);
}

/// Set a gauge to `value`.
///
/// Thin wrapper around `MetricsRecorder::gauge_set`.
#[inline]
pub fn gauge_set(name: &'static str, value: i64) {
    recorder().gauge_set(name, value);
}

```

### crates/ron-audit/src/prelude.rs
<a id="crates-ron-audit-src-prelude-rs"></a>

```rust
/*!
RO:WHAT — Convenience prelude for common ron-audit types and helpers.
RO:WHY — DX: allow hosts/tests/benches to import a stable surface with a single use line.
RO:INTERACTS — bounds, canon, hash, verify, sink, dto.
RO:INVARIANTS — stable re-export set; no heavy dependencies pulled in accidentally.
RO:METRICS/LOGS — none.
RO:CONFIG — none.
RO:SECURITY — re-exports only; no logic.
RO:TEST HOOKS — doc test in this file; tests/api_compat.rs.
*/

pub use crate::bounds::{check as check_bounds, DEFAULT_MAX_ATTRS_BYTES, DEFAULT_MAX_RECORD_BYTES};
pub use crate::canon::{canonicalize_without_self_hash, CanonError};
pub use crate::hash::{b3_no_self, dedupe_key};
pub use crate::sink::{AuditSink, AuditStream, ChainState};
pub use crate::verify::{verify_chain, verify_chain_soa, verify_link, verify_record};
pub use crate::AuditRecord;
pub use crate::{AppendError, BoundsError, VerifyError};

```

### crates/ron-audit/src/privacy/mod.rs
<a id="crates-ron-audit-src-privacy-mod-rs"></a>

```rust
//! Privacy policy helpers for audit records.
//!
//! This is intentionally conservative for now: `validate` is a no-op that
//! always succeeds. Future iterations can add heuristics or policy hooks.

use crate::AuditRecord;

/// Errors raised by privacy policy checks.
#[derive(Debug, thiserror::Error)]
pub enum PrivacyError {
    /// Placeholder error for when PII or disallowed data is detected.
    #[error("privacy policy violation detected")]
    Violation,
}

/// Validate an `AuditRecord` against privacy policies.
///
/// At the moment this performs no checks and always returns `Ok(())`.
/// Hosts can add richer inspection logic later without breaking the
/// public function signature.
pub fn validate(_rec: &AuditRecord) -> Result<(), PrivacyError> {
    Ok(())
}

```

### crates/ron-audit/src/sink/export.rs
<a id="crates-ron-audit-src-sink-export-rs"></a>

```rust
//! Checkpoint / export helpers for audit chains.
//!
//! This is intentionally minimal for now; it can be extended later to
//! implement Merkle-style roots or chunked exports.

#[cfg(feature = "export")]
use crate::AuditRecord;

/// Simple checkpoint description for a contiguous span of records.
#[cfg(feature = "export")]
#[derive(Debug, Clone)]
pub struct Checkpoint {
    /// Inclusive start sequence number.
    pub from_seq: u64,
    /// Inclusive end sequence number.
    pub to_seq: u64,
    /// Hash of the last record in the span.
    pub head: String,
}

/// Compute a trivial checkpoint from a slice of records.
///
/// For now we just capture `[seq_min, seq_max]` and the `self_hash` of
/// the last record; this is enough to get tests going and can be
/// swapped for a more sophisticated construction later.
#[cfg(feature = "export")]
pub fn checkpoint_from_slice(records: &[AuditRecord]) -> Option<Checkpoint> {
    let last = records.last()?;
    let first_seq = records.first().map(|r| r.seq).unwrap_or(last.seq);
    Some(Checkpoint {
        from_seq: first_seq,
        to_seq: last.seq,
        head: last.self_hash.clone(),
    })
}

```

### crates/ron-audit/src/sink/mod.rs
<a id="crates-ron-audit-src-sink-mod-rs"></a>

```rust
//! Sink traits and basic implementations for audit chains.

mod traits;
pub use traits::{AuditSink, AuditStream, ChainState};

pub mod ram;

#[cfg(feature = "wal")]
pub mod wal;

#[cfg(feature = "export")]
pub mod export;

```

### crates/ron-audit/src/sink/ram.rs
<a id="crates-ron-audit-src-sink-ram-rs"></a>

```rust
//! Simple in-memory `AuditSink` implementation.
//!
//! This is primarily for testing and small deployments; it does not provide
//! durability beyond process lifetime.

use std::collections::HashMap;
use std::sync::RwLock;

use crate::errors::AppendError;
use crate::sink::{AuditSink, AuditStream, ChainState};
use crate::{dto::ChainHeadDto, AuditRecord};

/// In-memory append-only sink, keyed by stream.
#[derive(Debug, Default)]
pub struct RamSink {
    inner: RwLock<HashMap<String, Vec<AuditRecord>>>,
}

impl RamSink {
    /// Create an empty in-memory sink.
    pub fn new() -> Self {
        Self::default()
    }

    /// Get a copy of all records for a stream.
    pub fn records_for(&self, stream: &str) -> Vec<AuditRecord> {
        let guard = self
            .inner
            .read()
            .unwrap_or_else(|poisoned| poisoned.into_inner());

        guard.get(stream).cloned().unwrap_or_default()
    }

    /// Export a snapshot of all known chain heads.
    ///
    /// This is an in-memory convenience helper intended for:
    /// - admin/diagnostic APIs, and
    /// - tests that need to assert on checkpoint semantics.
    ///
    /// Each entry corresponds to a single logical stream.
    pub fn heads(&self) -> Vec<ChainHeadDto> {
        let guard = self
            .inner
            .read()
            .unwrap_or_else(|poisoned| poisoned.into_inner());

        guard
            .iter()
            .filter_map(|(stream, records)| {
                records.last().map(|last| ChainHeadDto {
                    stream: stream.clone(),
                    seq: last.seq,
                    head: last.self_hash.clone(),
                })
            })
            .collect()
    }
}

impl AuditStream for RamSink {
    fn state(&self, stream: &str) -> ChainState {
        let guard = self
            .inner
            .read()
            .unwrap_or_else(|poisoned| poisoned.into_inner());

        if let Some(records) = guard.get(stream) {
            if let Some(last) = records.last() {
                return ChainState {
                    head: last.self_hash.clone(),
                    seq: last.seq,
                };
            }
        }

        ChainState::default()
    }
}

impl AuditSink for RamSink {
    fn append(&self, rec: &AuditRecord) -> Result<String, AppendError> {
        let mut guard = self
            .inner
            .write()
            .unwrap_or_else(|poisoned| poisoned.into_inner());

        let stream = rec.stream.clone();
        let records = guard.entry(stream.clone()).or_default();

        // Enforce simple append-only linkage rule: prev == last.self_hash.
        if let Some(last) = records.last() {
            if rec.prev != last.self_hash {
                return Err(AppendError::Tamper);
            }
        }

        records.push(rec.clone());
        Ok(rec.self_hash.clone())
    }
}

```

### crates/ron-audit/src/sink/traits.rs
<a id="crates-ron-audit-src-sink-traits-rs"></a>

```rust
//! Core sink traits for append-only audit chains.

use crate::errors::AppendError;
use crate::AuditRecord;

/// Snapshot of a chain head for a given stream.
#[derive(Debug, Clone, Default)]
pub struct ChainState {
    /// Last known `self_hash` at the head of the stream.
    pub head: String,
    /// Last known sequence number for the stream.
    pub seq: u64,
}

/// Read-only view of audit stream state.
pub trait AuditStream: Send + Sync {
    /// Return the current chain state for a given stream.
    fn state(&self, stream: &str) -> ChainState;

    /// Convenience helper: `state(stream).seq + 1`.
    fn next_seq(&self, stream: &str) -> u64 {
        self.state(stream).seq.saturating_add(1)
    }
}

/// Append-only sink for audit records.
///
/// Implementations are expected to:
/// - Enforce `prev/self_hash` consistency.
/// - Enforce monotonic `seq` within a stream.
/// - Provide persistence guarantees appropriate for the deployment.
pub trait AuditSink: Send + Sync {
    /// Append a single record to the sink.
    ///
    /// Implementations typically:
    /// - Validate bounds.
    /// - Validate hash and linkage.
    /// - Commit to WAL / storage.
    fn append(&self, rec: &AuditRecord) -> Result<String, AppendError>;

    /// Flush any buffered data to durable storage.
    fn flush(&self) -> Result<(), AppendError> {
        Ok(())
    }
}

```

### crates/ron-audit/src/sink/wal.rs
<a id="crates-ron-audit-src-sink-wal-rs"></a>

```rust
//! Placeholder WAL-backed sink implementation.
//!
//! This module is feature-gated behind `wal` and currently provides a
//! minimal, non-durable implementation that behaves like `RamSink`.
//!
//! A real WAL-backed sink can replace this without breaking the public
//! trait surface.

#[cfg(feature = "wal")]
use std::sync::Arc;

#[cfg(feature = "wal")]
use crate::sink::{AuditSink, AuditStream, ChainState};
#[cfg(feature = "wal")]
use crate::{errors::AppendError, AuditRecord};

/// Minimal WAL sink placeholder.
///
/// Internally this just forwards to an in-memory `RamSink`. The type is
/// present so that higher layers can experiment with the `wal` feature
/// flag without breaking compilation.
#[cfg(feature = "wal")]
#[derive(Debug, Default)]
pub struct WalSink {
    inner: Arc<crate::sink::ram::RamSink>,
}

#[cfg(feature = "wal")]
impl WalSink {
    /// Construct a new placeholder WAL sink.
    pub fn new() -> Self {
        Self {
            inner: Arc::new(crate::sink::ram::RamSink::new()),
        }
    }
}

#[cfg(feature = "wal")]
impl AuditStream for WalSink {
    fn state(&self, stream: &str) -> ChainState {
        self.inner.state(stream)
    }
}

#[cfg(feature = "wal")]
impl AuditSink for WalSink {
    fn append(&self, rec: &AuditRecord) -> Result<String, AppendError> {
        self.inner.append(rec)
    }

    fn flush(&self) -> Result<(), AppendError> {
        self.inner.flush()
    }
}

```

### crates/ron-audit/src/stream/mod.rs
<a id="crates-ron-audit-src-stream-mod-rs"></a>

```rust
//! Streaming helpers for audit sinks.
//!
//! For the initial seed we keep this extremely small; hosts can build
//! richer batching / mpsc-based streaming layers on top.

use crate::errors::AppendError;
use crate::sink::AuditSink;
use crate::AuditRecord;

/// A simple buffered sink wrapper that collects records and flushes them
/// in a single batch call.
///
/// The current implementation just forwards records one-by-one; it
/// exists mainly to give tests somewhere to hang future stream logic.
#[derive(Debug)]
pub struct BufferedSink<S> {
    inner: S,
}

impl<S> BufferedSink<S> {
    /// Wrap an existing sink.
    pub fn new(inner: S) -> Self {
        Self { inner }
    }

    /// Access the inner sink.
    pub fn into_inner(self) -> S {
        self.inner
    }
}

impl<S> BufferedSink<S>
where
    S: AuditSink,
{
    /// Append all given records, stopping on the first error.
    pub fn append_all(&self, records: &[AuditRecord]) -> Result<(), AppendError> {
        for rec in records {
            self.inner.append(rec)?;
        }
        self.inner.flush()
    }
}

```

### crates/ron-audit/src/verify/chain.rs
<a id="crates-ron-audit-src-verify-chain-rs"></a>

```rust
/*!
RO:WHAT — Scalar and SoA-style helpers for verifying audit chains.
RO:WHY — Integrity/RES: cheaply validate self_hash and prev/self linkage over large batches.
RO:INTERACTS — super::record::verify_record; crate::errors::VerifyError; crate::AuditRecord.
RO:INVARIANTS — no unsafe; verify_chain is the scalar reference; verify_chain_soa must be
                 semantics-identical. The `simd` feature is currently a no-op hook reserved for
                 future optimizations; scalar equality remains the oracle.
RO:METRICS/LOGS — none here; callers may instrument latency externally.
RO:CONFIG — none; batch size is provided by callers.
RO:SECURITY — tamper-evident: any mismatch is surfaced as VerifyError::HashMismatch or LinkMismatch.
RO:TEST HOOKS — tests/idempotency.rs, tests/multi_writer_ordering.rs, tests/verify_soa.rs;
                 benches/verify_chain.rs.
*/

use crate::errors::VerifyError;
use crate::verify::verify_record;
use crate::AuditRecord;

/// Internal helper for comparing prev/self_hash.
///
/// For now this is a thin wrapper around `==` in all configurations. The `simd`
/// feature flag is reserved for future, stable SIMD-based implementations once
/// the ecosystem and MSRV make that a good trade-off.
///
/// Keeping this helper as a single choke point allows us to:
/// - keep scalar equality as the correctness oracle today;
/// - later drop in a feature-gated optimized implementation without touching
///   the rest of the verification code.
#[inline]
fn eq_hashes(a: &str, b: &str) -> bool {
    // NOTE: `simd` feature currently does not change behavior. When we add a
    // stable SIMD implementation (via an external crate or std support),
    // it will live behind this helper.
    #[cfg(feature = "simd")]
    {
        a == b
    }

    #[cfg(not(feature = "simd"))]
    {
        a == b
    }
}

/// Verify that `next` correctly links to `prev`.
///
/// At minimum we check:
/// - `next.prev == prev.self_hash`
pub fn verify_link(prev: &AuditRecord, next: &AuditRecord) -> Result<(), VerifyError> {
    if eq_hashes(&next.prev, &prev.self_hash) {
        Ok(())
    } else {
        Err(VerifyError::LinkMismatch)
    }
}

/// Scalar reference implementation: verify a full chain of audit records
/// provided as an iterator.
///
/// The iterator is consumed; each record is verified individually and
/// adjacency is checked via [`verify_link`].
pub fn verify_chain<I>(iter: I) -> Result<(), VerifyError>
where
    I: IntoIterator<Item = AuditRecord>,
{
    let mut last: Option<AuditRecord> = None;

    for rec in iter {
        verify_record(&rec)?;
        if let Some(prev) = &last {
            verify_link(prev, &rec)?;
        }
        last = Some(rec);
    }

    Ok(())
}

/// SoA-style batch verifier over a contiguous slice of records.
///
/// This is intended as a "fast path" for hosts that already have a `&[AuditRecord]`
/// in memory. It is kept separate from [`verify_chain`] so the scalar reference
/// implementation can remain small and obviously correct.
///
/// Semantics:
/// - If the slice is empty, returns `Ok(())`.
/// - For each record, recomputes and checks its `self_hash`.
/// - For each adjacent pair `(prev, next)` checks `next.prev == prev.self_hash`
///   via the `eq_hashes` helper (which is currently scalar in all modes).
pub fn verify_chain_soa(chain: &[AuditRecord]) -> Result<(), VerifyError> {
    if chain.is_empty() {
        return Ok(());
    }

    // First pass: verify each record's self_hash.
    for rec in chain {
        verify_record(rec)?;
    }

    // Second pass: SoA-style linkage check.
    for i in 1..chain.len() {
        let prev = &chain[i - 1];
        let next = &chain[i];

        if !eq_hashes(&next.prev, &prev.self_hash) {
            return Err(VerifyError::LinkMismatch);
        }
    }

    Ok(())
}

```

### crates/ron-audit/src/verify/mod.rs
<a id="crates-ron-audit-src-verify-mod-rs"></a>

```rust
/*!
RO:WHAT — Verification helpers for individual audit records and chains.
RO:WHY — Integrity: enforce self_hash correctness and prev/self linkage invariants.
RO:INTERACTS — crate::hash, crate::errors, crate::dto::AuditRecord.
RO:INVARIANTS — no unsafe; verify_chain is scalar reference; verify_chain_soa is batch fast path with matching semantics.
RO:METRICS/LOGS — none here; callers may instrument latency/histograms externally.
RO:CONFIG — none.
RO:SECURITY — any tamper in the audit chain is surfaced as VerifyError.
RO:TEST HOOKS — unit tests (idempotency, multi_writer_ordering, verify_soa); benches/verify_chain.rs.
*/

mod chain;
mod record;

pub use chain::{verify_chain, verify_chain_soa, verify_link};
pub use record::verify_record;

```

### crates/ron-audit/src/verify/record.rs
<a id="crates-ron-audit-src-verify-record-rs"></a>

```rust
//! Per-record verification helpers.

use crate::errors::VerifyError;
use crate::hash::b3_no_self;
use crate::AuditRecord;

/// Verify a single `AuditRecord` by recomputing its canonical hash and
/// comparing it to `self_hash`.
pub fn verify_record(rec: &AuditRecord) -> Result<(), VerifyError> {
    let expected = b3_no_self(rec)?;
    if rec.self_hash == expected {
        Ok(())
    } else {
        Err(VerifyError::HashMismatch)
    }
}

```

### crates/ron-audit/testing/vectors/manifest_example.json
<a id="crates-ron-audit-testing-vectors-manifestexample-json"></a>

```json

```

### crates/ron-audit/testing/vectors/record_max.json
<a id="crates-ron-audit-testing-vectors-recordmax-json"></a>

```json

```

### crates/ron-audit/testing/vectors/record_small.json
<a id="crates-ron-audit-testing-vectors-recordsmall-json"></a>

```json

```

### crates/ron-audit/tests/api_compat.rs
<a id="crates-ron-audit-tests-apicompat-rs"></a>

```rust
/*!
RO:WHAT — API surface smoke test for prelude and core modules.
RO:WHY — GOV/DX: catch obvious API breakage before semver checks.
RO:INTERACTS — ron_audit::prelude; dto::AuditRecord.
RO:INVARIANTS — prelude compiles; basic hash/verify/bounds round-trip works.
RO:TEST HOOKS — Unit tests here; CI later wires cargo-public-api.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::prelude::*;
use serde_json::json;

fn mk_record() -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "writer@test".to_string(),
        seq: 0,
        stream: "stream@test".to_string(),
        kind: AuditKind::CapIssued,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("api-compat-test".to_string()),
        attrs: json!({ "ok": true }),
        prev: "b3:0".to_string(),
        self_hash: String::new(),
    }
}

#[test]
fn prelude_smoke_round_trip() {
    let mut rec = mk_record();

    // hash without self, then set self_hash and verify
    rec.self_hash = b3_no_self(&rec).expect("hash");
    verify_record(&rec).expect("verify");

    // bounds check via prelude re-exports
    check_bounds(&rec, DEFAULT_MAX_ATTRS_BYTES, DEFAULT_MAX_RECORD_BYTES).expect("bounds");
}

```

### crates/ron-audit/tests/append_only.rs
<a id="crates-ron-audit-tests-appendonly-rs"></a>

```rust
/*!
RO:WHAT — Append-only behavior and basic chain head semantics for RamSink.
RO:WHY — Integrity: enforce append-only and detect tamper on prev/self linkage.
RO:INTERACTS — ron_audit::sink::ram::RamSink; hash::b3_no_self; AppendError.
RO:INVARIANTS — append is append-only; prev must equal last.self_hash; per-stream heads tracked.
RO:TEST HOOKS — Unit tests in this file; fuzz/loom reserved for host q.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::b3_no_self;
use ron_audit::sink::{ram::RamSink, AuditSink, AuditStream};
use ron_audit::{AppendError, AuditRecord};
use serde_json::json;

fn mk_record(stream: &str, seq: u64, prev: &str) -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    let mut rec = AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "writer@test".to_string(),
        seq,
        stream: stream.to_string(),
        kind: AuditKind::Unknown,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("test-append-only".to_string()),
        attrs: json!({ "case": "append_only" }),
        prev: prev.to_string(),
        self_hash: String::new(),
    };

    rec.self_hash = b3_no_self(&rec).expect("hash");
    rec
}

#[test]
fn append_updates_head_and_seq_per_stream() {
    let sink = RamSink::new();

    let genesis = mk_record("s1", 0, "b3:0");
    let head1 = sink.append(&genesis).expect("append genesis");
    let state1 = sink.state("s1");
    assert_eq!(state1.seq, 0);
    assert_eq!(state1.head, head1);

    let rec2 = mk_record("s1", 1, &head1);
    let head2 = sink.append(&rec2).expect("append second");
    let state2 = sink.state("s1");
    assert_eq!(state2.seq, 1);
    assert_eq!(state2.head, head2);
    assert_ne!(state2.head, head1);
}

#[test]
fn append_rejects_prev_mismatch_tamper() {
    let sink = RamSink::new();

    let genesis = mk_record("s1", 0, "b3:0");
    let head1 = sink.append(&genesis).expect("append genesis");

    // Tampered record: prev does NOT match last.self_hash.
    let mut bad = mk_record("s1", 1, "b3:not-the-head");
    // keep self_hash consistent for the bad record itself
    bad.self_hash = b3_no_self(&bad).expect("hash bad");

    assert_ne!(bad.prev, head1);

    let err = sink.append(&bad).expect_err("tamper should be rejected");
    match err {
        AppendError::Tamper => {}
        other => panic!("expected AppendError::Tamper, got {other:?}"),
    }
}

```

### crates/ron-audit/tests/bounds.rs
<a id="crates-ron-audit-tests-bounds-rs"></a>

```rust
/*!
RO:WHAT — Bounds checking for attrs and full record sizes.
RO:WHY — PERF/RES: protect sinks from unbounded payloads.
RO:INTERACTS — ron_audit::bounds; dto::AuditRecord; serde_json.
RO:INVARIANTS — attrs ≤ configured max; record ≤ configured max.
RO:TEST HOOKS — Unit tests here; fuzz will hit more attr shapes later.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::bounds;
use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::{AuditRecord, BoundsError};
use serde_json::json;

fn base_record() -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "writer@test".to_string(),
        seq: 0,
        stream: "stream@test".to_string(),
        kind: AuditKind::Unknown,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("bounds-test".to_string()),
        attrs: json!({ "ok": true }),
        prev: "b3:0".to_string(),
        self_hash: "b3:placeholder".to_string(),
    }
}

#[test]
fn small_record_respects_default_bounds() {
    let rec = base_record();
    bounds::check(
        &rec,
        bounds::DEFAULT_MAX_ATTRS_BYTES,
        bounds::DEFAULT_MAX_RECORD_BYTES,
    )
    .expect("small record should pass bounds");
}

#[test]
fn oversized_attrs_are_rejected() {
    let mut rec = base_record();
    let big = "x".repeat(bounds::DEFAULT_MAX_ATTRS_BYTES + 1);
    rec.attrs = json!(big);

    let err = bounds::check(
        &rec,
        bounds::DEFAULT_MAX_ATTRS_BYTES,
        bounds::DEFAULT_MAX_RECORD_BYTES,
    )
    .expect_err("attrs beyond limit must be rejected");

    match err {
        BoundsError::AttrsTooLarge { .. } => {}
        other => panic!("expected AttrsTooLarge, got {other:?}"),
    }
}

#[test]
fn oversized_record_is_rejected() {
    let mut rec = base_record();
    // Make the record body large via a long reason string.
    rec.reason = ReasonCode("x".repeat(5_000));

    let err = bounds::check(&rec, bounds::DEFAULT_MAX_ATTRS_BYTES, 512)
        .expect_err("record beyond limit must be rejected");

    match err {
        BoundsError::RecordTooLarge { .. } => {}
        other => panic!("expected RecordTooLarge, got {other:?}"),
    }
}

```

### crates/ron-audit/tests/canonicalization.rs
<a id="crates-ron-audit-tests-canonicalization-rs"></a>

```rust
/*!
RO:WHAT — Canonicalization invariants (drop self_hash, NFC, no floats).
RO:WHY — Integrity: stable hash surface and replay idempotency.
RO:INTERACTS — ron_audit::canon; dto::AuditRecord; serde_json.
RO:INVARIANTS — self_hash ignored; strings NFC-normalized; floats rejected.
RO:TEST HOOKS — Unit tests here; fuzz covers attr edge cases later.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::canon::{canonicalize_without_self_hash, CanonError};
use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::AuditRecord;
use serde_json::json;

fn base_record() -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "writer@test".to_string(),
        seq: 0,
        stream: "stream@test".to_string(),
        kind: AuditKind::CapIssued,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("canon-test".to_string()),
        attrs: json!({ "label": "ok" }),
        prev: "b3:0".to_string(),
        self_hash: "b3:placeholder".to_string(),
    }
}

#[test]
fn canonicalization_drops_self_hash() {
    let mut r1 = base_record();
    r1.self_hash = "b3:aaaa".to_string();

    let mut r2 = r1.clone();
    r2.self_hash = "b3:bbbb".to_string();

    let c1 = canonicalize_without_self_hash(&r1).expect("canon r1");
    let c2 = canonicalize_without_self_hash(&r2).expect("canon r2");

    assert_eq!(c1, c2, "self_hash must not affect canonical bytes");
}

#[test]
fn canonicalization_rejects_floats_in_attrs() {
    let mut r = base_record();
    r.attrs = json!({ "price": 1.5 });

    let res = canonicalize_without_self_hash(&r);
    match res {
        Err(CanonError::FloatDisallowed) => {}
        other => panic!("expected FloatDisallowed, got {other:?}"),
    }
}

#[test]
fn canonicalization_nfc_normalizes_strings() {
    // "Café" with decomposed é
    let decomposed = "Cafe\u{0301}";

    let mut r = base_record();
    r.attrs = json!({ "label": decomposed });

    let bytes = canonicalize_without_self_hash(&r).expect("canon");
    let value: serde_json::Value = serde_json::from_slice(&bytes).expect("valid json from canon");

    let label = value["attrs"]["label"]
        .as_str()
        .expect("attrs.label must be string");

    assert_eq!(label, "Café", "label must be NFC-normalized");
}

```

### crates/ron-audit/tests/export_checkpoints.rs
<a id="crates-ron-audit-tests-exportcheckpoints-rs"></a>

```rust
use std::collections::HashMap;

use ron_audit::dto::{ActorRef, AuditKind, AuditRecord, ReasonCode, SubjectRef};
use ron_audit::sink::ram::RamSink;
use ron_audit::AuditSink;
use serde_json::json;

/// Helper to build a minimal, self-consistent `AuditRecord` for tests.
///
/// NOTE: This does *not* compute a real BLAKE3 self_hash; tests here only care
/// about append-only semantics and head export, not cryptographic integrity.
fn make_record(stream: &str, seq: u64, prev: &str, self_hash: &str) -> AuditRecord {
    AuditRecord {
        v: 1,
        ts_ms: 0,
        writer_id: "svc-test@inst-1".to_string(),
        seq,
        stream: stream.to_string(),
        kind: AuditKind::Unknown,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("test".to_string()),
        attrs: json!({}),
        prev: prev.to_string(),
        self_hash: self_hash.to_string(),
    }
}

#[test]
fn export_heads_returns_latest_head_per_stream() {
    let sink = RamSink::new();

    // Build a small chain on two logical streams: "ingress" and "policy".
    // We use simple fake hashes here; we only care about linkage and export.
    let r1_ing = make_record("ingress", 1, "b3:0", "b3:ing-1");
    let r2_ing = make_record("ingress", 2, "b3:ing-1", "b3:ing-2");

    let r1_pol = make_record("policy", 1, "b3:0", "b3:pol-1");
    let r2_pol = make_record("policy", 2, "b3:pol-1", "b3:pol-2");
    let r3_pol = make_record("policy", 3, "b3:pol-2", "b3:pol-3");

    // Append in interleaved order to ensure ordering logic is per-stream.
    sink.append(&r1_ing).expect("append r1_ing");
    sink.append(&r1_pol).expect("append r1_pol");
    sink.append(&r2_ing).expect("append r2_ing");
    sink.append(&r2_pol).expect("append r2_pol");
    sink.append(&r3_pol).expect("append r3_pol");

    let heads = sink.heads();
    assert_eq!(heads.len(), 2, "expected one head per stream");

    let mut by_stream: HashMap<String, (u64, String)> = HashMap::new();
    for head in heads {
        by_stream.insert(head.stream.clone(), (head.seq, head.head.clone()));
    }

    // ingress: last ing record was seq=2, self_hash="b3:ing-2"
    let ingress = by_stream.get("ingress").expect("ingress head missing");
    assert_eq!(ingress.0, 2, "Ingress seq should be 2");
    assert_eq!(ingress.1, "b3:ing-2", "Ingress head hash mismatch");

    // policy: last pol record was seq=3, self_hash="b3:pol-3"
    let policy = by_stream.get("policy").expect("policy head missing");
    assert_eq!(policy.0, 3, "Policy seq should be 3");
    assert_eq!(policy.1, "b3:pol-3", "Policy head hash mismatch");
}

#[test]
fn export_heads_skips_empty_streams() {
    let sink = RamSink::new();

    // Only write to "ingress", leave "policy" empty.
    let r1_ing = make_record("ingress", 1, "b3:0", "b3:ing-1");
    sink.append(&r1_ing).expect("append r1_ing");

    let heads = sink.heads();
    assert_eq!(heads.len(), 1, "only one non-empty stream expected");

    let head = &heads[0];
    assert_eq!(head.stream, "ingress");
    assert_eq!(head.seq, 1);
    assert_eq!(head.head, "b3:ing-1");
}

```

### crates/ron-audit/tests/idempotency.rs
<a id="crates-ron-audit-tests-idempotency-rs"></a>

```rust
/*!
RO:WHAT — Idempotency of dedupe_key and hash/verify pipeline.
RO:WHY — ECON/RES: safe replay via stable canonicalization.
RO:INTERACTS — ron_audit::hash; verify; dto::AuditRecord.
RO:INVARIANTS — Same canonical record → same dedupe key; tamper breaks verify.
RO:TEST HOOKS — Unit tests here; fuzz targets canonicalization later.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::{b3_no_self, dedupe_key};
use ron_audit::verify::verify_record;
use ron_audit::{AuditRecord, VerifyError};
use serde_json::json;

fn base_record() -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "writer@test".to_string(),
        seq: 0,
        stream: "stream@test".to_string(),
        kind: AuditKind::CapIssued,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("idempotency-test".to_string()),
        attrs: json!({ "k": "v" }),
        prev: "b3:0".to_string(),
        self_hash: "b3:placeholder".to_string(),
    }
}

#[test]
fn dedupe_key_is_stable_across_self_hash_changes() {
    let mut r1 = base_record();
    let mut r2 = base_record();

    r1.self_hash = "b3:aaaa".to_string();
    r2.self_hash = "b3:bbbb".to_string();

    let k1 = dedupe_key(&r1).expect("dedupe r1");
    let k2 = dedupe_key(&r2).expect("dedupe r2");

    assert_eq!(k1, k2, "dedupe key must ignore self_hash differences");
}

#[test]
fn verify_record_succeeds_for_matching_hash() {
    let mut r = base_record();
    r.self_hash = b3_no_self(&r).expect("hash");
    verify_record(&r).expect("verify must succeed");
}

#[test]
fn verify_record_fails_on_tamper() {
    let mut r = base_record();
    r.self_hash = b3_no_self(&r).expect("hash");
    verify_record(&r).expect("baseline verify");

    // Tamper: change attrs but keep old self_hash.
    r.attrs = json!({ "k": "tampered" });

    let err = verify_record(&r).expect_err("tamper must fail verify");
    match err {
        VerifyError::HashMismatch => {}
        other => panic!("expected HashMismatch, got {other:?}"),
    }
}

```

### crates/ron-audit/tests/multi_writer_ordering.rs
<a id="crates-ron-audit-tests-multiwriterordering-rs"></a>

```rust
/*!
RO:WHAT — Multi-stream / multi-writer state semantics for RamSink.
RO:WHY — GOV/RES: clarify that only per-stream heads are exposed; no global order.
RO:INTERACTS — ron_audit::sink::ram::RamSink; hash::b3_no_self.
RO:INVARIANTS — Single writer per stream head; streams are independent.
RO:TEST HOOKS — Unit tests here; loom model covers host queueing later.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::b3_no_self;
use ron_audit::sink::{ram::RamSink, AuditSink, AuditStream};
use ron_audit::AuditRecord;
use serde_json::json;

fn mk_record(writer_id: &str, stream: &str, seq: u64, prev: &str) -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    let mut rec = AuditRecord {
        v: 1,
        ts_ms,
        writer_id: writer_id.to_string(),
        seq,
        stream: stream.to_string(),
        kind: AuditKind::IndexWrite,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("multi-writer-test".to_string()),
        attrs: json!({ "stream": stream, "seq": seq }),
        prev: prev.to_string(),
        self_hash: String::new(),
    };
    rec.self_hash = b3_no_self(&rec).expect("hash");
    rec
}

#[test]
fn per_stream_heads_are_independent() {
    let sink = RamSink::new();

    let a1 = mk_record("writer-a", "stream-a", 0, "b3:0");
    let b1 = mk_record("writer-b", "stream-b", 0, "b3:0");

    let head_a = sink.append(&a1).expect("append a1");
    let head_b = sink.append(&b1).expect("append b1");

    let state_a = sink.state("stream-a");
    let state_b = sink.state("stream-b");

    assert_eq!(state_a.seq, 0);
    assert_eq!(state_b.seq, 0);
    assert_eq!(state_a.head, head_a);
    assert_eq!(state_b.head, head_b);
    assert_ne!(
        state_a.head, state_b.head,
        "heads for distinct streams must be independent"
    );
}

#[test]
fn stream_state_is_snapshot_only() {
    let sink = RamSink::new();

    let a1 = mk_record("writer-a", "stream-a", 0, "b3:0");
    let head1 = sink.append(&a1).expect("append a1");
    let snapshot_before = sink.state("stream-a");
    assert_eq!(snapshot_before.seq, 0);
    assert_eq!(snapshot_before.head, head1);

    let a2 = mk_record("writer-a", "stream-a", 1, &head1);
    let head2 = sink.append(&a2).expect("append a2");
    let snapshot_after = sink.state("stream-a");

    assert_eq!(snapshot_after.seq, 1);
    assert_eq!(snapshot_after.head, head2);
    assert_ne!(snapshot_after.head, snapshot_before.head);
}

```

### crates/ron-audit/tests/privacy_policies.rs
<a id="crates-ron-audit-tests-privacypolicies-rs"></a>

```rust
/*!
RO:WHAT — Privacy policy hook smoke tests.
RO:WHY — SEC/GOV: ensure the hook is callable and side-effect free for now.
RO:INTERACTS — ron_audit::privacy; dto::AuditRecord.
RO:INVARIANTS — validate() must not mutate; default is allow-all.
RO:TEST HOOKS — Unit tests here; future policy logic can extend coverage.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::privacy;
use ron_audit::AuditRecord;
use serde_json::json;

fn base_record() -> AuditRecord {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "writer@test".to_string(),
        seq: 0,
        stream: "stream@test".to_string(),
        kind: AuditKind::Unknown,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("privacy-test".to_string()),
        attrs: json!({ "field": "value" }),
        prev: "b3:0".to_string(),
        self_hash: "b3:placeholder".to_string(),
    }
}

#[test]
fn privacy_validate_is_noop_for_now() {
    let rec = base_record();
    privacy::validate(&rec).expect("default privacy hook should pass");
}

```

### crates/ron-audit/tests/verify_soa.rs
<a id="crates-ron-audit-tests-verifysoa-rs"></a>

```rust
/*!
RO:WHAT — Cross-check between scalar verify_chain and verify_chain_soa.
RO:WHY — GOV/RES: ensure SoA fast path preserves scalar semantics on good and bad chains.
RO:INTERACTS — ron_audit::verify::{verify_chain, verify_chain_soa}; hash::b3_no_self; dto::AuditRecord.
RO:INVARIANTS — both paths must agree on success/failure for the same input chain.
RO:METRICS/LOGS — none; this is test-only.
RO:CONFIG — chain lengths fixed in test.
RO:SECURITY — synthetic records; no real PII or keys.
RO:TEST HOOKS — part of ron-audit unit test suite.
*/

use std::time::{SystemTime, UNIX_EPOCH};

use ron_audit::dto::{ActorRef, AuditKind, ReasonCode, SubjectRef};
use ron_audit::hash::b3_no_self;
use ron_audit::verify::{verify_chain, verify_chain_soa};
use ron_audit::AuditRecord;
use serde_json::json;

fn mk_chain(len: usize) -> Vec<AuditRecord> {
    let ts_ms = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("time went backwards")
        .as_millis() as u64;

    let mut out = Vec::with_capacity(len);

    // genesis
    let mut genesis = AuditRecord {
        v: 1,
        ts_ms,
        writer_id: "verify-soa@test".to_string(),
        seq: 0,
        stream: "verify_soa".to_string(),
        kind: AuditKind::CapIssued,
        actor: ActorRef::default(),
        subject: SubjectRef::default(),
        reason: ReasonCode("verify-soa-test".to_string()),
        attrs: json!({ "seq": 0u64 }),
        prev: "b3:0".to_string(),
        self_hash: String::new(),
    };
    genesis.self_hash = b3_no_self(&genesis).expect("hash");
    out.push(genesis);

    while out.len() < len {
        let prev = out.last().expect("non-empty");
        let mut rec = AuditRecord {
            v: 1,
            ts_ms,
            writer_id: prev.writer_id.clone(),
            seq: prev.seq + 1,
            stream: prev.stream.clone(),
            kind: AuditKind::IndexWrite,
            actor: ActorRef::default(),
            subject: SubjectRef::default(),
            reason: ReasonCode("verify-soa-test".to_string()),
            attrs: json!({ "seq": prev.seq + 1 }),
            prev: prev.self_hash.clone(),
            self_hash: String::new(),
        };
        rec.self_hash = b3_no_self(&rec).expect("hash");
        out.push(rec);
    }

    out
}

#[test]
fn soa_and_scalar_agree_on_valid_chain() {
    let chain = mk_chain(128);

    // Scalar reference over owned iterator.
    verify_chain(chain.clone().into_iter()).expect("scalar verify");

    // SoA fast path over slice.
    verify_chain_soa(&chain).expect("soa verify");
}

#[test]
fn soa_and_scalar_agree_on_tampered_chain() {
    let mut chain = mk_chain(16);

    // Tamper: break linkage between two records.
    if chain.len() > 2 {
        chain[2].prev = "b3:not-a-real-prev".to_string();
    }

    let scalar = verify_chain(chain.clone().into_iter());
    let soa = verify_chain_soa(&chain);

    assert!(
        scalar.is_err() && soa.is_err(),
        "both scalar and soa verify must fail on tampered chain"
    );
}

```



---



# ron-app-sdk

_Source: crates/ron-app-sdk/CODEBUNDLE.MD_

<!-- Generated by scripts/make_crate_codex.sh on 2025-11-16T15:35:08Z -->
# Code Bundle — `ron-app-sdk`

> Generated for review/sharing. Source of truth remains the repo.
> Skips `docs/` and all `*.md`; includes common code/config extensions.

## Table of Contents
- [crates/ron-app-sdk/.github/workflows/api-semver.yml](#crates-ron-app-sdk--github-workflows-api-semver-yml)
- [crates/ron-app-sdk/.github/workflows/ci.yml](#crates-ron-app-sdk--github-workflows-ci-yml)
- [crates/ron-app-sdk/.github/workflows/perf-guardrails.yml](#crates-ron-app-sdk--github-workflows-perf-guardrails-yml)
- [crates/ron-app-sdk/.github/workflows/render-mermaid.yml](#crates-ron-app-sdk--github-workflows-render-mermaid-yml)
- [crates/ron-app-sdk/Cargo.toml](#crates-ron-app-sdk-Cargo-toml)
- [crates/ron-app-sdk/benches/sdk_benches.rs](#crates-ron-app-sdk-benches-sdkbenches-rs)
- [crates/ron-app-sdk/examples/demo.rs](#crates-ron-app-sdk-examples-demo-rs)
- [crates/ron-app-sdk/fuzz/Cargo.toml](#crates-ron-app-sdk-fuzz-Cargo-toml)
- [crates/ron-app-sdk/fuzz/fuzz_targets/dto_roundtrip.rs](#crates-ron-app-sdk-fuzz-fuzztargets-dtoroundtrip-rs)
- [crates/ron-app-sdk/fuzz/fuzz_targets/oap_frame_parser.rs](#crates-ron-app-sdk-fuzz-fuzztargets-oapframeparser-rs)
- [crates/ron-app-sdk/rust-toolchain.toml](#crates-ron-app-sdk-rust-toolchain-toml)
- [crates/ron-app-sdk/scripts/gen_api_snapshot.sh](#crates-ron-app-sdk-scripts-genapisnapshot-sh)
- [crates/ron-app-sdk/scripts/smoke_sdk.sh](#crates-ron-app-sdk-scripts-smokesdk-sh)
- [crates/ron-app-sdk/src/cache/lru.rs](#crates-ron-app-sdk-src-cache-lru-rs)
- [crates/ron-app-sdk/src/cache/mod.rs](#crates-ron-app-sdk-src-cache-mod-rs)
- [crates/ron-app-sdk/src/config/mod.rs](#crates-ron-app-sdk-src-config-mod-rs)
- [crates/ron-app-sdk/src/config/types.rs](#crates-ron-app-sdk-src-config-types-rs)
- [crates/ron-app-sdk/src/context.rs](#crates-ron-app-sdk-src-context-rs)
- [crates/ron-app-sdk/src/errors.rs](#crates-ron-app-sdk-src-errors-rs)
- [crates/ron-app-sdk/src/idempotency.rs](#crates-ron-app-sdk-src-idempotency-rs)
- [crates/ron-app-sdk/src/lib.rs](#crates-ron-app-sdk-src-lib-rs)
- [crates/ron-app-sdk/src/metrics.rs](#crates-ron-app-sdk-src-metrics-rs)
- [crates/ron-app-sdk/src/planes/edge.rs](#crates-ron-app-sdk-src-planes-edge-rs)
- [crates/ron-app-sdk/src/planes/index.rs](#crates-ron-app-sdk-src-planes-index-rs)
- [crates/ron-app-sdk/src/planes/mailbox.rs](#crates-ron-app-sdk-src-planes-mailbox-rs)
- [crates/ron-app-sdk/src/planes/mod.rs](#crates-ron-app-sdk-src-planes-mod-rs)
- [crates/ron-app-sdk/src/planes/storage.rs](#crates-ron-app-sdk-src-planes-storage-rs)
- [crates/ron-app-sdk/src/ready.rs](#crates-ron-app-sdk-src-ready-rs)
- [crates/ron-app-sdk/src/retry.rs](#crates-ron-app-sdk-src-retry-rs)
- [crates/ron-app-sdk/src/tracing.rs](#crates-ron-app-sdk-src-tracing-rs)
- [crates/ron-app-sdk/src/transport/handle.rs](#crates-ron-app-sdk-src-transport-handle-rs)
- [crates/ron-app-sdk/src/transport/mapping.rs](#crates-ron-app-sdk-src-transport-mapping-rs)
- [crates/ron-app-sdk/src/transport/mod.rs](#crates-ron-app-sdk-src-transport-mod-rs)
- [crates/ron-app-sdk/src/types.rs](#crates-ron-app-sdk-src-types-rs)
- [crates/ron-app-sdk/tests/i_10_semver_snapshot.rs](#crates-ron-app-sdk-tests-i10semversnapshot-rs)
- [crates/ron-app-sdk/tests/i_11_no_persistence.rs](#crates-ron-app-sdk-tests-i11nopersistence-rs)
- [crates/ron-app-sdk/tests/i_12_canon_deps.rs](#crates-ron-app-sdk-tests-i12canondeps-rs)
- [crates/ron-app-sdk/tests/i_1_profile_parity.rs](#crates-ron-app-sdk-tests-i1profileparity-rs)
- [crates/ron-app-sdk/tests/i_2_caps_required.rs](#crates-ron-app-sdk-tests-i2capsrequired-rs)
- [crates/ron-app-sdk/tests/i_3_oap_bounds.rs](#crates-ron-app-sdk-tests-i3oapbounds-rs)
- [crates/ron-app-sdk/tests/i_4_content_addressing.rs](#crates-ron-app-sdk-tests-i4contentaddressing-rs)
- [crates/ron-app-sdk/tests/i_5_retries_deadlines.rs](#crates-ron-app-sdk-tests-i5retriesdeadlines-rs)
- [crates/ron-app-sdk/tests/i_6_dto_strictness.rs](#crates-ron-app-sdk-tests-i6dtostrictness-rs)
- [crates/ron-app-sdk/tests/i_7_transport_agnostic.rs](#crates-ron-app-sdk-tests-i7transportagnostic-rs)
- [crates/ron-app-sdk/tests/i_8_deadlines_everywhere.rs](#crates-ron-app-sdk-tests-i8deadlineseverywhere-rs)
- [crates/ron-app-sdk/tests/i_9_error_taxonomy.rs](#crates-ron-app-sdk-tests-i9errortaxonomy-rs)
- [crates/ron-app-sdk/tests/interop_vectors.rs](#crates-ron-app-sdk-tests-interopvectors-rs)
- [crates/ron-app-sdk/tests/prop_oap_frames.rs](#crates-ron-app-sdk-tests-propoapframes-rs)
- [crates/ron-app-sdk/tests/prop_retry_bounds.rs](#crates-ron-app-sdk-tests-propretrybounds-rs)
- [crates/ron-app-sdk/tests/support/mock_gateway.rs](#crates-ron-app-sdk-tests-support-mockgateway-rs)
- [crates/ron-app-sdk/tests/vectors/capability_example.json](#crates-ron-app-sdk-tests-vectors-capabilityexample-json)
- [crates/ron-app-sdk/tests/vectors/oap1_min_req.json](#crates-ron-app-sdk-tests-vectors-oap1minreq-json)

### crates/ron-app-sdk/.github/workflows/api-semver.yml
<a id="crates-ron-app-sdk--github-workflows-api-semver-yml"></a>

```yaml
name: api-semver
on: [pull_request]
jobs:
  semver:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: echo "public-api check scaffold"
```

### crates/ron-app-sdk/.github/workflows/ci.yml
<a id="crates-ron-app-sdk--github-workflows-ci-yml"></a>

```yaml
name: ci
on: [push, pull_request]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy
      - run: cargo fmt --all -- --check
      - run: cargo clippy -p ron-app-sdk2 -- -D warnings
      - run: cargo test -p ron-app-sdk2
```

### crates/ron-app-sdk/.github/workflows/perf-guardrails.yml
<a id="crates-ron-app-sdk--github-workflows-perf-guardrails-yml"></a>

```yaml
name: perf-guardrails
on:
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *"
jobs:
  perf:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: cargo bench -p ron-app-sdk2 || true
```

### crates/ron-app-sdk/.github/workflows/render-mermaid.yml
<a id="crates-ron-app-sdk--github-workflows-render-mermaid-yml"></a>

```yaml
name: render-mermaid
on: [push, pull_request]
jobs:
  mmdc:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm i -g @mermaid-js/mermaid-cli
      - run: |
          mkdir -p docs/diagrams
          for f in $(git ls-files 'docs/diagrams/*.mmd'); do
            out="${f%.mmd}.svg"; mmdc -i "$f" -o "$out";
          done
```

### crates/ron-app-sdk/Cargo.toml
<a id="crates-ron-app-sdk-Cargo-toml"></a>

```toml
[package]
name = "ron-app-sdk"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
description = "RustyOnions application SDK (developer-facing client for RON-CORE)."
readme = "README.md"
repository = ""
publish = false

[lib]
path = "src/lib.rs"

[features]
# Default posture: direct TLS.
default = ["tls"]

# Transport toggles (we’ll wire actual deps as we add transport code).
tls = []
tor = []

# Optional extras we’ll hook up later (metrics, PQ hybrids, etc.).
metrics = []
pq = []
pq-hybrid = []

[dependencies]
# Error handling
anyhow = { workspace = true }

# Serialization
serde = { workspace = true, features = ["derive"] }
humantime-serde = { workspace = true }

# Canonical DTOs (capabilities, content IDs, mailbox, manifests, etc.)
ron-proto = { path = "../ron-proto" }

# Binary blob helper for plane APIs (edge/storage).
bytes = { version = "1.7", default-features = false }

# Async runtime + timers (used by retry/backoff in planes).
tokio = { workspace = true, features = ["macros", "rt-multi-thread", "time"] }

# JSON parsing for storage/edge/index/mailbox responses.
serde_json = { workspace = true }

# HTTP client used by TransportHandle (TLS path, rustls-based).
reqwest = { workspace = true, features = ["rustls-tls-native-roots", "json"] }

# Byte-friendly serde adapter for edge/get responses.
serde_bytes = { version = "0.11", default-features = false }

[dev-dependencies]
# Mini HTTP server for integration tests (mock gateway).
axum = { workspace = true, features = ["http1", "json", "tokio"] }

# Content addressing check (b3:hex).
blake3 = "1.5"

# Hex encoding for BLAKE3 digest.
hex = "0.4"

[package.metadata.docs]

```

### crates/ron-app-sdk/benches/sdk_benches.rs
<a id="crates-ron-app-sdk-benches-sdkbenches-rs"></a>

```rust
// Criterion benches placeholder (scaffold).
fn main() {
    println!("benches scaffold");
}

```

### crates/ron-app-sdk/examples/demo.rs
<a id="crates-ron-app-sdk-examples-demo-rs"></a>

```rust
//! Minimal demo for ron-app-sdk.
//!
//! RO:WHAT — Tiny example that exercises config loading, readiness
//!           checks, and constructing `RonAppSdk`.
//! RO:WHY  — Gives integrators a copy-paste starting point without
//!           requiring a running Micronode/Macronode or real gateway.
//! RO:NOTE — This example does *not* perform real plane calls yet,
//!           because the default `RON_SDK_GATEWAY_ADDR` in docs is
//!           usually `https://example.invalid`. It focuses on:
//!             - config-from-env
//!             - readiness (`check_ready`)
//!             - constructing the SDK client safely.

use ron_app_sdk::{check_ready, RonAppSdk, SdkConfig};

/// Run with something like:
///
/// ```bash
/// RON_SDK_GATEWAY_ADDR="https://example.invalid" \
/// RON_SDK_TRANSPORT="tls" \
/// RON_SDK_OVERALL_TIMEOUT_MS="30000" \
/// cargo run -p ron-app-sdk --example demo
/// ```
///
/// For real usage, point `RON_SDK_GATEWAY_ADDR` at a live Micronode /
/// Macronode gateway and provide a real capability when calling the
/// plane helpers (`storage_*`, `edge_get`, `mailbox_*`, `index_resolve`).
#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // 1) Load config from environment.
    let cfg = SdkConfig::from_env()?;

    println!(
        "[demo] loaded config: transport={:?}, gateway_addr={}",
        cfg.transport, cfg.gateway_addr
    );

    // 2) Run in-process readiness check (no network I/O).
    let report = check_ready(&cfg);

    println!(
        "[demo] ready_report: config_ok={}, transport_ok={}, tor_ok={:?}, missing={:?}",
        report.config_ok, report.transport_ok, report.tor_ok, report.missing
    );

    if !report.is_ready() {
        eprintln!("[demo] SDK configuration is NOT ready; refusing to construct client");
        eprintln!("[demo] fix the above `missing` fields and try again.");
        return Ok(());
    }

    // 3) Construct the SDK client. This re-validates config and
    // prepares the internal transport handle.
    let sdk = RonAppSdk::new(cfg).await?;
    let ctx = sdk.context();

    println!(
        "[demo] SDK context: profile={:?}, amnesia={}",
        ctx.profile(),
        ctx.amnesia()
    );

    // 4) (Optional) Sketch of how plane calls will look — left as
    // comments so this example stays safe even when pointing at
    // example.invalid.
    //
    // use ron_app_sdk::types::{Capability, IdemKey};
    //
    // let cap: Capability = /* obtain from svc-passport / auth flow */;
    //
    // // Example: storage_put (with optional idempotency key)
    // let bytes = bytes::Bytes::from_static(b"hello world");
    // let idem = None::<IdemKey>;
    // let addr = sdk
    //     .storage_put(cap.clone(), bytes, std::time::Duration::from_secs(5), idem)
    //     .await?;
    // println!("[demo] stored blob at addr_b3={}", addr);
    //
    // // Example: storage_get
    // let fetched = sdk
    //     .storage_get(cap.clone(), &addr, std::time::Duration::from_secs(5))
    //     .await?;
    // println!("[demo] fetched {} bytes", fetched.len());

    println!("[demo] done (no plane calls issued)");

    Ok(())
}

```

### crates/ron-app-sdk/fuzz/Cargo.toml
<a id="crates-ron-app-sdk-fuzz-Cargo-toml"></a>

```toml
[workspace]
members = ["."]
```

### crates/ron-app-sdk/fuzz/fuzz_targets/dto_roundtrip.rs
<a id="crates-ron-app-sdk-fuzz-fuzztargets-dtoroundtrip-rs"></a>

```rust
// fuzz target placeholder: dto_roundtrip (scaffold)
fn main() {}
```

### crates/ron-app-sdk/fuzz/fuzz_targets/oap_frame_parser.rs
<a id="crates-ron-app-sdk-fuzz-fuzztargets-oapframeparser-rs"></a>

```rust
// fuzz target placeholder: oap_frame_parser (scaffold)
fn main() {}
```

### crates/ron-app-sdk/rust-toolchain.toml
<a id="crates-ron-app-sdk-rust-toolchain-toml"></a>

```toml
[toolchain]
channel = "1.80.0"
components = ["rustfmt", "clippy"]
```

### crates/ron-app-sdk/scripts/gen_api_snapshot.sh
<a id="crates-ron-app-sdk-scripts-genapisnapshot-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail
# gen_api_snapshot.sh — run cargo public-api and save to docs/api-history (scaffold)
echo "api snapshot scaffold"
```

### crates/ron-app-sdk/scripts/smoke_sdk.sh
<a id="crates-ron-app-sdk-scripts-smokesdk-sh"></a>

```bash
#!/usr/bin/env bash
set -euo pipefail

# ron-app-sdk smoke: keep this crate honest without touching the rest
# of the workspace. Intended to be fast enough to run often.

echo "[STEP] fmt + clippy + unit tests"
cargo fmt -p ron-app-sdk
cargo clippy -p ron-app-sdk --no-deps -- -D warnings
cargo test  -p ron-app-sdk --lib

# NOTE: When we add a mock gateway + integration tests, extend this
# script with a small spawn/kill harness here (see NOTES.MD).
# For beta, unit tests are our DoD.

echo "[OK] ron-app-sdk smoke passed"

```

### crates/ron-app-sdk/src/cache/lru.rs
<a id="crates-ron-app-sdk-src-cache-lru-rs"></a>

```rust
//! RO:WHAT — Tiny, std-only LRU cache (size-bounded).
//! RO:WHY  — Provide a simple building block for SDK-local caches without
//!           pulling in an external LRU crate.
//! RO:INTERACTS — Wrapped by `cache::mod` to add TTL behavior and metrics.
//! RO:INVARIANTS —
//!   - Capacity is always >= 1.
//!   - Insertion is bounded: on overflow, the least-recently-used entry
//!     is evicted.
//!   - `get` and `insert` are O(n) (small n: max_entries from config).
//! RO:METRICS — None here; outer cache may emit hit/miss counters.
//! RO:CONFIG — Capacity supplied by `CacheCfg.max_entries`.
//! RO:SECURITY — In-memory only; no persistence.
//! RO:TEST — Unit tests in this module.

use std::collections::VecDeque;

/// Very small LRU cache backed by a `VecDeque`.
///
/// This is intentionally simple and does not attempt to be maximally
/// efficient; for typical SDK cache sizes (≈1k entries) an O(n) scan
/// is sufficient and keeps the implementation easy to audit.
#[derive(Debug)]
pub struct Lru<K, V> {
    capacity: usize,
    entries: VecDeque<(K, V)>,
}

impl<K, V> Lru<K, V> {
    /// Construct a new LRU with the given capacity.
    pub fn new(capacity: usize) -> Self {
        let cap = capacity.max(1);
        Self {
            capacity: cap,
            entries: VecDeque::with_capacity(cap),
        }
    }

    /// Current number of entries in the cache.
    pub fn len(&self) -> usize {
        self.entries.len()
    }

    /// Whether the cache is empty.
    pub fn is_empty(&self) -> bool {
        self.entries.is_empty()
    }
}

impl<K, V> Lru<K, V>
where
    K: Eq,
    V: Clone,
{
    /// Get a value by key, marking it as most-recently-used.
    ///
    /// Returns a cloned value. This keeps the implementation simple and
    /// avoids lifetime juggling while still being cheap for typical V.
    pub fn get(&mut self, key: &K) -> Option<V> {
        let mut hit_index = None;

        for (idx, (k, _)) in self.entries.iter().enumerate() {
            if k == key {
                hit_index = Some(idx);
                break;
            }
        }

        let idx = hit_index?;
        let (_, v) = &self.entries[idx];
        let value = v.clone();

        // Move the entry to the back if it wasn't already there.
        if idx + 1 != self.entries.len() {
            if let Some(entry) = self.entries.remove(idx) {
                self.entries.push_back(entry);
            }
        }

        Some(value)
    }

    /// Insert or replace a value.
    ///
    /// Returns the previous value for this key, if any.
    pub fn insert(&mut self, key: K, value: V) -> Option<V> {
        // Remove existing entry if present.
        let mut old = None;
        let mut existing_index = None;

        for (idx, (k, _)) in self.entries.iter().enumerate() {
            if k == &key {
                existing_index = Some(idx);
                break;
            }
        }

        if let Some(idx) = existing_index {
            if let Some((_, v)) = self.entries.remove(idx) {
                old = Some(v);
            }
        }

        self.entries.push_back((key, value));

        // Enforce capacity.
        if self.entries.len() > self.capacity {
            let _ = self.entries.pop_front();
        }

        old
    }

    /// Remove a key from the cache, returning its value if present.
    pub fn remove(&mut self, key: &K) -> Option<V> {
        let mut index = None;
        for (idx, (k, _)) in self.entries.iter().enumerate() {
            if k == key {
                index = Some(idx);
                break;
            }
        }

        index.and_then(|idx| self.entries.remove(idx).map(|(_, v)| v))
    }
}

#[cfg(test)]
mod tests {
    use super::Lru;

    #[test]
    fn obeys_capacity_and_lru_order() {
        let mut lru = Lru::new(2);

        lru.insert("a", 1);
        lru.insert("b", 2);

        // Access "a" to make it most recent.
        assert_eq!(lru.get(&"a"), Some(1));

        // Insert "c" — should evict "b".
        lru.insert("c", 3);

        assert_eq!(lru.get(&"a"), Some(1));
        assert_eq!(lru.get(&"b"), None);
        assert_eq!(lru.get(&"c"), Some(3));
    }

    #[test]
    fn remove_works() {
        let mut lru = Lru::new(2);
        lru.insert("a", 1);
        lru.insert("b", 2);

        assert_eq!(lru.remove(&"a"), Some(1));
        assert_eq!(lru.get(&"a"), None);
        assert_eq!(lru.len(), 1);
    }
}

```

### crates/ron-app-sdk/src/cache/mod.rs
<a id="crates-ron-app-sdk-src-cache-mod-rs"></a>

```rust
//! RO:WHAT — Ephemeral TTL cache facade for SDK callers.
//! RO:WHY  — Provide a small, in-memory cache to hide repeated GETs or
//!           metadata lookups without ever touching disk (I-11 no-persistence).
//! RO:INTERACTS — Wraps `cache::lru::Lru`; driven by `CacheCfg` from config;
//!                may be used by storage/index planes later.
//! RO:INVARIANTS —
//!   - Obeys `CacheCfg.max_entries` (bounded size).
//!   - Per-entry TTL enforced on read; expired entries are evicted.
//!   - Purely in-memory, process-local; no serialization.
//! RO:METRICS — Places to hook cache hit/miss counters via `SdkMetrics`.
//! RO:CONFIG — Reads `CacheCfg { enabled, max_entries, ttl }`.
//! RO:SECURITY — Does not store secrets long-term; caller chooses what to
//!               cache. Amnesia mode may disable cache at a higher level.
//! RO:TEST — Unit tests in this module.

mod lru;

pub use lru::Lru;

use std::time::{Duration, Instant};

use crate::config::CacheCfg;

/// Internal wrapper storing value + insertion timestamp.
#[derive(Debug, Clone)]
struct Entry<V> {
    value: V,
    inserted_at: Instant,
}

impl<V> Entry<V> {
    fn new(value: V) -> Self {
        Self {
            value,
            inserted_at: Instant::now(),
        }
    }

    fn is_expired(&self, ttl: Duration) -> bool {
        self.inserted_at.elapsed() > ttl
    }
}

/// Simple TTL + size-bounded cache built on top of `Lru`.
///
/// Generic over key and value types. This is intended for relatively
/// small caches (hundreds to a few thousand entries).
#[derive(Debug)]
pub struct TtlCache<K, V> {
    cfg: CacheCfg,
    inner: Lru<K, Entry<V>>,
}

impl<K, V> TtlCache<K, V>
where
    K: Eq,
    V: Clone,
{
    /// Create a new cache from configuration.
    ///
    /// If `cfg.enabled` is false, callers should typically avoid creating
    /// the cache at all and treat this as a no-op.
    pub fn new(cfg: CacheCfg) -> Self {
        let cap = cfg.max_entries.max(1);
        Self {
            cfg,
            inner: Lru::new(cap),
        }
    }

    /// Access the underlying config.
    pub fn config(&self) -> &CacheCfg {
        &self.cfg
    }

    /// Look up a value by key, enforcing TTL.
    ///
    /// Returns `None` if the key is not present or the entry has expired.
    pub fn get(&mut self, key: &K) -> Option<V> {
        if !self.cfg.enabled {
            return None;
        }

        let ttl = self.cfg.ttl;
        if ttl.is_zero() {
            return None;
        }

        if let Some(entry) = self.inner.get(key) {
            if entry.is_expired(ttl) {
                // Evict expired entry.
                let _ = self.inner.remove(key);
                None
            } else {
                Some(entry.value)
            }
        } else {
            None
        }
    }

    /// Insert or replace a value for the given key.
    pub fn insert(&mut self, key: K, value: V) {
        if !self.cfg.enabled {
            return;
        }

        let entry = Entry::new(value);
        let _ = self.inner.insert(key, entry);
    }

    /// Remove an entry (if present).
    pub fn remove(&mut self, key: &K) {
        let _ = self.inner.remove(key);
    }

    /// Clear all entries.
    pub fn clear(&mut self) {
        // Reinitialize the LRU with the configured capacity.
        let cap = self.cfg.max_entries.max(1);
        self.inner = Lru::new(cap);
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn cfg_enabled() -> CacheCfg {
        CacheCfg {
            enabled: true,
            max_entries: 2,
            ttl: Duration::from_millis(10),
        }
    }

    #[test]
    fn respects_enabled_flag() {
        let cfg = CacheCfg {
            enabled: false,
            max_entries: 2,
            ttl: Duration::from_secs(60),
        };

        let mut cache = TtlCache::new(cfg);
        cache.insert("a", 1);
        assert_eq!(cache.get(&"a"), None);
    }

    #[test]
    fn evicts_on_ttl() {
        let cfg = cfg_enabled();
        let mut cache = TtlCache::new(cfg);

        cache.insert("a", 1);
        assert_eq!(cache.get(&"a"), Some(1));

        std::thread::sleep(Duration::from_millis(15));
        assert_eq!(cache.get(&"a"), None);
    }

    #[test]
    fn respects_capacity_lru_behavior() {
        let cfg = CacheCfg {
            enabled: true,
            max_entries: 2,
            ttl: Duration::from_secs(60),
        };

        let mut cache = TtlCache::new(cfg);

        cache.insert("a", 1);
        cache.insert("b", 2);

        // Touch "a" to make it recently used.
        assert_eq!(cache.get(&"a"), Some(1));

        // Insert "c" — should evict "b".
        cache.insert("c", 3);

        assert_eq!(cache.get(&"a"), Some(1));
        assert_eq!(cache.get(&"b"), None);
        assert_eq!(cache.get(&"c"), Some(3));
    }
}

```

### crates/ron-app-sdk/src/config/mod.rs
<a id="crates-ron-app-sdk-src-config-mod-rs"></a>

```rust
//! High-level config helpers for ron-app-sdk.
//!
//! RO:WHAT — Glue for `SdkConfig`: validation + environment loader + helpers.
//! RO:WHY  — Central place for config rules so the rest of the SDK can stay
//!           boring (just read fields).
//! RO:INTERACTS — Used by `RonAppSdk::new`, examples, and tests; reads env
//!                via `SdkConfig::from_env()`.
//! RO:INVARIANTS — No panics; invalid configs surface as errors
//!                 (`anyhow::Result`); env parsing is explicit, no silent
//!                 fallbacks.

mod types;

pub use types::{
    CacheCfg, IdemCfg, Jitter, PqMode, Redaction, RetryCfg, SdkConfig, Timeouts, TorCfg,
    TracingCfg, Transport,
};

use std::{collections::HashMap, time::Duration};

use anyhow::{anyhow, bail, Result as AnyResult};

impl SdkConfig {
    /// Validate semantic invariants for this configuration.
    ///
    /// This is called automatically from `from_env` and should also be
    /// invoked by host apps that construct configs programmatically.
    pub fn validate(&self) -> AnyResult<()> {
        if self.gateway_addr.trim().is_empty() {
            bail!("gateway_addr must not be empty");
        }

        if self.retry.max_attempts == 0 {
            bail!("retry.max_attempts must be at least 1");
        }

        if self.retry.factor < 1.0 {
            bail!("retry.factor must be >= 1.0");
        }

        if self.retry.base.is_zero() {
            bail!("retry.base must be > 0");
        }

        if self.retry.cap < self.retry.base {
            bail!("retry.cap must be >= retry.base");
        }

        if self.overall_timeout < Duration::from_secs(1) {
            bail!("overall_timeout must be >= 1s");
        }

        if self.overall_timeout < self.timeouts.read || self.overall_timeout < self.timeouts.write {
            bail!("overall_timeout must be >= read/write timeouts");
        }

        if self.cache.enabled {
            if self.cache.max_entries == 0 {
                bail!("cache.max_entries must be >= 1 when cache.enabled=true");
            }
            if self.cache.ttl < Duration::from_secs(1) {
                bail!("cache.ttl must be >= 1s when cache.enabled=true");
            }
        }

        // PQ mode + Tor reachability checks can be extended later; for now
        // we just ensure the socks address is non-empty when Tor is chosen.
        if matches!(self.transport, Transport::Tor) && self.tor.socks5_addr.trim().is_empty() {
            bail!("tor.socks5_addr must not be empty when transport=tor");
        }

        Ok(())
    }

    /// Build a config from environment variables, with safe defaults.
    ///
    /// Mapping roughly follows `docs/CONFIG.md`:
    ///
    /// - `RON_SDK_TRANSPORT`              → `transport`
    /// - `RON_SDK_GATEWAY_ADDR`           → `gateway_addr`
    /// - `RON_SDK_OVERALL_TIMEOUT_MS`     → `overall_timeout`
    /// - `RON_SDK_CONNECT_TIMEOUT_MS`     → `timeouts.connect`
    /// - `RON_SDK_READ_TIMEOUT_MS`        → `timeouts.read`
    /// - `RON_SDK_WRITE_TIMEOUT_MS`       → `timeouts.write`
    /// - `RON_SDK_RETRY_BASE_MS`          → `retry.base`
    /// - `RON_SDK_RETRY_FACTOR`           → `retry.factor`
    /// - `RON_SDK_RETRY_CAP_MS`           → `retry.cap`
    /// - `RON_SDK_RETRY_MAX_ATTEMPTS`     → `retry.max_attempts`
    /// - `RON_SDK_RETRY_JITTER`           → `retry.jitter`
    /// - `RON_SDK_IDEM_ENABLED`           → `idempotency.enabled`
    /// - `RON_SDK_IDEM_PREFIX`            → `idempotency.key_prefix`
    /// - `RON_SDK_CACHE_ENABLED`          → `cache.enabled`
    /// - `RON_SDK_CACHE_MAX_ENTRIES`      → `cache.max_entries`
    /// - `RON_SDK_CACHE_TTL_MS`           → `cache.ttl`
    /// - `RON_SDK_TRACING_SPANS`          → `tracing.spans`
    /// - `RON_SDK_TRACING_METRICS`        → `tracing.metrics`
    /// - `RON_SDK_TRACING_REDACTION`      → `tracing.redaction`
    /// - `RON_SDK_PQ_MODE`                → `pq_mode`
    /// - `RON_SDK_TOR_SOCKS5_ADDR`        → `tor.socks5_addr`
    pub fn from_env() -> AnyResult<SdkConfig> {
        // FIX: pass `std::env::vars()` directly; it already implements
        // `IntoIterator<Item = (String, String)>`.
        Self::from_env_with(std::env::vars())
    }

    /// Testable helper behind `from_env` that works off an arbitrary map.
    pub(crate) fn from_env_with<I>(vars: I) -> AnyResult<SdkConfig>
    where
        I: IntoIterator<Item = (String, String)>,
    {
        let map: HashMap<_, _> = vars.into_iter().collect();
        let get = |key: &str| map.get(key).map(String::as_str);

        let mut cfg = SdkConfig::default();

        // Transport + gateway
        if let Some(v) = get("RON_SDK_TRANSPORT") {
            cfg.transport = match v.to_ascii_lowercase().as_str() {
                "tls" => Transport::Tls,
                "tor" => Transport::Tor,
                other => {
                    return Err(anyhow!(
                        "invalid RON_SDK_TRANSPORT: {other} (expected `tls` or `tor`)"
                    ));
                }
            };
        }

        if let Some(v) = get("RON_SDK_GATEWAY_ADDR") {
            cfg.gateway_addr = v.to_string();
        }

        // Timeouts (ms)
        if let Some(v) = get("RON_SDK_OVERALL_TIMEOUT_MS") {
            cfg.overall_timeout = parse_ms("RON_SDK_OVERALL_TIMEOUT_MS", v)?;
        }

        if let Some(v) = get("RON_SDK_CONNECT_TIMEOUT_MS") {
            cfg.timeouts.connect = parse_ms("RON_SDK_CONNECT_TIMEOUT_MS", v)?;
        }

        if let Some(v) = get("RON_SDK_READ_TIMEOUT_MS") {
            cfg.timeouts.read = parse_ms("RON_SDK_READ_TIMEOUT_MS", v)?;
        }

        if let Some(v) = get("RON_SDK_WRITE_TIMEOUT_MS") {
            cfg.timeouts.write = parse_ms("RON_SDK_WRITE_TIMEOUT_MS", v)?;
        }

        // Retry
        if let Some(v) = get("RON_SDK_RETRY_BASE_MS") {
            cfg.retry.base = parse_ms("RON_SDK_RETRY_BASE_MS", v)?;
        }

        if let Some(v) = get("RON_SDK_RETRY_FACTOR") {
            cfg.retry.factor = parse_f32("RON_SDK_RETRY_FACTOR", v)?;
        }

        if let Some(v) = get("RON_SDK_RETRY_CAP_MS") {
            cfg.retry.cap = parse_ms("RON_SDK_RETRY_CAP_MS", v)?;
        }

        if let Some(v) = get("RON_SDK_RETRY_MAX_ATTEMPTS") {
            cfg.retry.max_attempts = parse_u32("RON_SDK_RETRY_MAX_ATTEMPTS", v)?;
        }

        if let Some(v) = get("RON_SDK_RETRY_JITTER") {
            cfg.retry.jitter = match v.to_ascii_lowercase().as_str() {
                "full" => Jitter::Full,
                "none" => Jitter::None,
                other => {
                    return Err(anyhow!(
                        "invalid RON_SDK_RETRY_JITTER: {other} (expected `full` or `none`)"
                    ));
                }
            };
        }

        // Idempotency
        if let Some(v) = get("RON_SDK_IDEM_ENABLED") {
            cfg.idempotency.enabled = parse_bool("RON_SDK_IDEM_ENABLED", v)?;
        }

        if let Some(v) = get("RON_SDK_IDEM_PREFIX") {
            cfg.idempotency.key_prefix = if v.is_empty() {
                None
            } else {
                Some(v.to_string())
            };
        }

        // Cache
        if let Some(v) = get("RON_SDK_CACHE_ENABLED") {
            cfg.cache.enabled = parse_bool("RON_SDK_CACHE_ENABLED", v)?;
        }

        if let Some(v) = get("RON_SDK_CACHE_MAX_ENTRIES") {
            cfg.cache.max_entries = parse_usize("RON_SDK_CACHE_MAX_ENTRIES", v)?;
        }

        if let Some(v) = get("RON_SDK_CACHE_TTL_MS") {
            cfg.cache.ttl = parse_ms("RON_SDK_CACHE_TTL_MS", v)?;
        }

        // Tracing
        if let Some(v) = get("RON_SDK_TRACING_SPANS") {
            cfg.tracing.spans = parse_bool("RON_SDK_TRACING_SPANS", v)?;
        }

        if let Some(v) = get("RON_SDK_TRACING_METRICS") {
            cfg.tracing.metrics = parse_bool("RON_SDK_TRACING_METRICS", v)?;
        }

        if let Some(v) = get("RON_SDK_TRACING_REDACTION") {
            cfg.tracing.redaction = match v.to_ascii_lowercase().as_str() {
                "safe" => Redaction::Safe,
                "none" => Redaction::None,
                other => {
                    return Err(anyhow!(
                        "invalid RON_SDK_TRACING_REDACTION: {other} (expected `safe` or `none`)"
                    ));
                }
            };
        }

        // PQ mode
        if let Some(v) = get("RON_SDK_PQ_MODE") {
            cfg.pq_mode = match v.to_ascii_lowercase().as_str() {
                "off" => PqMode::Off,
                "hybrid" => PqMode::Hybrid,
                other => {
                    return Err(anyhow!(
                        "invalid RON_SDK_PQ_MODE: {other} (expected `off` or `hybrid`)"
                    ));
                }
            };
        }

        // Tor
        if let Some(v) = get("RON_SDK_TOR_SOCKS5_ADDR") {
            cfg.tor.socks5_addr = v.to_string();
        }

        // Final semantic pass.
        cfg.validate()?;
        Ok(cfg)
    }

    /// Convenience helper for tests/examples to override a handful of fields.
    pub fn with_overrides<F>(mut self, f: F) -> SdkConfig
    where
        F: FnOnce(&mut SdkConfig),
    {
        f(&mut self);
        self
    }
}

/// Parse a boolean env value.
///
/// Accepted truthy: `1`, `true`, `yes`, `on` (case-insensitive)  
/// Accepted falsy:  `0`, `false`, `no`, `off` (case-insensitive)
fn parse_bool(key: &str, raw: &str) -> AnyResult<bool> {
    let v = raw.to_ascii_lowercase();
    match v.as_str() {
        "1" | "true" | "yes" | "on" => Ok(true),
        "0" | "false" | "no" | "off" => Ok(false),
        _ => Err(anyhow!(
            "invalid {key}: {raw} (expected boolean like true/false)"
        )),
    }
}

/// Parse an integer millisecond value.
fn parse_ms(key: &str, raw: &str) -> AnyResult<Duration> {
    let ms: u64 = raw
        .parse()
        .map_err(|e| anyhow!("invalid {key}: {raw} (expected integer ms, err={e})"))?;
    Ok(Duration::from_millis(ms))
}

fn parse_f32(key: &str, raw: &str) -> AnyResult<f32> {
    raw.parse()
        .map_err(|e| anyhow!("invalid {key}: {raw} (expected f32, err={e})"))
}

fn parse_u32(key: &str, raw: &str) -> AnyResult<u32> {
    raw.parse()
        .map_err(|e| anyhow!("invalid {key}: {raw} (expected u32, err={e})"))
}

fn parse_usize(key: &str, raw: &str) -> AnyResult<usize> {
    raw.parse()
        .map_err(|e| anyhow!("invalid {key}: {raw} (expected usize, err={e})"))
}

```

### crates/ron-app-sdk/src/config/types.rs
<a id="crates-ron-app-sdk-src-config-types-rs"></a>

```rust
//! Config data types for ron-app-sdk.
//!
//! RO:WHAT — Pure data structs/enums for SDK configuration (no I/O).
//! RO:WHY  — Keeps `mod.rs` focused on helpers and env parsing; this file
//!           is just the shape + defaults of configuration.
//! RO:INTERACTS — Re-exported by `config::mod`; consumed across planes,
//!                retry helpers, and examples.
//! RO:INVARIANTS — Serializable with `serde`; defaults are safe/hardened;
//!                 no panics or external side effects.

use std::time::Duration;

use serde::{Deserialize, Serialize};

/// Wire-protocol transport flavor: direct TLS or Tor via SOCKS5.
#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum Transport {
    /// Direct TLS over TCP (recommended default).
    Tls,
    /// Tor via SOCKS5 (arti/tor).
    Tor,
}

/// Jitter mode for exponential backoff.
#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum Jitter {
    /// Full jitter: 0..base (random applied later).
    Full,
    /// No jitter: always use the base delay.
    None,
}

/// Log redaction posture for the SDK.
#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum Redaction {
    /// Redact sensitive material where possible.
    Safe,
    /// Do not redact; more verbose but less private.
    None,
}

/// Post-quantum mode for edge → node connections.
#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum PqMode {
    Off,
    Hybrid,
}

/// Per-connection timeout knobs (excluding the global per-call deadline).
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(default)]
pub struct Timeouts {
    /// Connect timeout for establishing a new transport connection.
    #[serde(with = "humantime_serde", default = "default_connect")]
    pub connect: Duration,
    /// Read timeout on an established connection.
    #[serde(with = "humantime_serde", default = "default_read")]
    pub read: Duration,
    /// Write timeout on an established connection.
    #[serde(with = "humantime_serde", default = "default_write")]
    pub write: Duration,
}

fn default_connect() -> Duration {
    Duration::from_secs(3)
}

fn default_read() -> Duration {
    Duration::from_secs(30)
}

fn default_write() -> Duration {
    Duration::from_secs(30)
}

impl Default for Timeouts {
    fn default() -> Self {
        Self {
            connect: default_connect(),
            read: default_read(),
            write: default_write(),
        }
    }
}

/// Retry/backoff configuration.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(default)]
pub struct RetryCfg {
    /// Base delay for the first retry attempt.
    #[serde(with = "humantime_serde", default = "default_retry_base")]
    pub base: Duration,
    /// Multiplicative factor per attempt.
    #[serde(default = "default_retry_factor")]
    pub factor: f32,
    /// Cap on backoff delay.
    #[serde(with = "humantime_serde", default = "default_retry_cap")]
    pub cap: Duration,
    /// Maximum number of attempts (including the first).
    #[serde(default = "default_retry_max_attempts")]
    pub max_attempts: u32,
    /// Jitter mode.
    #[serde(default = "default_jitter")]
    pub jitter: Jitter,
}

fn default_retry_base() -> Duration {
    Duration::from_millis(100)
}

fn default_retry_factor() -> f32 {
    2.0
}

fn default_retry_cap() -> Duration {
    Duration::from_secs(5)
}

fn default_retry_max_attempts() -> u32 {
    5
}

fn default_jitter() -> Jitter {
    Jitter::Full
}

impl Default for RetryCfg {
    fn default() -> Self {
        Self {
            base: default_retry_base(),
            factor: default_retry_factor(),
            cap: default_retry_cap(),
            max_attempts: default_retry_max_attempts(),
            jitter: default_jitter(),
        }
    }
}

/// Idempotency tuning.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(default)]
pub struct IdemCfg {
    /// Whether to attach idempotency keys by default on mutations.
    #[serde(default = "default_idem_enabled")]
    pub enabled: bool,
    /// Optional key prefix to avoid PII in idempotency keys.
    pub key_prefix: Option<String>,
}

fn default_idem_enabled() -> bool {
    true
}

impl Default for IdemCfg {
    fn default() -> Self {
        Self {
            enabled: default_idem_enabled(),
            key_prefix: None,
        }
    }
}

/// In-memory client-side cache configuration.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(default)]
pub struct CacheCfg {
    /// Whether the cache is enabled at all.
    #[serde(default)]
    pub enabled: bool,
    /// Maximum number of entries in the LRU.
    #[serde(default = "default_cache_entries")]
    pub max_entries: usize,
    /// TTL for each entry.
    #[serde(with = "humantime_serde", default = "default_cache_ttl")]
    pub ttl: Duration,
}

fn default_cache_entries() -> usize {
    1024
}

fn default_cache_ttl() -> Duration {
    Duration::from_secs(30)
}

impl Default for CacheCfg {
    fn default() -> Self {
        Self {
            enabled: false,
            max_entries: default_cache_entries(),
            ttl: default_cache_ttl(),
        }
    }
}

/// Tracing and metrics toggles.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(default)]
pub struct TracingCfg {
    /// Emit span events for SDK calls.
    #[serde(default)]
    pub spans: bool,
    /// Emit Prometheus-style metrics from the SDK.
    #[serde(default)]
    pub metrics: bool,
    /// Redaction posture.
    #[serde(default = "default_redaction")]
    pub redaction: Redaction,
}

fn default_redaction() -> Redaction {
    Redaction::Safe
}

impl Default for TracingCfg {
    fn default() -> Self {
        Self {
            spans: true,
            metrics: true,
            redaction: default_redaction(),
        }
    }
}

/// Tor-specific configuration.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(default)]
pub struct TorCfg {
    /// SOCKS5 address for the local Tor daemon.
    #[serde(default = "default_tor_socks")]
    pub socks5_addr: String,
}

fn default_tor_socks() -> String {
    "127.0.0.1:9050".to_string()
}

impl Default for TorCfg {
    fn default() -> Self {
        Self {
            socks5_addr: default_tor_socks(),
        }
    }
}

/// Application-facing configuration for ron-app-sdk.
///
/// This struct is intentionally "boring": just data + serde. All env
/// parsing and validation lives in `config::mod`.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(default, deny_unknown_fields)]
pub struct SdkConfig {
    /// Transport flavor (`tls` or `tor`).
    pub transport: Transport,
    /// Base gateway address (URL or `.onion`).
    pub gateway_addr: String,
    /// Overall per-call deadline (including retries).
    #[serde(with = "humantime_serde", default = "default_overall_timeout")]
    pub overall_timeout: Duration,
    /// Per-connection timeouts.
    pub timeouts: Timeouts,
    /// Retry/backoff tuning.
    pub retry: RetryCfg,
    /// Idempotency tuning.
    pub idempotency: IdemCfg,
    /// Client-side cache tuning.
    pub cache: CacheCfg,
    /// Tracing/metrics toggles.
    pub tracing: TracingCfg,
    /// Post-quantum mode.
    pub pq_mode: PqMode,
    /// Tor-specific configuration.
    pub tor: TorCfg,
}

fn default_overall_timeout() -> Duration {
    // README.md suggests 5000 ms as the baseline.
    Duration::from_millis(5000)
}

impl Default for SdkConfig {
    fn default() -> Self {
        Self {
            transport: Transport::Tls,
            gateway_addr: "http://127.0.0.1:8080".to_string(),
            overall_timeout: default_overall_timeout(),
            timeouts: Timeouts::default(),
            retry: RetryCfg::default(),
            idempotency: IdemCfg::default(),
            cache: CacheCfg::default(),
            tracing: TracingCfg::default(),
            pq_mode: PqMode::Off,
            tor: TorCfg::default(),
        }
    }
}

```

### crates/ron-app-sdk/src/context.rs
<a id="crates-ron-app-sdk-src-context-rs"></a>

```rust
//! RO:WHAT — Lightweight SDK context metadata.
//! RO:WHY  — Give callers a tiny “who am I talking to?” view without
//!           ever branching semantics based on profile (see I-1).
//! RO:INTERACTS — Constructed in `RonAppSdk::new`, may be enriched
//!                later when we add a real handshake.
//! RO:INVARIANTS —
//!   - No behavior decisions are made based on `NodeProfile`.
//!   - `amnesia` is a *hint* surfaced to hosts, not a control plane.

/// Logical deployment profile of the remote node.
///
/// This is intentionally small and matches the high-level Micronode /
/// Macronode split in the RON-CORE blueprints.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum NodeProfile {
    /// Micronode profile (amnesia-friendly, edge-first).
    Micronode,
    /// Macronode profile (persistent overlay / services).
    Macronode,
}

/// Small, immutable view of SDK context.
///
/// Today this is constructed from configuration + (eventually) a small
/// handshake. It is **never** used to branch semantics — that’s the
/// whole point of invariant I-1 (profile parity).
#[derive(Debug, Clone, Copy)]
pub struct SdkContext {
    /// Reported/assumed node profile (Micronode/Macronode).
    pub profile: NodeProfile,
    /// Whether the remote node is currently in “amnesia mode”.
    ///
    /// For Micronodes this often maps to “RAM-only” posture; for
    /// Macronodes this may indicate a temporary override.
    pub amnesia: bool,
}

impl SdkContext {
    /// Construct a new SDK context.
    pub fn new(profile: NodeProfile, amnesia: bool) -> Self {
        Self { profile, amnesia }
    }

    /// Get the node profile (Micronode/Macronode).
    pub fn profile(&self) -> NodeProfile {
        self.profile
    }

    /// Whether the node is in amnesia posture.
    pub fn amnesia(&self) -> bool {
        self.amnesia
    }
}

```

### crates/ron-app-sdk/src/errors.rs
<a id="crates-ron-app-sdk-src-errors-rs"></a>

```rust
//! RO:WHAT — Error taxonomy for ron-app-sdk.
//! RO:WHY  — Give applications a small, stable set of error classes
//!           they can reason about (timeouts vs caps vs conflicts).
//! RO:INTERACTS — Used across all planes and the transport shim;
//!                mapping from HTTP/OAP/wire happens here.
//! RO:INVARIANTS —
//!   - Enum is `#[non_exhaustive]` per API.md.
//!   - Retry classification is centralized here (I-5/I-8).
//! RO:SECURITY — Messages are safe for logs; no secrets included.

use std::{error::Error, fmt, time::Duration};

/// Stable, non-exhaustive SDK error type.
///
/// This matches the shape laid out in `docs/API.md`. New variants may
/// be added over time, but existing ones will not be removed or
/// renamed without a SemVer bump.
#[non_exhaustive]
#[derive(Debug)]
pub enum SdkError {
    /// Overall deadline for the operation was exceeded.
    DeadlineExceeded,

    /// Underlying transport failed (TCP, DNS, etc.).
    Transport(std::io::ErrorKind),

    /// TLS handshake/verification error.
    Tls,

    /// Tor was requested but not available/usable.
    TorUnavailable,

    /// OAP/1 protocol or bounds violation (e.g., frame too large).
    OapViolation {
        /// Human-readable reason string (static).
        reason: &'static str,
    },

    /// Capability has expired (e.g., `nbf`/`exp` window).
    CapabilityExpired,

    /// Capability does not grant access to the requested resource.
    CapabilityDenied,

    /// Schema/validation error at the SDK boundary.
    ///
    /// Examples: invalid `AddrB3` string, wrong DTO shape, etc.
    SchemaViolation {
        /// Logical path (e.g., `"addr_b3"`, `"payload.body"`).
        path: String,
        /// Short description of what went wrong.
        detail: String,
    },

    /// Resource not found (404-style).
    NotFound,

    /// Conflict (409-style) — usually idempotency or version clash.
    Conflict,

    /// Rate-limited by the remote service.
    ///
    /// Optional `retry_after` allows well-behaved exponential backoff
    /// or respect for concrete `Retry-After` hints when present.
    RateLimited { retry_after: Option<Duration> },

    /// Remote server error with raw status code.
    Server(u16),

    /// Catch-all for errors that don’t fit other variants yet.
    Unknown(String),
}

/// Coarse retry classification for SDK errors.
///
/// This keeps the retry/backoff logic in one place and lets callers
/// apply their own policies if they want something fancier.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum RetryClass {
    /// Retrying *may* succeed (timeouts, 5xx, backpressure).
    Retriable,
    /// Retrying is not expected to help (caps, schema, conflicts).
    NoRetry,
}

impl SdkError {
    /// Create a schema violation error with structured fields.
    pub fn schema_violation(path: impl Into<String>, detail: impl Into<String>) -> Self {
        SdkError::SchemaViolation {
            path: path.into(),
            detail: detail.into(),
        }
    }

    /// Create a rate-limited error with optional retry hint.
    pub fn rate_limited(retry_after: Option<Duration>) -> Self {
        SdkError::RateLimited { retry_after }
    }

    /// Map an IO error into the transport bucket.
    pub fn from_io(err: std::io::Error) -> Self {
        SdkError::Transport(err.kind())
    }

    /// Classify this error for retry purposes.
    pub fn retry_class(&self) -> RetryClass {
        use RetryClass::{NoRetry, Retriable};

        match *self {
            SdkError::DeadlineExceeded => Retriable,
            SdkError::Transport(_) => Retriable,
            SdkError::RateLimited { .. } => Retriable,
            SdkError::Server(code) if (500..600).contains(&code) => Retriable,

            // Everything else we conservatively treat as non-retriable.
            SdkError::Tls
            | SdkError::TorUnavailable
            | SdkError::OapViolation { .. }
            | SdkError::CapabilityExpired
            | SdkError::CapabilityDenied
            | SdkError::SchemaViolation { .. }
            | SdkError::NotFound
            | SdkError::Conflict
            | SdkError::Server(_)
            | SdkError::Unknown(_) => NoRetry,
        }
    }

    /// Convenience helper.
    pub fn is_retriable(&self) -> bool {
        self.retry_class() == RetryClass::Retriable
    }
}

impl fmt::Display for SdkError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        use SdkError::*;

        match self {
            DeadlineExceeded => write!(f, "deadline exceeded"),
            Transport(kind) => write!(f, "transport error ({kind:?})"),
            Tls => write!(f, "TLS error"),
            TorUnavailable => write!(f, "Tor transport unavailable"),
            OapViolation { reason } => write!(f, "OAP violation: {reason}"),
            CapabilityExpired => write!(f, "capability expired"),
            CapabilityDenied => write!(f, "capability denied"),
            SchemaViolation { path, detail } => {
                write!(f, "schema violation at `{path}`: {detail}")
            }
            NotFound => write!(f, "not found"),
            Conflict => write!(f, "conflict"),
            RateLimited { retry_after } => {
                if let Some(d) = retry_after {
                    write!(f, "rate limited (retry after {d:?})")
                } else {
                    write!(f, "rate limited")
                }
            }
            Server(code) => write!(f, "server error ({code})"),
            Unknown(msg) => write!(f, "unknown error: {msg}"),
        }
    }
}

impl Error for SdkError {}

```

### crates/ron-app-sdk/src/idempotency.rs
<a id="crates-ron-app-sdk-src-idempotency-rs"></a>

```rust
//! RO:WHAT — Idempotency key derivation + header mapping helpers.
//! RO:WHY  — Give applications a deterministic, low-PII way to derive
//!           idempotency keys for “logical operations” (governance I-G1).
//! RO:INTERACTS — Uses `crate::config::IdemCfg`; will be used by planes
//!                (storage/mailbox/index) and transport wrappers.
//! RO:INVARIANTS —
//!   - Never generates two different keys for the same logical op.
//!   - Stable across process restarts (pure function of inputs).
//!   - No randomness; no dependency on wall-clock time.
//!   - No PII baked into the key string when a prefix is used.
//! RO:METRICS — None directly (planes may emit counters per idempotent call).
//! RO:CONFIG — Reads `IdemCfg { enabled, key_prefix }`.
//! RO:SECURITY — Keys are opaque 64-bit fingerprints; callers should avoid
//!               embedding raw PII into the “logical_key” input.
//! RO:TEST — Unit tests in this module (determinism + collision sanity).

use std::collections::hash_map::DefaultHasher;
use std::fmt;
use std::hash::{Hash, Hasher};

use crate::config::IdemCfg;

/// Default HTTP header name for idempotency keys.
///
/// This is a *convention*, not a hard requirement. Some hosts may
/// prefer a different header name at the gateway level.
pub const IDEMPOTENCY_HEADER: &str = "Idempotency-Key";

/// Opaque idempotency key value.
///
/// Semantically represented as a string, but we keep it wrapped so the
/// semantics remain clear and we can refine the format later without
/// breaking callers.
#[derive(Clone, PartialEq, Eq, Hash)]
pub struct IdempotencyKey(String);

impl IdempotencyKey {
    /// Access the underlying string.
    #[inline]
    pub fn as_str(&self) -> &str {
        &self.0
    }

    /// Consume and return the underlying string.
    #[inline]
    pub fn into_string(self) -> String {
        self.0
    }

    /// Convenience helper to turn this key into a `(header_name, value)` pair.
    #[inline]
    pub fn into_header(self) -> (String, String) {
        (IDEMPOTENCY_HEADER.to_string(), self.0)
    }
}

impl AsRef<str> for IdempotencyKey {
    #[inline]
    fn as_ref(&self) -> &str {
        self.as_str()
    }
}

impl fmt::Debug for IdempotencyKey {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        // Redact to avoid accidental key exposure in logs.
        f.debug_tuple("IdempotencyKey")
            .field(&"...redacted...")
            .finish()
    }
}

impl fmt::Display for IdempotencyKey {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.write_str(&self.0)
    }
}

/// Derive an idempotency key for a logical operation.
///
/// Inputs:
/// - `cfg` — idempotency configuration (enable/disable, optional prefix).
/// - `method` — logical verb (e.g., "PUT", "POST"); case-insensitive.
/// - `endpoint` — stable endpoint identifier (path or logical name).
/// - `logical_key` — caller-defined identifier for the logical op
///   (e.g., order ID, manifest ID). May be `None` for simple cases.
///
/// Returns `None` when idempotency is disabled in config.
#[allow(dead_code)] // Public helper; may be used only by SDK consumers.
pub fn derive_idempotency_key(
    cfg: &IdemCfg,
    method: &str,
    endpoint: &str,
    logical_key: Option<&str>,
) -> Option<IdempotencyKey> {
    if !cfg.enabled {
        return None;
    }

    // Normalize inputs into a single logical string.
    let method_norm = method.to_ascii_uppercase();
    let endpoint_norm = endpoint.trim();
    let logical_norm = logical_key.unwrap_or("").trim();

    let fingerprint = stable_fingerprint(&format!(
        "{}\n{}\n{}",
        method_norm, endpoint_norm, logical_norm
    ));

    // Optional prefix helps keep keys non-PII even if logical_key has
    // some user-provided content.
    let prefix = cfg.key_prefix.as_deref().unwrap_or("ron"); // short + recognizable.

    let key = format!("{prefix}_{fingerprint:016x}");
    Some(IdempotencyKey(key))
}

/// Internal helper — 64-bit stable fingerprint using the standard hasher.
///
/// This is *not* cryptographic and is not intended for security; it’s
/// just a low-collision, deterministic fingerprint for idempotency.
#[allow(dead_code)] // Only used by `derive_idempotency_key` and tests.
fn stable_fingerprint(input: &str) -> u64 {
    let mut h = DefaultHasher::new();
    input.hash(&mut h);
    h.finish()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn disabled_returns_none() {
        let cfg = IdemCfg {
            enabled: false,
            key_prefix: None,
        };
        let key = derive_idempotency_key(&cfg, "POST", "/storage/put", Some("abc"));
        assert!(key.is_none());
    }

    #[test]
    fn same_inputs_same_key() {
        let cfg = IdemCfg {
            enabled: true,
            key_prefix: Some("test".to_string()),
        };

        let a = derive_idempotency_key(&cfg, "POST", "/storage/put", Some("abc")).unwrap();
        let b = derive_idempotency_key(&cfg, "post", " /storage/put ", Some("abc")).unwrap();

        assert_eq!(a, b);
        // also assert AsRef/Display behave
        assert_eq!(a.as_ref(), b.as_str());
        assert_eq!(a.to_string(), b.to_string());
    }

    #[test]
    fn different_logical_key_changes_fingerprint() {
        let cfg = IdemCfg {
            enabled: true,
            key_prefix: Some("test".to_string()),
        };

        let a = derive_idempotency_key(&cfg, "POST", "/storage/put", Some("abc")).unwrap();
        let b = derive_idempotency_key(&cfg, "POST", "/storage/put", Some("def")).unwrap();

        assert_ne!(a, b);
    }
}

```

### crates/ron-app-sdk/src/lib.rs
<a id="crates-ron-app-sdk-src-lib-rs"></a>

```rust
#![allow(clippy::doc_lazy_continuation, clippy::doc_overindented_list_items)]
#![forbid(unsafe_code)]
//! ron-app-sdk — Application SDK for RON-CORE.
//!
//! RO:WHAT — Tiny async client façade over Micronode/Macronode node
//!           surfaces (edge, storage, mailbox, index).
//! RO:WHY  — Give apps a boring, well-typed, capability-first client
//!           with consistent retries, deadlines, and DTO hygiene.
//! RO:INTERACTS —
//!   - `config` for `SdkConfig` + env loading/validation.
//!   - `transport` for OAP/1 calls (TLS/Tor).
//!   - `planes::*` for storage/edge/mailbox/index helpers.
//!   - `metrics`/`tracing` for observability hooks.
//! RO:INVARIANTS —
//!   - All outbound calls carry a capability (I-2).
//!   - No semantic branching on `NodeProfile` (I-1).
//!   - OAP frame cap is enforced in the transport layer (I-3).

pub mod cache;
pub mod config;
mod context;
pub mod errors;
mod idempotency;
pub mod metrics;
mod ready;
mod retry;
mod tracing;
pub mod transport;
mod types;

// Planes: defined as a nested module so we can keep each plane in a
// dedicated file under `src/planes/`.
pub mod planes {
    pub mod edge;
    pub mod index;
    pub mod mailbox;
    pub mod storage;
}

pub use context::{NodeProfile, SdkContext};
pub use errors::{RetryClass, SdkError};
pub use ready::{check_ready, ReadyReport};
pub use types::{Ack, AddrB3, ByteRange, Capability, IdemKey, IndexKey, Mail, MailInbox, Receipt};

pub use config::{
    CacheCfg, IdemCfg, Jitter, PqMode, Redaction, SdkConfig, Timeouts, TorCfg, TracingCfg,
    Transport,
};

pub use metrics::{NoopSdkMetrics, SdkMetrics};

use bytes::Bytes;
use std::time::Duration;

use context::NodeProfile as CtxProfile;
use transport::TransportHandle;

/// High-level async client façade for RON-CORE nodes.
///
/// Constructed from `SdkConfig` and a (future) handshake, and then
/// used to issue calls to the various planes (storage, edge, mailbox,
/// index) with consistent deadlines/retries/error handling.
pub struct RonAppSdk {
    transport: TransportHandle,
    ctx: SdkContext,
    metrics: Box<dyn SdkMetrics>,
}

impl RonAppSdk {
    /// Create a new SDK client from configuration.
    ///
    /// This validates the config and prepares internal handles. In
    /// future revisions it may perform a light handshake to fill in
    /// `SdkContext` with accurate profile/amnesia metadata.
    pub async fn new(cfg: SdkConfig) -> Result<RonAppSdk, SdkError> {
        // Fail-closed on invalid config.
        cfg.validate()
            .map_err(|err| SdkError::schema_violation("config", err.to_string()))?;

        let transport = TransportHandle::new(cfg);
        // Until a real handshake exists, assume Micronode + non-amnesia.
        let ctx = SdkContext::new(CtxProfile::Micronode, false);

        Ok(RonAppSdk {
            transport,
            ctx,
            metrics: Box::<NoopSdkMetrics>::default(),
        })
    }

    /// Expose the SDK context (profile + amnesia hint).
    pub fn context(&self) -> SdkContext {
        self.ctx
    }

    /// Get a reference to the metrics sink.
    pub fn metrics(&self) -> &dyn SdkMetrics {
        &*self.metrics
    }

    /// Mutably access the metrics sink.
    pub fn metrics_mut(&mut self) -> &mut dyn SdkMetrics {
        &mut *self.metrics
    }

    /// Replace the metrics sink with a custom implementation.
    pub fn set_metrics<M>(&mut self, metrics: M)
    where
        M: SdkMetrics + 'static,
    {
        self.metrics = Box::new(metrics);
    }

    // -------------- Mailbox plane --------------

    /// Send a message via the mailbox plane.
    pub async fn mailbox_send(
        &self,
        cap: Capability,
        msg: Mail,
        deadline: Duration,
        idem: Option<IdemKey>,
    ) -> Result<Receipt, SdkError> {
        planes::mailbox::mailbox_send(&self.transport, &*self.metrics, cap, msg, deadline, idem)
            .await
    }

    /// Receive messages from the mailbox plane.
    pub async fn mailbox_recv(
        &self,
        cap: Capability,
        deadline: Duration,
    ) -> Result<Vec<MailInbox>, SdkError> {
        planes::mailbox::mailbox_recv(&self.transport, &*self.metrics, cap, deadline).await
    }

    /// Acknowledge mailbox messages.
    pub async fn mailbox_ack(
        &self,
        cap: Capability,
        ack: Receipt,
        deadline: Duration,
    ) -> Result<(), SdkError> {
        planes::mailbox::mailbox_ack(&self.transport, &*self.metrics, cap, ack, deadline).await
    }

    // -------------- Edge plane --------------

    /// Fetch an edge resource with an optional byte range.
    pub async fn edge_get(
        &self,
        cap: Capability,
        path: &str,
        range: Option<ByteRange>,
        deadline: Duration,
    ) -> Result<Bytes, SdkError> {
        planes::edge::edge_get(&self.transport, &*self.metrics, cap, path, range, deadline).await
    }

    // -------------- Storage plane --------------

    /// Perform a content-addressed GET from the storage plane.
    ///
    /// `addr_b3_hex` must be a `"b3:<64 hex>"` string; invalid values
    /// are reported as `SdkError::SchemaViolation`.
    pub async fn storage_get(
        &self,
        cap: Capability,
        addr_b3_hex: &str,
        deadline: Duration,
    ) -> Result<Bytes, SdkError> {
        let addr = AddrB3::parse(addr_b3_hex)
            .map_err(|err| SdkError::schema_violation("addr_b3", err.to_string()))?;

        planes::storage::storage_get(&self.transport, &*self.metrics, cap, &addr, deadline).await
    }

    /// Perform a content-addressed PUT to the storage plane.
    pub async fn storage_put(
        &self,
        cap: Capability,
        blob: Bytes,
        deadline: Duration,
        idem: Option<IdemKey>,
    ) -> Result<AddrB3, SdkError> {
        planes::storage::storage_put(&self.transport, &*self.metrics, cap, blob, deadline, idem)
            .await
    }

    // -------------- Index plane --------------

    /// Resolve a logical index key into a content address.
    pub async fn index_resolve(
        &self,
        cap: Capability,
        key: &IndexKey,
        deadline: Duration,
    ) -> Result<AddrB3, SdkError> {
        planes::index::index_resolve(&self.transport, &*self.metrics, cap, key, deadline).await
    }
}

```

### crates/ron-app-sdk/src/metrics.rs
<a id="crates-ron-app-sdk-src-metrics-rs"></a>

```rust
//! RO:WHAT — Minimal metrics facade for SDK operations.
//! RO:WHY  — Give hosts a single, stable trait they can implement using
//!           Prometheus, OpenTelemetry, or their own metrics stack.
//! RO:INTERACTS — Intended to be threaded through planes (storage/edge/
//!                mailbox/index) and caches; default impl is no-op.
//! RO:INVARIANTS —
//!   - No global state; host controls concrete implementation.
//!   - No dependency on any metrics crate (Prometheus/Otel lives outside).
//!   - Low-cardinality labels: endpoints should be path-like, not per-ID.
//! RO:METRICS — Shape only; concrete counters/histograms are defined by hosts.
//! RO:CONFIG — Typically driven by `TracingCfg.metrics` and host config.
//! RO:SECURITY — Callers should avoid using PII-heavy label values.
//! RO:TEST — Basic unit tests for the no-op implementation.

/// High-level metrics trait for SDK operations.
///
/// Host applications can implement this trait using whatever metrics
/// framework they prefer. The SDK only cares about the *shape* of the
/// metrics, not how they are exported.
pub trait SdkMetrics: Send + Sync + 'static {
    /// Observe latency of a single SDK call (in milliseconds).
    ///
    /// `endpoint` should be a low-cardinality identifier such as a path
    /// (`/storage/put`) or logical name (`storage_put`).
    fn observe_latency(&self, endpoint: &str, success: bool, latency_ms: u64);

    /// Increment the retry counter for a given endpoint.
    fn inc_retry(&self, endpoint: &str);

    /// Increment a failure counter tagged with a coarse reason.
    fn inc_failure(&self, endpoint: &str, reason: &'static str);

    /// Count cache hits for SDK-level caches (if used).
    fn inc_cache_hit(&self, endpoint: &str);

    /// Count cache misses for SDK-level caches (if used).
    fn inc_cache_miss(&self, endpoint: &str);
}

/// No-op metrics implementation (default).
///
/// This is useful for tests, examples, and hosts that do not care about
/// metrics. All methods are intentionally zero-cost.
#[derive(Debug, Default, Clone, Copy)]
pub struct NoopSdkMetrics;

impl SdkMetrics for NoopSdkMetrics {
    #[inline]
    fn observe_latency(&self, _endpoint: &str, _success: bool, _latency_ms: u64) {
        // no-op
    }

    #[inline]
    fn inc_retry(&self, _endpoint: &str) {
        // no-op
    }

    #[inline]
    fn inc_failure(&self, _endpoint: &str, _reason: &'static str) {
        // no-op
    }

    #[inline]
    fn inc_cache_hit(&self, _endpoint: &str) {
        // no-op
    }

    #[inline]
    fn inc_cache_miss(&self, _endpoint: &str) {
        // no-op
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn noop_is_send_sync_static() {
        fn assert_bounds<T: SdkMetrics>() {}
        assert_bounds::<NoopSdkMetrics>();
    }
}

```

### crates/ron-app-sdk/src/planes/edge.rs
<a id="crates-ron-app-sdk-src-planes-edge-rs"></a>

```rust
//! RO:WHAT — Edge plane helpers (GET with optional byte range).
//! RO:WHY  — Range-aware fetch with strict range validation.
//! RO:INTERACTS — transport.call_oap_json.
//! RO:INVARIANTS — deadlines > 0; ranges validated (inclusive semantics).

use std::time::{Duration, Instant};

use bytes::Bytes;

use crate::errors::SdkError;
use crate::metrics::SdkMetrics;
use crate::transport::TransportHandle;
use crate::types::{ByteRange, Capability};

// Gateway endpoint.
const EP_EDGE_GET: &str = "/edge/get";

// Metric label.
const EDGE_GET_ENDPOINT: &str = "edge_get";

// ---------- DTOs ----------

#[derive(serde::Serialize)]
struct EdgeGetReq<'a> {
    cap: &'a Capability,
    path: &'a str,
    #[serde(skip_serializing_if = "Option::is_none")]
    range: Option<EdgeRange>,
}

#[derive(serde::Serialize)]
struct EdgeRange {
    start: u64,
    end: u64, // inclusive
}

#[derive(serde::Deserialize)]
#[serde(deny_unknown_fields)]
struct EdgeGetResp {
    #[serde(with = "serde_bytes")]
    blob: Vec<u8>,
}

// ---------- API ----------

pub async fn edge_get(
    transport: &TransportHandle,
    metrics: &dyn SdkMetrics,
    cap: Capability,
    path: &str,
    range: Option<ByteRange>,
    deadline: Duration,
) -> Result<Bytes, SdkError> {
    if deadline.is_zero() {
        return Err(SdkError::schema_violation(
            "edge_get.deadline",
            "deadline must be > 0",
        ));
    }

    // Validate range if provided.
    let range_json = if let Some(r) = range {
        if r.start > r.end {
            return Err(SdkError::schema_violation(
                "edge_get.range",
                "start must be <= end (inclusive semantics)",
            ));
        }
        Some(EdgeRange {
            start: r.start,
            end: r.end,
        })
    } else {
        None
    };

    let start = Instant::now();
    let payload = EdgeGetReq {
        cap: &cap,
        path,
        range: range_json,
    };

    let raw = transport
        .call_oap_json(EP_EDGE_GET, &payload, deadline)
        .await;
    let elapsed_ms = start.elapsed().as_millis() as u64;

    match raw {
        Ok(bytes) => {
            let parsed: EdgeGetResp = serde_json::from_slice(&bytes)
                .map_err(|e| SdkError::schema_violation("edge_get.body", e.to_string()))?;
            metrics.observe_latency(EDGE_GET_ENDPOINT, true, elapsed_ms);
            Ok(Bytes::from(parsed.blob))
        }
        Err(err) => {
            metrics.observe_latency(EDGE_GET_ENDPOINT, false, elapsed_ms);
            metrics.inc_failure(EDGE_GET_ENDPOINT, classify(&err));
            Err(err)
        }
    }
}

fn classify(err: &SdkError) -> &'static str {
    use SdkError::*;
    match err {
        DeadlineExceeded => "deadline",
        Transport(_) => "transport",
        TorUnavailable => "tor",
        Tls => "tls",
        OapViolation { .. } => "oap",
        CapabilityExpired | CapabilityDenied => "capability",
        SchemaViolation { .. } => "schema",
        NotFound => "not_found",
        Conflict => "conflict",
        RateLimited { .. } => "rate_limited",
        Server(_) => "server",
        Unknown(_) => "unknown",
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn byte_range_header_format_is_inclusive() {
        let r = ByteRange { start: 0, end: 9 };
        // inclusive means length is (end - start + 1)
        assert_eq!(r.len(), 10);
    }

    #[test]
    fn byte_range_validation_accepts_well_formed_range() {
        let r = ByteRange { start: 5, end: 7 };
        assert!(r.start <= r.end);
    }

    #[test]
    fn byte_range_validation_rejects_inverted_range() {
        let r = ByteRange { start: 8, end: 7 };
        assert!(r.start > r.end);
    }
}

```

### crates/ron-app-sdk/src/planes/index.rs
<a id="crates-ron-app-sdk-src-planes-index-rs"></a>

```rust
//! RO:WHAT — Index plane helpers (logical key → AddrB3 resolve).
//! RO:WHY  — Capability-first resolve with strict schema checks.
//! RO:INTERACTS — transport.call_oap_json.
//! RO:INVARIANTS — deadlines > 0; returned address must parse as AddrB3.

use std::time::{Duration, Instant};

use crate::errors::SdkError;
use crate::metrics::SdkMetrics;
use crate::transport::TransportHandle;
use crate::types::{AddrB3, Capability, IndexKey};

// Gateway endpoint.
const EP_INDEX_RESOLVE: &str = "/index/resolve";

// Metric label.
const INDEX_RESOLVE_ENDPOINT: &str = "index_resolve";

// ---------- DTOs ----------

#[derive(serde::Serialize)]
struct ResolveReq<'a> {
    cap: &'a Capability,
    key: &'a IndexKey,
}

#[derive(serde::Deserialize)]
#[serde(deny_unknown_fields)]
struct ResolveResp {
    addr_b3: String, // "b3:<hex64>"
}

// ---------- API ----------

pub async fn index_resolve(
    transport: &TransportHandle,
    metrics: &dyn SdkMetrics,
    cap: Capability,
    key: &IndexKey,
    deadline: Duration,
) -> Result<AddrB3, SdkError> {
    if deadline.is_zero() {
        // Keep metrics trait simple for beta: just latency + failure classification.
        metrics.observe_latency(INDEX_RESOLVE_ENDPOINT, false, 0);
        metrics.inc_failure(INDEX_RESOLVE_ENDPOINT, "index_resolve.deadline");
        return Err(SdkError::schema_violation(
            "index_resolve.deadline",
            "deadline must be > 0",
        ));
    }

    let started = Instant::now();
    let payload = ResolveReq { cap: &cap, key };

    // Serialize + transport.
    let raw = transport
        .call_oap_json(EP_INDEX_RESOLVE, &payload, deadline)
        .await;
    let elapsed_ms = started.elapsed().as_millis() as u64;

    match raw {
        Ok(bytes) => {
            // Parse body.
            let parsed: ResolveResp = match serde_json::from_slice(&bytes) {
                Ok(v) => v,
                Err(e) => {
                    metrics.observe_latency(INDEX_RESOLVE_ENDPOINT, false, elapsed_ms);
                    metrics.inc_failure(INDEX_RESOLVE_ENDPOINT, "index_resolve.body");
                    return Err(SdkError::schema_violation(
                        "index_resolve.body",
                        e.to_string(),
                    ));
                }
            };

            // Validate the returned address.
            let addr = AddrB3::parse(&parsed.addr_b3).map_err(|e| {
                metrics.observe_latency(INDEX_RESOLVE_ENDPOINT, false, elapsed_ms);
                metrics.inc_failure(INDEX_RESOLVE_ENDPOINT, "index_resolve.addr");
                SdkError::schema_violation("index_resolve.addr_b3", e.to_string())
            })?;

            metrics.observe_latency(INDEX_RESOLVE_ENDPOINT, true, elapsed_ms);
            Ok(addr)
        }
        Err(err) => {
            metrics.observe_latency(INDEX_RESOLVE_ENDPOINT, false, elapsed_ms);
            metrics.inc_failure(INDEX_RESOLVE_ENDPOINT, classify(&err));
            Err(err)
        }
    }
}

fn classify(err: &SdkError) -> &'static str {
    use SdkError::*;
    match err {
        DeadlineExceeded => "deadline",
        Transport(_) => "transport",
        TorUnavailable => "tor",
        Tls => "tls",
        OapViolation { .. } => "oap",
        CapabilityExpired | CapabilityDenied => "capability",
        SchemaViolation { .. } => "schema",
        NotFound => "not_found",
        Conflict => "conflict",
        RateLimited { .. } => "rate_limited",
        Server(_) => "server",
        Unknown(_) => "unknown",
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn dummy_compile_only() {
        // Keep a tiny test so the module is exercised without needing
        // helpers from other crates.
        let _ = (INDEX_RESOLVE_ENDPOINT, EP_INDEX_RESOLVE);
    }
}

```

### crates/ron-app-sdk/src/planes/mailbox.rs
<a id="crates-ron-app-sdk-src-planes-mailbox-rs"></a>

```rust
// REPLACE ENTIRE FILE with this version
//! RO:WHAT — Mailbox plane helpers (send/recv/ack trio).
//! RO:WHY  — Provide a simple at-least-once-style interface.
//! RO:NOTE — JSON-on-OAP for this increment; retries via transport.

use std::time::{Duration, Instant};

use crate::errors::SdkError;
use crate::metrics::SdkMetrics;
use crate::transport::TransportHandle;
use crate::types::{Capability, IdemKey, Mail, MailInbox, Receipt};

const MAILBOX_SEND_ENDPOINT: &str = "mailbox_send";
const MAILBOX_RECV_ENDPOINT: &str = "mailbox_recv";
const MAILBOX_ACK_ENDPOINT: &str = "mailbox_ack";

// Wire endpoints (gateway-facing).
const EP_SEND: &str = "/mb/send";
const EP_RECV: &str = "/mb/recv";
const EP_ACK: &str = "/mb/ack";

#[derive(serde::Serialize)]
struct SendReq<'a> {
    cap: &'a Capability,
    mail: &'a Mail,
    #[serde(skip_serializing_if = "Option::is_none")]
    idem: Option<&'a str>,
}

#[derive(serde::Deserialize)]
struct SendResp {
    receipt: Receipt,
}

#[derive(serde::Serialize)]
struct RecvReq<'a> {
    cap: &'a Capability,
}

#[derive(serde::Deserialize)]
struct RecvResp {
    inbox: Vec<MailInbox>,
}

#[derive(serde::Serialize)]
struct AckReq<'a> {
    cap: &'a Capability,
    receipt: &'a Receipt,
}

pub async fn mailbox_send(
    transport: &TransportHandle,
    metrics: &dyn SdkMetrics,
    cap: Capability,
    msg: Mail,
    deadline: Duration,
    idem: Option<IdemKey>,
) -> Result<Receipt, SdkError> {
    if deadline == Duration::from_millis(0) {
        return Err(SdkError::schema_violation(
            "mailbox_send.deadline",
            "deadline must be > 0",
        ));
    }

    let start = Instant::now();
    let payload = SendReq {
        cap: &cap,
        mail: &msg,
        // FIX: borrow the inner &str via IdemKey::as_str()
        idem: idem.as_ref().map(|k| k.as_str()),
    };

    let raw = transport.call_oap_json(EP_SEND, &payload, deadline).await;
    let elapsed_ms = start.elapsed().as_millis() as u64;

    match raw {
        Ok(bytes) => {
            let parsed: SendResp = serde_json::from_slice(&bytes)
                .map_err(|e| SdkError::schema_violation("mailbox_send.body", e.to_string()))?;
            metrics.observe_latency(MAILBOX_SEND_ENDPOINT, true, elapsed_ms);
            Ok(parsed.receipt)
        }
        Err(err) => {
            metrics.observe_latency(MAILBOX_SEND_ENDPOINT, false, elapsed_ms);
            metrics.inc_failure(MAILBOX_SEND_ENDPOINT, classify(&err));
            Err(err)
        }
    }
}

pub async fn mailbox_recv(
    transport: &TransportHandle,
    metrics: &dyn SdkMetrics,
    cap: Capability,
    deadline: Duration,
) -> Result<Vec<MailInbox>, SdkError> {
    if deadline == Duration::from_millis(0) {
        return Err(SdkError::schema_violation(
            "mailbox_recv.deadline",
            "deadline must be > 0",
        ));
    }

    let start = Instant::now();
    let payload = RecvReq { cap: &cap };

    let raw = transport.call_oap_json(EP_RECV, &payload, deadline).await;
    let elapsed_ms = start.elapsed().as_millis() as u64;

    match raw {
        Ok(bytes) => {
            let parsed: RecvResp = serde_json::from_slice(&bytes)
                .map_err(|e| SdkError::schema_violation("mailbox_recv.body", e.to_string()))?;
            metrics.observe_latency(MAILBOX_RECV_ENDPOINT, true, elapsed_ms);
            Ok(parsed.inbox)
        }
        Err(err) => {
            metrics.observe_latency(MAILBOX_RECV_ENDPOINT, false, elapsed_ms);
            metrics.inc_failure(MAILBOX_RECV_ENDPOINT, classify(&err));
            Err(err)
        }
    }
}

pub async fn mailbox_ack(
    transport: &TransportHandle,
    metrics: &dyn SdkMetrics,
    cap: Capability,
    receipt: Receipt,
    deadline: Duration,
) -> Result<(), SdkError> {
    if deadline == Duration::from_millis(0) {
        return Err(SdkError::schema_violation(
            "mailbox_ack.deadline",
            "deadline must be > 0",
        ));
    }

    let start = Instant::now();
    let payload = AckReq {
        cap: &cap,
        receipt: &receipt,
    };

    let res = transport.call_oap_json(EP_ACK, &payload, deadline).await;
    let elapsed_ms = start.elapsed().as_millis() as u64;

    match res {
        Ok(_) => {
            metrics.observe_latency(MAILBOX_ACK_ENDPOINT, true, elapsed_ms);
            Ok(())
        }
        Err(err) => {
            metrics.observe_latency(MAILBOX_ACK_ENDPOINT, false, elapsed_ms);
            metrics.inc_failure(MAILBOX_ACK_ENDPOINT, classify(&err));
            Err(err)
        }
    }
}

fn classify(err: &SdkError) -> &'static str {
    use SdkError::*;
    match err {
        DeadlineExceeded => "deadline",
        Transport(_) => "transport",
        TorUnavailable => "tor",
        Tls => "tls",
        OapViolation { .. } => "oap",
        CapabilityExpired | CapabilityDenied => "capability",
        SchemaViolation { .. } => "schema",
        NotFound => "not_found",
        Conflict => "conflict",
        RateLimited { .. } => "rate_limited",
        Server(_) => "server",
        Unknown(_) => "unknown",
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::config::SdkConfig;
    use crate::metrics::NoopSdkMetrics;

    fn dummy_capability() -> Capability {
        Capability {
            subject: "test-subject".to_string(),
            scope: "test-scope".to_string(),
            issued_at: 0,
            expires_at: u64::MAX,
            caveats: Vec::new(),
        }
    }

    fn dummy_mail() -> Mail {
        Mail {
            msg_id: "msg-1".to_string(),
            to: "dest".to_string(),
            kind: "test-kind".to_string(),
            payload: Vec::new(),
            idempotency_key: None,
        }
    }

    fn dummy_receipt() -> Receipt {
        Receipt {
            msg_id: "ack-1".to_string(),
            ok: true,
            error: None,
        }
    }

    #[tokio::test]
    async fn mailbox_send_rejects_zero_deadline() {
        let transport = TransportHandle::new(SdkConfig::default());
        let metrics = NoopSdkMetrics;
        let cap = dummy_capability();
        let mail = dummy_mail();

        let err = mailbox_send(
            &transport,
            &metrics,
            cap,
            mail,
            Duration::from_millis(0),
            None,
        )
        .await
        .unwrap_err();
        match err {
            SdkError::SchemaViolation { path, .. } => assert_eq!(path, "mailbox_send.deadline"),
            other => panic!("unexpected error: {other:?}"),
        }
    }

    #[tokio::test]
    async fn mailbox_recv_rejects_zero_deadline() {
        let transport = TransportHandle::new(SdkConfig::default());
        let metrics = NoopSdkMetrics;
        let cap = dummy_capability();

        let err = mailbox_recv(&transport, &metrics, cap, Duration::ZERO)
            .await
            .unwrap_err();
        match err {
            SdkError::SchemaViolation { path, .. } => assert_eq!(path, "mailbox_recv.deadline"),
            other => panic!("unexpected error: {other:?}"),
        }
    }

    #[tokio::test]
    async fn mailbox_ack_rejects_zero_deadline() {
        let transport = TransportHandle::new(SdkConfig::default());
        let metrics = NoopSdkMetrics;
        let cap = dummy_capability();
        let receipt = dummy_receipt();

        let err = mailbox_ack(&transport, &metrics, cap, receipt, Duration::ZERO)
            .await
            .unwrap_err();
        match err {
            SdkError::SchemaViolation { path, .. } => assert_eq!(path, "mailbox_ack.deadline"),
            other => panic!("unexpected error: {other:?}"),
        }
    }
}

```

### crates/ron-app-sdk/src/planes/mod.rs
<a id="crates-ron-app-sdk-src-planes-mod-rs"></a>

```rust
//! planes/mod.rs — re-exports for edge/storage/mailbox/index (scaffold).
pub mod storage;
pub mod edge;
pub mod mailbox;
pub mod index;
```

### crates/ron-app-sdk/src/planes/storage.rs
<a id="crates-ron-app-sdk-src-planes-storage-rs"></a>

```rust
//! RO:WHAT — Storage plane helpers for content-addressed blobs.
//! RO:WHY  — Give SDK users a boring `get/put` API on top of OAP/1 and
//!           capabilities, with size caps and error taxonomy handled here.
//! RO:INTERACTS — Delegates to `TransportHandle::call_oap` and uses
//!                `SdkMetrics` for latency/failure tracking.
//! RO:INVARIANTS —
//!   - All calls require a `Capability`; no anonymous storage access.
//!   - Requests larger than `OAP_MAX_FRAME_BYTES` are rejected client-side.
//!   - Errors are surfaced as `SdkError` (no panics).
//! RO:METRICS — Uses `SdkMetrics` with low-cardinality endpoints
//!              (`"storage_get"`, `"storage_put"`).
//! RO:CONFIG — Size cap is enforced via `OAP_MAX_FRAME_BYTES`; deadlines
//!             are per-call and must be supplied by the caller.
//! RO:SECURITY — Capability header must already encode macaroon-style
//!               restrictions; we do not log capability contents.
//! RO:TEST HOOKS — Unit tests here; integration/interop tests live under
//!                  `tests/i_*` once we wire real transport.

use std::time::{Duration, Instant};

use bytes::Bytes;

use crate::errors::SdkError;
use crate::metrics::SdkMetrics;
use crate::transport::{TransportHandle, OAP_MAX_FRAME_BYTES};
use crate::types::{AddrB3, Capability};

/// Optional idempotency key type alias (from `idempotency.rs`).
pub type IdemKey = crate::idempotency::IdempotencyKey;

/// Logical metric endpoints for this plane.
const STORAGE_GET_ENDPOINT: &str = "storage_get";
const STORAGE_PUT_ENDPOINT: &str = "storage_put";

/// Fetch a blob by content ID.
///
/// Thin wrapper:
/// - Validates the deadline is non-zero.
/// - Delegates to `TransportHandle::call_oap`.
/// - Emits latency + failure metrics.
///
/// Transport currently treats `endpoint` as a logical path and maps
/// it to concrete HTTP. We use `/o/<b3>` for reads (raw bytes body).
pub async fn storage_get(
    transport: &TransportHandle,
    metrics: &dyn SdkMetrics,
    cap: Capability,
    addr: &AddrB3,
    deadline: Duration,
) -> Result<Bytes, SdkError> {
    if deadline.is_zero() {
        return Err(SdkError::schema_violation(
            "storage_get.deadline",
            "deadline must be > 0",
        ));
    }

    let start = Instant::now();
    let endpoint = format!("/o/{}", addr.as_str());

    // Capability threading is a TODO for the transport layer. For now
    // it is validated at the gateway; we avoid logging cap contents.
    let _ = cap;

    let result = transport.call_oap(&endpoint, &[], deadline).await;
    let elapsed_ms = start.elapsed().as_millis() as u64;

    match result {
        Ok(body) => {
            metrics.observe_latency(STORAGE_GET_ENDPOINT, true, elapsed_ms);
            Ok(Bytes::from(body))
        }
        Err(err) => {
            metrics.observe_latency(STORAGE_GET_ENDPOINT, false, elapsed_ms);
            metrics.inc_failure(STORAGE_GET_ENDPOINT, classify_error(&err));
            Err(err)
        }
    }
}

/// Store a blob and return its content ID (`AddrB3`).
///
/// Behavior:
/// - Rejects payloads larger than `OAP_MAX_FRAME_BYTES`.
/// - Delegates to transport (`POST /put`) returning plain-text `b3:...`.
/// - Parses/validates `AddrB3`.
/// - Emits latency + failure metrics.
///
/// Idempotency:
/// - `idem_key` is forwarded once the wire header is finalized. For now
///   it’s accepted but not yet serialized on the wire.
pub async fn storage_put(
    transport: &TransportHandle,
    metrics: &dyn SdkMetrics,
    cap: Capability,
    blob: Bytes,
    deadline: Duration,
    idem_key: Option<IdemKey>,
) -> Result<AddrB3, SdkError> {
    if deadline.is_zero() {
        return Err(SdkError::schema_violation(
            "storage_put.deadline",
            "deadline must be > 0",
        ));
    }

    // Enforce the OAP frame cap at the SDK boundary.
    if blob.len() > OAP_MAX_FRAME_BYTES {
        return Err(SdkError::OapViolation {
            reason: "payload-too-large",
        });
    }

    let start = Instant::now();
    let endpoint = "/put";

    // TODO: pass capability + idempotency key in OAP headers once the
    // client transport supports it. Keep them out of logs.
    let _ = cap;
    let _ = idem_key;

    let result = transport
        .call_oap(endpoint, blob.as_ref(), deadline)
        .await
        .and_then(|body| parse_addr_b3_from_body(&body));

    let elapsed_ms = start.elapsed().as_millis() as u64;

    match result {
        Ok(addr) => {
            metrics.observe_latency(STORAGE_PUT_ENDPOINT, true, elapsed_ms);
            Ok(addr)
        }
        Err(err) => {
            metrics.observe_latency(STORAGE_PUT_ENDPOINT, false, elapsed_ms);
            metrics.inc_failure(STORAGE_PUT_ENDPOINT, classify_error(&err));
            Err(err)
        }
    }
}

/// Try to parse an `AddrB3` from the gateway response body (plain text).
///
/// Accepts canonical `b3:<64 hex>`; returns `SchemaViolation` if the
/// body is not valid UTF-8 or not a valid address string.
fn parse_addr_b3_from_body(body: &[u8]) -> Result<AddrB3, SdkError> {
    let s = std::str::from_utf8(body).map_err(|_| {
        SdkError::schema_violation("storage_put.body", "response was not valid UTF-8")
    })?;
    let trimmed = s.trim();
    AddrB3::parse(trimmed).map_err(|_| {
        SdkError::schema_violation(
            "storage_put.body",
            "response did not contain a valid AddrB3",
        )
    })
}

/// Map an error into a coarse, low-cardinality reason string for metrics.
fn classify_error(err: &SdkError) -> &'static str {
    use crate::errors::RetryClass;
    use SdkError::*;

    match err {
        DeadlineExceeded => "deadline",
        Transport(_) => "transport",
        TorUnavailable => "tor",
        Tls => "tls",
        OapViolation { .. } => "oap",
        CapabilityExpired | CapabilityDenied => "capability",
        SchemaViolation { .. } => "schema",
        NotFound => "not_found",
        Conflict => "conflict",
        RateLimited { .. } => "rate_limited",
        Server(_) => "server",
        Unknown(_) => match err.retry_class() {
            RetryClass::Retriable => "unknown_retriable",
            RetryClass::NoRetry => "unknown_permanent",
        },
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::time::Duration;

    use bytes::Bytes;

    use crate::config::SdkConfig;
    use crate::metrics::NoopSdkMetrics;
    use crate::transport::TransportHandle;

    fn dummy_capability() -> Capability {
        Capability {
            subject: "test-subject".to_string(),
            scope: "test-scope".to_string(),
            issued_at: 0,
            expires_at: u64::MAX,
            caveats: Vec::new(),
        }
    }

    #[tokio::test]
    async fn storage_put_rejects_payload_larger_than_oap_cap() {
        let cfg = SdkConfig::default();
        let transport = TransportHandle::new(cfg);
        let metrics = NoopSdkMetrics;
        let cap = dummy_capability();

        // One byte over cap → client-side failure.
        let oversized = Bytes::from(vec![0u8; OAP_MAX_FRAME_BYTES + 1]);
        let deadline = Duration::from_secs(1);

        let err = storage_put(&transport, &metrics, cap, oversized, deadline, None)
            .await
            .expect_err("expected OapViolation for oversized payload");

        match err {
            SdkError::OapViolation { reason } => assert_eq!(reason, "payload-too-large"),
            other => panic!("expected OapViolation, got {:?}", other),
        }
    }

    #[test]
    fn parse_addr_b3_rejects_garbage() {
        let body = b"not-a-valid-b3-id";
        let err = parse_addr_b3_from_body(body).expect_err("should reject invalid CID");
        match err {
            SdkError::SchemaViolation { path, .. } => assert_eq!(path, "storage_put.body"),
            other => panic!("expected SchemaViolation, got {:?}", other),
        }
    }

    #[tokio::test]
    async fn storage_get_rejects_zero_deadline() {
        let cfg = SdkConfig::default();
        let transport = TransportHandle::new(cfg);
        let metrics = NoopSdkMetrics;
        let cap = dummy_capability();
        let addr =
            AddrB3::parse("b3:0000000000000000000000000000000000000000000000000000000000000000")
                .unwrap();

        let err = storage_get(&transport, &metrics, cap, &addr, Duration::ZERO)
            .await
            .expect_err("deadline=0 must fail");

        match err {
            SdkError::SchemaViolation { path, .. } => assert_eq!(path, "storage_get.deadline"),
            other => panic!("expected SchemaViolation, got {:?}", other),
        }
    }
}

```

### crates/ron-app-sdk/src/ready.rs
<a id="crates-ron-app-sdk-src-ready-rs"></a>

```rust
//! RO:WHAT — Lightweight readiness probe for ron-app-sdk.
//! RO:WHY  — Give hosts a simple, synchronous way to ask “is this SDK
//!           configuration plausibly usable?” without performing any
//!           network I/O.
//! RO:INTERACTS — Uses `SdkConfig::validate()` plus some direct checks
//!                on transport profile (e.g., Tor SOCKS addr).
//! RO:INVARIANTS —
//!   - Purely in-process; no sockets, no DNS.
//!   - Never panics; all issues are reflected in `missing` + flags.
//! RO:SECURITY — Does not log or expose secrets; only high-level flags.

use crate::config::{SdkConfig, Transport};

/// Readiness summary for the SDK.
///
/// This is intentionally small and boring so host applications can
/// translate it into whatever readiness surface they prefer
/// (`/readyz`, health widgets, etc.).
#[derive(Debug, Clone)]
pub struct ReadyReport {
    /// `true` if `SdkConfig::validate()` succeeded.
    pub config_ok: bool,
    /// `true` if the selected transport profile is internally consistent.
    pub transport_ok: bool,
    /// For Tor profiles, whether the SOCKS endpoint is usable at the
    /// *config* level (non-empty); `None` when transport != Tor.
    pub tor_ok: Option<bool>,
    /// High-level reasons why readiness is not yet achieved.
    ///
    /// This is intentionally coarse (e.g., "config", "tor_socks5_addr")
    /// so it can be safely surfaced in logs and UIs.
    pub missing: Vec<&'static str>,
}

impl ReadyReport {
    /// Convenience getter: overall readiness.
    ///
    /// Hosts are free to apply stricter policies, but this is a
    /// sensible default: config + transport OK and Tor (if used) OK.
    pub fn is_ready(&self) -> bool {
        self.config_ok && self.transport_ok && self.tor_ok.unwrap_or(true)
    }
}

/// Evaluate SDK readiness based on configuration alone.
///
/// This does **not** attempt any network calls, TLS handshakes, or Tor
/// reachability tests. Those belong in higher-level smoke checks. Here
/// we only ask “would it even make sense to construct a client?”
pub fn check_ready(cfg: &SdkConfig) -> ReadyReport {
    let mut missing = Vec::new();

    // 1) Config validation (semantic invariants from CONFIG.md).
    let config_ok = cfg.validate().is_ok();
    if !config_ok {
        missing.push("config");
    }

    // 2) Transport profile.
    let mut transport_ok = true;
    let mut tor_ok = None;

    match cfg.transport {
        Transport::Tls => {
            // Nothing extra to check here for now — TLS reachability lives
            // in the underlying transport (ron-transport) and smoke tests.
        }
        Transport::Tor => {
            if cfg.tor.socks5_addr.trim().is_empty() {
                transport_ok = false;
                tor_ok = Some(false);
                missing.push("tor_socks5_addr");
            } else {
                tor_ok = Some(true);
            }
        }
    }

    ReadyReport {
        config_ok,
        transport_ok,
        tor_ok,
        missing,
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::config::{
        CacheCfg, IdemCfg, Jitter, PqMode, Redaction, RetryCfg, Timeouts, TorCfg, TracingCfg,
    };
    use std::time::Duration;

    fn baseline_cfg() -> SdkConfig {
        SdkConfig {
            transport: Transport::Tls,
            gateway_addr: "https://example.invalid".to_string(),
            overall_timeout: Duration::from_secs(30),
            timeouts: Timeouts {
                connect: Duration::from_secs(5),
                read: Duration::from_secs(10),
                write: Duration::from_secs(10),
            },
            retry: RetryCfg {
                base: Duration::from_millis(100),
                factor: 2.0,
                cap: Duration::from_secs(5),
                max_attempts: 3,
                jitter: Jitter::Full,
            },
            idempotency: IdemCfg {
                enabled: true,
                key_prefix: Some("test".to_string()),
            },
            cache: CacheCfg {
                enabled: false,
                max_entries: 0,
                ttl: Duration::from_secs(0),
            },
            tracing: TracingCfg {
                spans: true,
                metrics: true,
                redaction: Redaction::Safe,
            },
            pq_mode: PqMode::Off,
            tor: TorCfg {
                socks5_addr: String::new(),
            },
        }
    }

    #[test]
    fn tls_baseline_is_ready() {
        let cfg = baseline_cfg();
        let report = check_ready(&cfg);
        assert!(report.config_ok);
        assert!(report.transport_ok);
        assert_eq!(report.tor_ok, None);
        assert!(report.is_ready());
        assert!(report.missing.is_empty());
    }

    #[test]
    fn tor_without_socks_addr_is_not_ready() {
        let mut cfg = baseline_cfg();
        cfg.transport = Transport::Tor;
        cfg.tor.socks5_addr.clear();

        let report = check_ready(&cfg);

        // This is an invalid config (Tor + empty SOCKS addr),
        // so `config_ok` should be false.
        assert!(!report.config_ok);
        assert!(!report.transport_ok);
        assert_eq!(report.tor_ok, Some(false));
        assert!(!report.is_ready());
        assert!(report.missing.contains(&"config"));
        assert!(report.missing.contains(&"tor_socks5_addr"));
    }

    #[test]
    fn tor_with_socks_addr_becomes_ready() {
        let mut cfg = baseline_cfg();
        cfg.transport = Transport::Tor;
        cfg.tor.socks5_addr = "127.0.0.1:9050".to_string();

        let report = check_ready(&cfg);
        assert!(report.config_ok);
        assert!(report.transport_ok);
        assert_eq!(report.tor_ok, Some(true));
        assert!(report.is_ready());
    }
}

```

### crates/ron-app-sdk/src/retry.rs
<a id="crates-ron-app-sdk-src-retry-rs"></a>

```rust
//! Retry and backoff helpers for ron-app-sdk.
//!
//! RO:WHAT — Exponential backoff schedule helpers driven by `RetryCfg`.
//! RO:WHY  — Central place for retry math so all planes behave consistently.
//! RO:INTERACTS — Used by edge/storage/mailbox/index planes and examples.
//! RO:INVARIANTS — Pure functions; no I/O; no sleeping; jitter kept within
//!                 bounds (currently deterministic, ready for real jitter).

use std::time::Duration;

use crate::config::{Jitter, RetryCfg};

/// Compute the base (non-jittered) delay for a given attempt index.
///
/// `attempt` is zero-based: 0 → first retry, 1 → second, etc.
pub fn base_delay(cfg: &RetryCfg, attempt: u32) -> Duration {
    if attempt == 0 {
        return cfg.base;
    }

    let factor = cfg.factor.max(1.0) as f64;
    let base_ms = cfg.base.as_millis() as f64;
    let pow = factor.powi(attempt as i32);

    let mut ms = (base_ms * pow).round();
    let cap_ms = cfg.cap.as_millis() as f64;

    if ms > cap_ms {
        ms = cap_ms;
    }

    Duration::from_millis(ms as u64)
}

/// Apply jitter to a base delay.
///
/// For now `Jitter::Full` does not introduce randomness yet; it simply
/// returns the base delay. This keeps the implementation deterministic.
/// In a later revision we can introduce true full jitter using `rand`
/// once the dependency is wired and property tests are in place.
pub fn apply_jitter(base: Duration, jitter: Jitter) -> Duration {
    match jitter {
        Jitter::None => base,
        Jitter::Full => base,
    }
}

/// Iterator over retry delays according to the given configuration.
///
/// This does **not** sleep; callers are responsible for awaiting between
/// iterations.
pub fn backoff_schedule<'a>(cfg: &'a RetryCfg) -> impl Iterator<Item = Duration> + 'a {
    (0..cfg.max_attempts).map(move |attempt| {
        let base = base_delay(cfg, attempt);
        apply_jitter(base, cfg.jitter)
    })
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn schedule_is_monotonic_and_capped() {
        let cfg = RetryCfg::default();
        let mut last = Duration::ZERO;
        for d in backoff_schedule(&cfg) {
            assert!(d >= last);
            assert!(d <= cfg.cap);
            last = d;
        }
    }
}

```

### crates/ron-app-sdk/src/tracing.rs
<a id="crates-ron-app-sdk-src-tracing-rs"></a>

```rust
//! RO:WHAT — Span/field helper utilities for SDK calls.
//! RO:WHY  — Keep span naming/redaction/correlation consistent across
//!           storage/edge/mailbox/index planes without hardwiring to
//!           any particular tracing backend.
//! RO:INTERACTS — Uses `TracingCfg` + `Redaction` from `config`; callers
//!                may translate `SpanFields` into actual `tracing` spans.
//! RO:INVARIANTS —
//!   - Does not depend on external tracing crates (pure data only).
//!   - Redaction rules centralized and testable.
//!   - Endpoint field is stable and low-cardinality (path-like).
//! RO:METRICS — None directly; fields are reused by metrics labels.
//! RO:CONFIG — Reads `TracingCfg { spans, metrics, redaction }`.
//! RO:SECURITY — Redaction mode aims to strip query strings and obvious
//!               identifiers from endpoints when `Redaction::Safe`.
//! RO:TEST — Unit tests for redaction + field shaping.

use std::borrow::Cow;
use std::time::Duration;

use crate::config::{Redaction, TracingCfg};

/// Data model for span fields that SDK callers may attach to a tracing span.
///
/// This keeps the *shape* of our tracing consistent without forcing a
/// particular tracing backend into the SDK crate.
#[allow(dead_code)] // Public DTO; may be constructed only by hosts.
#[derive(Debug, Clone)]
pub struct SpanFields<'a> {
    /// Stable endpoint identifier (e.g., `/storage/put`).
    pub endpoint: Cow<'a, str>,
    /// Retry attempt number (0 == first attempt).
    pub attempt: u32,
    /// Deadline in milliseconds from "now" when the call started.
    pub deadline_ms: u64,
    /// Optional correlation ID propagated from the caller.
    pub corr_id: Option<Cow<'a, str>>,
}

/// Convenience function to build span fields for an SDK call.
///
/// Callers can use this to populate a `tracing::Span`, log entry, or
/// metrics label set; the SDK itself remains backend-agnostic.
#[allow(dead_code)] // Public helper; may be used only by SDK consumers.
pub fn build_span_fields<'a>(
    cfg: &TracingCfg,
    endpoint: &'a str,
    attempt: u32,
    overall_deadline: Duration,
    corr_id: Option<&'a str>,
) -> Option<SpanFields<'a>> {
    if !cfg.spans {
        // Spans disabled at config level — callers can short-circuit.
        return None;
    }

    let endpoint_field = match cfg.redaction {
        Redaction::Safe => redact_endpoint(endpoint),
        Redaction::None => Cow::Borrowed(endpoint),
    };

    let deadline_ms = overall_deadline.as_millis() as u64;
    let corr_field = corr_id.map(|v| Cow::Owned(v.to_string()));

    Some(SpanFields {
        endpoint: endpoint_field,
        attempt,
        deadline_ms,
        corr_id: corr_field,
    })
}

/// Apply a conservative redaction policy to endpoint strings.
///
/// Current policy:
/// - Strip query strings (`?…`).
/// - Collapse multiple consecutive slashes.
/// - Leave path segments untouched (gateway should avoid PII in paths).
#[allow(dead_code)] // Used by `build_span_fields` and tests.
fn redact_endpoint(raw: &str) -> Cow<'_, str> {
    let mut s = raw;

    if let Some(idx) = raw.find('?') {
        s = &raw[..idx];
    }

    // Simple collapse of "//" → "/" to avoid noisy paths.
    if s.contains("//") {
        let collapsed = s
            .split('/')
            .filter(|seg| !seg.is_empty())
            .collect::<Vec<_>>()
            .join("/");
        Cow::Owned(format!("/{}", collapsed))
    } else {
        Cow::Borrowed(s)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn spans_disabled_returns_none() {
        let cfg = TracingCfg {
            spans: false,
            metrics: true,
            redaction: Redaction::Safe,
        };

        let out = build_span_fields(&cfg, "/storage/put", 0, Duration::from_millis(5000), None);
        assert!(out.is_none());
    }

    #[test]
    fn strips_query_and_collapses_slashes() {
        let cfg = TracingCfg {
            spans: true,
            metrics: true,
            redaction: Redaction::Safe,
        };

        let out = build_span_fields(
            &cfg,
            "/storage//put?id=123&foo=bar",
            0,
            Duration::from_millis(1000),
            None,
        )
        .unwrap();

        // Query stripped, duplicate slash collapsed.
        assert_eq!(out.endpoint.as_ref(), "/storage/put");
    }

    #[test]
    fn redaction_none_keeps_query() {
        let cfg = TracingCfg {
            spans: true,
            metrics: true,
            redaction: Redaction::None,
        };

        let out = build_span_fields(
            &cfg,
            "/storage/put?id=123",
            0,
            Duration::from_millis(1000),
            None,
        )
        .unwrap();

        // With `Redaction::None`, endpoint is preserved verbatim.
        assert_eq!(out.endpoint.as_ref(), "/storage/put?id=123");
    }
}

```

### crates/ron-app-sdk/src/transport/handle.rs
<a id="crates-ron-app-sdk-src-transport-handle-rs"></a>

```rust
//! RO:WHAT — Transport handle + retry wrapper for ron-app-sdk.
//! RO:WHY  — Central place to enforce OAP/1 limits (1 MiB max frame)
//!           and apply per-call deadlines/retries, independent of
//!           concrete transport flavor (TLS/Tor).
//! RO:INTERACTS — Uses crate::config::{SdkConfig, Transport},
//!                crate::errors::{SdkError, RetryClass},
//!                crate::retry::backoff_schedule, and reqwest for HTTPS;
//!                called by planes::{storage, edge, mailbox, index}.
//! RO:INVARIANTS — client-only (no listeners); no lock across `.await`;
//!                 OAP_MAX_FRAME_BYTES enforced before network I/O;
//!                 outer deadlines respected including backoff sleeps.
//! RO:METRICS — planes record metrics around these calls; this module
//!              itself is metric-agnostic.
//! RO:CONFIG — reads SdkConfig.transport/gateway_addr/overall_timeout/
//!             timeouts/retry.
//! RO:SECURITY — TLS verification delegated to reqwest+rustls;
//!               capability headers/payloads are supplied by planes;
//!               no secrets logged here.
//! RO:TEST — local unit tests for size/deadline behavior; integration
//!           invariants in `tests/i_3_oap_bounds.rs` and
//!           `tests/i_5_retries_deadlines.rs` once fully wired.

use std::{cmp, time::Duration};

use tokio::time::{sleep, Instant};

use crate::config::{SdkConfig, Transport as TransportKind};
use crate::errors::{RetryClass, SdkError};
use crate::retry::backoff_schedule;

use super::mapping::{map_http_status, map_reqwest_error};

/// Hard OAP/1 frame size cap (1 MiB).
///
/// Callers must ensure no single OAP DATA frame ever exceeds this
/// size. The transport adapter enforces this before any network I/O
/// is attempted, so oversized payloads fail fast client-side.
pub const OAP_MAX_FRAME_BYTES: usize = 1024 * 1024;

/// Opaque handle for SDK transport.
///
/// For now this wraps `SdkConfig` and builds a `reqwest::Client`
/// per-call. Once we wire in a richer OAP client or connection
/// pooling, this type is where that will live.
#[derive(Debug, Clone)]
pub struct TransportHandle {
    cfg: SdkConfig,
}

impl TransportHandle {
    /// Construct a new handle from configuration.
    ///
    /// This is intentionally infallible so that `RonAppSdk::new` can
    /// stay simple; any construction errors for the underlying HTTP
    /// client are surfaced at call time as `SdkError`.
    pub fn new(cfg: SdkConfig) -> Self {
        Self { cfg }
    }

    /// Access the underlying configuration.
    pub fn config(&self) -> &SdkConfig {
        &self.cfg
    }

    /// Convenience: serialize `value` as JSON and send via OAP POST.
    ///
    /// This helper centralizes JSON encoding so planes can remain thin.
    pub async fn call_oap_json<T: serde::Serialize>(
        &self,
        endpoint: &str,
        value: &T,
        deadline: Duration,
    ) -> Result<Vec<u8>, SdkError> {
        let body = serde_json::to_vec(value)
            .map_err(|e| SdkError::Unknown(format!("json encode failed: {e}")))?;
        self.call_oap(endpoint, &body, deadline).await
    }

    /// Perform a single low-level OAP request over the configured transport.
    ///
    /// This method:
    /// - Enforces `OAP_MAX_FRAME_BYTES` at the SDK boundary.
    /// - Honors `SdkConfig::transport` (currently: TLS only; Tor is
    ///   fail-fast with `SdkError::TorUnavailable`).
    /// - Clamps the per-call `deadline` by `SdkConfig::overall_timeout`.
    /// - Maps HTTP status codes + reqwest errors into `SdkError`.
    ///
    /// It does **not** perform retries; see `call_oap_with_retry` for
    /// the higher-level wrapper that uses `RetryCfg` + `RetryClass`.
    pub async fn call_oap(
        &self,
        endpoint: &str,
        payload: &[u8],
        deadline: Duration,
    ) -> Result<Vec<u8>, SdkError> {
        // Enforce OAP/1 max frame cap at SDK boundary.
        if payload.len() > OAP_MAX_FRAME_BYTES {
            return Err(SdkError::OapViolation {
                reason: "oap payload exceeds OAP_MAX_FRAME_BYTES (1 MiB)",
            });
        }

        // Tor transport is not wired yet; fail-fast with a stable error.
        if matches!(self.cfg.transport, TransportKind::Tor) {
            return Err(SdkError::TorUnavailable);
        }

        // Clamp the per-call deadline by the config-level overall timeout.
        let cfg_deadline = self.cfg.overall_timeout;
        let effective_deadline = cmp::min(deadline, cfg_deadline);
        if effective_deadline.is_zero() {
            return Err(SdkError::DeadlineExceeded);
        }

        // Build the full URL: <gateway_addr>/<endpoint>.
        let base = self.cfg.gateway_addr.trim_end_matches('/');
        let path = endpoint.trim_start_matches('/');
        let url = format!("{base}/{path}");

        // Minimal HTTP client; we keep it per-call for now to keep
        // `TransportHandle::new` infallible. We can pool this later.
        let client = reqwest::Client::builder()
            .connect_timeout(self.cfg.timeouts.connect)
            .timeout(effective_deadline)
            .build()
            .map_err(map_reqwest_error)?;

        let resp = client
            .post(&url)
            .body(payload.to_vec())
            .send()
            .await
            .map_err(map_reqwest_error)?;

        let status = resp.status();

        if !status.is_success() {
            // Extract Retry-After if present (for 429).
            let retry_after = if status == reqwest::StatusCode::TOO_MANY_REQUESTS {
                resp.headers()
                    .get(reqwest::header::RETRY_AFTER)
                    .and_then(|v| v.to_str().ok())
                    .and_then(|s| s.parse::<u64>().ok())
                    .map(Duration::from_secs)
            } else {
                None
            };

            return Err(map_http_status(status, retry_after));
        }

        let body = resp.bytes().await.map_err(map_reqwest_error)?;
        Ok(body.to_vec())
    }

    /// Perform an OAP request with retries and deadline awareness.
    ///
    /// Behavior:
    /// - Uses `RetryCfg` from `SdkConfig` to drive exponential backoff.
    /// - Uses `SdkError::retry_class()` to decide which failures are
    ///   safe to retry.
    /// - Enforces an **outer** deadline equal to
    ///   `min(deadline, overall_timeout)`, including sleep.
    /// - Respects `max_attempts` (including the initial attempt).
    ///
    /// This is the helper that plane modules should normally call.
    pub async fn call_oap_with_retry(
        &self,
        endpoint: &str,
        payload: &[u8],
        deadline: Duration,
    ) -> Result<Vec<u8>, SdkError> {
        let outer_deadline = cmp::min(deadline, self.cfg.overall_timeout);
        if outer_deadline.is_zero() {
            return Err(SdkError::DeadlineExceeded);
        }

        let start = Instant::now();
        let retry_cfg = &self.cfg.retry;

        // Attempt 0 is the initial attempt (no backoff before it).
        let mut attempt: u32 = 0;

        loop {
            let elapsed = start.elapsed();
            if elapsed >= outer_deadline {
                return Err(SdkError::DeadlineExceeded);
            }

            let remaining = outer_deadline.saturating_sub(elapsed);

            match self.call_oap(endpoint, payload, remaining).await {
                Ok(bytes) => return Ok(bytes),
                Err(err) => {
                    // If this isn't retriable, bail immediately.
                    if !matches!(err.retry_class(), RetryClass::Retriable) {
                        return Err(err);
                    }

                    // `max_attempts` is total attempts including the first.
                    let max_attempts = if retry_cfg.max_attempts == 0 {
                        1
                    } else {
                        retry_cfg.max_attempts
                    };

                    // We've already done `attempt + 1` attempts (initial + retries so far).
                    if attempt + 1 >= max_attempts {
                        return Err(err);
                    }

                    // Compute backoff for this retry attempt.
                    let delay = backoff_schedule(retry_cfg)
                        .nth(attempt as usize)
                        .unwrap_or(retry_cfg.cap);

                    let sleep_dur = cmp::min(delay, outer_deadline.saturating_sub(start.elapsed()));

                    if !sleep_dur.is_zero() {
                        sleep(sleep_dur).await;
                    }
                    attempt += 1;
                }
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::config::{
        CacheCfg, IdemCfg, PqMode, RetryCfg, SdkConfig, Timeouts, TorCfg, TracingCfg,
        Transport as TransportKind,
    };

    fn dummy_config() -> SdkConfig {
        SdkConfig {
            transport: TransportKind::Tls,
            gateway_addr: "http://127.0.0.1:8080".to_string(),
            overall_timeout: Duration::from_millis(5000),
            timeouts: Timeouts::default(),
            retry: RetryCfg::default(),
            idempotency: IdemCfg::default(),
            cache: CacheCfg::default(),
            tracing: TracingCfg::default(),
            pq_mode: PqMode::Off,
            tor: TorCfg::default(),
        }
    }

    /// Oversized payloads must fail fast without network I/O.
    #[tokio::test]
    async fn rejects_payload_larger_than_oap_cap() {
        let cfg = dummy_config();
        let handle = TransportHandle::new(cfg);
        let payload = vec![0u8; OAP_MAX_FRAME_BYTES + 1];

        let res = handle
            .call_oap("healthz", &payload, Duration::from_secs(1))
            .await;

        assert!(matches!(res, Err(SdkError::OapViolation { .. })));
    }

    /// Zero deadlines must be rejected up front.
    #[tokio::test]
    async fn deadline_zero_fails_fast() {
        let cfg = dummy_config();
        let handle = TransportHandle::new(cfg);
        let payload: [u8; 0] = [];

        let res = handle.call_oap("healthz", &payload, Duration::ZERO).await;

        assert!(matches!(res, Err(SdkError::DeadlineExceeded)));
    }

    /// Outer deadline should stop retries rather than looping forever.
    #[tokio::test]
    async fn outer_deadline_limits_retries() {
        let mut cfg = dummy_config();
        cfg.overall_timeout = Duration::from_millis(10);
        cfg.retry.max_attempts = 10;
        let handle = TransportHandle::new(cfg);

        let payload: [u8; 0] = [];
        let res = handle
            .call_oap_with_retry("healthz", &payload, Duration::ZERO)
            .await;

        assert!(matches!(res, Err(SdkError::DeadlineExceeded)));
    }
}

```

### crates/ron-app-sdk/src/transport/mapping.rs
<a id="crates-ron-app-sdk-src-transport-mapping-rs"></a>

```rust
//! RO:WHAT — HTTP / reqwest → SdkError mapping helpers.
//! RO:WHY  — Keep `TransportHandle` focused on deadlines/backoff and
//!           centralize wire-to-taxonomy mapping here.
//! RO:INTERACTS — Used only from `transport::handle`; consults
//!                `crate::errors::SdkError` and reqwest error/status APIs.
//! RO:INVARIANTS — never panic; unknown statuses/errors become
//!                 `SdkError::Unknown` with human-readable message;
//!                 timeouts map to `Transport(std::io::ErrorKind::TimedOut)`.
//! RO:METRICS — none directly; higher layers may aggregate by error type.
//! RO:CONFIG — none (pure helpers).
//! RO:SECURITY — messages are safe for logs; no secrets included.
//! RO:TEST — local unit tests for representative mappings.

use std::{io::ErrorKind, time::Duration};

use crate::errors::SdkError;

/// Map an HTTP status code into the stable `SdkError` taxonomy.
///
/// This follows the mapping table in `ALL_DOCS.md` (error taxonomy
/// section) so that callers can rely on consistent semantics across
/// transports and services.
pub(crate) fn map_http_status(
    status: reqwest::StatusCode,
    retry_after: Option<Duration>,
) -> SdkError {
    use reqwest::StatusCode;

    match status {
        StatusCode::NOT_FOUND => SdkError::NotFound,
        StatusCode::CONFLICT => SdkError::Conflict,
        StatusCode::UNAUTHORIZED => SdkError::CapabilityExpired,
        StatusCode::FORBIDDEN => SdkError::CapabilityDenied,
        StatusCode::TOO_MANY_REQUESTS => SdkError::RateLimited { retry_after },
        s if s.is_server_error() => SdkError::Server(s.as_u16()),
        s => SdkError::Unknown(format!("unexpected http status: {s}")),
    }
}

/// Map reqwest errors into the stable `SdkError` taxonomy.
///
/// We deliberately distinguish transport-level timeouts and generic
/// I/O failures from "overall deadline exceeded", which is handled
/// explicitly in the retry wrapper.
pub(crate) fn map_reqwest_error(err: reqwest::Error) -> SdkError {
    if err.is_timeout() {
        return SdkError::Transport(ErrorKind::TimedOut);
    }

    // Heuristic TLS detection based on error text; the underlying
    // `reqwest`/`rustls` error types are not stable across versions.
    let msg = err.to_string();
    let lower = msg.to_lowercase();
    if lower.contains("tls") || lower.contains("certificate") || lower.contains("ssl") {
        return SdkError::Tls;
    }

    if err.is_connect() || err.is_request() || err.is_body() {
        return SdkError::Transport(ErrorKind::Other);
    }

    SdkError::Unknown(msg)
}

#[cfg(test)]
mod tests {
    use super::*;
    use reqwest::StatusCode;

    #[test]
    fn http_status_mapping_basic() {
        assert!(matches!(
            map_http_status(StatusCode::NOT_FOUND, None),
            SdkError::NotFound
        ));
        assert!(matches!(
            map_http_status(StatusCode::CONFLICT, None),
            SdkError::Conflict
        ));
        assert!(matches!(
            map_http_status(StatusCode::TOO_MANY_REQUESTS, Some(Duration::from_secs(1))),
            SdkError::RateLimited { .. }
        ));
        assert!(matches!(
            map_http_status(StatusCode::INTERNAL_SERVER_ERROR, None),
            SdkError::Server(500)
        ));
    }
}

```

### crates/ron-app-sdk/src/transport/mod.rs
<a id="crates-ron-app-sdk-src-transport-mod-rs"></a>

```rust
//! RO:WHAT — Transport module root for ron-app-sdk.
//! RO:WHY  — Split the transport adapter into smaller focused files
//!           (handle + HTTP/error mapping) while keeping a stable API.
//! RO:INTERACTS — crate::config, crate::errors, crate::retry; used by
//!                plane modules (storage, edge, mailbox, index).
//! RO:INVARIANTS — client-only; no server/listener code; all outbound
//!                 calls go through `TransportHandle`; OAP frame cap
//!                 re-exported as `OAP_MAX_FRAME_BYTES`.
//! RO:METRICS — metrics are recorded in planes; this module stays
//!              metric-agnostic.
//! RO:CONFIG — reads SdkConfig fields (transport, gateway_addr,
//!             overall_timeout, timeouts, retry) via `TransportHandle`.
//! RO:SECURITY — TLS/Tor configuration only; macaroon capabilities are
//!               handled at higher layers (planes).
//! RO:TEST — unit tests live in submodules; integration tests under
//!           `tests/i_*` exercise invariants end-to-end.

mod handle;
mod mapping;

pub use handle::{TransportHandle, OAP_MAX_FRAME_BYTES};

```

### crates/ron-app-sdk/src/types.rs
<a id="crates-ron-app-sdk-src-types-rs"></a>

```rust
//! RO:WHAT — Public DTO surface for ron-app-sdk.
//! RO:WHY  — One stable place to import capability, content IDs,
//!           mailbox DTOs, and SDK-local aliases, without depending
//!           on `ron-proto` directly.
//! RO:INTERACTS — Re-exports canonical DTOs from `ron-proto` and
//!                aliases SDK types like `IdemKey`.
//! RO:INVARIANTS — DTOs remain pure data; no I/O or crypto.
//! RO:SECURITY — Capability is a header DTO only; verification lives
//!               in services like ron-auth.

use crate::idempotency::IdempotencyKey;

// Re-export canonical DTOs from `ron-proto`.
#[allow(unused_imports)] // Intentionally surfaced for callers even if not used here yet.
pub use ron_proto::{
    Ack as MailboxAck, // canonical mailbox receipt
    CapTokenHdr,       // capability header (macaroon-style)
    ContentId,         // BLAKE3 content address
    ManifestV1,        // exposed for future SDK callers
    NameRef,           // index key (logical name/alias)
    Recv as MailboxRecv,
    Send as MailboxSend,
};

/// Capability token header (macaroon-style claims, no signature).
pub type Capability = CapTokenHdr;

/// Canonical BLAKE3 content address used by storage/index planes.
pub type AddrB3 = ContentId;

/// Logical index key used by the index plane.
pub type IndexKey = NameRef;

/// SDK-level alias for idempotency keys (SDK-owned type).
pub type IdemKey = IdempotencyKey;

/// Mail payload used when *sending* via the mailbox plane.
pub type Mail = MailboxSend;

/// Mail payload delivered when *receiving* from the mailbox plane.
pub type MailInbox = MailboxRecv;

/// Receipt/acknowledgement from mailbox operations (canonical name).
pub type Receipt = MailboxAck;

/// Short alias matching the docs (`Ack`).
pub type Ack = Receipt;

/// Byte range used by the edge plane (inclusive start, inclusive end).
///
/// Defined locally so the SDK doesn’t depend on svc-edge.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct ByteRange {
    /// Start offset.
    pub start: u64,
    /// End offset (inclusive).
    pub end: u64,
}

impl ByteRange {
    /// Inclusive length; `{ start: 0, end: 9 }` → `10`.
    pub fn len(&self) -> u64 {
        self.end.saturating_sub(self.start) + 1
    }

    /// Returns true if the range is logically empty.
    ///
    /// In normal usage, ranges should be validated so `start <= end`;
    /// this treats any inverted range as empty to satisfy the usual
    /// `len`/`is_empty` contract.
    pub fn is_empty(&self) -> bool {
        self.end < self.start
    }
}

#[cfg(test)]
mod tests {
    use super::ByteRange;

    #[test]
    fn byte_range_len_is_inclusive() {
        let r = ByteRange { start: 0, end: 9 };
        assert_eq!(r.len(), 10);
    }

    #[test]
    fn byte_range_is_empty_for_inverted_ranges() {
        let r = ByteRange { start: 10, end: 5 };
        assert!(r.is_empty());
    }
}

```

### crates/ron-app-sdk/tests/i_10_semver_snapshot.rs
<a id="crates-ron-app-sdk-tests-i10semversnapshot-rs"></a>

```rust
// Invariant: public API snapshot honored (scaffold).
#[test]
fn i_10_semver_snapshot_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/i_11_no_persistence.rs
<a id="crates-ron-app-sdk-tests-i11nopersistence-rs"></a>

```rust
// Invariant: no on-disk persistence (scaffold).
#[test]
fn i_11_no_persistence_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/i_12_canon_deps.rs
<a id="crates-ron-app-sdk-tests-i12canondeps-rs"></a>

```rust
// Invariant: workspace pins / canon deps (scaffold).
#[test]
fn i_12_canon_deps_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/i_1_profile_parity.rs
<a id="crates-ron-app-sdk-tests-i1profileparity-rs"></a>

```rust
// Invariant: profile parity across transports (scaffold).
#[test]
fn i_1_profile_parity_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/i_2_caps_required.rs
<a id="crates-ron-app-sdk-tests-i2capsrequired-rs"></a>

```rust
// Invariant: capabilities required on mutations (scaffold).
#[test]
fn i_2_caps_required_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/i_3_oap_bounds.rs
<a id="crates-ron-app-sdk-tests-i3oapbounds-rs"></a>

```rust
// Invariant: OAP/1 frame cap <= 1 MiB (scaffold).
#[test]
fn i_3_oap_bounds_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/i_4_content_addressing.rs
<a id="crates-ron-app-sdk-tests-i4contentaddressing-rs"></a>

```rust
//! I-4 — Content-addressing roundtrip against a mock gateway.
//!
//! RO:WHAT — Spins up a tiny Axum server that exposes just enough of the
//!           gateway surface for `storage_put` / `storage_get` to work.
//! RO:WHY  — Proves the SDK can:
//!             - speak OAP over HTTP to a gateway-like surface,
//!             - roundtrip blobs via content-addressed IDs (`b3:<hex>`),
//!             - honour the `SdkConfig` / `Transport` wiring.
//! RO:INVARIANTS —
//!   - Address format is `b3:<64 hex>`.
//!   - Returned digest matches `blake3(blob)`.
//!   - `storage_get` returns the exact blob we stored.

use std::{
    collections::HashMap,
    net::SocketAddr,
    sync::{Arc, Mutex},
    time::Duration,
};

use axum::{
    body::Bytes as BodyBytes,
    extract::{Path, State},
    http::StatusCode,
    routing::post,
    Router,
};
use bytes::Bytes;
use tokio::net::TcpListener;

use blake3;
use hex;

use ron_app_sdk::{check_ready, Capability, RonAppSdk, SdkConfig, Timeouts, Transport};

/// In-memory CAS store keyed by `b3:<hex>` strings.
///
/// We only need this inside the test to emulate the gateway's storage plane.
type Store = Arc<Mutex<HashMap<String, Vec<u8>>>>;

/// Construct a very simple capability token for tests.
///
/// We don't care about real macaroon semantics here — just that the SDK can
/// serialize and send a `Capability` header.
fn mk_cap() -> Capability {
    // These fields mirror the simple header used elsewhere in tests.
    // No real validation happens in this mock; the transport currently
    // treats capabilities as opaque.
    let now: u64 = 1_700_000_000;
    Capability {
        subject: "itest-user".to_string(),
        scope: "storage:rw".to_string(),
        issued_at: now,
        expires_at: now + 3600,
        caveats: Vec::new(),
    }
}

/// Handler for `POST /put`.
///
/// - Body: raw blob bytes.
/// - Response: `b3:<hex>` as UTF-8 text.
async fn handle_storage_put(State(store): State<Store>, body: BodyBytes) -> (StatusCode, String) {
    let blob = body.to_vec();
    let digest = blake3::hash(&blob);
    let addr = format!("b3:{}", hex::encode(digest.as_bytes()));

    {
        let mut guard = store.lock().expect("store mutex poisoned");
        guard.insert(addr.clone(), blob);
    }

    (StatusCode::OK, addr)
}

/// Handler for `POST /o/:addr`.
///
/// - Body: ignored (SDK sends an empty body for `storage_get`).
/// - Response: raw bytes for the given content address, or 404 if missing.
async fn handle_storage_get(
    State(store): State<Store>,
    Path(addr): Path<String>,
) -> (StatusCode, Bytes) {
    let maybe = {
        let guard = store.lock().expect("store mutex poisoned");
        guard.get(&addr).cloned()
    };

    match maybe {
        Some(buf) => (StatusCode::OK, Bytes::from(buf)),
        None => (StatusCode::NOT_FOUND, Bytes::new()),
    }
}

/// Spin up a minimal Axum-based mock gateway.
///
/// Returns:
///   - `base_url` suitable for `SdkConfig.gateway_addr` (e.g. `http://127.0.0.1:12345`)
///   - shared `Store` so the test can peek into the server-side CAS
///   - join handle for the server task (we just let it run for the test lifetime)
async fn spawn_mock_gateway() -> (String, Store, tokio::task::JoinHandle<()>) {
    let store: Store = Arc::new(Mutex::new(HashMap::new()));

    // Endpoints chosen to match `planes::storage`:
    // - storage_put → POST /put
    // - storage_get → POST /o/{addr}
    let app = Router::new()
        .route("/put", post(handle_storage_put))
        .route("/o/:addr", post(handle_storage_get))
        .with_state(store.clone());

    let listener = TcpListener::bind("127.0.0.1:0")
        .await
        .expect("bind mock gateway");
    let addr: SocketAddr = listener.local_addr().expect("local_addr");
    let base_url = format!("http://{}", addr);

    let server = tokio::spawn(async move {
        axum::serve(listener, app)
            .await
            .expect("mock gateway server failed");
    });

    (base_url, store, server)
}

#[tokio::test]
async fn oap_content_addressing_roundtrip() {
    // 1) Start the mock gateway.
    let (base_url, store, _server) = spawn_mock_gateway().await;

    // 2) Build an SDK config that points at the mock gateway.
    //
    // We keep it close to the default posture but override:
    //   - gateway_addr
    //   - timeouts
    let mut cfg = SdkConfig::default();
    cfg.gateway_addr = base_url;
    cfg.transport = Transport::Tls;
    cfg.timeouts = Timeouts {
        connect: Duration::from_millis(500),
        read: Duration::from_millis(1_000),
        write: Duration::from_millis(1_000),
    };
    cfg.overall_timeout = Duration::from_millis(5_000);

    // 3) Ready check: prove config + transport wiring are sane.
    let ready = check_ready(&cfg);
    assert!(ready.is_ready(), "SDK ready check failed: {:?}", ready);

    // 4) Instantiate the SDK.
    let sdk = RonAppSdk::new(cfg).await.expect("construct RonAppSdk");

    let cap = mk_cap();
    let deadline = Duration::from_millis(1_000);

    // 5) PUT a blob via the storage plane.
    let blob = Bytes::from_static(b"hello-oap-content-addressing");
    let addr = sdk
        .storage_put(cap.clone(), blob.clone(), deadline, None)
        .await
        .expect("storage_put should succeed");

    // Ensure address format is `b3:<64 hex>`.
    let addr_str = addr.as_str();
    assert!(
        addr_str.starts_with("b3:"),
        "content address should start with 'b3:', got {addr_str}",
    );
    let hex_part = &addr_str[3..];
    assert_eq!(
        hex_part.len(),
        64,
        "digest hex should be 64 chars, got {}",
        hex_part.len()
    );

    // Verify digest matches blake3(blob).
    let expected_hex = hex::encode(blake3::hash(&blob).as_bytes());
    assert_eq!(
        hex_part, expected_hex,
        "content ID digest did not match BLAKE3(blob)"
    );

    // 6) Peek into the mock gateway's store and ensure it has the blob.
    {
        let guard = store.lock().expect("store mutex poisoned");
        let stored = guard
            .get(addr_str)
            .expect("mock gateway did not store blob");
        assert_eq!(
            stored.as_slice(),
            blob.as_ref(),
            "server-side blob mismatch"
        );
    }

    // 7) GET the blob back via the storage plane.
    let roundtrip = sdk
        .storage_get(cap, addr_str, deadline)
        .await
        .expect("storage_get should succeed");

    assert_eq!(
        roundtrip.as_ref(),
        blob.as_ref(),
        "roundtrip blob mismatch"
    );
}

```

### crates/ron-app-sdk/tests/i_5_retries_deadlines.rs
<a id="crates-ron-app-sdk-tests-i5retriesdeadlines-rs"></a>

```rust
// Invariant: bounded retries + deadlines (scaffold).
#[test]
fn i_5_retries_deadlines_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/i_6_dto_strictness.rs
<a id="crates-ron-app-sdk-tests-i6dtostrictness-rs"></a>

```rust
// Invariant: strict DTO parsing (deny_unknown_fields) (scaffold).
#[test]
fn i_6_dto_strictness_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/i_7_transport_agnostic.rs
<a id="crates-ron-app-sdk-tests-i7transportagnostic-rs"></a>

```rust
// Invariant: transport-agnostic semantics (TLS vs Tor) (scaffold).
#[test]
fn i_7_transport_agnostic_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/i_8_deadlines_everywhere.rs
<a id="crates-ron-app-sdk-tests-i8deadlineseverywhere-rs"></a>

```rust
// Invariant: deadlines on all external I/O (scaffold).
#[test]
fn i_8_deadlines_everywhere_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/i_9_error_taxonomy.rs
<a id="crates-ron-app-sdk-tests-i9errortaxonomy-rs"></a>

```rust
// Invariant: error taxonomy mapping + retry classes (scaffold).
#[test]
fn i_9_error_taxonomy_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/interop_vectors.rs
<a id="crates-ron-app-sdk-tests-interopvectors-rs"></a>

```rust
// Canonical interop vectors runner (scaffold).
#[test]
fn interop_vectors_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/prop_oap_frames.rs
<a id="crates-ron-app-sdk-tests-propoapframes-rs"></a>

```rust
// Property test placeholder: frames near 1 MiB bound (scaffold).
#[test]
fn prop_oap_frames_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/prop_retry_bounds.rs
<a id="crates-ron-app-sdk-tests-propretrybounds-rs"></a>

```rust
// Property test placeholder: retry sleeps sum < overall deadline (scaffold).
#[test]
fn prop_retry_bounds_scaffold() {
    assert!(true);
}

```

### crates/ron-app-sdk/tests/support/mock_gateway.rs
<a id="crates-ron-app-sdk-tests-support-mockgateway-rs"></a>

```rust
//! Test support: minimal Axum gateway that accepts any OAP-ish POST and
//! returns controlled JSON bodies / statuses for client-side verification.
//!
//! RO:WHY — Lets us prove end-to-end OAP calls (happy path + error mapping)
//! without coupling tests to real services.
//! RO:INVARIANTS —
//! - Binds ephemeral 127.0.0.1:0 and exposes its chosen port.
//! - Wildcard POST /*path; handlers can branch by request path.
//! - Helpers to reply with fixed JSON bodies that match planes' expectations.

use axum::{
    body::Bytes as AxumBytes,
    extract::{Path, State},
    http::{HeaderMap, StatusCode},
    response::{IntoResponse, Response},
    routing::post,
    Json, Router,
};
use serde::{Deserialize, Serialize};
use std::{net::SocketAddr, sync::Arc};
use tokio::net::TcpListener;

#[derive(Clone, Default)]
pub struct AppState {
    // You can stash toggles/fixtures here if needed later
}

#[derive(Serialize, Deserialize)]
struct BlobResp<'a> {
    // Using serde_bytes encoding semantics on client; here we just send base64 via serde_json.
    blob: &'a [u8],
}

#[derive(Serialize, Deserialize)]
struct PutResp<'a> {
    addr_b3: &'a str,
}

pub struct Running {
    pub addr: SocketAddr,
    _state: Arc<AppState>,
    _task: tokio::task::JoinHandle<()>,
}

pub async fn start() -> Running {
    let state = Arc::new(AppState::default());

    // Wildcard POST endpoint
    let app = Router::new()
        .route("/*path", post(handle_post))
        .with_state(state.clone());

    let listener = TcpListener::bind(("127.0.0.1", 0)).await.unwrap();
    let addr = listener.local_addr().unwrap();

    let task = tokio::spawn(async move {
        if let Err(err) = axum::serve(listener, app).await {
            eprintln!("[mock-gateway] serve error: {err}");
        }
    });

    Running {
        addr,
        _state: state,
        _task: task,
    }
}

async fn handle_post(
    State(_state): State<Arc<AppState>>,
    Path(path): Path<String>,
    headers: HeaderMap,
    body: AxumBytes,
) -> Response {
    // Basic "capability present" check — we don't validate value here.
    let cap_present = headers
        .keys()
        .any(|k| k.as_str().eq_ignore_ascii_case("cap"));

    // Exercise size-cap response if body is absurdly huge (we still accept; client enforces cap itself).
    let _bytes_len = body.len();

    // Route-based canned replies, matching planes documented in carry-over notes.
    match path.as_str() {
        // Storage GET returns {"blob": <bytes>}
        p if p.ends_with("/storage/get") => {
            if !cap_present {
                return (StatusCode::UNAUTHORIZED, "missing cap").into_response();
            }
            let resp = BlobResp { blob: b"hello-oap" };
            (StatusCode::OK, Json(resp)).into_response()
        }
        // Storage PUT returns {"addr_b3":"b3:<64 hex>"}
        p if p.ends_with("/storage/put") => {
            if !cap_present {
                return (StatusCode::UNAUTHORIZED, "missing cap").into_response();
            }
            let resp = PutResp {
                addr_b3: "b3:0000000000000000000000000000000000000000000000000000000000000000",
            };
            (StatusCode::OK, Json(resp)).into_response()
        }
        // Edge GET returns {"blob": <bytes>}
        p if p.ends_with("/edge/get") => {
            if !cap_present {
                return (StatusCode::UNAUTHORIZED, "missing cap").into_response();
            }
            let resp = BlobResp { blob: b"edge-bytes" };
            (StatusCode::OK, Json(resp)).into_response()
        }
        // Index resolve returns {"addr_b3": "..."}
        p if p.ends_with("/index/resolve") => {
            if !cap_present {
                return (StatusCode::UNAUTHORIZED, "missing cap").into_response();
            }
            let resp = PutResp {
                addr_b3: "b3:aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",
            };
            (StatusCode::OK, Json(resp)).into_response()
        }
        // Unknown path → 404 (to test mapping)
        _ => (StatusCode::NOT_FOUND, "no route").into_response(),
    }
}

```

### crates/ron-app-sdk/tests/vectors/capability_example.json
<a id="crates-ron-app-sdk-tests-vectors-capabilityexample-json"></a>

```json
{"capability":"placeholder"}
```

### crates/ron-app-sdk/tests/vectors/oap1_min_req.json
<a id="crates-ron-app-sdk-tests-vectors-oap1minreq-json"></a>

```json
{"placeholder": true}
```



---

